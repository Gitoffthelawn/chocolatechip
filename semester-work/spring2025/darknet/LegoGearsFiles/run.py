import csv
from datetime import datetime
from cloudmesh.common.StopWatch import StopWatch
from cloudmesh.gpu.gpu import Gpu
import subprocess
import train_setup  # links training data to its labels
import os
import getpass
import glob
import shutil
import re
from threading import Thread, Event
import unicodedata

from pathlib import Path
import zipfile
from hw_info import summarize_env, resolve_gpu_selection, fio_seq_rw, get_disk_info


uva_running = os.environ.get("UVA_VIRGINIA_RUNNING", "false").lower() == "true"


def is_wsl():
    """
    Detect if running in Windows Subsystem for Linux (WSL)
    """
    try:
        with open("/proc/version", "r") as f:
            version_info = f.read()
        # In WSL, /proc/version usually contains "Microsoft" or "WSL"
        if "Microsoft" in version_info or "WSL" in version_info:
            return True
    except Exception:
        pass
    return False


def slugify(text: str, allowed: str = "-_.") -> str:
    """
    Make a filesystem-friendly string:
    - ASCII only (strip accents)
    - Replace spaces with underscores
    - Any char not alnum or in `allowed` -> underscore
    - Collapse multiple underscores and trim punctuation
    """
    s = unicodedata.normalize("NFKD", str(text)).encode("ascii", "ignore").decode("ascii")
    s = s.replace(" ", "_")
    s = re.sub(fr"[^A-Za-z0-9{re.escape(allowed)}]+", "_", s)
    s = re.sub(r"_+", "_", s).strip("._-")
    return s[:180]  # keep it reasonable


if __name__ == "__main__":
    username = getpass.getuser()
    now = datetime.now().strftime("%Y%m%d_%H%M%S")

    # Get GPU name
    # Step 2: Get GPU info
    gpu = Gpu()

    # GPU selection & inventory (centralized)
    sel = resolve_gpu_selection(gpu)
    indices = sel["indices_abs"]
    gpus_str = sel["gpus_str_for_cli"]
    gpu_name = ", ".join(sel["selected_names"]) if sel["selected_names"] else "Unknown GPU"
    vram = ", ".join(sel["selected_vram"]) if sel["selected_vram"] else "N/A"


    # Create safe strings for filenames
    gpu_name_safe = slugify(gpu_name.replace(",", "-"))  # turn commas into a separator, then slugify
    # We'll set cpu_name_safe later after we obtain sysinfo

    # Step 3: If running in Apptainer, create an output folder and change into it.
    # This ensures that files generated by the darknet subprocess go into this directory.

    if "APPTAINER_ENVIRONMENT" in os.environ:
        print("Running in Apptainer environment")
        # pick the path that exists in your apptainer bind setup
        darknetloc = "/host_workspace/darknet/build/src-cli/darknet"  # or "darknet"
    elif os.path.exists("/.dockerenv"):
        print("Running in Docker")
        username = os.environ.get("TRUE_USER", "default_username")
        darknetloc = "/host_workspace/darknet/build/src-cli/darknet"
    else:
        print("Running non-apptainer")
        darknetloc = "darknet"

    output_dir = os.path.join("/outputs", f"benchmark__{username}__{gpu_name_safe}__{now}")
    os.makedirs(output_dir, exist_ok=True)
    os.chdir(output_dir)
    print(f"Changed directory to output folder: {output_dir}")
    # darknetloc = '/host_workspace/darknet/build/src-cli/darknet'

    
    # --- start GPU watcher (background thread) ---
    gpu_watch_thread = None
    watch_log = os.path.join(output_dir, "mylogfile.log")
    watch_stop = Event()

    try:
        if gpu.count > 0:
            gpu_watch_thread = Thread(target=gpu.watch, kwargs={
                "logfile": watch_log,
                "delay": 1.0,
                "dense": True,
                # monitor the GPUs you've selected; None means "all visible"
                "gpu": indices if indices else None,
                "install_signal_handler": False,   # important in threads
                "stop_event": watch_stop,          # allows clean shutdown
            })
            gpu_watch_thread.daemon = True
            gpu_watch_thread.start()
            print(f"GPU watcher logging to {watch_log}")
        else:
            print("No GPUs detected; skipping GPU watch.")
    except Exception as e:
        print(f"Skipping GPU watch: {e}")
    # --- end GPU watcher start ---


    try:
        # Step 5: Run benchmark / training
        StopWatch.start("benchmark")
        cmd = (
            f"{darknetloc} detector -map -dont_show -nocolor "
            + (f"-gpus {gpus_str} " if gpus_str else "")
            + "train /workspace/LegoGears_v2/LegoGears.data "
            "/workspace/LegoGears_v2/LegoGears.cfg "
            "2>&1 | tee training_output.log"
        )
        subprocess.call(cmd, shell=True)
        StopWatch.stop("benchmark")
    finally:
        # --- stop GPU watcher ---
        if gpu_watch_thread is not None:
            try:
                watch_stop.set()     # tell watch() to exit
                gpu.running = False  # belt & suspenders
                gpu_watch_thread.join(timeout=3)
                print(f"GPU watcher stopped; log at {watch_log}")
            except Exception as e:
                print(f"Error stopping GPU watcher: {e}")
        # --- end stop ---


    benchmark_result = StopWatch.get_benchmark()

    # Step 6: Extract sysinfo and benchmark results
    sysinfo = benchmark_result["sysinfo"]
    benchmark = benchmark_result["benchmark"]["benchmark"]

    # Now that we have sysinfo, create a safe CPU name string.
    cpu_name_safe = slugify(sysinfo["cpu"])

    # Get disk information using lsblk.
    print("Getting disk information")
    disk_info = get_disk_info()

    # Run dd speed tests to get file-based write and read speeds.
    print("Running disk speed test")
    dd_write_speed, dd_read_speed = fio_seq_rw()  # defaults: 1M block, 20s, 1G

    # Gather CUDA/cuDNN/GPU info
    env = summarize_env(indices=indices, training_log_path=os.path.join(output_dir, "training_output.log"))

    data = {
        "Benchmark Time (s)": benchmark["time"],
        "CPU Name": sysinfo["cpu"],
        "CPU Threads": sysinfo["cpu_threads"],
        "GPU Name": gpu_name,
        "GPU VRAM": vram,
        "Total Memory": sysinfo["mem.total"],
        "OS": "WSL" if is_wsl() else sysinfo["uname.system"],
        "Architecture": sysinfo["uname.machine"],
        "Python Version": sysinfo["python.version"],
        "Disk Capacity": disk_info["Disk Capacity"],
        "Disk Model": disk_info["Disk Model"],
        "Write Speed": dd_write_speed,
        "Read Speed": dd_read_speed,
        "Working Dir": os.getenv("ACTUAL_PWD", "N/A"),
        "CUDA Version": env["cuda_version"],
        "cuDNN Version": env["cudnn_version"],
        "GPUs Used": env["num_gpus_used"],
        "Compute Capability": env["compute_caps_str"],
    }

    # Step 7: Create a unique CSV filename in the current (output) directory
    csv_name = f"benchmark__{username}__{gpu_name_safe}__{cpu_name_safe}__{now}.csv"
    csv_path = os.path.join(output_dir, csv_name)
    with open(csv_path, mode="w", newline="") as file:
        writer = csv.DictWriter(file, fieldnames=data.keys())
        writer.writeheader()
        writer.writerow(data)
    print(f"Benchmark results saved to {csv_path}")

    
    # Move all files matching "*weights" from /workspace/LegoGears_v2/ to /outputs
    for file in glob.glob("/workspace/LegoGears_v2/*weights"):
        shutil.move(file, output_dir)


    bundle_name = f"benchmark_bundle__{username}__{gpu_name_safe}__{cpu_name_safe}__{now}.zip"
    bundle_path = Path(output_dir) / bundle_name

    with zipfile.ZipFile(bundle_path, mode="w", compression=zipfile.ZIP_DEFLATED) as z:
        for p in Path(output_dir).rglob("*"):
            if not p.is_file():
                continue
            if p.name == bundle_name:
                continue  # don't include the zip itself
            if p.name.lower().endswith(".weights"):
                continue  # exclude Darknet weight files
            z.write(p, arcname=p.relative_to(output_dir))

    print(f"Zipped outputs to: {bundle_path}")
