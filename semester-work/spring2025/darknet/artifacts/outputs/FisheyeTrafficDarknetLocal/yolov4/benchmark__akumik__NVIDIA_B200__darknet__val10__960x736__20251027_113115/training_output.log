Darknet V5 "Moonlit" v5.0-158-gb0e55463 [feature/map-reporting-fixes-superclean]
CUDA runtime version 12080 (v12.8), driver version 12080 (v12.8)
cuDNN version 12080 (v9.7.0), use of half-size floats is ENABLED
=> 0: NVIDIA B200 [#10.0], 178.4 GiB
OpenCV 4.6.0, Ubuntu 24.04, docker
0
Prepare additional network for mAP calculation...
0: compute_capability=1000, cudnn_half=1, GPU=NVIDIA B200
Allocating workspace to transfer between CPU and GPU:  64.7 MiB
0: compute_capability=1000, cudnn_half=1, GPU=NVIDIA B200
Allocating workspace to transfer between CPU and GPU:  4.3 GiB
Learning Rate: 0.001300, Momentum: 0.949000, Decay: 0.000500
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
mAP calculations will be every 406 iterations
weights will be saved every 1000 iterations
Using 112 threads to prime loading 25984 images.
-> loading image 129/25984 (0%) in 532.455 milliseconds         -> loading image 208/25984 (1%) in 865.585 milliseconds         -> loading image 290/25984 (1%) in 1.199 seconds         -> loading image 367/25984 (1%) in 1.532 seconds         -> loading image 422/25984 (2%) in 1.865 seconds         -> loading image 441/25984 (2%) in 2.198 seconds         -> loading image 526/25984 (2%) in 2.531 seconds         -> loading image 609/25984 (2%) in 2.864 seconds         -> loading image 690/25984 (3%) in 3.197 seconds         -> loading image 770/25984 (3%) in 3.530 seconds         -> loading image 848/25984 (3%) in 3.863 seconds         -> loading image 928/25984 (4%) in 4.196 seconds         -> loading image 1004/25984 (4%) in 4.529 seconds         -> loading image 1069/25984 (4%) in 4.863 seconds         -> loading image 1107/25984 (4%) in 5.196 seconds         -> loading image 1170/25984 (5%) in 5.529 seconds         -> loading image 1246/25984 (5%) in 5.862 seconds         -> loading image 1320/25984 (5%) in 6.195 seconds         -> loading image 1398/25984 (5%) in 6.528 seconds         -> loading image 1475/25984 (6%) in 6.861 seconds         -> loading image 1555/25984 (6%) in 7.194 seconds         -> loading image 1592/25984 (6%) in 7.527 seconds         -> loading image 1636/25984 (6%) in 7.860 seconds         -> loading image 1719/25984 (7%) in 8.193 seconds         -> loading image 1801/25984 (7%) in 8.526 seconds         -> loading image 1884/25984 (7%) in 8.859 seconds         -> loading image 1966/25984 (8%) in 9.192 seconds         -> loading image 2044/25984 (8%) in 9.526 seconds         -> loading image 2123/25984 (8%) in 9.859 seconds         -> loading image 2195/25984 (8%) in 10.192 seconds         -> loading image 2238/25984 (9%) in 10.525 seconds         -> loading image 2265/25984 (9%) in 10.858 seconds         -> loading image 2350/25984 (9%) in 11.191 seconds         -> loading image 2431/25984 (9%) in 11.524 seconds         -> loading image 2515/25984 (10%) in 11.857 seconds         -> loading image 2597/25984 (10%) in 12.190 seconds         -> loading image 2677/25984 (10%) in 12.523 seconds         -> loading image 2707/25984 (10%) in 12.856 seconds         -> loading image 2759/25984 (11%) in 13.189 seconds         -> loading image 2843/25984 (11%) in 13.522 seconds         -> loading image 2925/25984 (11%) in 13.856 seconds         -> loading image 3005/25984 (12%) in 14.189 seconds         -> loading image 3086/25984 (12%) in 14.522 seconds         -> loading image 3168/25984 (12%) in 14.855 seconds         -> loading image 3246/25984 (12%) in 15.188 seconds         -> loading image 3316/25984 (13%) in 15.521 seconds         -> loading image 3327/25984 (13%) in 15.854 seconds         -> loading image 3395/25984 (13%) in 16.187 seconds         -> loading image 3477/25984 (13%) in 16.520 seconds         -> loading image 3559/25984 (14%) in 16.853 seconds         -> loading image 3640/25984 (14%) in 17.186 seconds         -> loading image 3723/25984 (14%) in 17.519 seconds         -> loading image 3798/25984 (15%) in 17.852 seconds         -> loading image 3873/25984 (15%) in 18.185 seconds         -> loading image 3935/25984 (15%) in 18.519 seconds         -> loading image 3984/25984 (15%) in 18.852 seconds         -> loading image 4043/25984 (16%) in 19.185 seconds         -> loading image 4104/25984 (16%) in 19.518 seconds         -> loading image 4157/25984 (16%) in 19.851 seconds         -> loading image 4243/25984 (16%) in 20.184 seconds         -> loading image 4325/25984 (17%) in 20.517 seconds         -> loading image 4408/25984 (17%) in 20.850 seconds         -> loading image 4485/25984 (17%) in 21.183 seconds         -> loading image 4567/25984 (18%) in 21.516 seconds         -> loading image 4643/25984 (18%) in 21.849 seconds         -> loading image 4714/25984 (18%) in 22.182 seconds         -> loading image 4767/25984 (18%) in 22.515 seconds         -> loading image 4808/25984 (19%) in 22.848 seconds         -> loading image 4883/25984 (19%) in 23.182 seconds         -> loading image 4964/25984 (19%) in 23.515 seconds         -> loading image 5040/25984 (19%) in 23.848 seconds         -> loading image 5115/25984 (20%) in 24.181 seconds         -> loading image 5188/25984 (20%) in 24.514 seconds         -> loading image 5262/25984 (20%) in 24.847 seconds         -> loading image 5328/25984 (21%) in 25.180 seconds         -> loading image 5394/25984 (21%) in 25.513 seconds         -> loading image 5451/25984 (21%) in 25.846 seconds         -> loading image 5524/25984 (21%) in 26.179 seconds         -> loading image 5596/25984 (22%) in 26.512 seconds         -> loading image 5672/25984 (22%) in 26.845 seconds         -> loading image 5745/25984 (22%) in 27.178 seconds         -> loading image 5811/25984 (22%) in 27.512 seconds         -> loading image 5884/25984 (23%) in 27.845 seconds         -> loading image 5915/25984 (23%) in 28.178 seconds         -> loading image 5981/25984 (23%) in 28.511 seconds         -> loading image 6065/25984 (23%) in 28.844 seconds         -> loading image 6147/25984 (24%) in 29.177 seconds         -> loading image 6227/25984 (24%) in 29.510 seconds         -> loading image 6310/25984 (24%) in 29.843 seconds         -> loading image 6387/25984 (25%) in 30.176 seconds         -> loading image 6458/25984 (25%) in 30.509 seconds         -> loading image 6531/25984 (25%) in 30.842 seconds         -> loading image 6539/25984 (25%) in 31.175 seconds         -> loading image 6615/25984 (25%) in 31.508 seconds         -> loading image 6696/25984 (26%) in 31.842 seconds         -> loading image 6779/25984 (26%) in 32.175 seconds         -> loading image 6861/25984 (26%) in 32.515 seconds         -> loading image 6940/25984 (27%) in 32.848 seconds         -> loading image 7020/25984 (27%) in 33.181 seconds         -> loading image 7095/25984 (27%) in 33.514 seconds         -> loading image 7149/25984 (28%) in 33.847 seconds         -> loading image 7199/25984 (28%) in 34.180 seconds         -> loading image 7256/25984 (28%) in 34.513 seconds         -> loading image 7336/25984 (28%) in 34.846 seconds         -> loading image 7415/25984 (29%) in 35.180 seconds         -> loading image 7490/25984 (29%) in 35.513 seconds         -> loading image 7568/25984 (29%) in 35.846 seconds         -> loading image 7646/25984 (29%) in 36.179 seconds         -> loading image 7711/25984 (30%) in 36.512 seconds         -> loading image 7773/25984 (30%) in 36.845 seconds         -> loading image 7833/25984 (30%) in 37.178 seconds         -> loading image 7895/25984 (30%) in 37.511 seconds         -> loading image 7972/25984 (31%) in 37.844 seconds         -> loading image 8050/25984 (31%) in 38.177 seconds         -> loading image 8126/25984 (31%) in 38.510 seconds         -> loading image 8185/25984 (32%) in 38.843 seconds         -> loading image 8213/25984 (32%) in 39.176 seconds         -> loading image 8296/25984 (32%) in 39.510 seconds         -> loading image 8378/25984 (32%) in 39.843 seconds         -> loading image 8461/25984 (33%) in 40.176 seconds         -> loading image 8543/25984 (33%) in 40.509 seconds         -> loading image 8622/25984 (33%) in 40.842 seconds         -> loading image 8703/25984 (33%) in 41.175 seconds         -> loading image 8779/25984 (34%) in 41.508 seconds         -> loading image 8819/25984 (34%) in 41.841 seconds         -> loading image 8847/25984 (34%) in 42.174 seconds         -> loading image 8930/25984 (34%) in 42.507 seconds         -> loading image 9013/25984 (35%) in 42.840 seconds         -> loading image 9095/25984 (35%) in 43.173 seconds         -> loading image 9173/25984 (35%) in 43.506 seconds         -> loading image 9256/25984 (36%) in 43.840 seconds         -> loading image 9332/25984 (36%) in 44.173 seconds         -> loading image 9405/25984 (36%) in 44.506 seconds         -> loading image 9452/25984 (36%) in 44.839 seconds         -> loading image 9471/25984 (36%) in 45.172 seconds         -> loading image 9554/25984 (37%) in 45.505 seconds         -> loading image 9639/25984 (37%) in 45.838 seconds         -> loading image 9720/25984 (37%) in 46.171 seconds         -> loading image 9801/25984 (38%) in 46.504 seconds         -> loading image 9881/25984 (38%) in 46.837 seconds         -> loading image 9960/25984 (38%) in 47.170 seconds         -> loading image 10016/25984 (39%) in 47.503 seconds         -> loading image 10031/25984 (39%) in 47.836 seconds         -> loading image 10113/25984 (39%) in 48.169 seconds         -> loading image 10198/25984 (39%) in 48.503 seconds         -> loading image 10281/25984 (40%) in 48.836 seconds         -> loading image 10360/25984 (40%) in 49.169 seconds         -> loading image 10441/25984 (40%) in 49.502 seconds         -> loading image 10518/25984 (40%) in 49.835 seconds         -> loading image 10585/25984 (41%) in 50.168 seconds         -> loading image 10651/25984 (41%) in 50.501 seconds         -> loading image 10672/25984 (41%) in 50.834 seconds         -> loading image 10733/25984 (41%) in 51.167 seconds         -> loading image 10816/25984 (42%) in 51.500 seconds         -> loading image 10900/25984 (42%) in 51.833 seconds         -> loading image 10980/25984 (42%) in 52.166 seconds         -> loading image 11060/25984 (43%) in 52.499 seconds         -> loading image 11140/25984 (43%) in 52.833 seconds         -> loading image 11215/25984 (43%) in 53.166 seconds         -> loading image 11288/25984 (43%) in 53.499 seconds         -> loading image 11312/25984 (44%) in 53.832 seconds         -> loading image 11366/25984 (44%) in 54.165 seconds         -> loading image 11449/25984 (44%) in 54.498 seconds         -> loading image 11532/25984 (44%) in 54.831 seconds         -> loading image 11609/25984 (45%) in 55.164 seconds         -> loading image 11689/25984 (45%) in 55.497 seconds         -> loading image 11770/25984 (45%) in 55.830 seconds         -> loading image 11845/25984 (46%) in 56.163 seconds         -> loading image 11906/25984 (46%) in 56.496 seconds         -> loading image 11959/25984 (46%) in 56.829 seconds         -> loading image 12010/25984 (46%) in 57.162 seconds         -> loading image 12085/25984 (47%) in 57.496 seconds         -> loading image 12166/25984 (47%) in 57.829 seconds         -> loading image 12243/25984 (47%) in 58.162 seconds         -> loading image 12268/25984 (47%) in 58.495 seconds         -> loading image 12343/25984 (48%) in 58.828 seconds         -> loading image 12425/25984 (48%) in 59.161 seconds         -> loading image 12508/25984 (48%) in 59.494 seconds         -> loading image 12590/25984 (48%) in 59.828 seconds         -> loading image 12670/25984 (49%) in 60.161 seconds         
-> time limit reached
-> loaded 12670 images in 60.161 seconds
-> done with the 112 image prime threads
Resizing, random_coef=1.400000, batch=4, 1376x1056
Creating 6 permanent CPU threads to load images and bounding boxes.
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b4b4000000
1: loss=7869.540, avg loss=7869.540, last=none, best=none, next=1000, rate=0.00000000, load 64=2.0 seconds, train=6.8 seconds, 64 images, time remaining=33.3 hours
2: loss=7861.934, avg loss=7868.779, last=none, best=none, next=1000, rate=0.00000000, load 64=2.3 seconds, train=6.0 seconds, 128 images, time remaining=23.3 hours
3: loss=7859.503, avg loss=7867.851, last=none, best=none, next=1000, rate=0.00000000, load 64=1.8 seconds, train=6.0 seconds, 192 images, time remaining=20 hours
4: loss=7860.964, avg loss=7867.162, last=none, best=none, next=1000, rate=0.00000000, load 64=2.0 seconds, train=6.0 seconds, 256 images, time remaining=18.3 hours
5: loss=7856.664, avg loss=7866.112, last=none, best=none, next=1000, rate=0.00000000, load 64=1.8 seconds, train=6.1 seconds, 320 images, time remaining=17.3 hours
6: loss=7872.880, avg loss=7866.789, last=none, best=none, next=1000, rate=0.00000000, load 64=1.8 seconds, train=6.0 seconds, 384 images, time remaining=16.7 hours
7: loss=7862.621, avg loss=7866.372, last=none, best=none, next=1000, rate=0.00000000, load 64=2.0 seconds, train=6.0 seconds, 448 images, time remaining=16.2 hours
8: loss=7852.686, avg loss=7865.003, last=none, best=none, next=1000, rate=0.00000000, load 64=2.0 seconds, train=6.1 seconds, 512 images, time remaining=16.1 hours
9: loss=7858.198, avg loss=7864.323, last=none, best=none, next=1000, rate=0.00000000, load 64=2.0 seconds, train=6.1 seconds, 576 images, time remaining=15.8 hours
10: loss=7863.792, avg loss=7864.270, last=none, best=none, next=1000, rate=0.00000000, load 64=1.9 seconds, train=6.0 seconds, 640 images, time remaining=15.5 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b4b4000000
11: loss=6110.408, avg loss=7688.883, last=none, best=none, next=1000, rate=0.00000000, load 64=1.5 seconds, train=4.9 seconds, 704 images, time remaining=15.3 hours
12: loss=6117.431, avg loss=7531.738, last=none, best=none, next=1000, rate=0.00000000, load 64=1.9 seconds, train=4.9 seconds, 768 images, time remaining=15 hours
13: loss=6117.430, avg loss=7390.307, last=none, best=none, next=1000, rate=0.00000000, load 64=1.7 seconds, train=4.8 seconds, 832 images, time remaining=14.7 hours
14: loss=6120.428, avg loss=7263.318, last=none, best=none, next=1000, rate=0.00000000, load 64=1.7 seconds, train=4.7 seconds, 896 images, time remaining=14.4 hours
15: loss=6114.125, avg loss=7148.399, last=none, best=none, next=1000, rate=0.00000000, load 64=1.5 seconds, train=4.8 seconds, 960 images, time remaining=14.2 hours
16: loss=6117.334, avg loss=7045.292, last=none, best=none, next=1000, rate=0.00000000, load 64=1.7 seconds, train=4.7 seconds, 1024 images, time remaining=13.9 hours
17: loss=6114.856, avg loss=6952.249, last=none, best=none, next=1000, rate=0.00000000, load 64=1.7 seconds, train=4.6 seconds, 1088 images, time remaining=13.7 hours
18: loss=6112.257, avg loss=6868.249, last=none, best=none, next=1000, rate=0.00000000, load 64=1.8 seconds, train=4.7 seconds, 1152 images, time remaining=13.5 hours
19: loss=6108.128, avg loss=6792.237, last=none, best=none, next=1000, rate=0.00000000, load 64=1.7 seconds, train=4.7 seconds, 1216 images, time remaining=13.3 hours
20: loss=6105.913, avg loss=6723.604, last=none, best=none, next=1000, rate=0.00000000, load 64=1.6 seconds, train=4.7 seconds, 1280 images, time remaining=13.2 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
21: loss=5246.905, avg loss=6575.934, last=none, best=none, next=1000, rate=0.00000000, load 64=1.6 seconds, train=4.4 seconds, 1344 images, time remaining=13.2 hours
22: loss=5247.801, avg loss=6443.121, last=none, best=none, next=1000, rate=0.00000000, load 64=1.6 seconds, train=4.4 seconds, 1408 images, time remaining=13.1 hours
23: loss=5232.503, avg loss=6322.059, last=none, best=none, next=1000, rate=0.00000000, load 64=1.5 seconds, train=4.4 seconds, 1472 images, time remaining=12.9 hours
24: loss=5230.505, avg loss=6212.903, last=none, best=none, next=1000, rate=0.00000000, load 64=1.5 seconds, train=4.4 seconds, 1536 images, time remaining=12.7 hours
25: loss=5227.946, avg loss=6114.407, last=none, best=none, next=1000, rate=0.00000000, load 64=1.7 seconds, train=4.4 seconds, 1600 images, time remaining=12.7 hours
26: loss=5220.076, avg loss=6024.974, last=none, best=none, next=1000, rate=0.00000000, load 64=1.6 seconds, train=4.4 seconds, 1664 images, time remaining=12.5 hours
27: loss=5211.578, avg loss=5943.634, last=none, best=none, next=1000, rate=0.00000000, load 64=1.5 seconds, train=4.3 seconds, 1728 images, time remaining=12.5 hours
28: loss=5195.550, avg loss=5868.826, last=none, best=none, next=1000, rate=0.00000000, load 64=1.5 seconds, train=4.3 seconds, 1792 images, time remaining=12.3 hours
29: loss=5196.715, avg loss=5801.614, last=none, best=none, next=1000, rate=0.00000000, load 64=1.8 seconds, train=4.3 seconds, 1856 images, time remaining=12.2 hours
30: loss=5174.925, avg loss=5738.945, last=none, best=none, next=1000, rate=0.00000000, load 64=1.8 seconds, train=4.3 seconds, 1920 images, time remaining=12.1 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b58b000000
31: loss=3785.532, avg loss=5543.604, last=none, best=none, next=1000, rate=0.00000000, load 64=1.3 seconds, train=2.9 seconds, 1984 images, time remaining=12.1 hours
32: loss=3772.381, avg loss=5366.481, last=none, best=none, next=1000, rate=0.00000000, load 64=1.8 seconds, train=2.9 seconds, 2048 images, time remaining=11.9 hours
33: loss=3753.263, avg loss=5205.160, last=none, best=none, next=1000, rate=0.00000000, load 64=1.5 seconds, train=2.8 seconds, 2112 images, time remaining=11.7 hours
34: loss=3741.926, avg loss=5058.836, last=none, best=none, next=1000, rate=0.00000000, load 64=1.3 seconds, train=2.8 seconds, 2176 images, time remaining=11.5 hours
35: loss=3723.619, avg loss=4925.314, last=none, best=none, next=1000, rate=0.00000000, load 64=1.4 seconds, train=2.9 seconds, 2240 images, time remaining=11.4 hours
36: loss=3703.677, avg loss=4803.150, last=none, best=none, next=1000, rate=0.00000000, load 64=1.4 seconds, train=2.8 seconds, 2304 images, time remaining=11.2 hours
37: loss=3682.904, avg loss=4691.125, last=none, best=none, next=1000, rate=0.00000000, load 64=1.5 seconds, train=2.8 seconds, 2368 images, time remaining=11.1 hours
38: loss=3661.016, avg loss=4588.114, last=none, best=none, next=1000, rate=0.00000000, load 64=1.8 seconds, train=2.8 seconds, 2432 images, time remaining=11 hours
39: loss=3634.608, avg loss=4492.764, last=none, best=none, next=1000, rate=0.00000000, load 64=1.3 seconds, train=2.8 seconds, 2496 images, time remaining=10.8 hours
40: loss=3604.357, avg loss=4403.923, last=none, best=none, next=1000, rate=0.00000000, load 64=1.6 seconds, train=2.9 seconds, 2560 images, time remaining=10.7 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
41: loss=4881.893, avg loss=4451.720, last=none, best=none, next=1000, rate=0.00000000, load 64=1.5 seconds, train=4.3 seconds, 2624 images, time remaining=10.9 hours
42: loss=4830.427, avg loss=4489.590, last=none, best=none, next=1000, rate=0.00000000, load 64=1.6 seconds, train=4.3 seconds, 2688 images, time remaining=10.9 hours
43: loss=4782.189, avg loss=4518.850, last=none, best=none, next=1000, rate=0.00000000, load 64=1.6 seconds, train=4.2 seconds, 2752 images, time remaining=10.8 hours
44: loss=4723.366, avg loss=4539.302, last=none, best=none, next=1000, rate=0.00000000, load 64=1.6 seconds, train=4.3 seconds, 2816 images, time remaining=10.8 hours
45: loss=4668.700, avg loss=4552.242, last=none, best=none, next=1000, rate=0.00000001, load 64=1.6 seconds, train=4.4 seconds, 2880 images, time remaining=10.8 hours
46: loss=4595.651, avg loss=4556.583, last=none, best=none, next=1000, rate=0.00000001, load 64=1.5 seconds, train=4.4 seconds, 2944 images, time remaining=10.8 hours
47: loss=4523.444, avg loss=4553.269, last=none, best=none, next=1000, rate=0.00000001, load 64=1.6 seconds, train=4.3 seconds, 3008 images, time remaining=10.7 hours
48: loss=4443.401, avg loss=4542.282, last=none, best=none, next=1000, rate=0.00000001, load 64=1.6 seconds, train=4.4 seconds, 3072 images, time remaining=10.7 hours
49: loss=4356.565, avg loss=4523.710, last=none, best=none, next=1000, rate=0.00000001, load 64=1.6 seconds, train=4.4 seconds, 3136 images, time remaining=10.7 hours
50: loss=4265.558, avg loss=4497.895, last=none, best=none, next=1000, rate=0.00000001, load 64=1.8 seconds, train=4.4 seconds, 3200 images, time remaining=10.6 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
51: loss=4448.359, avg loss=4492.941, last=none, best=none, next=1000, rate=0.00000001, load 64=3.0 seconds, train=4.9 seconds, 3264 images, time remaining=10.8 hours
52: loss=4326.051, avg loss=4476.252, last=none, best=none, next=1000, rate=0.00000001, load 64=1.4 seconds, train=4.8 seconds, 3328 images, time remaining=10.8 hours
53: loss=4213.283, avg loss=4449.955, last=none, best=none, next=1000, rate=0.00000001, load 64=1.8 seconds, train=4.9 seconds, 3392 images, time remaining=10.8 hours
54: loss=4091.371, avg loss=4414.097, last=none, best=none, next=1000, rate=0.00000001, load 64=1.6 seconds, train=4.8 seconds, 3456 images, time remaining=10.8 hours
55: loss=3963.196, avg loss=4369.006, last=none, best=none, next=1000, rate=0.00000001, load 64=1.5 seconds, train=4.9 seconds, 3520 images, time remaining=10.8 hours
56: loss=3824.882, avg loss=4314.594, last=none, best=none, next=1000, rate=0.00000001, load 64=1.5 seconds, train=4.9 seconds, 3584 images, time remaining=10.8 hours
57: loss=3673.768, avg loss=4250.511, last=none, best=none, next=1000, rate=0.00000001, load 64=1.6 seconds, train=5.0 seconds, 3648 images, time remaining=10.8 hours
58: loss=3532.361, avg loss=4178.696, last=none, best=none, next=1000, rate=0.00000001, load 64=1.5 seconds, train=4.8 seconds, 3712 images, time remaining=10.8 hours
59: loss=3391.211, avg loss=4099.948, last=none, best=none, next=1000, rate=0.00000002, load 64=1.8 seconds, train=4.9 seconds, 3776 images, time remaining=10.8 hours
60: loss=3228.754, avg loss=4012.828, last=none, best=none, next=1000, rate=0.00000002, load 64=1.6 seconds, train=4.9 seconds, 3840 images, time remaining=10.8 hours
Resizing, random_coef=1.40, batch=4, 1184x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
61: loss=3162.340, avg loss=3927.780, last=none, best=none, next=1000, rate=0.00000002, load 64=1.6 seconds, train=4.6 seconds, 3904 images, time remaining=10.9 hours
62: loss=3006.111, avg loss=3835.613, last=none, best=none, next=1000, rate=0.00000002, load 64=1.8 seconds, train=4.5 seconds, 3968 images, time remaining=10.8 hours
63: loss=2828.986, avg loss=3734.950, last=none, best=none, next=1000, rate=0.00000002, load 64=1.7 seconds, train=4.5 seconds, 4032 images, time remaining=10.8 hours
64: loss=2675.478, avg loss=3629.003, last=none, best=none, next=1000, rate=0.00000002, load 64=1.6 seconds, train=4.6 seconds, 4096 images, time remaining=10.8 hours
65: loss=2480.740, avg loss=3514.176, last=none, best=none, next=1000, rate=0.00000002, load 64=1.7 seconds, train=4.5 seconds, 4160 images, time remaining=10.8 hours
66: loss=2297.703, avg loss=3392.529, last=none, best=none, next=1000, rate=0.00000002, load 64=1.6 seconds, train=4.6 seconds, 4224 images, time remaining=10.8 hours
67: loss=2142.693, avg loss=3267.545, last=none, best=none, next=1000, rate=0.00000003, load 64=1.9 seconds, train=4.6 seconds, 4288 images, time remaining=10.8 hours
68: loss=1978.435, avg loss=3138.634, last=none, best=none, next=1000, rate=0.00000003, load 64=1.6 seconds, train=4.5 seconds, 4352 images, time remaining=10.8 hours
69: loss=1797.178, avg loss=3004.488, last=none, best=none, next=1000, rate=0.00000003, load 64=1.6 seconds, train=4.5 seconds, 4416 images, time remaining=10.8 hours
70: loss=1630.328, avg loss=2867.072, last=none, best=none, next=1000, rate=0.00000003, load 64=1.7 seconds, train=4.7 seconds, 4480 images, time remaining=10.8 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
71: loss=1383.283, avg loss=2718.693, last=none, best=none, next=1000, rate=0.00000003, load 64=1.5 seconds, train=4.3 seconds, 4544 images, time remaining=10.8 hours
72: loss=1234.865, avg loss=2570.311, last=none, best=none, next=1000, rate=0.00000003, load 64=1.8 seconds, train=4.4 seconds, 4608 images, time remaining=10.8 hours
73: loss=1110.944, avg loss=2424.374, last=none, best=none, next=1000, rate=0.00000004, load 64=1.6 seconds, train=4.3 seconds, 4672 images, time remaining=10.8 hours
74: loss=1002.542, avg loss=2282.190, last=none, best=none, next=1000, rate=0.00000004, load 64=1.7 seconds, train=4.4 seconds, 4736 images, time remaining=10.7 hours
75: loss=897.323, avg loss=2143.704, last=none, best=none, next=1000, rate=0.00000004, load 64=1.6 seconds, train=4.4 seconds, 4800 images, time remaining=10.7 hours
76: loss=787.457, avg loss=2008.079, last=none, best=none, next=1000, rate=0.00000004, load 64=2.2 seconds, train=4.3 seconds, 4864 images, time remaining=10.7 hours
77: loss=697.252, avg loss=1876.996, last=none, best=none, next=1000, rate=0.00000005, load 64=1.5 seconds, train=4.3 seconds, 4928 images, time remaining=10.7 hours
78: loss=621.350, avg loss=1751.432, last=none, best=none, next=1000, rate=0.00000005, load 64=1.7 seconds, train=4.3 seconds, 4992 images, time remaining=10.7 hours
79: loss=548.487, avg loss=1631.137, last=none, best=none, next=1000, rate=0.00000005, load 64=1.5 seconds, train=4.2 seconds, 5056 images, time remaining=10.7 hours
80: loss=491.034, avg loss=1517.127, last=none, best=none, next=1000, rate=0.00000005, load 64=2.1 seconds, train=4.5 seconds, 5120 images, time remaining=10.6 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b531400000
81: loss=221.301, avg loss=1387.544, last=none, best=none, next=1000, rate=0.00000006, load 64=1.1 seconds, train=2.0 seconds, 5184 images, time remaining=10.6 hours
82: loss=196.845, avg loss=1268.474, last=none, best=none, next=1000, rate=0.00000006, load 64=1.4 seconds, train=1.9 seconds, 5248 images, time remaining=10.5 hours
83: loss=178.689, avg loss=1159.496, last=none, best=none, next=1000, rate=0.00000006, load 64=1.3 seconds, train=2.0 seconds, 5312 images, time remaining=10.4 hours
84: loss=163.867, avg loss=1059.933, last=none, best=none, next=1000, rate=0.00000006, load 64=1.3 seconds, train=2.0 seconds, 5376 images, time remaining=10.4 hours
85: loss=151.655, avg loss=969.105, last=none, best=none, next=1000, rate=0.00000007, load 64=1.5 seconds, train=2.0 seconds, 5440 images, time remaining=10.3 hours
86: loss=138.431, avg loss=886.038, last=none, best=none, next=1000, rate=0.00000007, load 64=1.6 seconds, train=2.0 seconds, 5504 images, time remaining=10.2 hours
87: loss=120.160, avg loss=809.450, last=none, best=none, next=1000, rate=0.00000007, load 64=1.2 seconds, train=2.0 seconds, 5568 images, time remaining=10.2 hours
88: loss=117.186, avg loss=740.223, last=none, best=none, next=1000, rate=0.00000008, load 64=1.4 seconds, train=2.0 seconds, 5632 images, time remaining=10.1 hours
89: loss=114.025, avg loss=677.604, last=none, best=none, next=1000, rate=0.00000008, load 64=2.0 seconds, train=2.0 seconds, 5696 images, time remaining=10 hours
90: loss=109.852, avg loss=620.828, last=none, best=none, next=1000, rate=0.00000009, load 64=1.3 seconds, train=1.9 seconds, 5760 images, time remaining=10 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
91: loss=182.671, avg loss=577.013, last=none, best=none, next=1000, rate=0.00000009, load 64=1.6 seconds, train=4.8 seconds, 5824 images, time remaining=10.1 hours
92: loss=166.187, avg loss=535.930, last=none, best=none, next=1000, rate=0.00000009, load 64=1.8 seconds, train=4.7 seconds, 5888 images, time remaining=10.1 hours
93: loss=159.122, avg loss=498.249, last=none, best=none, next=1000, rate=0.00000010, load 64=1.5 seconds, train=4.7 seconds, 5952 images, time remaining=10.1 hours
94: loss=137.709, avg loss=462.195, last=none, best=none, next=1000, rate=0.00000010, load 64=1.6 seconds, train=4.7 seconds, 6016 images, time remaining=10.1 hours
95: loss=128.132, avg loss=428.789, last=none, best=none, next=1000, rate=0.00000011, load 64=1.7 seconds, train=4.7 seconds, 6080 images, time remaining=10.1 hours
96: loss=116.718, avg loss=397.582, last=none, best=none, next=1000, rate=0.00000011, load 64=1.6 seconds, train=4.6 seconds, 6144 images, time remaining=10.1 hours
97: loss=116.780, avg loss=369.501, last=none, best=none, next=1000, rate=0.00000012, load 64=1.6 seconds, train=4.7 seconds, 6208 images, time remaining=10.1 hours
98: loss=104.237, avg loss=342.975, last=none, best=none, next=1000, rate=0.00000012, load 64=1.6 seconds, train=4.8 seconds, 6272 images, time remaining=10.1 hours
99: loss=99.368, avg loss=318.614, last=none, best=none, next=1000, rate=0.00000012, load 64=1.6 seconds, train=4.7 seconds, 6336 images, time remaining=10.1 hours
100: loss=90.774, avg loss=295.830, last=none, best=none, next=1000, rate=0.00000013, load 64=1.7 seconds, train=4.8 seconds, 6400 images, time remaining=10.1 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
101: loss=87.354, avg loss=274.983, last=none, best=none, next=1000, rate=0.00000014, load 64=1.5 seconds, train=4.9 seconds, 6464 images, time remaining=10.2 hours
102: loss=81.552, avg loss=255.640, last=none, best=none, next=1000, rate=0.00000014, load 64=1.5 seconds, train=4.9 seconds, 6528 images, time remaining=10.2 hours
103: loss=78.222, avg loss=237.898, last=none, best=none, next=1000, rate=0.00000015, load 64=1.6 seconds, train=4.8 seconds, 6592 images, time remaining=10.2 hours
104: loss=72.866, avg loss=221.395, last=none, best=none, next=1000, rate=0.00000015, load 64=1.5 seconds, train=4.8 seconds, 6656 images, time remaining=10.2 hours
105: loss=75.524, avg loss=206.807, last=none, best=none, next=1000, rate=0.00000016, load 64=1.7 seconds, train=4.8 seconds, 6720 images, time remaining=10.2 hours
106: loss=73.685, avg loss=193.495, last=none, best=none, next=1000, rate=0.00000016, load 64=3.2 seconds, train=4.9 seconds, 6784 images, time remaining=10.2 hours
107: loss=80.309, avg loss=182.177, last=none, best=none, next=1000, rate=0.00000017, load 64=1.9 seconds, train=5.0 seconds, 6848 images, time remaining=10.2 hours
108: loss=66.574, avg loss=170.616, last=none, best=none, next=1000, rate=0.00000018, load 64=1.6 seconds, train=4.8 seconds, 6912 images, time remaining=10.2 hours
109: loss=73.253, avg loss=160.880, last=none, best=none, next=1000, rate=0.00000018, load 64=1.6 seconds, train=4.8 seconds, 6976 images, time remaining=10.2 hours
110: loss=75.952, avg loss=152.387, last=none, best=none, next=1000, rate=0.00000019, load 64=3.5 seconds, train=4.9 seconds, 7040 images, time remaining=10.2 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b625800000
111: loss=64.751, avg loss=143.624, last=none, best=none, next=1000, rate=0.00000020, load 64=1.4 seconds, train=2.3 seconds, 7104 images, time remaining=10.2 hours
112: loss=69.039, avg loss=136.165, last=none, best=none, next=1000, rate=0.00000020, load 64=1.2 seconds, train=2.4 seconds, 7168 images, time remaining=10.1 hours
113: loss=60.050, avg loss=128.554, last=none, best=none, next=1000, rate=0.00000021, load 64=2.3 seconds, train=2.3 seconds, 7232 images, time remaining=10.1 hours
114: loss=58.645, avg loss=121.563, last=none, best=none, next=1000, rate=0.00000022, load 64=1.3 seconds, train=2.4 seconds, 7296 images, time remaining=10 hours
115: loss=64.377, avg loss=115.844, last=none, best=none, next=1000, rate=0.00000023, load 64=1.6 seconds, train=2.4 seconds, 7360 images, time remaining=10 hours
116: loss=56.012, avg loss=109.861, last=none, best=none, next=1000, rate=0.00000024, load 64=1.5 seconds, train=2.4 seconds, 7424 images, time remaining=9.9 hours
117: loss=58.718, avg loss=104.747, last=none, best=none, next=1000, rate=0.00000024, load 64=1.6 seconds, train=2.3 seconds, 7488 images, time remaining=9.9 hours
118: loss=56.222, avg loss=99.894, last=none, best=none, next=1000, rate=0.00000025, load 64=1.6 seconds, train=2.4 seconds, 7552 images, time remaining=9.9 hours
119: loss=60.855, avg loss=95.990, last=none, best=none, next=1000, rate=0.00000026, load 64=1.4 seconds, train=2.3 seconds, 7616 images, time remaining=9.8 hours
120: loss=64.184, avg loss=92.810, last=none, best=none, next=1000, rate=0.00000027, load 64=1.5 seconds, train=2.4 seconds, 7680 images, time remaining=9.8 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b5e0800000
121: loss=57.895, avg loss=89.318, last=none, best=none, next=1000, rate=0.00000028, load 64=1.3 seconds, train=2.3 seconds, 7744 images, time remaining=9.8 hours
122: loss=62.706, avg loss=86.657, last=none, best=none, next=1000, rate=0.00000029, load 64=1.4 seconds, train=2.4 seconds, 7808 images, time remaining=9.7 hours
123: loss=56.072, avg loss=83.598, last=none, best=none, next=1000, rate=0.00000030, load 64=1.6 seconds, train=2.4 seconds, 7872 images, time remaining=9.7 hours
124: loss=56.427, avg loss=80.881, last=none, best=none, next=1000, rate=0.00000031, load 64=1.5 seconds, train=2.4 seconds, 7936 images, time remaining=9.7 hours
125: loss=61.244, avg loss=78.917, last=none, best=none, next=1000, rate=0.00000032, load 64=1.3 seconds, train=2.3 seconds, 8000 images, time remaining=9.6 hours
126: loss=63.663, avg loss=77.392, last=none, best=none, next=1000, rate=0.00000033, load 64=1.3 seconds, train=2.4 seconds, 8064 images, time remaining=9.6 hours
127: loss=56.197, avg loss=75.273, last=none, best=none, next=1000, rate=0.00000034, load 64=1.4 seconds, train=2.3 seconds, 8128 images, time remaining=9.5 hours
128: loss=56.932, avg loss=73.439, last=none, best=none, next=1000, rate=0.00000035, load 64=1.2 seconds, train=2.4 seconds, 8192 images, time remaining=9.5 hours
129: loss=59.619, avg loss=72.057, last=none, best=none, next=1000, rate=0.00000036, load 64=1.3 seconds, train=2.3 seconds, 8256 images, time remaining=9.5 hours
130: loss=51.542, avg loss=70.005, last=none, best=none, next=1000, rate=0.00000037, load 64=1.3 seconds, train=2.5 seconds, 8320 images, time remaining=9.4 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b5e0800000
131: loss=57.057, avg loss=68.710, last=none, best=none, next=1000, rate=0.00000038, load 64=1.3 seconds, train=1.8 seconds, 8384 images, time remaining=9.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
132: loss=50.727, avg loss=66.912, last=none, best=none, next=1000, rate=0.00000039, load 64=2.7 seconds, train=2.1 seconds, 8448 images, time remaining=9.4 hours
133: loss=52.312, avg loss=65.452, last=none, best=none, next=1000, rate=0.00000041, load 64=1.7 seconds, train=2.2 seconds, 8512 images, time remaining=9.4 hours
134: loss=52.164, avg loss=64.123, last=none, best=none, next=1000, rate=0.00000042, load 64=1.5 seconds, train=2.2 seconds, 8576 images, time remaining=9.3 hours
135: loss=55.721, avg loss=63.283, last=none, best=none, next=1000, rate=0.00000043, load 64=1.5 seconds, train=2.2 seconds, 8640 images, time remaining=9.3 hours
136: loss=55.395, avg loss=62.494, last=none, best=none, next=1000, rate=0.00000044, load 64=1.5 seconds, train=2.2 seconds, 8704 images, time remaining=9.3 hours
137: loss=60.277, avg loss=62.272, last=none, best=none, next=1000, rate=0.00000046, load 64=1.3 seconds, train=2.3 seconds, 8768 images, time remaining=9.2 hours
138: loss=56.317, avg loss=61.677, last=none, best=none, next=1000, rate=0.00000047, load 64=1.5 seconds, train=2.2 seconds, 8832 images, time remaining=9.2 hours
139: loss=53.545, avg loss=60.864, last=none, best=none, next=1000, rate=0.00000049, load 64=1.4 seconds, train=2.3 seconds, 8896 images, time remaining=9.2 hours
140: loss=60.817, avg loss=60.859, last=none, best=none, next=1000, rate=0.00000050, load 64=1.3 seconds, train=2.3 seconds, 8960 images, time remaining=9.1 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
141: loss=55.329, avg loss=60.306, last=none, best=none, next=1000, rate=0.00000051, load 64=1.4 seconds, train=2.7 seconds, 9024 images, time remaining=9.1 hours
142: loss=56.961, avg loss=59.971, last=none, best=none, next=1000, rate=0.00000053, load 64=1.5 seconds, train=2.7 seconds, 9088 images, time remaining=9.1 hours
143: loss=65.155, avg loss=60.490, last=none, best=none, next=1000, rate=0.00000054, load 64=1.4 seconds, train=2.7 seconds, 9152 images, time remaining=9.1 hours
144: loss=55.035, avg loss=59.944, last=none, best=none, next=1000, rate=0.00000056, load 64=1.4 seconds, train=2.4 seconds, 9216 images, time remaining=9.1 hours
145: loss=61.171, avg loss=60.067, last=none, best=none, next=1000, rate=0.00000057, load 64=2.4 seconds, train=2.7 seconds, 9280 images, time remaining=9 hours
146: loss=59.854, avg loss=60.046, last=none, best=none, next=1000, rate=0.00000059, load 64=1.8 seconds, train=2.7 seconds, 9344 images, time remaining=9 hours
147: loss=52.551, avg loss=59.296, last=none, best=none, next=1000, rate=0.00000061, load 64=1.3 seconds, train=2.6 seconds, 9408 images, time remaining=9 hours
148: loss=53.756, avg loss=58.742, last=none, best=none, next=1000, rate=0.00000062, load 64=1.3 seconds, train=2.7 seconds, 9472 images, time remaining=9 hours
149: loss=48.521, avg loss=57.720, last=none, best=none, next=1000, rate=0.00000064, load 64=1.5 seconds, train=2.6 seconds, 9536 images, time remaining=9 hours
150: loss=61.260, avg loss=58.074, last=none, best=none, next=1000, rate=0.00000066, load 64=1.5 seconds, train=2.7 seconds, 9600 images, time remaining=8.9 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
151: loss=53.519, avg loss=57.619, last=none, best=none, next=1000, rate=0.00000068, load 64=1.2 seconds, train=2.7 seconds, 9664 images, time remaining=8.9 hours
152: loss=59.017, avg loss=57.758, last=none, best=none, next=1000, rate=0.00000069, load 64=1.5 seconds, train=2.7 seconds, 9728 images, time remaining=8.9 hours
153: loss=54.813, avg loss=57.464, last=none, best=none, next=1000, rate=0.00000071, load 64=1.6 seconds, train=2.7 seconds, 9792 images, time remaining=8.9 hours
154: loss=59.997, avg loss=57.717, last=none, best=none, next=1000, rate=0.00000073, load 64=1.6 seconds, train=2.7 seconds, 9856 images, time remaining=8.9 hours
155: loss=49.121, avg loss=56.858, last=none, best=none, next=1000, rate=0.00000075, load 64=1.6 seconds, train=2.6 seconds, 9920 images, time remaining=8.9 hours
156: loss=52.727, avg loss=56.444, last=none, best=none, next=1000, rate=0.00000077, load 64=1.2 seconds, train=2.6 seconds, 9984 images, time remaining=8.8 hours
157: loss=48.114, avg loss=55.611, last=none, best=none, next=1000, rate=0.00000079, load 64=1.2 seconds, train=2.7 seconds, 10048 images, time remaining=8.8 hours
158: loss=48.077, avg loss=54.858, last=none, best=none, next=1000, rate=0.00000081, load 64=1.4 seconds, train=2.6 seconds, 10112 images, time remaining=8.8 hours
159: loss=51.186, avg loss=54.491, last=none, best=none, next=1000, rate=0.00000083, load 64=1.2 seconds, train=2.6 seconds, 10176 images, time remaining=8.8 hours
160: loss=45.028, avg loss=53.545, last=none, best=none, next=1000, rate=0.00000085, load 64=1.6 seconds, train=2.6 seconds, 10240 images, time remaining=8.8 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b5a7a00000
161: loss=59.596, avg loss=54.150, last=none, best=none, next=1000, rate=0.00000087, load 64=1.2 seconds, train=2.7 seconds, 10304 images, time remaining=8.8 hours
162: loss=57.930, avg loss=54.528, last=none, best=none, next=1000, rate=0.00000090, load 64=1.3 seconds, train=2.7 seconds, 10368 images, time remaining=8.7 hours
163: loss=53.302, avg loss=54.405, last=none, best=none, next=1000, rate=0.00000092, load 64=1.3 seconds, train=2.7 seconds, 10432 images, time remaining=8.7 hours
164: loss=53.566, avg loss=54.321, last=none, best=none, next=1000, rate=0.00000094, load 64=1.4 seconds, train=2.7 seconds, 10496 images, time remaining=8.7 hours
165: loss=54.361, avg loss=54.325, last=none, best=none, next=1000, rate=0.00000096, load 64=1.3 seconds, train=2.8 seconds, 10560 images, time remaining=8.7 hours
166: loss=52.573, avg loss=54.150, last=none, best=none, next=1000, rate=0.00000099, load 64=1.2 seconds, train=2.7 seconds, 10624 images, time remaining=8.7 hours
167: loss=45.876, avg loss=53.323, last=none, best=none, next=1000, rate=0.00000101, load 64=1.4 seconds, train=2.7 seconds, 10688 images, time remaining=8.7 hours
168: loss=45.081, avg loss=52.498, last=none, best=none, next=1000, rate=0.00000104, load 64=1.4 seconds, train=2.7 seconds, 10752 images, time remaining=8.7 hours
169: loss=50.774, avg loss=52.326, last=none, best=none, next=1000, rate=0.00000106, load 64=1.6 seconds, train=2.8 seconds, 10816 images, time remaining=8.6 hours
170: loss=49.692, avg loss=52.063, last=none, best=none, next=1000, rate=0.00000109, load 64=1.5 seconds, train=2.7 seconds, 10880 images, time remaining=8.6 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b63f600000
171: loss=47.713, avg loss=51.628, last=none, best=none, next=1000, rate=0.00000111, load 64=1.2 seconds, train=2.8 seconds, 10944 images, time remaining=8.6 hours
172: loss=50.106, avg loss=51.475, last=none, best=none, next=1000, rate=0.00000114, load 64=1.5 seconds, train=2.8 seconds, 11008 images, time remaining=8.6 hours
173: loss=50.591, avg loss=51.387, last=none, best=none, next=1000, rate=0.00000116, load 64=2.1 seconds, train=2.9 seconds, 11072 images, time remaining=8.6 hours
174: loss=50.844, avg loss=51.333, last=none, best=none, next=1000, rate=0.00000119, load 64=1.4 seconds, train=2.8 seconds, 11136 images, time remaining=8.6 hours
175: loss=51.662, avg loss=51.366, last=none, best=none, next=1000, rate=0.00000122, load 64=1.4 seconds, train=2.8 seconds, 11200 images, time remaining=8.6 hours
176: loss=49.248, avg loss=51.154, last=none, best=none, next=1000, rate=0.00000125, load 64=1.7 seconds, train=2.8 seconds, 11264 images, time remaining=8.5 hours
177: loss=48.511, avg loss=50.890, last=none, best=none, next=1000, rate=0.00000128, load 64=1.3 seconds, train=2.8 seconds, 11328 images, time remaining=8.5 hours
178: loss=47.154, avg loss=50.516, last=none, best=none, next=1000, rate=0.00000131, load 64=1.4 seconds, train=2.8 seconds, 11392 images, time remaining=8.5 hours
179: loss=50.792, avg loss=50.544, last=none, best=none, next=1000, rate=0.00000133, load 64=2.1 seconds, train=2.7 seconds, 11456 images, time remaining=8.5 hours
180: loss=53.374, avg loss=50.827, last=none, best=none, next=1000, rate=0.00000136, load 64=1.6 seconds, train=2.8 seconds, 11520 images, time remaining=8.5 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b614200000
181: loss=48.903, avg loss=50.634, last=none, best=none, next=1000, rate=0.00000140, load 64=1.6 seconds, train=2.8 seconds, 11584 images, time remaining=8.5 hours
182: loss=46.076, avg loss=50.178, last=none, best=none, next=1000, rate=0.00000143, load 64=1.5 seconds, train=2.9 seconds, 11648 images, time remaining=8.5 hours
183: loss=44.656, avg loss=49.626, last=none, best=none, next=1000, rate=0.00000146, load 64=1.5 seconds, train=2.7 seconds, 11712 images, time remaining=8.5 hours
184: loss=48.565, avg loss=49.520, last=none, best=none, next=1000, rate=0.00000149, load 64=1.4 seconds, train=2.8 seconds, 11776 images, time remaining=8.4 hours
185: loss=54.299, avg loss=49.998, last=none, best=none, next=1000, rate=0.00000152, load 64=1.6 seconds, train=2.8 seconds, 11840 images, time remaining=8.4 hours
186: loss=46.743, avg loss=49.672, last=none, best=none, next=1000, rate=0.00000156, load 64=1.5 seconds, train=2.7 seconds, 11904 images, time remaining=8.4 hours
187: loss=47.265, avg loss=49.432, last=none, best=none, next=1000, rate=0.00000159, load 64=1.4 seconds, train=2.7 seconds, 11968 images, time remaining=8.4 hours
188: loss=46.362, avg loss=49.125, last=none, best=none, next=1000, rate=0.00000162, load 64=1.3 seconds, train=2.8 seconds, 12032 images, time remaining=8.4 hours
189: loss=49.836, avg loss=49.196, last=none, best=none, next=1000, rate=0.00000166, load 64=1.6 seconds, train=2.8 seconds, 12096 images, time remaining=8.4 hours
190: loss=45.383, avg loss=48.815, last=none, best=none, next=1000, rate=0.00000169, load 64=1.4 seconds, train=2.8 seconds, 12160 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1152x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
191: loss=48.001, avg loss=48.733, last=none, best=none, next=1000, rate=0.00000173, load 64=1.5 seconds, train=4.5 seconds, 12224 images, time remaining=8.4 hours
192: loss=49.374, avg loss=48.797, last=none, best=none, next=1000, rate=0.00000177, load 64=1.8 seconds, train=4.4 seconds, 12288 images, time remaining=8.4 hours
193: loss=45.757, avg loss=48.493, last=none, best=none, next=1000, rate=0.00000180, load 64=1.7 seconds, train=4.4 seconds, 12352 images, time remaining=8.4 hours
194: loss=47.750, avg loss=48.419, last=none, best=none, next=1000, rate=0.00000184, load 64=1.6 seconds, train=4.3 seconds, 12416 images, time remaining=8.4 hours
195: loss=49.640, avg loss=48.541, last=none, best=none, next=1000, rate=0.00000188, load 64=1.6 seconds, train=4.4 seconds, 12480 images, time remaining=8.4 hours
196: loss=49.600, avg loss=48.647, last=none, best=none, next=1000, rate=0.00000192, load 64=1.5 seconds, train=4.4 seconds, 12544 images, time remaining=8.4 hours
197: loss=48.374, avg loss=48.620, last=none, best=none, next=1000, rate=0.00000196, load 64=1.5 seconds, train=4.5 seconds, 12608 images, time remaining=8.4 hours
198: loss=51.151, avg loss=48.873, last=none, best=none, next=1000, rate=0.00000200, load 64=1.5 seconds, train=4.4 seconds, 12672 images, time remaining=8.4 hours
199: loss=48.170, avg loss=48.803, last=none, best=none, next=1000, rate=0.00000204, load 64=1.5 seconds, train=4.4 seconds, 12736 images, time remaining=8.4 hours
200: loss=41.658, avg loss=48.088, last=none, best=none, next=1000, rate=0.00000208, load 64=1.5 seconds, train=4.3 seconds, 12800 images, time remaining=8.5 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
201: loss=42.075, avg loss=47.487, last=none, best=none, next=1000, rate=0.00000212, load 64=1.6 seconds, train=5.8 seconds, 12864 images, time remaining=8.5 hours
202: loss=42.691, avg loss=47.007, last=none, best=none, next=1000, rate=0.00000216, load 64=3.6 seconds, train=5.8 seconds, 12928 images, time remaining=8.5 hours
203: loss=39.641, avg loss=46.271, last=none, best=none, next=1000, rate=0.00000221, load 64=3.5 seconds, train=5.8 seconds, 12992 images, time remaining=8.6 hours
204: loss=42.220, avg loss=45.866, last=none, best=none, next=1000, rate=0.00000225, load 64=1.8 seconds, train=5.9 seconds, 13056 images, time remaining=8.6 hours
205: loss=42.512, avg loss=45.530, last=none, best=none, next=1000, rate=0.00000230, load 64=1.8 seconds, train=5.8 seconds, 13120 images, time remaining=8.6 hours
206: loss=43.724, avg loss=45.350, last=none, best=none, next=1000, rate=0.00000234, load 64=2.6 seconds, train=6.1 seconds, 13184 images, time remaining=8.6 hours
207: loss=41.780, avg loss=44.993, last=none, best=none, next=1000, rate=0.00000239, load 64=1.9 seconds, train=5.7 seconds, 13248 images, time remaining=8.6 hours
208: loss=37.731, avg loss=44.266, last=none, best=none, next=1000, rate=0.00000243, load 64=3.3 seconds, train=5.6 seconds, 13312 images, time remaining=8.7 hours
209: loss=40.552, avg loss=43.895, last=none, best=none, next=1000, rate=0.00000248, load 64=4.3 seconds, train=5.8 seconds, 13376 images, time remaining=8.7 hours
210: loss=37.735, avg loss=43.279, last=none, best=none, next=1000, rate=0.00000253, load 64=1.8 seconds, train=5.7 seconds, 13440 images, time remaining=8.7 hours
Resizing, random_coef=1.40, batch=4, 1184x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
211: loss=39.232, avg loss=42.874, last=none, best=none, next=1000, rate=0.00000258, load 64=1.6 seconds, train=4.4 seconds, 13504 images, time remaining=8.7 hours
212: loss=40.800, avg loss=42.667, last=none, best=none, next=1000, rate=0.00000263, load 64=3.6 seconds, train=4.5 seconds, 13568 images, time remaining=8.7 hours
213: loss=36.832, avg loss=42.083, last=none, best=none, next=1000, rate=0.00000268, load 64=1.7 seconds, train=4.4 seconds, 13632 images, time remaining=8.7 hours
214: loss=41.209, avg loss=41.996, last=none, best=none, next=1000, rate=0.00000273, load 64=2.5 seconds, train=4.5 seconds, 13696 images, time remaining=8.7 hours
215: loss=39.090, avg loss=41.705, last=none, best=none, next=1000, rate=0.00000278, load 64=1.5 seconds, train=4.5 seconds, 13760 images, time remaining=8.7 hours
216: loss=37.714, avg loss=41.306, last=none, best=none, next=1000, rate=0.00000283, load 64=1.8 seconds, train=4.5 seconds, 13824 images, time remaining=8.7 hours
217: loss=41.612, avg loss=41.337, last=none, best=none, next=1000, rate=0.00000288, load 64=1.6 seconds, train=4.5 seconds, 13888 images, time remaining=8.7 hours
218: loss=34.238, avg loss=40.627, last=none, best=none, next=1000, rate=0.00000294, load 64=1.7 seconds, train=4.5 seconds, 13952 images, time remaining=8.7 hours
219: loss=35.080, avg loss=40.072, last=none, best=none, next=1000, rate=0.00000299, load 64=1.6 seconds, train=4.5 seconds, 14016 images, time remaining=8.7 hours
220: loss=31.810, avg loss=39.246, last=none, best=none, next=1000, rate=0.00000305, load 64=1.5 seconds, train=4.5 seconds, 14080 images, time remaining=8.7 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
221: loss=34.748, avg loss=38.796, last=none, best=none, next=1000, rate=0.00000310, load 64=1.6 seconds, train=5.4 seconds, 14144 images, time remaining=8.8 hours
222: loss=39.054, avg loss=38.822, last=none, best=none, next=1000, rate=0.00000316, load 64=1.7 seconds, train=5.4 seconds, 14208 images, time remaining=8.8 hours
223: loss=37.098, avg loss=38.650, last=none, best=none, next=1000, rate=0.00000321, load 64=1.7 seconds, train=5.5 seconds, 14272 images, time remaining=8.8 hours
224: loss=36.628, avg loss=38.447, last=none, best=none, next=1000, rate=0.00000327, load 64=1.8 seconds, train=5.4 seconds, 14336 images, time remaining=8.8 hours
225: loss=39.440, avg loss=38.547, last=none, best=none, next=1000, rate=0.00000333, load 64=1.8 seconds, train=5.4 seconds, 14400 images, time remaining=8.8 hours
226: loss=35.389, avg loss=38.231, last=none, best=none, next=1000, rate=0.00000339, load 64=2.0 seconds, train=5.4 seconds, 14464 images, time remaining=8.9 hours
227: loss=41.826, avg loss=38.590, last=none, best=none, next=1000, rate=0.00000345, load 64=1.6 seconds, train=5.5 seconds, 14528 images, time remaining=8.9 hours
228: loss=37.950, avg loss=38.526, last=none, best=none, next=1000, rate=0.00000351, load 64=1.7 seconds, train=5.4 seconds, 14592 images, time remaining=8.9 hours
229: loss=33.157, avg loss=37.989, last=none, best=none, next=1000, rate=0.00000358, load 64=1.5 seconds, train=5.4 seconds, 14656 images, time remaining=8.9 hours
230: loss=37.376, avg loss=37.928, last=none, best=none, next=1000, rate=0.00000364, load 64=5.4 seconds, train=5.4 seconds, 14720 images, time remaining=8.9 hours
Resizing, random_coef=1.40, batch=4, 992x768
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
231: loss=35.070, avg loss=37.642, last=none, best=none, next=1000, rate=0.00000370, load 64=4.5 seconds, train=3.8 seconds, 14784 images, time remaining=8.9 hours
232: loss=34.863, avg loss=37.364, last=none, best=none, next=1000, rate=0.00000377, load 64=1.4 seconds, train=3.7 seconds, 14848 images, time remaining=8.9 hours
233: loss=37.004, avg loss=37.328, last=none, best=none, next=1000, rate=0.00000383, load 64=2.4 seconds, train=3.8 seconds, 14912 images, time remaining=8.9 hours
234: loss=33.245, avg loss=36.920, last=none, best=none, next=1000, rate=0.00000390, load 64=1.5 seconds, train=3.8 seconds, 14976 images, time remaining=8.9 hours
235: loss=37.065, avg loss=36.934, last=none, best=none, next=1000, rate=0.00000396, load 64=1.7 seconds, train=3.8 seconds, 15040 images, time remaining=8.9 hours
236: loss=33.193, avg loss=36.560, last=none, best=none, next=1000, rate=0.00000403, load 64=1.5 seconds, train=3.8 seconds, 15104 images, time remaining=8.9 hours
237: loss=36.106, avg loss=36.515, last=none, best=none, next=1000, rate=0.00000410, load 64=1.4 seconds, train=3.8 seconds, 15168 images, time remaining=8.9 hours
238: loss=32.801, avg loss=36.143, last=none, best=none, next=1000, rate=0.00000417, load 64=1.6 seconds, train=3.7 seconds, 15232 images, time remaining=8.9 hours
239: loss=31.657, avg loss=35.695, last=none, best=none, next=1000, rate=0.00000424, load 64=1.4 seconds, train=3.8 seconds, 15296 images, time remaining=8.9 hours
240: loss=27.255, avg loss=34.851, last=none, best=none, next=1000, rate=0.00000431, load 64=1.4 seconds, train=3.8 seconds, 15360 images, time remaining=8.9 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
241: loss=32.355, avg loss=34.601, last=none, best=none, next=1000, rate=0.00000439, load 64=1.4 seconds, train=2.8 seconds, 15424 images, time remaining=8.9 hours
242: loss=31.108, avg loss=34.252, last=none, best=none, next=1000, rate=0.00000446, load 64=1.4 seconds, train=2.8 seconds, 15488 images, time remaining=8.9 hours
243: loss=33.959, avg loss=34.223, last=none, best=none, next=1000, rate=0.00000453, load 64=1.4 seconds, train=2.8 seconds, 15552 images, time remaining=8.9 hours
244: loss=32.793, avg loss=34.080, last=none, best=none, next=1000, rate=0.00000461, load 64=1.3 seconds, train=2.8 seconds, 15616 images, time remaining=8.9 hours
245: loss=32.803, avg loss=33.952, last=none, best=none, next=1000, rate=0.00000468, load 64=1.5 seconds, train=2.8 seconds, 15680 images, time remaining=8.8 hours
246: loss=33.622, avg loss=33.919, last=none, best=none, next=1000, rate=0.00000476, load 64=1.3 seconds, train=2.8 seconds, 15744 images, time remaining=8.8 hours
247: loss=32.050, avg loss=33.732, last=none, best=none, next=1000, rate=0.00000484, load 64=1.3 seconds, train=2.8 seconds, 15808 images, time remaining=8.8 hours
248: loss=31.833, avg loss=33.542, last=none, best=none, next=1000, rate=0.00000492, load 64=1.5 seconds, train=2.8 seconds, 15872 images, time remaining=8.8 hours
249: loss=29.414, avg loss=33.129, last=none, best=none, next=1000, rate=0.00000500, load 64=1.4 seconds, train=2.8 seconds, 15936 images, time remaining=8.8 hours
250: loss=31.732, avg loss=32.990, last=none, best=none, next=1000, rate=0.00000508, load 64=1.3 seconds, train=2.8 seconds, 16000 images, time remaining=8.8 hours
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
251: loss=32.327, avg loss=32.923, last=none, best=none, next=1000, rate=0.00000516, load 64=1.6 seconds, train=5.7 seconds, 16064 images, time remaining=8.8 hours
252: loss=36.196, avg loss=33.251, last=none, best=none, next=1000, rate=0.00000524, load 64=1.9 seconds, train=5.6 seconds, 16128 images, time remaining=8.9 hours
253: loss=36.898, avg loss=33.615, last=none, best=none, next=1000, rate=0.00000533, load 64=3.5 seconds, train=5.6 seconds, 16192 images, time remaining=8.9 hours
254: loss=30.085, avg loss=33.262, last=none, best=none, next=1000, rate=0.00000541, load 64=1.7 seconds, train=5.5 seconds, 16256 images, time remaining=8.9 hours
255: loss=32.262, avg loss=33.162, last=none, best=none, next=1000, rate=0.00000550, load 64=1.6 seconds, train=5.6 seconds, 16320 images, time remaining=8.9 hours
256: loss=32.550, avg loss=33.101, last=none, best=none, next=1000, rate=0.00000558, load 64=1.8 seconds, train=5.6 seconds, 16384 images, time remaining=8.9 hours
257: loss=34.653, avg loss=33.256, last=none, best=none, next=1000, rate=0.00000567, load 64=2.3 seconds, train=5.6 seconds, 16448 images, time remaining=8.9 hours
258: loss=30.541, avg loss=32.985, last=none, best=none, next=1000, rate=0.00000576, load 64=1.7 seconds, train=5.5 seconds, 16512 images, time remaining=8.9 hours
259: loss=29.369, avg loss=32.623, last=none, best=none, next=1000, rate=0.00000585, load 64=1.6 seconds, train=5.5 seconds, 16576 images, time remaining=8.9 hours
260: loss=36.204, avg loss=32.981, last=none, best=none, next=1000, rate=0.00000594, load 64=1.7 seconds, train=5.6 seconds, 16640 images, time remaining=8.9 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b54ec00000
261: loss=30.103, avg loss=32.693, last=none, best=none, next=1000, rate=0.00000603, load 64=1.3 seconds, train=2.1 seconds, 16704 images, time remaining=8.9 hours
262: loss=33.502, avg loss=32.774, last=none, best=none, next=1000, rate=0.00000613, load 64=1.4 seconds, train=2.2 seconds, 16768 images, time remaining=8.9 hours
263: loss=30.388, avg loss=32.536, last=none, best=none, next=1000, rate=0.00000622, load 64=1.6 seconds, train=2.1 seconds, 16832 images, time remaining=8.9 hours
264: loss=31.843, avg loss=32.466, last=none, best=none, next=1000, rate=0.00000631, load 64=1.3 seconds, train=2.1 seconds, 16896 images, time remaining=8.9 hours
265: loss=29.915, avg loss=32.211, last=none, best=none, next=1000, rate=0.00000641, load 64=1.3 seconds, train=2.1 seconds, 16960 images, time remaining=8.9 hours
266: loss=31.227, avg loss=32.113, last=none, best=none, next=1000, rate=0.00000651, load 64=1.4 seconds, train=2.1 seconds, 17024 images, time remaining=8.8 hours
267: loss=31.550, avg loss=32.056, last=none, best=none, next=1000, rate=0.00000661, load 64=1.4 seconds, train=2.1 seconds, 17088 images, time remaining=8.8 hours
268: loss=28.148, avg loss=31.666, last=none, best=none, next=1000, rate=0.00000671, load 64=1.2 seconds, train=2.1 seconds, 17152 images, time remaining=8.8 hours
269: loss=26.315, avg loss=31.131, last=none, best=none, next=1000, rate=0.00000681, load 64=1.9 seconds, train=2.1 seconds, 17216 images, time remaining=8.8 hours
270: loss=29.413, avg loss=30.959, last=none, best=none, next=1000, rate=0.00000691, load 64=1.3 seconds, train=1.8 seconds, 17280 images, time remaining=8.8 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
271: loss=33.873, avg loss=31.250, last=none, best=none, next=1000, rate=0.00000701, load 64=2.7 seconds, train=4.1 seconds, 17344 images, time remaining=8.8 hours
272: loss=29.491, avg loss=31.074, last=none, best=none, next=1000, rate=0.00000712, load 64=1.5 seconds, train=4.1 seconds, 17408 images, time remaining=8.8 hours
273: loss=29.486, avg loss=30.915, last=none, best=none, next=1000, rate=0.00000722, load 64=1.4 seconds, train=4.0 seconds, 17472 images, time remaining=8.8 hours
274: loss=35.822, avg loss=31.406, last=none, best=none, next=1000, rate=0.00000733, load 64=1.4 seconds, train=4.1 seconds, 17536 images, time remaining=8.8 hours
275: loss=34.031, avg loss=31.669, last=none, best=none, next=1000, rate=0.00000743, load 64=1.5 seconds, train=4.0 seconds, 17600 images, time remaining=8.8 hours
276: loss=28.055, avg loss=31.307, last=none, best=none, next=1000, rate=0.00000754, load 64=2.3 seconds, train=4.0 seconds, 17664 images, time remaining=8.8 hours
277: loss=29.258, avg loss=31.102, last=none, best=none, next=1000, rate=0.00000765, load 64=1.5 seconds, train=4.0 seconds, 17728 images, time remaining=8.8 hours
278: loss=32.726, avg loss=31.265, last=none, best=none, next=1000, rate=0.00000776, load 64=1.4 seconds, train=4.1 seconds, 17792 images, time remaining=8.8 hours
279: loss=30.046, avg loss=31.143, last=none, best=none, next=1000, rate=0.00000788, load 64=1.5 seconds, train=4.1 seconds, 17856 images, time remaining=8.8 hours
280: loss=33.945, avg loss=31.423, last=none, best=none, next=1000, rate=0.00000799, load 64=1.6 seconds, train=4.0 seconds, 17920 images, time remaining=8.8 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
281: loss=34.208, avg loss=31.701, last=none, best=none, next=1000, rate=0.00000811, load 64=1.5 seconds, train=4.6 seconds, 17984 images, time remaining=8.9 hours
282: loss=34.258, avg loss=31.957, last=none, best=none, next=1000, rate=0.00000822, load 64=1.7 seconds, train=4.7 seconds, 18048 images, time remaining=8.9 hours
283: loss=33.011, avg loss=32.062, last=none, best=none, next=1000, rate=0.00000834, load 64=1.5 seconds, train=4.6 seconds, 18112 images, time remaining=8.9 hours
284: loss=32.652, avg loss=32.121, last=none, best=none, next=1000, rate=0.00000846, load 64=1.7 seconds, train=4.8 seconds, 18176 images, time remaining=8.9 hours
285: loss=31.326, avg loss=32.042, last=none, best=none, next=1000, rate=0.00000858, load 64=1.5 seconds, train=4.6 seconds, 18240 images, time remaining=8.9 hours
286: loss=29.460, avg loss=31.784, last=none, best=none, next=1000, rate=0.00000870, load 64=1.6 seconds, train=4.6 seconds, 18304 images, time remaining=8.9 hours
287: loss=33.389, avg loss=31.944, last=none, best=none, next=1000, rate=0.00000882, load 64=1.6 seconds, train=4.7 seconds, 18368 images, time remaining=8.9 hours
288: loss=30.318, avg loss=31.782, last=none, best=none, next=1000, rate=0.00000894, load 64=1.5 seconds, train=4.6 seconds, 18432 images, time remaining=8.9 hours
289: loss=29.182, avg loss=31.522, last=none, best=none, next=1000, rate=0.00000907, load 64=1.6 seconds, train=4.6 seconds, 18496 images, time remaining=8.9 hours
290: loss=37.538, avg loss=32.123, last=none, best=none, next=1000, rate=0.00000919, load 64=1.4 seconds, train=4.7 seconds, 18560 images, time remaining=8.9 hours
Resizing, random_coef=1.40, batch=4, 1088x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
291: loss=29.290, avg loss=31.840, last=none, best=none, next=1000, rate=0.00000932, load 64=1.4 seconds, train=4.2 seconds, 18624 images, time remaining=8.9 hours
292: loss=33.324, avg loss=31.988, last=none, best=none, next=1000, rate=0.00000945, load 64=1.6 seconds, train=4.3 seconds, 18688 images, time remaining=8.9 hours
293: loss=33.666, avg loss=32.156, last=none, best=none, next=1000, rate=0.00000958, load 64=1.5 seconds, train=4.2 seconds, 18752 images, time remaining=8.9 hours
294: loss=29.197, avg loss=31.860, last=none, best=none, next=1000, rate=0.00000971, load 64=1.4 seconds, train=4.2 seconds, 18816 images, time remaining=8.9 hours
295: loss=28.049, avg loss=31.479, last=none, best=none, next=1000, rate=0.00000985, load 64=1.8 seconds, train=4.2 seconds, 18880 images, time remaining=8.9 hours
296: loss=32.112, avg loss=31.542, last=none, best=none, next=1000, rate=0.00000998, load 64=1.6 seconds, train=4.2 seconds, 18944 images, time remaining=8.9 hours
297: loss=31.424, avg loss=31.530, last=none, best=none, next=1000, rate=0.00001012, load 64=1.5 seconds, train=4.3 seconds, 19008 images, time remaining=8.9 hours
298: loss=33.908, avg loss=31.768, last=none, best=none, next=1000, rate=0.00001025, load 64=1.6 seconds, train=4.3 seconds, 19072 images, time remaining=8.9 hours
299: loss=28.139, avg loss=31.405, last=none, best=none, next=1000, rate=0.00001039, load 64=1.8 seconds, train=4.3 seconds, 19136 images, time remaining=8.9 hours
300: loss=29.675, avg loss=31.232, last=none, best=none, next=1000, rate=0.00001053, load 64=1.6 seconds, train=4.2 seconds, 19200 images, time remaining=8.9 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14b5afc00000
301: loss=25.483, avg loss=30.657, last=none, best=none, next=1000, rate=0.00001067, load 64=1.3 seconds, train=2.2 seconds, 19264 images, time remaining=8.9 hours
302: loss=25.819, avg loss=30.174, last=none, best=none, next=1000, rate=0.00001081, load 64=1.7 seconds, train=2.2 seconds, 19328 images, time remaining=8.9 hours
303: loss=30.716, avg loss=30.228, last=none, best=none, next=1000, rate=0.00001096, load 64=1.4 seconds, train=2.2 seconds, 19392 images, time remaining=8.8 hours
304: loss=26.478, avg loss=29.853, last=none, best=none, next=1000, rate=0.00001110, load 64=1.3 seconds, train=2.2 seconds, 19456 images, time remaining=8.8 hours
305: loss=28.323, avg loss=29.700, last=none, best=none, next=1000, rate=0.00001125, load 64=1.5 seconds, train=2.2 seconds, 19520 images, time remaining=8.8 hours
306: loss=28.628, avg loss=29.593, last=none, best=none, next=1000, rate=0.00001140, load 64=1.5 seconds, train=2.2 seconds, 19584 images, time remaining=8.8 hours
307: loss=30.328, avg loss=29.666, last=none, best=none, next=1000, rate=0.00001155, load 64=1.5 seconds, train=2.2 seconds, 19648 images, time remaining=8.8 hours
308: loss=30.183, avg loss=29.718, last=none, best=none, next=1000, rate=0.00001170, load 64=1.2 seconds, train=2.2 seconds, 19712 images, time remaining=8.8 hours
309: loss=28.751, avg loss=29.621, last=none, best=none, next=1000, rate=0.00001185, load 64=1.5 seconds, train=2.2 seconds, 19776 images, time remaining=8.8 hours
310: loss=25.782, avg loss=29.237, last=none, best=none, next=1000, rate=0.00001201, load 64=1.4 seconds, train=2.2 seconds, 19840 images, time remaining=8.8 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14cad7a00000
311: loss=25.516, avg loss=28.865, last=none, best=none, next=1000, rate=0.00001216, load 64=1.4 seconds, train=2.2 seconds, 19904 images, time remaining=8.7 hours
312: loss=26.239, avg loss=28.603, last=none, best=none, next=1000, rate=0.00001232, load 64=1.3 seconds, train=2.3 seconds, 19968 images, time remaining=8.7 hours
313: loss=26.080, avg loss=28.350, last=none, best=none, next=1000, rate=0.00001248, load 64=1.5 seconds, train=2.2 seconds, 20032 images, time remaining=8.7 hours
314: loss=31.586, avg loss=28.674, last=none, best=none, next=1000, rate=0.00001264, load 64=1.1 seconds, train=2.4 seconds, 20096 images, time remaining=8.7 hours
315: loss=28.282, avg loss=28.635, last=none, best=none, next=1000, rate=0.00001280, load 64=1.4 seconds, train=2.3 seconds, 20160 images, time remaining=8.7 hours
316: loss=29.069, avg loss=28.678, last=none, best=none, next=1000, rate=0.00001296, load 64=1.4 seconds, train=2.4 seconds, 20224 images, time remaining=8.7 hours
317: loss=31.199, avg loss=28.930, last=none, best=none, next=1000, rate=0.00001313, load 64=1.6 seconds, train=2.3 seconds, 20288 images, time remaining=8.7 hours
318: loss=27.159, avg loss=28.753, last=none, best=none, next=1000, rate=0.00001329, load 64=1.2 seconds, train=2.3 seconds, 20352 images, time remaining=8.7 hours
319: loss=26.895, avg loss=28.567, last=none, best=none, next=1000, rate=0.00001346, load 64=1.3 seconds, train=2.4 seconds, 20416 images, time remaining=8.6 hours
320: loss=29.199, avg loss=28.630, last=none, best=none, next=1000, rate=0.00001363, load 64=1.3 seconds, train=2.3 seconds, 20480 images, time remaining=8.6 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b626800000
321: loss=27.176, avg loss=28.485, last=none, best=none, next=1000, rate=0.00001380, load 64=1.2 seconds, train=2.7 seconds, 20544 images, time remaining=8.6 hours
322: loss=29.504, avg loss=28.587, last=none, best=none, next=1000, rate=0.00001398, load 64=1.3 seconds, train=2.8 seconds, 20608 images, time remaining=8.6 hours
323: loss=24.662, avg loss=28.194, last=none, best=none, next=1000, rate=0.00001415, load 64=1.4 seconds, train=2.6 seconds, 20672 images, time remaining=8.6 hours
324: loss=26.689, avg loss=28.044, last=none, best=none, next=1000, rate=0.00001433, load 64=1.8 seconds, train=2.8 seconds, 20736 images, time remaining=8.6 hours
325: loss=29.439, avg loss=28.183, last=none, best=none, next=1000, rate=0.00001450, load 64=1.4 seconds, train=2.6 seconds, 20800 images, time remaining=8.6 hours
326: loss=23.877, avg loss=27.753, last=none, best=none, next=1000, rate=0.00001468, load 64=2.3 seconds, train=2.7 seconds, 20864 images, time remaining=8.6 hours
327: loss=26.970, avg loss=27.674, last=none, best=none, next=1000, rate=0.00001486, load 64=1.2 seconds, train=2.6 seconds, 20928 images, time remaining=8.6 hours
328: loss=28.493, avg loss=27.756, last=none, best=none, next=1000, rate=0.00001505, load 64=1.2 seconds, train=2.6 seconds, 20992 images, time remaining=8.6 hours
329: loss=23.765, avg loss=27.357, last=none, best=none, next=1000, rate=0.00001523, load 64=1.4 seconds, train=2.6 seconds, 21056 images, time remaining=8.6 hours
330: loss=26.448, avg loss=27.266, last=none, best=none, next=1000, rate=0.00001542, load 64=1.4 seconds, train=2.6 seconds, 21120 images, time remaining=8.6 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b546400000
331: loss=24.527, avg loss=26.992, last=none, best=none, next=1000, rate=0.00001560, load 64=1.7 seconds, train=1.9 seconds, 21184 images, time remaining=8.5 hours
332: loss=21.264, avg loss=26.419, last=none, best=none, next=1000, rate=0.00001579, load 64=1.7 seconds, train=1.8 seconds, 21248 images, time remaining=8.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
333: loss=25.441, avg loss=26.322, last=none, best=none, next=1000, rate=0.00001599, load 64=2.7 seconds, train=1.9 seconds, 21312 images, time remaining=8.5 hours
334: loss=27.672, avg loss=26.457, last=none, best=none, next=1000, rate=0.00001618, load 64=1.9 seconds, train=2.0 seconds, 21376 images, time remaining=8.5 hours
335: loss=26.384, avg loss=26.449, last=none, best=none, next=1000, rate=0.00001637, load 64=1.5 seconds, train=2.0 seconds, 21440 images, time remaining=8.5 hours
336: loss=26.822, avg loss=26.487, last=none, best=none, next=1000, rate=0.00001657, load 64=1.3 seconds, train=1.9 seconds, 21504 images, time remaining=8.5 hours
337: loss=26.103, avg loss=26.448, last=none, best=none, next=1000, rate=0.00001677, load 64=1.1 seconds, train=1.8 seconds, 21568 images, time remaining=8.5 hours
338: loss=28.138, avg loss=26.617, last=none, best=none, next=1000, rate=0.00001697, load 64=1.7 seconds, train=2.0 seconds, 21632 images, time remaining=8.5 hours
339: loss=26.381, avg loss=26.594, last=none, best=none, next=1000, rate=0.00001717, load 64=1.2 seconds, train=1.9 seconds, 21696 images, time remaining=8.4 hours
340: loss=24.483, avg loss=26.383, last=none, best=none, next=1000, rate=0.00001737, load 64=1.4 seconds, train=1.9 seconds, 21760 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b5fee00000
341: loss=31.349, avg loss=26.879, last=none, best=none, next=1000, rate=0.00001758, load 64=1.8 seconds, train=2.8 seconds, 21824 images, time remaining=8.4 hours
342: loss=28.892, avg loss=27.081, last=none, best=none, next=1000, rate=0.00001778, load 64=1.4 seconds, train=2.7 seconds, 21888 images, time remaining=8.4 hours
343: loss=27.824, avg loss=27.155, last=none, best=none, next=1000, rate=0.00001799, load 64=1.8 seconds, train=2.8 seconds, 21952 images, time remaining=8.4 hours
344: loss=26.068, avg loss=27.046, last=none, best=none, next=1000, rate=0.00001820, load 64=1.3 seconds, train=2.7 seconds, 22016 images, time remaining=8.4 hours
345: loss=29.083, avg loss=27.250, last=none, best=none, next=1000, rate=0.00001842, load 64=2.1 seconds, train=2.7 seconds, 22080 images, time remaining=8.4 hours
346: loss=25.839, avg loss=27.109, last=none, best=none, next=1000, rate=0.00001863, load 64=1.8 seconds, train=2.7 seconds, 22144 images, time remaining=8.4 hours
347: loss=25.734, avg loss=26.971, last=none, best=none, next=1000, rate=0.00001885, load 64=1.2 seconds, train=2.7 seconds, 22208 images, time remaining=8.4 hours
348: loss=29.082, avg loss=27.182, last=none, best=none, next=1000, rate=0.00001907, load 64=1.2 seconds, train=2.6 seconds, 22272 images, time remaining=8.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
349: loss=29.601, avg loss=27.424, last=none, best=none, next=1000, rate=0.00001929, load 64=4.3 seconds, train=2.7 seconds, 22336 images, time remaining=8.4 hours
350: loss=26.240, avg loss=27.306, last=none, best=none, next=1000, rate=0.00001951, load 64=1.7 seconds, train=2.6 seconds, 22400 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
351: loss=29.046, avg loss=27.480, last=none, best=none, next=1000, rate=0.00001973, load 64=3.8 seconds, train=4.0 seconds, 22464 images, time remaining=8.4 hours
352: loss=31.083, avg loss=27.840, last=none, best=none, next=1000, rate=0.00001996, load 64=1.5 seconds, train=4.1 seconds, 22528 images, time remaining=8.4 hours
353: loss=28.709, avg loss=27.927, last=none, best=none, next=1000, rate=0.00002019, load 64=1.5 seconds, train=3.9 seconds, 22592 images, time remaining=8.4 hours
354: loss=26.955, avg loss=27.830, last=none, best=none, next=1000, rate=0.00002042, load 64=2.7 seconds, train=4.0 seconds, 22656 images, time remaining=8.4 hours
355: loss=29.241, avg loss=27.971, last=none, best=none, next=1000, rate=0.00002065, load 64=1.8 seconds, train=4.0 seconds, 22720 images, time remaining=8.4 hours
356: loss=23.634, avg loss=27.537, last=none, best=none, next=1000, rate=0.00002088, load 64=1.4 seconds, train=4.0 seconds, 22784 images, time remaining=8.4 hours
357: loss=29.772, avg loss=27.761, last=none, best=none, next=1000, rate=0.00002112, load 64=1.5 seconds, train=4.0 seconds, 22848 images, time remaining=8.4 hours
358: loss=31.111, avg loss=28.096, last=none, best=none, next=1000, rate=0.00002135, load 64=1.4 seconds, train=4.0 seconds, 22912 images, time remaining=8.4 hours
359: loss=27.900, avg loss=28.076, last=none, best=none, next=1000, rate=0.00002159, load 64=1.4 seconds, train=4.0 seconds, 22976 images, time remaining=8.4 hours
360: loss=26.072, avg loss=27.876, last=none, best=none, next=1000, rate=0.00002184, load 64=1.4 seconds, train=4.0 seconds, 23040 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
361: loss=28.695, avg loss=27.958, last=none, best=none, next=1000, rate=0.00002208, load 64=1.4 seconds, train=3.9 seconds, 23104 images, time remaining=8.4 hours
362: loss=27.328, avg loss=27.895, last=none, best=none, next=1000, rate=0.00002232, load 64=1.4 seconds, train=4.0 seconds, 23168 images, time remaining=8.4 hours
363: loss=29.667, avg loss=28.072, last=none, best=none, next=1000, rate=0.00002257, load 64=1.3 seconds, train=4.0 seconds, 23232 images, time remaining=8.4 hours
364: loss=31.903, avg loss=28.455, last=none, best=none, next=1000, rate=0.00002282, load 64=1.4 seconds, train=3.9 seconds, 23296 images, time remaining=8.4 hours
365: loss=29.695, avg loss=28.579, last=none, best=none, next=1000, rate=0.00002307, load 64=1.3 seconds, train=3.9 seconds, 23360 images, time remaining=8.4 hours
366: loss=27.179, avg loss=28.439, last=none, best=none, next=1000, rate=0.00002333, load 64=1.6 seconds, train=3.9 seconds, 23424 images, time remaining=8.4 hours
367: loss=26.579, avg loss=28.253, last=none, best=none, next=1000, rate=0.00002358, load 64=2.8 seconds, train=3.9 seconds, 23488 images, time remaining=8.4 hours
368: loss=24.085, avg loss=27.836, last=none, best=none, next=1000, rate=0.00002384, load 64=1.4 seconds, train=3.9 seconds, 23552 images, time remaining=8.4 hours
369: loss=27.923, avg loss=27.845, last=none, best=none, next=1000, rate=0.00002410, load 64=1.3 seconds, train=3.9 seconds, 23616 images, time remaining=8.4 hours
370: loss=26.361, avg loss=27.696, last=none, best=none, next=1000, rate=0.00002436, load 64=1.9 seconds, train=3.9 seconds, 23680 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
371: loss=27.654, avg loss=27.692, last=none, best=none, next=1000, rate=0.00002463, load 64=1.5 seconds, train=4.8 seconds, 23744 images, time remaining=8.4 hours
372: loss=26.378, avg loss=27.561, last=none, best=none, next=1000, rate=0.00002490, load 64=1.9 seconds, train=4.8 seconds, 23808 images, time remaining=8.4 hours
373: loss=30.566, avg loss=27.861, last=none, best=none, next=1000, rate=0.00002516, load 64=2.9 seconds, train=4.8 seconds, 23872 images, time remaining=8.4 hours
374: loss=31.183, avg loss=28.194, last=none, best=none, next=1000, rate=0.00002543, load 64=1.4 seconds, train=4.8 seconds, 23936 images, time remaining=8.4 hours
375: loss=29.399, avg loss=28.314, last=none, best=none, next=1000, rate=0.00002571, load 64=1.5 seconds, train=4.9 seconds, 24000 images, time remaining=8.4 hours
376: loss=28.853, avg loss=28.368, last=none, best=none, next=1000, rate=0.00002598, load 64=1.5 seconds, train=4.9 seconds, 24064 images, time remaining=8.4 hours
377: loss=27.588, avg loss=28.290, last=none, best=none, next=1000, rate=0.00002626, load 64=1.5 seconds, train=4.8 seconds, 24128 images, time remaining=8.4 hours
378: loss=27.066, avg loss=28.167, last=none, best=none, next=1000, rate=0.00002654, load 64=1.5 seconds, train=4.7 seconds, 24192 images, time remaining=8.4 hours
379: loss=29.497, avg loss=28.300, last=none, best=none, next=1000, rate=0.00002682, load 64=3.0 seconds, train=4.9 seconds, 24256 images, time remaining=8.4 hours
380: loss=25.278, avg loss=27.998, last=none, best=none, next=1000, rate=0.00002711, load 64=1.5 seconds, train=4.8 seconds, 24320 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14b7fb200000
381: loss=30.330, avg loss=28.231, last=none, best=none, next=1000, rate=0.00002739, load 64=1.3 seconds, train=2.2 seconds, 24384 images, time remaining=8.4 hours
382: loss=24.385, avg loss=27.847, last=none, best=none, next=1000, rate=0.00002768, load 64=1.3 seconds, train=2.1 seconds, 24448 images, time remaining=8.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
383: loss=25.455, avg loss=27.608, last=none, best=none, next=1000, rate=0.00002797, load 64=3.9 seconds, train=2.3 seconds, 24512 images, time remaining=8.4 hours
384: loss=25.968, avg loss=27.444, last=none, best=none, next=1000, rate=0.00002827, load 64=1.4 seconds, train=2.2 seconds, 24576 images, time remaining=8.4 hours
385: loss=25.014, avg loss=27.201, last=none, best=none, next=1000, rate=0.00002856, load 64=1.3 seconds, train=2.2 seconds, 24640 images, time remaining=8.4 hours
386: loss=22.561, avg loss=26.737, last=none, best=none, next=1000, rate=0.00002886, load 64=1.6 seconds, train=2.2 seconds, 24704 images, time remaining=8.4 hours
387: loss=26.980, avg loss=26.761, last=none, best=none, next=1000, rate=0.00002916, load 64=1.3 seconds, train=2.2 seconds, 24768 images, time remaining=8.4 hours
388: loss=26.197, avg loss=26.705, last=none, best=none, next=1000, rate=0.00002946, load 64=1.5 seconds, train=2.2 seconds, 24832 images, time remaining=8.4 hours
389: loss=24.379, avg loss=26.472, last=none, best=none, next=1000, rate=0.00002977, load 64=1.3 seconds, train=2.0 seconds, 24896 images, time remaining=8.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
390: loss=25.039, avg loss=26.329, last=none, best=none, next=1000, rate=0.00003007, load 64=2.9 seconds, train=2.2 seconds, 24960 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
391: loss=30.850, avg loss=26.781, last=none, best=none, next=1000, rate=0.00003038, load 64=1.6 seconds, train=4.7 seconds, 25024 images, time remaining=8.4 hours
392: loss=27.614, avg loss=26.864, last=none, best=none, next=1000, rate=0.00003070, load 64=1.6 seconds, train=4.6 seconds, 25088 images, time remaining=8.4 hours
393: loss=28.524, avg loss=27.030, last=none, best=none, next=1000, rate=0.00003101, load 64=1.7 seconds, train=4.7 seconds, 25152 images, time remaining=8.4 hours
394: loss=31.204, avg loss=27.448, last=none, best=none, next=1000, rate=0.00003133, load 64=1.6 seconds, train=4.6 seconds, 25216 images, time remaining=8.4 hours
395: loss=27.062, avg loss=27.409, last=none, best=none, next=1000, rate=0.00003165, load 64=1.7 seconds, train=4.6 seconds, 25280 images, time remaining=8.4 hours
396: loss=28.006, avg loss=27.469, last=none, best=none, next=1000, rate=0.00003197, load 64=1.9 seconds, train=4.6 seconds, 25344 images, time remaining=8.4 hours
397: loss=25.874, avg loss=27.309, last=none, best=none, next=1000, rate=0.00003229, load 64=1.6 seconds, train=4.5 seconds, 25408 images, time remaining=8.4 hours
398: loss=27.673, avg loss=27.346, last=none, best=none, next=1000, rate=0.00003262, load 64=4.1 seconds, train=4.7 seconds, 25472 images, time remaining=8.4 hours
399: loss=26.826, avg loss=27.294, last=none, best=none, next=1000, rate=0.00003295, load 64=1.5 seconds, train=4.6 seconds, 25536 images, time remaining=8.4 hours
400: loss=27.160, avg loss=27.280, last=none, best=none, next=1000, rate=0.00003328, load 64=1.5 seconds, train=4.6 seconds, 25600 images, time remaining=8.4 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
401: loss=27.073, avg loss=27.260, last=none, best=none, next=1000, rate=0.00003361, load 64=1.4 seconds, train=2.7 seconds, 25664 images, time remaining=8.4 hours
402: loss=28.335, avg loss=27.367, last=none, best=none, next=1000, rate=0.00003395, load 64=1.2 seconds, train=2.8 seconds, 25728 images, time remaining=8.4 hours
403: loss=22.705, avg loss=26.901, last=none, best=none, next=1000, rate=0.00003429, load 64=1.4 seconds, train=2.7 seconds, 25792 images, time remaining=8.4 hours
404: loss=23.441, avg loss=26.555, last=none, best=none, next=1000, rate=0.00003463, load 64=1.9 seconds, train=2.7 seconds, 25856 images, time remaining=8.4 hours
405: loss=24.179, avg loss=26.317, last=none, best=none, next=1000, rate=0.00003498, load 64=1.4 seconds, train=2.7 seconds, 25920 images, time remaining=8.4 hours
406: loss=22.671, avg loss=25.953, last=none, best=none, next=1000, rate=0.00003532, load 64=1.7 seconds, train=2.7 seconds, 25984 images, time remaining=8.4 hours
407: loss=22.024, avg loss=25.560, last=none, best=none, next=1000, rate=0.00003567, load 64=1.5 seconds, train=2.7 seconds, 26048 images, time remaining=8.4 hours
408: loss=24.864, avg loss=25.490, last=none, best=none, next=1000, rate=0.00003602, load 64=1.6 seconds, train=2.7 seconds, 26112 images, time remaining=8.3 hours
409: loss=28.190, avg loss=25.760, last=none, best=none, next=1000, rate=0.00003638, load 64=1.2 seconds, train=2.6 seconds, 26176 images, time remaining=8.3 hours
410: loss=24.610, avg loss=25.645, last=none, best=none, next=1000, rate=0.00003673, load 64=1.5 seconds, train=2.7 seconds, 26240 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
411: loss=26.693, avg loss=25.750, last=none, best=none, next=1000, rate=0.00003709, load 64=1.3 seconds, train=4.1 seconds, 26304 images, time remaining=8.3 hours
412: loss=26.574, avg loss=25.832, last=none, best=none, next=1000, rate=0.00003746, load 64=2.0 seconds, train=3.9 seconds, 26368 images, time remaining=8.3 hours
413: loss=25.514, avg loss=25.801, last=none, best=none, next=1000, rate=0.00003782, load 64=1.6 seconds, train=3.9 seconds, 26432 images, time remaining=8.3 hours
414: loss=25.505, avg loss=25.771, last=none, best=none, next=1000, rate=0.00003819, load 64=1.4 seconds, train=4.0 seconds, 26496 images, time remaining=8.3 hours
415: loss=27.692, avg loss=25.963, last=none, best=none, next=1000, rate=0.00003856, load 64=1.4 seconds, train=3.8 seconds, 26560 images, time remaining=8.3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
416: loss=24.682, avg loss=25.835, last=none, best=none, next=1000, rate=0.00003893, load 64=4.3 seconds, train=3.9 seconds, 26624 images, time remaining=8.3 hours
417: loss=26.753, avg loss=25.927, last=none, best=none, next=1000, rate=0.00003931, load 64=1.5 seconds, train=3.9 seconds, 26688 images, time remaining=8.3 hours
418: loss=23.827, avg loss=25.717, last=none, best=none, next=1000, rate=0.00003969, load 64=1.5 seconds, train=4.0 seconds, 26752 images, time remaining=8.3 hours
419: loss=24.366, avg loss=25.582, last=none, best=none, next=1000, rate=0.00004007, load 64=1.5 seconds, train=3.9 seconds, 26816 images, time remaining=8.3 hours
420: loss=27.421, avg loss=25.766, last=none, best=none, next=1000, rate=0.00004045, load 64=1.7 seconds, train=4.0 seconds, 26880 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
421: loss=29.011, avg loss=26.090, last=none, best=none, next=1000, rate=0.00004084, load 64=2.2 seconds, train=3.9 seconds, 26944 images, time remaining=8.3 hours
422: loss=24.163, avg loss=25.898, last=none, best=none, next=1000, rate=0.00004123, load 64=1.9 seconds, train=3.8 seconds, 27008 images, time remaining=8.3 hours
423: loss=24.088, avg loss=25.717, last=none, best=none, next=1000, rate=0.00004162, load 64=3.8 seconds, train=3.9 seconds, 27072 images, time remaining=8.3 hours
424: loss=21.593, avg loss=25.304, last=none, best=none, next=1000, rate=0.00004202, load 64=1.6 seconds, train=3.8 seconds, 27136 images, time remaining=8.3 hours
425: loss=26.083, avg loss=25.382, last=none, best=none, next=1000, rate=0.00004241, load 64=2.4 seconds, train=3.8 seconds, 27200 images, time remaining=8.3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
426: loss=24.934, avg loss=25.337, last=none, best=none, next=1000, rate=0.00004281, load 64=4.6 seconds, train=3.8 seconds, 27264 images, time remaining=8.3 hours
427: loss=23.449, avg loss=25.148, last=none, best=none, next=1000, rate=0.00004322, load 64=1.4 seconds, train=3.9 seconds, 27328 images, time remaining=8.3 hours
428: loss=26.550, avg loss=25.289, last=none, best=none, next=1000, rate=0.00004362, load 64=1.7 seconds, train=3.9 seconds, 27392 images, time remaining=8.3 hours
429: loss=23.677, avg loss=25.127, last=none, best=none, next=1000, rate=0.00004403, load 64=1.5 seconds, train=3.9 seconds, 27456 images, time remaining=8.3 hours
430: loss=24.746, avg loss=25.089, last=none, best=none, next=1000, rate=0.00004444, load 64=1.7 seconds, train=4.0 seconds, 27520 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b5b0600000
431: loss=22.829, avg loss=24.863, last=none, best=none, next=1000, rate=0.00004486, load 64=1.2 seconds, train=2.3 seconds, 27584 images, time remaining=8.3 hours
432: loss=23.233, avg loss=24.700, last=none, best=none, next=1000, rate=0.00004528, load 64=1.2 seconds, train=2.4 seconds, 27648 images, time remaining=8.3 hours
433: loss=24.101, avg loss=24.640, last=none, best=none, next=1000, rate=0.00004570, load 64=1.4 seconds, train=2.2 seconds, 27712 images, time remaining=8.3 hours
434: loss=20.343, avg loss=24.211, last=none, best=none, next=1000, rate=0.00004612, load 64=1.9 seconds, train=2.4 seconds, 27776 images, time remaining=8.3 hours
435: loss=25.790, avg loss=24.369, last=none, best=none, next=1000, rate=0.00004655, load 64=1.3 seconds, train=2.3 seconds, 27840 images, time remaining=8.3 hours
436: loss=23.534, avg loss=24.285, last=none, best=none, next=1000, rate=0.00004698, load 64=1.6 seconds, train=2.3 seconds, 27904 images, time remaining=8.3 hours
437: loss=23.229, avg loss=24.179, last=none, best=none, next=1000, rate=0.00004741, load 64=2.0 seconds, train=2.2 seconds, 27968 images, time remaining=8.3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
438: loss=23.142, avg loss=24.076, last=none, best=none, next=1000, rate=0.00004785, load 64=2.4 seconds, train=2.3 seconds, 28032 images, time remaining=8.3 hours
439: loss=22.593, avg loss=23.927, last=none, best=none, next=1000, rate=0.00004828, load 64=1.1 seconds, train=2.3 seconds, 28096 images, time remaining=8.3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
440: loss=23.163, avg loss=23.851, last=none, best=none, next=1000, rate=0.00004873, load 64=3.2 seconds, train=2.4 seconds, 28160 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 992x768
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
441: loss=22.328, avg loss=23.699, last=none, best=none, next=1000, rate=0.00004917, load 64=3.9 seconds, train=3.7 seconds, 28224 images, time remaining=8.3 hours
442: loss=25.229, avg loss=23.852, last=none, best=none, next=1000, rate=0.00004962, load 64=1.4 seconds, train=3.8 seconds, 28288 images, time remaining=8.3 hours
443: loss=22.440, avg loss=23.711, last=none, best=none, next=1000, rate=0.00005007, load 64=1.2 seconds, train=3.7 seconds, 28352 images, time remaining=8.3 hours
444: loss=23.419, avg loss=23.681, last=none, best=none, next=1000, rate=0.00005052, load 64=2.4 seconds, train=3.9 seconds, 28416 images, time remaining=8.3 hours
445: loss=19.328, avg loss=23.246, last=none, best=none, next=1000, rate=0.00005098, load 64=1.3 seconds, train=3.7 seconds, 28480 images, time remaining=8.3 hours
446: loss=24.177, avg loss=23.339, last=none, best=none, next=1000, rate=0.00005144, load 64=1.3 seconds, train=3.8 seconds, 28544 images, time remaining=8.3 hours
447: loss=24.797, avg loss=23.485, last=none, best=none, next=1000, rate=0.00005190, load 64=1.5 seconds, train=3.9 seconds, 28608 images, time remaining=8.3 hours
448: loss=20.727, avg loss=23.209, last=none, best=none, next=1000, rate=0.00005237, load 64=1.4 seconds, train=3.8 seconds, 28672 images, time remaining=8.3 hours
449: loss=22.812, avg loss=23.170, last=none, best=none, next=1000, rate=0.00005284, load 64=2.0 seconds, train=3.6 seconds, 28736 images, time remaining=8.3 hours
450: loss=22.840, avg loss=23.137, last=none, best=none, next=1000, rate=0.00005331, load 64=2.1 seconds, train=3.8 seconds, 28800 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
451: loss=22.469, avg loss=23.070, last=none, best=none, next=1000, rate=0.00005378, load 64=2.1 seconds, train=4.8 seconds, 28864 images, time remaining=8.3 hours
452: loss=23.214, avg loss=23.084, last=none, best=none, next=1000, rate=0.00005426, load 64=1.6 seconds, train=4.8 seconds, 28928 images, time remaining=8.3 hours
453: loss=24.947, avg loss=23.270, last=none, best=none, next=1000, rate=0.00005474, load 64=1.5 seconds, train=4.9 seconds, 28992 images, time remaining=8.3 hours
454: loss=21.850, avg loss=23.128, last=none, best=none, next=1000, rate=0.00005523, load 64=1.6 seconds, train=4.7 seconds, 29056 images, time remaining=8.3 hours
455: loss=23.801, avg loss=23.196, last=none, best=none, next=1000, rate=0.00005572, load 64=1.5 seconds, train=4.8 seconds, 29120 images, time remaining=8.3 hours
456: loss=23.297, avg loss=23.206, last=none, best=none, next=1000, rate=0.00005621, load 64=1.7 seconds, train=4.8 seconds, 29184 images, time remaining=8.3 hours
457: loss=23.258, avg loss=23.211, last=none, best=none, next=1000, rate=0.00005670, load 64=2.2 seconds, train=4.8 seconds, 29248 images, time remaining=8.3 hours
458: loss=24.219, avg loss=23.312, last=none, best=none, next=1000, rate=0.00005720, load 64=1.5 seconds, train=4.8 seconds, 29312 images, time remaining=8.3 hours
459: loss=20.947, avg loss=23.075, last=none, best=none, next=1000, rate=0.00005770, load 64=1.8 seconds, train=4.7 seconds, 29376 images, time remaining=8.3 hours
460: loss=22.493, avg loss=23.017, last=none, best=none, next=1000, rate=0.00005821, load 64=1.8 seconds, train=4.8 seconds, 29440 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 896x672
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
461: loss=22.369, avg loss=22.952, last=none, best=none, next=1000, rate=0.00005871, load 64=1.3 seconds, train=2.3 seconds, 29504 images, time remaining=8.3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
462: loss=22.290, avg loss=22.886, last=none, best=none, next=1000, rate=0.00005923, load 64=2.8 seconds, train=2.6 seconds, 29568 images, time remaining=8.3 hours
463: loss=20.650, avg loss=22.662, last=none, best=none, next=1000, rate=0.00005974, load 64=1.4 seconds, train=2.4 seconds, 29632 images, time remaining=8.3 hours
464: loss=22.719, avg loss=22.668, last=none, best=none, next=1000, rate=0.00006026, load 64=1.7 seconds, train=2.5 seconds, 29696 images, time remaining=8.3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
465: loss=21.074, avg loss=22.509, last=none, best=none, next=1000, rate=0.00006078, load 64=2.7 seconds, train=2.7 seconds, 29760 images, time remaining=8.3 hours
466: loss=22.244, avg loss=22.482, last=none, best=none, next=1000, rate=0.00006130, load 64=1.4 seconds, train=2.5 seconds, 29824 images, time remaining=8.3 hours
467: loss=21.430, avg loss=22.377, last=none, best=none, next=1000, rate=0.00006183, load 64=1.2 seconds, train=2.4 seconds, 29888 images, time remaining=8.3 hours
468: loss=21.056, avg loss=22.245, last=none, best=none, next=1000, rate=0.00006236, load 64=1.7 seconds, train=2.6 seconds, 29952 images, time remaining=8.3 hours
469: loss=21.271, avg loss=22.147, last=none, best=none, next=1000, rate=0.00006290, load 64=1.4 seconds, train=2.6 seconds, 30016 images, time remaining=8.2 hours
470: loss=22.576, avg loss=22.190, last=none, best=none, next=1000, rate=0.00006344, load 64=1.5 seconds, train=2.6 seconds, 30080 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b55e600000
471: loss=21.848, avg loss=22.156, last=none, best=none, next=1000, rate=0.00006398, load 64=1.7 seconds, train=2.2 seconds, 30144 images, time remaining=8.2 hours
472: loss=23.596, avg loss=22.300, last=none, best=none, next=1000, rate=0.00006452, load 64=1.3 seconds, train=2.2 seconds, 30208 images, time remaining=8.2 hours
473: loss=23.302, avg loss=22.400, last=none, best=none, next=1000, rate=0.00006507, load 64=1.3 seconds, train=2.1 seconds, 30272 images, time remaining=8.2 hours
474: loss=19.438, avg loss=22.104, last=none, best=none, next=1000, rate=0.00006562, load 64=1.2 seconds, train=2.1 seconds, 30336 images, time remaining=8.2 hours
475: loss=21.224, avg loss=22.016, last=none, best=none, next=1000, rate=0.00006618, load 64=1.5 seconds, train=2.0 seconds, 30400 images, time remaining=8.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
476: loss=21.747, avg loss=21.989, last=none, best=none, next=1000, rate=0.00006674, load 64=2.9 seconds, train=2.2 seconds, 30464 images, time remaining=8.2 hours
477: loss=20.328, avg loss=21.823, last=none, best=none, next=1000, rate=0.00006730, load 64=1.5 seconds, train=2.2 seconds, 30528 images, time remaining=8.2 hours
478: loss=20.631, avg loss=21.704, last=none, best=none, next=1000, rate=0.00006787, load 64=1.5 seconds, train=2.0 seconds, 30592 images, time remaining=8.2 hours
479: loss=20.066, avg loss=21.540, last=none, best=none, next=1000, rate=0.00006844, load 64=1.8 seconds, train=2.0 seconds, 30656 images, time remaining=8.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
480: loss=19.955, avg loss=21.382, last=none, best=none, next=1000, rate=0.00006901, load 64=3.1 seconds, train=2.1 seconds, 30720 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
481: loss=25.804, avg loss=21.824, last=none, best=none, next=1000, rate=0.00006959, load 64=1.5 seconds, train=5.2 seconds, 30784 images, time remaining=8.2 hours
482: loss=24.020, avg loss=22.043, last=none, best=none, next=1000, rate=0.00007017, load 64=2.1 seconds, train=5.3 seconds, 30848 images, time remaining=8.2 hours
483: loss=27.854, avg loss=22.624, last=none, best=none, next=1000, rate=0.00007075, load 64=1.8 seconds, train=5.2 seconds, 30912 images, time remaining=8.2 hours
484: loss=22.289, avg loss=22.591, last=none, best=none, next=1000, rate=0.00007134, load 64=1.7 seconds, train=5.4 seconds, 30976 images, time remaining=8.2 hours
485: loss=24.910, avg loss=22.823, last=none, best=none, next=1000, rate=0.00007193, load 64=1.6 seconds, train=5.2 seconds, 31040 images, time remaining=8.2 hours
486: loss=22.862, avg loss=22.827, last=none, best=none, next=1000, rate=0.00007253, load 64=2.3 seconds, train=5.4 seconds, 31104 images, time remaining=8.2 hours
487: loss=24.254, avg loss=22.969, last=none, best=none, next=1000, rate=0.00007312, load 64=1.7 seconds, train=5.4 seconds, 31168 images, time remaining=8.2 hours
488: loss=22.275, avg loss=22.900, last=none, best=none, next=1000, rate=0.00007373, load 64=1.7 seconds, train=5.4 seconds, 31232 images, time remaining=8.2 hours
489: loss=26.329, avg loss=23.243, last=none, best=none, next=1000, rate=0.00007433, load 64=1.7 seconds, train=5.4 seconds, 31296 images, time remaining=8.2 hours
490: loss=22.852, avg loss=23.204, last=none, best=none, next=1000, rate=0.00007494, load 64=1.7 seconds, train=5.3 seconds, 31360 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
491: loss=20.906, avg loss=22.974, last=none, best=none, next=1000, rate=0.00007556, load 64=1.5 seconds, train=2.8 seconds, 31424 images, time remaining=8.2 hours
492: loss=22.057, avg loss=22.882, last=none, best=none, next=1000, rate=0.00007617, load 64=1.5 seconds, train=2.8 seconds, 31488 images, time remaining=8.2 hours
493: loss=22.733, avg loss=22.867, last=none, best=none, next=1000, rate=0.00007679, load 64=1.6 seconds, train=2.6 seconds, 31552 images, time remaining=8.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
494: loss=24.532, avg loss=23.034, last=none, best=none, next=1000, rate=0.00007742, load 64=3.5 seconds, train=2.7 seconds, 31616 images, time remaining=8.2 hours
495: loss=23.601, avg loss=23.091, last=none, best=none, next=1000, rate=0.00007805, load 64=1.4 seconds, train=2.7 seconds, 31680 images, time remaining=8.2 hours
496: loss=20.439, avg loss=22.825, last=none, best=none, next=1000, rate=0.00007868, load 64=2.5 seconds, train=2.8 seconds, 31744 images, time remaining=8.2 hours
497: loss=19.232, avg loss=22.466, last=none, best=none, next=1000, rate=0.00007932, load 64=1.8 seconds, train=2.7 seconds, 31808 images, time remaining=8.2 hours
498: loss=24.834, avg loss=22.703, last=none, best=none, next=1000, rate=0.00007996, load 64=2.2 seconds, train=2.8 seconds, 31872 images, time remaining=8.2 hours
499: loss=21.726, avg loss=22.605, last=none, best=none, next=1000, rate=0.00008060, load 64=1.4 seconds, train=2.9 seconds, 31936 images, time remaining=8.2 hours
500: loss=22.403, avg loss=22.585, last=none, best=none, next=1000, rate=0.00008125, load 64=1.4 seconds, train=2.8 seconds, 32000 images, time remaining=8.2 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
501: loss=28.617, avg loss=23.188, last=none, best=none, next=1000, rate=0.00008190, load 64=2.1 seconds, train=6.2 seconds, 32064 images, time remaining=8.2 hours
502: loss=23.286, avg loss=23.198, last=none, best=none, next=1000, rate=0.00008256, load 64=1.8 seconds, train=6.0 seconds, 32128 images, time remaining=8.2 hours
503: loss=22.753, avg loss=23.154, last=none, best=none, next=1000, rate=0.00008322, load 64=1.9 seconds, train=6.0 seconds, 32192 images, time remaining=8.2 hours
504: loss=19.956, avg loss=22.834, last=none, best=none, next=1000, rate=0.00008388, load 64=1.8 seconds, train=6.0 seconds, 32256 images, time remaining=8.2 hours
505: loss=25.711, avg loss=23.121, last=none, best=none, next=1000, rate=0.00008455, load 64=1.9 seconds, train=6.0 seconds, 32320 images, time remaining=8.2 hours
506: loss=22.768, avg loss=23.086, last=none, best=none, next=1000, rate=0.00008522, load 64=2.0 seconds, train=6.1 seconds, 32384 images, time remaining=8.3 hours
507: loss=25.179, avg loss=23.295, last=none, best=none, next=1000, rate=0.00008590, load 64=1.9 seconds, train=6.0 seconds, 32448 images, time remaining=8.3 hours
508: loss=22.458, avg loss=23.212, last=none, best=none, next=1000, rate=0.00008658, load 64=2.6 seconds, train=6.0 seconds, 32512 images, time remaining=8.3 hours
509: loss=24.995, avg loss=23.390, last=none, best=none, next=1000, rate=0.00008726, load 64=1.8 seconds, train=6.1 seconds, 32576 images, time remaining=8.3 hours
510: loss=21.490, avg loss=23.200, last=none, best=none, next=1000, rate=0.00008795, load 64=1.8 seconds, train=6.0 seconds, 32640 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
511: loss=24.958, avg loss=23.376, last=none, best=none, next=1000, rate=0.00008864, load 64=1.7 seconds, train=5.9 seconds, 32704 images, time remaining=8.3 hours
512: loss=24.162, avg loss=23.454, last=none, best=none, next=1000, rate=0.00008934, load 64=4.5 seconds, train=5.9 seconds, 32768 images, time remaining=8.3 hours
513: loss=22.475, avg loss=23.356, last=none, best=none, next=1000, rate=0.00009004, load 64=1.9 seconds, train=5.8 seconds, 32832 images, time remaining=8.3 hours
514: loss=24.730, avg loss=23.494, last=none, best=none, next=1000, rate=0.00009074, load 64=2.3 seconds, train=5.7 seconds, 32896 images, time remaining=8.3 hours
515: loss=23.023, avg loss=23.447, last=none, best=none, next=1000, rate=0.00009145, load 64=2.1 seconds, train=6.0 seconds, 32960 images, time remaining=8.3 hours
516: loss=24.150, avg loss=23.517, last=none, best=none, next=1000, rate=0.00009216, load 64=1.7 seconds, train=5.9 seconds, 33024 images, time remaining=8.3 hours
517: loss=26.601, avg loss=23.825, last=none, best=none, next=1000, rate=0.00009288, load 64=1.8 seconds, train=5.9 seconds, 33088 images, time remaining=8.3 hours
518: loss=21.671, avg loss=23.610, last=none, best=none, next=1000, rate=0.00009360, load 64=1.9 seconds, train=5.9 seconds, 33152 images, time remaining=8.3 hours
519: loss=22.399, avg loss=23.489, last=none, best=none, next=1000, rate=0.00009432, load 64=1.8 seconds, train=5.8 seconds, 33216 images, time remaining=8.4 hours
520: loss=22.509, avg loss=23.391, last=none, best=none, next=1000, rate=0.00009505, load 64=2.1 seconds, train=5.9 seconds, 33280 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b30e000000
521: loss=24.827, avg loss=23.535, last=none, best=none, next=1000, rate=0.00009578, load 64=2.4 seconds, train=2.7 seconds, 33344 images, time remaining=8.4 hours
522: loss=18.479, avg loss=23.029, last=none, best=none, next=1000, rate=0.00009652, load 64=2.3 seconds, train=2.7 seconds, 33408 images, time remaining=8.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
523: loss=19.681, avg loss=22.694, last=none, best=none, next=1000, rate=0.00009726, load 64=4.2 seconds, train=2.7 seconds, 33472 images, time remaining=8.4 hours
524: loss=21.853, avg loss=22.610, last=none, best=none, next=1000, rate=0.00009801, load 64=1.4 seconds, train=2.5 seconds, 33536 images, time remaining=8.3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
525: loss=20.030, avg loss=22.352, last=none, best=none, next=1000, rate=0.00009876, load 64=4.2 seconds, train=2.7 seconds, 33600 images, time remaining=8.3 hours
526: loss=20.635, avg loss=22.180, last=none, best=none, next=1000, rate=0.00009951, load 64=1.6 seconds, train=2.7 seconds, 33664 images, time remaining=8.3 hours
527: loss=19.220, avg loss=21.884, last=none, best=none, next=1000, rate=0.00010027, load 64=1.7 seconds, train=2.7 seconds, 33728 images, time remaining=8.3 hours
528: loss=21.505, avg loss=21.846, last=none, best=none, next=1000, rate=0.00010104, load 64=1.4 seconds, train=2.6 seconds, 33792 images, time remaining=8.3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
529: loss=22.130, avg loss=21.875, last=none, best=none, next=1000, rate=0.00010180, load 64=3.4 seconds, train=2.8 seconds, 33856 images, time remaining=8.3 hours
530: loss=21.416, avg loss=21.829, last=none, best=none, next=1000, rate=0.00010258, load 64=1.5 seconds, train=2.6 seconds, 33920 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 1344x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
531: loss=27.548, avg loss=22.401, last=none, best=none, next=1000, rate=0.00010335, load 64=2.1 seconds, train=6.1 seconds, 33984 images, time remaining=8.3 hours
532: loss=23.793, avg loss=22.540, last=none, best=none, next=1000, rate=0.00010413, load 64=2.0 seconds, train=5.9 seconds, 34048 images, time remaining=8.4 hours
533: loss=19.694, avg loss=22.255, last=none, best=none, next=1000, rate=0.00010492, load 64=1.9 seconds, train=6.0 seconds, 34112 images, time remaining=8.4 hours
534: loss=24.758, avg loss=22.506, last=none, best=none, next=1000, rate=0.00010571, load 64=1.9 seconds, train=6.0 seconds, 34176 images, time remaining=8.4 hours
535: loss=20.865, avg loss=22.342, last=none, best=none, next=1000, rate=0.00010650, load 64=1.8 seconds, train=6.0 seconds, 34240 images, time remaining=8.4 hours
536: loss=21.439, avg loss=22.251, last=none, best=none, next=1000, rate=0.00010730, load 64=2.0 seconds, train=5.9 seconds, 34304 images, time remaining=8.4 hours
537: loss=24.339, avg loss=22.460, last=none, best=none, next=1000, rate=0.00010810, load 64=1.7 seconds, train=6.0 seconds, 34368 images, time remaining=8.4 hours
538: loss=19.702, avg loss=22.184, last=none, best=none, next=1000, rate=0.00010891, load 64=1.8 seconds, train=5.9 seconds, 34432 images, time remaining=8.4 hours
539: loss=19.120, avg loss=21.878, last=none, best=none, next=1000, rate=0.00010972, load 64=1.9 seconds, train=5.9 seconds, 34496 images, time remaining=8.4 hours
540: loss=19.306, avg loss=21.621, last=none, best=none, next=1000, rate=0.00011054, load 64=1.8 seconds, train=5.9 seconds, 34560 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
541: loss=23.089, avg loss=21.768, last=none, best=none, next=1000, rate=0.00011136, load 64=1.3 seconds, train=4.3 seconds, 34624 images, time remaining=8.4 hours
542: loss=21.697, avg loss=21.760, last=none, best=none, next=1000, rate=0.00011219, load 64=1.7 seconds, train=4.3 seconds, 34688 images, time remaining=8.4 hours
543: loss=20.004, avg loss=21.585, last=none, best=none, next=1000, rate=0.00011302, load 64=1.8 seconds, train=4.3 seconds, 34752 images, time remaining=8.4 hours
544: loss=21.240, avg loss=21.550, last=none, best=none, next=1000, rate=0.00011385, load 64=1.5 seconds, train=4.3 seconds, 34816 images, time remaining=8.4 hours
545: loss=20.246, avg loss=21.420, last=none, best=none, next=1000, rate=0.00011469, load 64=1.5 seconds, train=4.4 seconds, 34880 images, time remaining=8.4 hours
546: loss=19.612, avg loss=21.239, last=none, best=none, next=1000, rate=0.00011554, load 64=2.1 seconds, train=4.4 seconds, 34944 images, time remaining=8.4 hours
547: loss=21.366, avg loss=21.252, last=none, best=none, next=1000, rate=0.00011638, load 64=1.5 seconds, train=4.3 seconds, 35008 images, time remaining=8.4 hours
548: loss=22.484, avg loss=21.375, last=none, best=none, next=1000, rate=0.00011724, load 64=1.5 seconds, train=4.4 seconds, 35072 images, time remaining=8.4 hours
549: loss=20.661, avg loss=21.304, last=none, best=none, next=1000, rate=0.00011810, load 64=1.5 seconds, train=4.3 seconds, 35136 images, time remaining=8.4 hours
550: loss=19.102, avg loss=21.083, last=none, best=none, next=1000, rate=0.00011896, load 64=1.5 seconds, train=4.4 seconds, 35200 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1344x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
551: loss=18.939, avg loss=20.869, last=none, best=none, next=1000, rate=0.00011983, load 64=1.7 seconds, train=6.0 seconds, 35264 images, time remaining=8.4 hours
552: loss=20.352, avg loss=20.817, last=none, best=none, next=1000, rate=0.00012070, load 64=1.7 seconds, train=6.0 seconds, 35328 images, time remaining=8.4 hours
553: loss=21.870, avg loss=20.923, last=none, best=none, next=1000, rate=0.00012157, load 64=1.6 seconds, train=6.1 seconds, 35392 images, time remaining=8.4 hours
554: loss=18.984, avg loss=20.729, last=none, best=none, next=1000, rate=0.00012246, load 64=1.9 seconds, train=5.9 seconds, 35456 images, time remaining=8.5 hours
555: loss=20.805, avg loss=20.736, last=none, best=none, next=1000, rate=0.00012334, load 64=1.8 seconds, train=6.0 seconds, 35520 images, time remaining=8.5 hours
556: loss=17.680, avg loss=20.431, last=none, best=none, next=1000, rate=0.00012423, load 64=1.9 seconds, train=5.9 seconds, 35584 images, time remaining=8.5 hours
557: loss=19.899, avg loss=20.378, last=none, best=none, next=1000, rate=0.00012513, load 64=1.9 seconds, train=6.0 seconds, 35648 images, time remaining=8.5 hours
558: loss=19.683, avg loss=20.308, last=none, best=none, next=1000, rate=0.00012603, load 64=1.8 seconds, train=6.0 seconds, 35712 images, time remaining=8.5 hours
559: loss=20.861, avg loss=20.363, last=none, best=none, next=1000, rate=0.00012694, load 64=1.6 seconds, train=5.9 seconds, 35776 images, time remaining=8.5 hours
560: loss=20.341, avg loss=20.361, last=none, best=none, next=1000, rate=0.00012785, load 64=1.9 seconds, train=6.0 seconds, 35840 images, time remaining=8.5 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
561: loss=17.010, avg loss=20.026, last=none, best=none, next=1000, rate=0.00012876, load 64=1.7 seconds, train=5.7 seconds, 35904 images, time remaining=8.5 hours
562: loss=18.263, avg loss=19.850, last=none, best=none, next=1000, rate=0.00012968, load 64=1.8 seconds, train=5.7 seconds, 35968 images, time remaining=8.5 hours
563: loss=18.770, avg loss=19.742, last=none, best=none, next=1000, rate=0.00013061, load 64=1.8 seconds, train=5.7 seconds, 36032 images, time remaining=8.5 hours
564: loss=19.423, avg loss=19.710, last=none, best=none, next=1000, rate=0.00013154, load 64=1.7 seconds, train=5.7 seconds, 36096 images, time remaining=8.5 hours
565: loss=18.049, avg loss=19.544, last=none, best=none, next=1000, rate=0.00013248, load 64=2.0 seconds, train=5.6 seconds, 36160 images, time remaining=8.5 hours
566: loss=18.997, avg loss=19.489, last=none, best=none, next=1000, rate=0.00013342, load 64=1.7 seconds, train=5.7 seconds, 36224 images, time remaining=8.5 hours
567: loss=21.260, avg loss=19.666, last=none, best=none, next=1000, rate=0.00013436, load 64=1.9 seconds, train=5.8 seconds, 36288 images, time remaining=8.5 hours
568: loss=18.325, avg loss=19.532, last=none, best=none, next=1000, rate=0.00013531, load 64=1.9 seconds, train=5.7 seconds, 36352 images, time remaining=8.5 hours
569: loss=19.202, avg loss=19.499, last=none, best=none, next=1000, rate=0.00013627, load 64=1.7 seconds, train=5.7 seconds, 36416 images, time remaining=8.5 hours
570: loss=18.314, avg loss=19.381, last=none, best=none, next=1000, rate=0.00013723, load 64=2.1 seconds, train=5.7 seconds, 36480 images, time remaining=8.5 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2b6000000
571: loss=20.915, avg loss=19.534, last=none, best=none, next=1000, rate=0.00013819, load 64=1.3 seconds, train=2.6 seconds, 36544 images, time remaining=8.5 hours
572: loss=19.165, avg loss=19.497, last=none, best=none, next=1000, rate=0.00013916, load 64=1.7 seconds, train=2.7 seconds, 36608 images, time remaining=8.5 hours
573: loss=18.037, avg loss=19.351, last=none, best=none, next=1000, rate=0.00014014, load 64=1.3 seconds, train=2.6 seconds, 36672 images, time remaining=8.5 hours
574: loss=20.139, avg loss=19.430, last=none, best=none, next=1000, rate=0.00014112, load 64=1.3 seconds, train=2.6 seconds, 36736 images, time remaining=8.5 hours
575: loss=19.642, avg loss=19.451, last=none, best=none, next=1000, rate=0.00014211, load 64=1.4 seconds, train=2.7 seconds, 36800 images, time remaining=8.5 hours
576: loss=18.082, avg loss=19.314, last=none, best=none, next=1000, rate=0.00014310, load 64=1.4 seconds, train=2.6 seconds, 36864 images, time remaining=8.5 hours
577: loss=18.933, avg loss=19.276, last=none, best=none, next=1000, rate=0.00014409, load 64=1.2 seconds, train=2.6 seconds, 36928 images, time remaining=8.5 hours
578: loss=19.290, avg loss=19.277, last=none, best=none, next=1000, rate=0.00014510, load 64=1.4 seconds, train=2.7 seconds, 36992 images, time remaining=8.5 hours
579: loss=17.230, avg loss=19.073, last=none, best=none, next=1000, rate=0.00014610, load 64=1.4 seconds, train=2.6 seconds, 37056 images, time remaining=8.5 hours
580: loss=16.294, avg loss=18.795, last=none, best=none, next=1000, rate=0.00014711, load 64=1.2 seconds, train=2.6 seconds, 37120 images, time remaining=8.5 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b783c00000
581: loss=15.361, avg loss=18.452, last=none, best=none, next=1000, rate=0.00014813, load 64=1.2 seconds, train=2.8 seconds, 37184 images, time remaining=8.5 hours
582: loss=18.613, avg loss=18.468, last=none, best=none, next=1000, rate=0.00014915, load 64=1.4 seconds, train=2.9 seconds, 37248 images, time remaining=8.5 hours
583: loss=17.383, avg loss=18.359, last=none, best=none, next=1000, rate=0.00015018, load 64=1.4 seconds, train=2.8 seconds, 37312 images, time remaining=8.5 hours
584: loss=17.635, avg loss=18.287, last=none, best=none, next=1000, rate=0.00015121, load 64=1.4 seconds, train=2.8 seconds, 37376 images, time remaining=8.5 hours
585: loss=17.527, avg loss=18.211, last=none, best=none, next=1000, rate=0.00015225, load 64=1.4 seconds, train=2.8 seconds, 37440 images, time remaining=8.5 hours
586: loss=17.288, avg loss=18.119, last=none, best=none, next=1000, rate=0.00015330, load 64=1.5 seconds, train=2.8 seconds, 37504 images, time remaining=8.5 hours
587: loss=15.077, avg loss=17.814, last=none, best=none, next=1000, rate=0.00015435, load 64=1.4 seconds, train=2.8 seconds, 37568 images, time remaining=8.5 hours
588: loss=17.973, avg loss=17.830, last=none, best=none, next=1000, rate=0.00015540, load 64=1.4 seconds, train=2.8 seconds, 37632 images, time remaining=8.4 hours
589: loss=18.019, avg loss=17.849, last=none, best=none, next=1000, rate=0.00015646, load 64=1.6 seconds, train=2.8 seconds, 37696 images, time remaining=8.4 hours
590: loss=17.746, avg loss=17.839, last=none, best=none, next=1000, rate=0.00015753, load 64=1.2 seconds, train=2.8 seconds, 37760 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
591: loss=18.980, avg loss=17.953, last=none, best=none, next=1000, rate=0.00015860, load 64=1.5 seconds, train=4.9 seconds, 37824 images, time remaining=8.5 hours
592: loss=19.834, avg loss=18.141, last=none, best=none, next=1000, rate=0.00015967, load 64=1.5 seconds, train=4.8 seconds, 37888 images, time remaining=8.5 hours
593: loss=17.895, avg loss=18.116, last=none, best=none, next=1000, rate=0.00016075, load 64=1.6 seconds, train=4.9 seconds, 37952 images, time remaining=8.5 hours
594: loss=18.447, avg loss=18.150, last=none, best=none, next=1000, rate=0.00016184, load 64=1.6 seconds, train=4.8 seconds, 38016 images, time remaining=8.5 hours
595: loss=16.492, avg loss=17.984, last=none, best=none, next=1000, rate=0.00016293, load 64=1.4 seconds, train=4.8 seconds, 38080 images, time remaining=8.5 hours
596: loss=19.201, avg loss=18.105, last=none, best=none, next=1000, rate=0.00016403, load 64=1.5 seconds, train=4.9 seconds, 38144 images, time remaining=8.5 hours
597: loss=16.817, avg loss=17.977, last=none, best=none, next=1000, rate=0.00016514, load 64=1.6 seconds, train=4.8 seconds, 38208 images, time remaining=8.5 hours
598: loss=18.745, avg loss=18.053, last=none, best=none, next=1000, rate=0.00016624, load 64=1.4 seconds, train=4.9 seconds, 38272 images, time remaining=8.5 hours
599: loss=18.707, avg loss=18.119, last=none, best=none, next=1000, rate=0.00016736, load 64=1.5 seconds, train=4.8 seconds, 38336 images, time remaining=8.5 hours
600: loss=16.938, avg loss=18.001, last=none, best=none, next=1000, rate=0.00016848, load 64=1.4 seconds, train=4.8 seconds, 38400 images, time remaining=8.5 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b59e200000
601: loss=17.447, avg loss=17.945, last=none, best=none, next=1000, rate=0.00016961, load 64=1.3 seconds, train=2.6 seconds, 38464 images, time remaining=8.5 hours
602: loss=18.536, avg loss=18.004, last=none, best=none, next=1000, rate=0.00017074, load 64=1.4 seconds, train=2.7 seconds, 38528 images, time remaining=8.5 hours
603: loss=17.641, avg loss=17.968, last=none, best=none, next=1000, rate=0.00017187, load 64=1.3 seconds, train=2.6 seconds, 38592 images, time remaining=8.5 hours
604: loss=17.669, avg loss=17.938, last=none, best=none, next=1000, rate=0.00017302, load 64=1.3 seconds, train=2.6 seconds, 38656 images, time remaining=8.4 hours
605: loss=19.820, avg loss=18.126, last=none, best=none, next=1000, rate=0.00017417, load 64=1.4 seconds, train=2.6 seconds, 38720 images, time remaining=8.4 hours
606: loss=17.096, avg loss=18.023, last=none, best=none, next=1000, rate=0.00017532, load 64=1.2 seconds, train=2.6 seconds, 38784 images, time remaining=8.4 hours
607: loss=17.959, avg loss=18.017, last=none, best=none, next=1000, rate=0.00017648, load 64=1.3 seconds, train=2.6 seconds, 38848 images, time remaining=8.4 hours
608: loss=16.239, avg loss=17.839, last=none, best=none, next=1000, rate=0.00017765, load 64=1.3 seconds, train=2.7 seconds, 38912 images, time remaining=8.4 hours
609: loss=16.829, avg loss=17.738, last=none, best=none, next=1000, rate=0.00017882, load 64=1.5 seconds, train=2.6 seconds, 38976 images, time remaining=8.4 hours
610: loss=17.708, avg loss=17.735, last=none, best=none, next=1000, rate=0.00018000, load 64=1.3 seconds, train=2.7 seconds, 39040 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
611: loss=21.903, avg loss=18.152, last=none, best=none, next=1000, rate=0.00018118, load 64=1.7 seconds, train=6.1 seconds, 39104 images, time remaining=8.4 hours
612: loss=18.627, avg loss=18.199, last=none, best=none, next=1000, rate=0.00018237, load 64=1.8 seconds, train=6.2 seconds, 39168 images, time remaining=8.4 hours
613: loss=21.446, avg loss=18.524, last=none, best=none, next=1000, rate=0.00018356, load 64=1.8 seconds, train=6.0 seconds, 39232 images, time remaining=8.4 hours
614: loss=19.182, avg loss=18.590, last=none, best=none, next=1000, rate=0.00018476, load 64=1.8 seconds, train=5.9 seconds, 39296 images, time remaining=8.5 hours
615: loss=19.014, avg loss=18.632, last=none, best=none, next=1000, rate=0.00018597, load 64=1.7 seconds, train=6.1 seconds, 39360 images, time remaining=8.5 hours
616: loss=18.709, avg loss=18.640, last=none, best=none, next=1000, rate=0.00018718, load 64=2.0 seconds, train=6.1 seconds, 39424 images, time remaining=8.5 hours
617: loss=19.355, avg loss=18.711, last=none, best=none, next=1000, rate=0.00018840, load 64=1.7 seconds, train=6.0 seconds, 39488 images, time remaining=8.5 hours
618: loss=19.677, avg loss=18.808, last=none, best=none, next=1000, rate=0.00018963, load 64=1.7 seconds, train=6.0 seconds, 39552 images, time remaining=8.5 hours
619: loss=17.976, avg loss=18.725, last=none, best=none, next=1000, rate=0.00019086, load 64=1.7 seconds, train=6.1 seconds, 39616 images, time remaining=8.5 hours
620: loss=20.076, avg loss=18.860, last=none, best=none, next=1000, rate=0.00019209, load 64=1.8 seconds, train=6.1 seconds, 39680 images, time remaining=8.5 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
621: loss=16.447, avg loss=18.619, last=none, best=none, next=1000, rate=0.00019333, load 64=1.6 seconds, train=5.5 seconds, 39744 images, time remaining=8.5 hours
622: loss=18.501, avg loss=18.607, last=none, best=none, next=1000, rate=0.00019458, load 64=1.7 seconds, train=5.5 seconds, 39808 images, time remaining=8.5 hours
623: loss=19.793, avg loss=18.726, last=none, best=none, next=1000, rate=0.00019584, load 64=1.7 seconds, train=5.6 seconds, 39872 images, time remaining=8.5 hours
624: loss=16.691, avg loss=18.522, last=none, best=none, next=1000, rate=0.00019710, load 64=1.7 seconds, train=5.4 seconds, 39936 images, time remaining=8.5 hours
625: loss=15.673, avg loss=18.237, last=none, best=none, next=1000, rate=0.00019836, load 64=1.6 seconds, train=5.4 seconds, 40000 images, time remaining=8.5 hours
626: loss=18.858, avg loss=18.299, last=none, best=none, next=1000, rate=0.00019964, load 64=1.7 seconds, train=5.4 seconds, 40064 images, time remaining=8.5 hours
627: loss=16.723, avg loss=18.142, last=none, best=none, next=1000, rate=0.00020092, load 64=1.5 seconds, train=5.4 seconds, 40128 images, time remaining=8.5 hours
628: loss=15.700, avg loss=17.897, last=none, best=none, next=1000, rate=0.00020220, load 64=1.6 seconds, train=5.4 seconds, 40192 images, time remaining=8.5 hours
629: loss=15.045, avg loss=17.612, last=none, best=none, next=1000, rate=0.00020349, load 64=1.8 seconds, train=5.4 seconds, 40256 images, time remaining=8.5 hours
630: loss=16.395, avg loss=17.491, last=none, best=none, next=1000, rate=0.00020479, load 64=1.6 seconds, train=5.4 seconds, 40320 images, time remaining=8.5 hours
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
631: loss=17.749, avg loss=17.516, last=none, best=none, next=1000, rate=0.00020609, load 64=1.4 seconds, train=4.0 seconds, 40384 images, time remaining=8.5 hours
632: loss=17.842, avg loss=17.549, last=none, best=none, next=1000, rate=0.00020740, load 64=1.3 seconds, train=4.0 seconds, 40448 images, time remaining=8.5 hours
633: loss=18.429, avg loss=17.637, last=none, best=none, next=1000, rate=0.00020872, load 64=1.4 seconds, train=4.0 seconds, 40512 images, time remaining=8.5 hours
634: loss=18.733, avg loss=17.746, last=none, best=none, next=1000, rate=0.00021004, load 64=1.3 seconds, train=4.0 seconds, 40576 images, time remaining=8.5 hours
635: loss=16.218, avg loss=17.594, last=none, best=none, next=1000, rate=0.00021137, load 64=1.6 seconds, train=4.0 seconds, 40640 images, time remaining=8.5 hours
636: loss=17.881, avg loss=17.622, last=none, best=none, next=1000, rate=0.00021270, load 64=1.4 seconds, train=4.0 seconds, 40704 images, time remaining=8.5 hours
637: loss=17.186, avg loss=17.579, last=none, best=none, next=1000, rate=0.00021404, load 64=1.4 seconds, train=3.9 seconds, 40768 images, time remaining=8.5 hours
638: loss=15.888, avg loss=17.410, last=none, best=none, next=1000, rate=0.00021539, load 64=1.3 seconds, train=4.0 seconds, 40832 images, time remaining=8.5 hours
639: loss=17.845, avg loss=17.453, last=none, best=none, next=1000, rate=0.00021674, load 64=1.4 seconds, train=4.0 seconds, 40896 images, time remaining=8.5 hours
640: loss=16.588, avg loss=17.367, last=none, best=none, next=1000, rate=0.00021810, load 64=1.4 seconds, train=4.0 seconds, 40960 images, time remaining=8.5 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b798000000
641: loss=16.494, avg loss=17.279, last=none, best=none, next=1000, rate=0.00021947, load 64=1.2 seconds, train=2.3 seconds, 41024 images, time remaining=8.5 hours
642: loss=16.209, avg loss=17.172, last=none, best=none, next=1000, rate=0.00022084, load 64=1.2 seconds, train=2.4 seconds, 41088 images, time remaining=8.5 hours
643: loss=15.851, avg loss=17.040, last=none, best=none, next=1000, rate=0.00022222, load 64=1.4 seconds, train=2.5 seconds, 41152 images, time remaining=8.5 hours
644: loss=14.770, avg loss=16.813, last=none, best=none, next=1000, rate=0.00022361, load 64=1.4 seconds, train=2.4 seconds, 41216 images, time remaining=8.5 hours
645: loss=15.577, avg loss=16.689, last=none, best=none, next=1000, rate=0.00022500, load 64=1.3 seconds, train=2.3 seconds, 41280 images, time remaining=8.5 hours
646: loss=15.107, avg loss=16.531, last=none, best=none, next=1000, rate=0.00022640, load 64=1.4 seconds, train=2.5 seconds, 41344 images, time remaining=8.5 hours
647: loss=15.713, avg loss=16.449, last=none, best=none, next=1000, rate=0.00022780, load 64=1.4 seconds, train=2.4 seconds, 41408 images, time remaining=8.5 hours
648: loss=15.940, avg loss=16.399, last=none, best=none, next=1000, rate=0.00022922, load 64=1.2 seconds, train=2.4 seconds, 41472 images, time remaining=8.5 hours
649: loss=14.314, avg loss=16.190, last=none, best=none, next=1000, rate=0.00023063, load 64=1.4 seconds, train=2.3 seconds, 41536 images, time remaining=8.5 hours
650: loss=15.195, avg loss=16.091, last=none, best=none, next=1000, rate=0.00023206, load 64=1.2 seconds, train=2.5 seconds, 41600 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
651: loss=19.338, avg loss=16.415, last=none, best=none, next=1000, rate=0.00023349, load 64=1.6 seconds, train=5.4 seconds, 41664 images, time remaining=8.5 hours
652: loss=16.682, avg loss=16.442, last=none, best=none, next=1000, rate=0.00023493, load 64=1.6 seconds, train=5.3 seconds, 41728 images, time remaining=8.5 hours
653: loss=17.164, avg loss=16.514, last=none, best=none, next=1000, rate=0.00023637, load 64=1.8 seconds, train=5.3 seconds, 41792 images, time remaining=8.5 hours
654: loss=18.763, avg loss=16.739, last=none, best=none, next=1000, rate=0.00023782, load 64=1.7 seconds, train=5.3 seconds, 41856 images, time remaining=8.5 hours
655: loss=15.487, avg loss=16.614, last=none, best=none, next=1000, rate=0.00023928, load 64=1.6 seconds, train=5.3 seconds, 41920 images, time remaining=8.5 hours
656: loss=18.128, avg loss=16.765, last=none, best=none, next=1000, rate=0.00024075, load 64=1.5 seconds, train=5.4 seconds, 41984 images, time remaining=8.5 hours
657: loss=17.661, avg loss=16.855, last=none, best=none, next=1000, rate=0.00024222, load 64=1.6 seconds, train=5.4 seconds, 42048 images, time remaining=8.5 hours
658: loss=15.551, avg loss=16.724, last=none, best=none, next=1000, rate=0.00024370, load 64=1.6 seconds, train=5.3 seconds, 42112 images, time remaining=8.5 hours
659: loss=16.467, avg loss=16.699, last=none, best=none, next=1000, rate=0.00024518, load 64=1.5 seconds, train=5.3 seconds, 42176 images, time remaining=8.5 hours
660: loss=17.943, avg loss=16.823, last=none, best=none, next=1000, rate=0.00024667, load 64=1.5 seconds, train=5.4 seconds, 42240 images, time remaining=8.5 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b6bbe00000
661: loss=19.135, avg loss=17.054, last=none, best=none, next=1000, rate=0.00024817, load 64=1.1 seconds, train=1.9 seconds, 42304 images, time remaining=8.5 hours
662: loss=15.740, avg loss=16.923, last=none, best=none, next=1000, rate=0.00024968, load 64=1.1 seconds, train=1.9 seconds, 42368 images, time remaining=8.5 hours
663: loss=18.312, avg loss=17.062, last=none, best=none, next=1000, rate=0.00025119, load 64=1.2 seconds, train=2.0 seconds, 42432 images, time remaining=8.5 hours
664: loss=18.163, avg loss=17.172, last=none, best=none, next=1000, rate=0.00025271, load 64=1.3 seconds, train=2.0 seconds, 42496 images, time remaining=8.5 hours
665: loss=20.117, avg loss=17.466, last=none, best=none, next=1000, rate=0.00025423, load 64=1.3 seconds, train=1.9 seconds, 42560 images, time remaining=8.4 hours
666: loss=17.263, avg loss=17.446, last=none, best=none, next=1000, rate=0.00025576, load 64=1.4 seconds, train=1.9 seconds, 42624 images, time remaining=8.4 hours
667: loss=15.759, avg loss=17.277, last=none, best=none, next=1000, rate=0.00025730, load 64=1.2 seconds, train=1.9 seconds, 42688 images, time remaining=8.4 hours
668: loss=17.123, avg loss=17.262, last=none, best=none, next=1000, rate=0.00025885, load 64=1.2 seconds, train=2.0 seconds, 42752 images, time remaining=8.4 hours
669: loss=18.216, avg loss=17.357, last=none, best=none, next=1000, rate=0.00026040, load 64=1.3 seconds, train=2.0 seconds, 42816 images, time remaining=8.4 hours
670: loss=16.556, avg loss=17.277, last=none, best=none, next=1000, rate=0.00026196, load 64=1.4 seconds, train=2.0 seconds, 42880 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
671: loss=21.454, avg loss=17.695, last=none, best=none, next=1000, rate=0.00026353, load 64=1.7 seconds, train=5.6 seconds, 42944 images, time remaining=8.4 hours
672: loss=19.455, avg loss=17.871, last=none, best=none, next=1000, rate=0.00026511, load 64=1.8 seconds, train=5.6 seconds, 43008 images, time remaining=8.4 hours
673: loss=18.664, avg loss=17.950, last=none, best=none, next=1000, rate=0.00026669, load 64=1.6 seconds, train=5.6 seconds, 43072 images, time remaining=8.4 hours
674: loss=17.935, avg loss=17.949, last=none, best=none, next=1000, rate=0.00026828, load 64=1.6 seconds, train=5.6 seconds, 43136 images, time remaining=8.4 hours
675: loss=20.298, avg loss=18.184, last=none, best=none, next=1000, rate=0.00026987, load 64=1.6 seconds, train=5.7 seconds, 43200 images, time remaining=8.4 hours
676: loss=19.170, avg loss=18.282, last=none, best=none, next=1000, rate=0.00027148, load 64=1.7 seconds, train=5.7 seconds, 43264 images, time remaining=8.4 hours
677: loss=16.459, avg loss=18.100, last=none, best=none, next=1000, rate=0.00027309, load 64=1.7 seconds, train=5.5 seconds, 43328 images, time remaining=8.4 hours
678: loss=17.291, avg loss=18.019, last=none, best=none, next=1000, rate=0.00027470, load 64=1.7 seconds, train=5.5 seconds, 43392 images, time remaining=8.5 hours
679: loss=16.017, avg loss=17.819, last=none, best=none, next=1000, rate=0.00027633, load 64=1.7 seconds, train=5.6 seconds, 43456 images, time remaining=8.5 hours
680: loss=22.152, avg loss=18.252, last=none, best=none, next=1000, rate=0.00027796, load 64=1.8 seconds, train=5.7 seconds, 43520 images, time remaining=8.5 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
681: loss=19.660, avg loss=18.393, last=none, best=none, next=1000, rate=0.00027960, load 64=1.7 seconds, train=5.8 seconds, 43584 images, time remaining=8.5 hours
682: loss=18.314, avg loss=18.385, last=none, best=none, next=1000, rate=0.00028124, load 64=2.2 seconds, train=5.7 seconds, 43648 images, time remaining=8.5 hours
683: loss=16.796, avg loss=18.226, last=none, best=none, next=1000, rate=0.00028290, load 64=1.7 seconds, train=5.7 seconds, 43712 images, time remaining=8.5 hours
684: loss=18.583, avg loss=18.262, last=none, best=none, next=1000, rate=0.00028456, load 64=1.8 seconds, train=5.7 seconds, 43776 images, time remaining=8.5 hours
685: loss=16.605, avg loss=18.096, last=none, best=none, next=1000, rate=0.00028622, load 64=1.8 seconds, train=5.7 seconds, 43840 images, time remaining=8.5 hours
686: loss=17.279, avg loss=18.014, last=none, best=none, next=1000, rate=0.00028790, load 64=1.9 seconds, train=5.7 seconds, 43904 images, time remaining=8.5 hours
687: loss=18.728, avg loss=18.086, last=none, best=none, next=1000, rate=0.00028958, load 64=1.9 seconds, train=5.8 seconds, 43968 images, time remaining=8.5 hours
688: loss=18.132, avg loss=18.090, last=none, best=none, next=1000, rate=0.00029127, load 64=2.2 seconds, train=5.9 seconds, 44032 images, time remaining=8.5 hours
689: loss=15.536, avg loss=17.835, last=none, best=none, next=1000, rate=0.00029297, load 64=1.9 seconds, train=5.7 seconds, 44096 images, time remaining=8.5 hours
690: loss=15.536, avg loss=17.605, last=none, best=none, next=1000, rate=0.00029467, load 64=1.7 seconds, train=5.7 seconds, 44160 images, time remaining=8.5 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b2be000000
691: loss=22.228, avg loss=18.067, last=none, best=none, next=1000, rate=0.00029638, load 64=1.4 seconds, train=2.1 seconds, 44224 images, time remaining=8.5 hours
692: loss=18.949, avg loss=18.156, last=none, best=none, next=1000, rate=0.00029810, load 64=1.3 seconds, train=2.2 seconds, 44288 images, time remaining=8.5 hours
693: loss=15.033, avg loss=17.843, last=none, best=none, next=1000, rate=0.00029983, load 64=1.2 seconds, train=2.1 seconds, 44352 images, time remaining=8.5 hours
694: loss=19.488, avg loss=18.008, last=none, best=none, next=1000, rate=0.00030157, load 64=1.2 seconds, train=2.2 seconds, 44416 images, time remaining=8.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
695: loss=16.649, avg loss=17.872, last=none, best=none, next=1000, rate=0.00030331, load 64=2.6 seconds, train=2.1 seconds, 44480 images, time remaining=8.5 hours
696: loss=18.485, avg loss=17.933, last=none, best=none, next=1000, rate=0.00030506, load 64=1.5 seconds, train=2.2 seconds, 44544 images, time remaining=8.5 hours
697: loss=15.464, avg loss=17.686, last=none, best=none, next=1000, rate=0.00030681, load 64=1.3 seconds, train=2.2 seconds, 44608 images, time remaining=8.5 hours
698: loss=16.937, avg loss=17.611, last=none, best=none, next=1000, rate=0.00030858, load 64=1.4 seconds, train=2.3 seconds, 44672 images, time remaining=8.5 hours
699: loss=14.456, avg loss=17.296, last=none, best=none, next=1000, rate=0.00031035, load 64=1.2 seconds, train=2.1 seconds, 44736 images, time remaining=8.4 hours
700: loss=18.601, avg loss=17.426, last=none, best=none, next=1000, rate=0.00031213, load 64=1.3 seconds, train=2.2 seconds, 44800 images, time remaining=8.4 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14cb4dc00000
701: loss=17.304, avg loss=17.414, last=none, best=none, next=1000, rate=0.00031392, load 64=1.4 seconds, train=2.3 seconds, 44864 images, time remaining=8.4 hours
702: loss=14.742, avg loss=17.147, last=none, best=none, next=1000, rate=0.00031571, load 64=1.4 seconds, train=2.4 seconds, 44928 images, time remaining=8.4 hours
703: loss=16.783, avg loss=17.111, last=none, best=none, next=1000, rate=0.00031752, load 64=1.3 seconds, train=2.4 seconds, 44992 images, time remaining=8.4 hours
704: loss=15.887, avg loss=16.988, last=none, best=none, next=1000, rate=0.00031933, load 64=1.3 seconds, train=2.4 seconds, 45056 images, time remaining=8.4 hours
705: loss=15.578, avg loss=16.847, last=none, best=none, next=1000, rate=0.00032114, load 64=1.4 seconds, train=2.3 seconds, 45120 images, time remaining=8.4 hours
706: loss=14.457, avg loss=16.608, last=none, best=none, next=1000, rate=0.00032297, load 64=1.3 seconds, train=2.4 seconds, 45184 images, time remaining=8.4 hours
707: loss=14.725, avg loss=16.420, last=none, best=none, next=1000, rate=0.00032480, load 64=1.4 seconds, train=2.3 seconds, 45248 images, time remaining=8.4 hours
708: loss=16.789, avg loss=16.457, last=none, best=none, next=1000, rate=0.00032665, load 64=1.3 seconds, train=2.4 seconds, 45312 images, time remaining=8.4 hours
709: loss=15.756, avg loss=16.387, last=none, best=none, next=1000, rate=0.00032849, load 64=1.4 seconds, train=2.4 seconds, 45376 images, time remaining=8.4 hours
710: loss=15.703, avg loss=16.318, last=none, best=none, next=1000, rate=0.00033035, load 64=1.4 seconds, train=2.5 seconds, 45440 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
711: loss=18.343, avg loss=16.521, last=none, best=none, next=1000, rate=0.00033222, load 64=1.5 seconds, train=4.3 seconds, 45504 images, time remaining=8.4 hours
712: loss=16.751, avg loss=16.544, last=none, best=none, next=1000, rate=0.00033409, load 64=1.4 seconds, train=4.3 seconds, 45568 images, time remaining=8.4 hours
713: loss=14.452, avg loss=16.335, last=none, best=none, next=1000, rate=0.00033597, load 64=1.4 seconds, train=4.3 seconds, 45632 images, time remaining=8.4 hours
714: loss=15.671, avg loss=16.268, last=none, best=none, next=1000, rate=0.00033786, load 64=1.5 seconds, train=4.3 seconds, 45696 images, time remaining=8.4 hours
715: loss=16.081, avg loss=16.249, last=none, best=none, next=1000, rate=0.00033976, load 64=1.6 seconds, train=4.4 seconds, 45760 images, time remaining=8.4 hours
716: loss=15.277, avg loss=16.152, last=none, best=none, next=1000, rate=0.00034166, load 64=1.6 seconds, train=4.3 seconds, 45824 images, time remaining=8.4 hours
717: loss=15.257, avg loss=16.063, last=none, best=none, next=1000, rate=0.00034357, load 64=1.6 seconds, train=4.4 seconds, 45888 images, time remaining=8.4 hours
718: loss=16.304, avg loss=16.087, last=none, best=none, next=1000, rate=0.00034549, load 64=1.6 seconds, train=4.4 seconds, 45952 images, time remaining=8.4 hours
719: loss=16.577, avg loss=16.136, last=none, best=none, next=1000, rate=0.00034742, load 64=1.6 seconds, train=4.4 seconds, 46016 images, time remaining=8.4 hours
720: loss=16.320, avg loss=16.154, last=none, best=none, next=1000, rate=0.00034936, load 64=1.5 seconds, train=4.4 seconds, 46080 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
721: loss=15.243, avg loss=16.063, last=none, best=none, next=1000, rate=0.00035131, load 64=1.5 seconds, train=4.0 seconds, 46144 images, time remaining=8.4 hours
722: loss=14.655, avg loss=15.922, last=none, best=none, next=1000, rate=0.00035326, load 64=1.5 seconds, train=4.1 seconds, 46208 images, time remaining=8.4 hours
723: loss=17.172, avg loss=16.047, last=none, best=none, next=1000, rate=0.00035522, load 64=1.5 seconds, train=4.1 seconds, 46272 images, time remaining=8.4 hours
724: loss=15.264, avg loss=15.969, last=none, best=none, next=1000, rate=0.00035719, load 64=1.4 seconds, train=4.1 seconds, 46336 images, time remaining=8.4 hours
725: loss=16.388, avg loss=16.011, last=none, best=none, next=1000, rate=0.00035917, load 64=1.5 seconds, train=4.2 seconds, 46400 images, time remaining=8.4 hours
726: loss=14.033, avg loss=15.813, last=none, best=none, next=1000, rate=0.00036115, load 64=1.4 seconds, train=4.0 seconds, 46464 images, time remaining=8.4 hours
727: loss=15.787, avg loss=15.810, last=none, best=none, next=1000, rate=0.00036315, load 64=1.9 seconds, train=4.1 seconds, 46528 images, time remaining=8.4 hours
728: loss=15.685, avg loss=15.798, last=none, best=none, next=1000, rate=0.00036515, load 64=1.4 seconds, train=4.1 seconds, 46592 images, time remaining=8.4 hours
729: loss=12.457, avg loss=15.464, last=none, best=none, next=1000, rate=0.00036716, load 64=1.5 seconds, train=4.0 seconds, 46656 images, time remaining=8.4 hours
730: loss=15.178, avg loss=15.435, last=none, best=none, next=1000, rate=0.00036918, load 64=1.5 seconds, train=4.1 seconds, 46720 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b7bca00000
731: loss=12.673, avg loss=15.159, last=none, best=none, next=1000, rate=0.00037120, load 64=1.4 seconds, train=2.7 seconds, 46784 images, time remaining=8.4 hours
732: loss=16.528, avg loss=15.296, last=none, best=none, next=1000, rate=0.00037324, load 64=1.5 seconds, train=2.7 seconds, 46848 images, time remaining=8.4 hours
733: loss=14.611, avg loss=15.227, last=none, best=none, next=1000, rate=0.00037528, load 64=1.5 seconds, train=2.7 seconds, 46912 images, time remaining=8.4 hours
734: loss=16.827, avg loss=15.387, last=none, best=none, next=1000, rate=0.00037734, load 64=1.4 seconds, train=2.8 seconds, 46976 images, time remaining=8.4 hours
735: loss=12.887, avg loss=15.137, last=none, best=none, next=1000, rate=0.00037940, load 64=1.5 seconds, train=2.7 seconds, 47040 images, time remaining=8.4 hours
736: loss=14.842, avg loss=15.108, last=none, best=none, next=1000, rate=0.00038146, load 64=1.4 seconds, train=2.7 seconds, 47104 images, time remaining=8.4 hours
737: loss=13.986, avg loss=14.996, last=none, best=none, next=1000, rate=0.00038354, load 64=1.4 seconds, train=2.7 seconds, 47168 images, time remaining=8.4 hours
738: loss=14.527, avg loss=14.949, last=none, best=none, next=1000, rate=0.00038563, load 64=1.6 seconds, train=2.7 seconds, 47232 images, time remaining=8.3 hours
739: loss=13.124, avg loss=14.766, last=none, best=none, next=1000, rate=0.00038772, load 64=2.0 seconds, train=2.7 seconds, 47296 images, time remaining=8.3 hours
740: loss=12.223, avg loss=14.512, last=none, best=none, next=1000, rate=0.00038983, load 64=1.6 seconds, train=2.6 seconds, 47360 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 1344x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
741: loss=17.116, avg loss=14.772, last=none, best=none, next=1000, rate=0.00039194, load 64=1.7 seconds, train=6.0 seconds, 47424 images, time remaining=8.4 hours
742: loss=13.581, avg loss=14.653, last=none, best=none, next=1000, rate=0.00039406, load 64=1.9 seconds, train=5.9 seconds, 47488 images, time remaining=8.4 hours
743: loss=15.931, avg loss=14.781, last=none, best=none, next=1000, rate=0.00039619, load 64=1.8 seconds, train=6.0 seconds, 47552 images, time remaining=8.4 hours
744: loss=18.899, avg loss=15.193, last=none, best=none, next=1000, rate=0.00039832, load 64=2.0 seconds, train=5.9 seconds, 47616 images, time remaining=8.4 hours
745: loss=15.551, avg loss=15.229, last=none, best=none, next=1000, rate=0.00040047, load 64=1.7 seconds, train=6.0 seconds, 47680 images, time remaining=8.4 hours
746: loss=18.395, avg loss=15.545, last=none, best=none, next=1000, rate=0.00040262, load 64=2.1 seconds, train=5.9 seconds, 47744 images, time remaining=8.4 hours
747: loss=18.555, avg loss=15.846, last=none, best=none, next=1000, rate=0.00040479, load 64=1.7 seconds, train=6.1 seconds, 47808 images, time remaining=8.4 hours
748: loss=18.041, avg loss=16.066, last=none, best=none, next=1000, rate=0.00040696, load 64=1.9 seconds, train=6.0 seconds, 47872 images, time remaining=8.4 hours
749: loss=16.379, avg loss=16.097, last=none, best=none, next=1000, rate=0.00040914, load 64=2.0 seconds, train=6.0 seconds, 47936 images, time remaining=8.4 hours
750: loss=16.876, avg loss=16.175, last=none, best=none, next=1000, rate=0.00041133, load 64=1.9 seconds, train=6.0 seconds, 48000 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
751: loss=16.888, avg loss=16.246, last=none, best=none, next=1000, rate=0.00041353, load 64=1.9 seconds, train=4.1 seconds, 48064 images, time remaining=8.4 hours
752: loss=17.299, avg loss=16.351, last=none, best=none, next=1000, rate=0.00041573, load 64=1.6 seconds, train=4.1 seconds, 48128 images, time remaining=8.4 hours
753: loss=14.790, avg loss=16.195, last=none, best=none, next=1000, rate=0.00041795, load 64=1.7 seconds, train=4.2 seconds, 48192 images, time remaining=8.4 hours
754: loss=18.733, avg loss=16.449, last=none, best=none, next=1000, rate=0.00042017, load 64=1.6 seconds, train=3.9 seconds, 48256 images, time remaining=8.4 hours
755: loss=16.698, avg loss=16.474, last=none, best=none, next=1000, rate=0.00042241, load 64=2.7 seconds, train=4.1 seconds, 48320 images, time remaining=8.4 hours
756: loss=16.806, avg loss=16.507, last=none, best=none, next=1000, rate=0.00042465, load 64=1.6 seconds, train=4.1 seconds, 48384 images, time remaining=8.4 hours
757: loss=15.497, avg loss=16.406, last=none, best=none, next=1000, rate=0.00042690, load 64=1.4 seconds, train=4.1 seconds, 48448 images, time remaining=8.4 hours
758: loss=13.233, avg loss=16.089, last=none, best=none, next=1000, rate=0.00042916, load 64=2.8 seconds, train=4.0 seconds, 48512 images, time remaining=8.4 hours
759: loss=15.857, avg loss=16.066, last=none, best=none, next=1000, rate=0.00043143, load 64=1.5 seconds, train=4.1 seconds, 48576 images, time remaining=8.4 hours
760: loss=16.135, avg loss=16.073, last=none, best=none, next=1000, rate=0.00043371, load 64=2.2 seconds, train=4.1 seconds, 48640 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
761: loss=15.296, avg loss=15.995, last=none, best=none, next=1000, rate=0.00043600, load 64=1.7 seconds, train=5.7 seconds, 48704 images, time remaining=8.4 hours
762: loss=15.177, avg loss=15.913, last=none, best=none, next=1000, rate=0.00043829, load 64=2.1 seconds, train=5.8 seconds, 48768 images, time remaining=8.4 hours
763: loss=12.995, avg loss=15.621, last=none, best=none, next=1000, rate=0.00044060, load 64=1.9 seconds, train=5.7 seconds, 48832 images, time remaining=8.4 hours
764: loss=17.271, avg loss=15.786, last=none, best=none, next=1000, rate=0.00044291, load 64=1.7 seconds, train=5.7 seconds, 48896 images, time remaining=8.4 hours
765: loss=15.655, avg loss=15.773, last=none, best=none, next=1000, rate=0.00044523, load 64=1.7 seconds, train=5.6 seconds, 48960 images, time remaining=8.4 hours
766: loss=15.440, avg loss=15.740, last=none, best=none, next=1000, rate=0.00044757, load 64=1.7 seconds, train=5.8 seconds, 49024 images, time remaining=8.4 hours
767: loss=16.452, avg loss=15.811, last=none, best=none, next=1000, rate=0.00044991, load 64=1.7 seconds, train=5.8 seconds, 49088 images, time remaining=8.4 hours
768: loss=15.656, avg loss=15.796, last=none, best=none, next=1000, rate=0.00045226, load 64=1.9 seconds, train=5.6 seconds, 49152 images, time remaining=8.4 hours
769: loss=15.024, avg loss=15.718, last=none, best=none, next=1000, rate=0.00045462, load 64=2.1 seconds, train=5.7 seconds, 49216 images, time remaining=8.4 hours
770: loss=15.975, avg loss=15.744, last=none, best=none, next=1000, rate=0.00045699, load 64=1.7 seconds, train=5.7 seconds, 49280 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
771: loss=16.839, avg loss=15.854, last=none, best=none, next=1000, rate=0.00045937, load 64=1.9 seconds, train=4.0 seconds, 49344 images, time remaining=8.4 hours
772: loss=14.325, avg loss=15.701, last=none, best=none, next=1000, rate=0.00046176, load 64=2.1 seconds, train=3.9 seconds, 49408 images, time remaining=8.4 hours
773: loss=13.536, avg loss=15.484, last=none, best=none, next=1000, rate=0.00046415, load 64=1.4 seconds, train=3.8 seconds, 49472 images, time remaining=8.4 hours
774: loss=15.675, avg loss=15.503, last=none, best=none, next=1000, rate=0.00046656, load 64=1.3 seconds, train=3.8 seconds, 49536 images, time remaining=8.4 hours
775: loss=13.571, avg loss=15.310, last=none, best=none, next=1000, rate=0.00046898, load 64=1.3 seconds, train=3.9 seconds, 49600 images, time remaining=8.4 hours
776: loss=14.151, avg loss=15.194, last=none, best=none, next=1000, rate=0.00047140, load 64=1.2 seconds, train=3.9 seconds, 49664 images, time remaining=8.4 hours
777: loss=15.841, avg loss=15.259, last=none, best=none, next=1000, rate=0.00047384, load 64=1.4 seconds, train=4.0 seconds, 49728 images, time remaining=8.4 hours
778: loss=13.431, avg loss=15.076, last=none, best=none, next=1000, rate=0.00047628, load 64=1.4 seconds, train=4.0 seconds, 49792 images, time remaining=8.4 hours
779: loss=13.330, avg loss=14.901, last=none, best=none, next=1000, rate=0.00047873, load 64=1.4 seconds, train=3.9 seconds, 49856 images, time remaining=8.4 hours
780: loss=14.832, avg loss=14.895, last=none, best=none, next=1000, rate=0.00048120, load 64=1.6 seconds, train=3.9 seconds, 49920 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
781: loss=15.351, avg loss=14.940, last=none, best=none, next=1000, rate=0.00048367, load 64=1.4 seconds, train=3.8 seconds, 49984 images, time remaining=8.4 hours
782: loss=12.441, avg loss=14.690, last=none, best=none, next=1000, rate=0.00048615, load 64=2.3 seconds, train=3.9 seconds, 50048 images, time remaining=8.4 hours
783: loss=15.324, avg loss=14.754, last=none, best=none, next=1000, rate=0.00048864, load 64=1.8 seconds, train=3.9 seconds, 50112 images, time remaining=8.4 hours
784: loss=11.997, avg loss=14.478, last=none, best=none, next=1000, rate=0.00049114, load 64=1.3 seconds, train=3.9 seconds, 50176 images, time remaining=8.4 hours
785: loss=16.481, avg loss=14.678, last=none, best=none, next=1000, rate=0.00049365, load 64=1.9 seconds, train=3.9 seconds, 50240 images, time remaining=8.4 hours
786: loss=14.126, avg loss=14.623, last=none, best=none, next=1000, rate=0.00049617, load 64=1.8 seconds, train=3.9 seconds, 50304 images, time remaining=8.4 hours
787: loss=12.810, avg loss=14.442, last=none, best=none, next=1000, rate=0.00049870, load 64=1.9 seconds, train=3.9 seconds, 50368 images, time remaining=8.4 hours
788: loss=13.559, avg loss=14.353, last=none, best=none, next=1000, rate=0.00050124, load 64=2.1 seconds, train=3.9 seconds, 50432 images, time remaining=8.4 hours
789: loss=14.823, avg loss=14.400, last=none, best=none, next=1000, rate=0.00050379, load 64=1.6 seconds, train=3.8 seconds, 50496 images, time remaining=8.4 hours
790: loss=14.896, avg loss=14.450, last=none, best=none, next=1000, rate=0.00050635, load 64=2.7 seconds, train=3.9 seconds, 50560 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
791: loss=15.080, avg loss=14.513, last=none, best=none, next=1000, rate=0.00050892, load 64=1.4 seconds, train=4.0 seconds, 50624 images, time remaining=8.4 hours
792: loss=13.189, avg loss=14.381, last=none, best=none, next=1000, rate=0.00051150, load 64=1.4 seconds, train=3.9 seconds, 50688 images, time remaining=8.4 hours
793: loss=12.549, avg loss=14.197, last=none, best=none, next=1000, rate=0.00051409, load 64=1.3 seconds, train=4.0 seconds, 50752 images, time remaining=8.4 hours
794: loss=13.418, avg loss=14.119, last=none, best=none, next=1000, rate=0.00051668, load 64=2.1 seconds, train=4.0 seconds, 50816 images, time remaining=8.4 hours
795: loss=13.867, avg loss=14.094, last=none, best=none, next=1000, rate=0.00051929, load 64=1.6 seconds, train=4.0 seconds, 50880 images, time remaining=8.4 hours
796: loss=13.252, avg loss=14.010, last=none, best=none, next=1000, rate=0.00052191, load 64=1.6 seconds, train=3.9 seconds, 50944 images, time remaining=8.4 hours
797: loss=12.264, avg loss=13.835, last=none, best=none, next=1000, rate=0.00052454, load 64=1.6 seconds, train=3.9 seconds, 51008 images, time remaining=8.4 hours
798: loss=12.195, avg loss=13.671, last=none, best=none, next=1000, rate=0.00052718, load 64=1.6 seconds, train=4.0 seconds, 51072 images, time remaining=8.4 hours
799: loss=13.689, avg loss=13.673, last=none, best=none, next=1000, rate=0.00052982, load 64=1.5 seconds, train=4.0 seconds, 51136 images, time remaining=8.4 hours
800: loss=14.044, avg loss=13.710, last=none, best=none, next=1000, rate=0.00053248, load 64=1.4 seconds, train=4.0 seconds, 51200 images, time remaining=8.4 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 896x672
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2b6000000
801: loss=13.550, avg loss=13.694, last=none, best=none, next=1000, rate=0.00053515, load 64=1.5 seconds, train=2.6 seconds, 51264 images, time remaining=8.4 hours
802: loss=13.040, avg loss=13.629, last=none, best=none, next=1000, rate=0.00053782, load 64=1.3 seconds, train=2.7 seconds, 51328 images, time remaining=8.4 hours
803: loss=14.368, avg loss=13.703, last=none, best=none, next=1000, rate=0.00054051, load 64=1.3 seconds, train=2.5 seconds, 51392 images, time remaining=8.4 hours
804: loss=13.452, avg loss=13.678, last=none, best=none, next=1000, rate=0.00054321, load 64=1.6 seconds, train=2.6 seconds, 51456 images, time remaining=8.4 hours
805: loss=12.691, avg loss=13.579, last=none, best=none, next=1000, rate=0.00054592, load 64=1.3 seconds, train=2.6 seconds, 51520 images, time remaining=8.4 hours
806: loss=12.363, avg loss=13.457, last=none, best=none, next=1000, rate=0.00054864, load 64=1.5 seconds, train=2.5 seconds, 51584 images, time remaining=8.4 hours
807: loss=13.720, avg loss=13.484, last=none, best=none, next=1000, rate=0.00055136, load 64=1.3 seconds, train=2.5 seconds, 51648 images, time remaining=8.4 hours
808: loss=14.048, avg loss=13.540, last=none, best=none, next=1000, rate=0.00055410, load 64=1.4 seconds, train=2.6 seconds, 51712 images, time remaining=8.3 hours
809: loss=12.703, avg loss=13.456, last=none, best=none, next=1000, rate=0.00055685, load 64=1.4 seconds, train=2.5 seconds, 51776 images, time remaining=8.3 hours
810: loss=14.679, avg loss=13.579, last=none, best=none, next=1000, rate=0.00055961, load 64=1.3 seconds, train=2.6 seconds, 51840 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
811: loss=15.309, avg loss=13.752, last=none, best=none, next=1000, rate=0.00056238, load 64=1.5 seconds, train=4.3 seconds, 51904 images, time remaining=8.3 hours
812: loss=12.921, avg loss=13.669, last=none, best=none, next=1000, rate=0.00056515, load 64=1.8 seconds, train=4.3 seconds, 51968 images, time remaining=8.3 hours
813: loss=13.374, avg loss=13.639, last=none, best=none, next=1000, rate=0.00056794, load 64=1.9 seconds, train=4.4 seconds, 52032 images, time remaining=8.3 hours
814: loss=17.558, avg loss=14.031, last=none, best=none, next=1000, rate=0.00057074, load 64=1.8 seconds, train=4.5 seconds, 52096 images, time remaining=8.3 hours
815: loss=15.682, avg loss=14.196, last=none, best=none, next=1000, rate=0.00057355, load 64=1.5 seconds, train=4.4 seconds, 52160 images, time remaining=8.3 hours
816: loss=12.916, avg loss=14.068, last=none, best=none, next=1000, rate=0.00057637, load 64=1.6 seconds, train=4.3 seconds, 52224 images, time remaining=8.3 hours
817: loss=14.260, avg loss=14.087, last=none, best=none, next=1000, rate=0.00057920, load 64=1.5 seconds, train=4.3 seconds, 52288 images, time remaining=8.3 hours
818: loss=12.347, avg loss=13.913, last=none, best=none, next=1000, rate=0.00058205, load 64=1.4 seconds, train=4.3 seconds, 52352 images, time remaining=8.3 hours
819: loss=13.755, avg loss=13.897, last=none, best=none, next=1000, rate=0.00058490, load 64=1.6 seconds, train=4.3 seconds, 52416 images, time remaining=8.3 hours
820: loss=13.977, avg loss=13.905, last=none, best=none, next=1000, rate=0.00058776, load 64=2.0 seconds, train=4.3 seconds, 52480 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b4ffa00000
821: loss=16.307, avg loss=14.146, last=none, best=none, next=1000, rate=0.00059063, load 64=1.6 seconds, train=2.7 seconds, 52544 images, time remaining=8.3 hours
822: loss=12.483, avg loss=13.979, last=none, best=none, next=1000, rate=0.00059351, load 64=1.4 seconds, train=2.6 seconds, 52608 images, time remaining=8.3 hours
823: loss=14.597, avg loss=14.041, last=none, best=none, next=1000, rate=0.00059641, load 64=1.3 seconds, train=2.6 seconds, 52672 images, time remaining=8.3 hours
824: loss=13.478, avg loss=13.985, last=none, best=none, next=1000, rate=0.00059931, load 64=1.2 seconds, train=2.5 seconds, 52736 images, time remaining=8.3 hours
825: loss=14.992, avg loss=14.086, last=none, best=none, next=1000, rate=0.00060223, load 64=1.5 seconds, train=2.7 seconds, 52800 images, time remaining=8.3 hours
826: loss=12.957, avg loss=13.973, last=none, best=none, next=1000, rate=0.00060515, load 64=1.7 seconds, train=2.7 seconds, 52864 images, time remaining=8.3 hours
827: loss=12.738, avg loss=13.849, last=none, best=none, next=1000, rate=0.00060809, load 64=1.8 seconds, train=2.7 seconds, 52928 images, time remaining=8.3 hours
828: loss=12.856, avg loss=13.750, last=none, best=none, next=1000, rate=0.00061103, load 64=1.3 seconds, train=2.6 seconds, 52992 images, time remaining=8.3 hours
829: loss=14.104, avg loss=13.785, last=none, best=none, next=1000, rate=0.00061399, load 64=1.2 seconds, train=2.6 seconds, 53056 images, time remaining=8.3 hours
830: loss=13.187, avg loss=13.725, last=none, best=none, next=1000, rate=0.00061696, load 64=1.3 seconds, train=2.6 seconds, 53120 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b4ffa00000
831: loss=13.922, avg loss=13.745, last=none, best=none, next=1000, rate=0.00061994, load 64=1.5 seconds, train=2.7 seconds, 53184 images, time remaining=8.3 hours
832: loss=12.214, avg loss=13.592, last=none, best=none, next=1000, rate=0.00062293, load 64=1.4 seconds, train=2.6 seconds, 53248 images, time remaining=8.3 hours
833: loss=13.268, avg loss=13.560, last=none, best=none, next=1000, rate=0.00062593, load 64=1.4 seconds, train=2.7 seconds, 53312 images, time remaining=8.3 hours
834: loss=12.213, avg loss=13.425, last=none, best=none, next=1000, rate=0.00062894, load 64=1.3 seconds, train=2.7 seconds, 53376 images, time remaining=8.3 hours
835: loss=13.679, avg loss=13.450, last=none, best=none, next=1000, rate=0.00063196, load 64=1.4 seconds, train=2.6 seconds, 53440 images, time remaining=8.3 hours
836: loss=10.573, avg loss=13.163, last=none, best=none, next=1000, rate=0.00063499, load 64=1.4 seconds, train=2.7 seconds, 53504 images, time remaining=8.3 hours
837: loss=11.064, avg loss=12.953, last=none, best=none, next=1000, rate=0.00063804, load 64=1.3 seconds, train=2.6 seconds, 53568 images, time remaining=8.3 hours
838: loss=12.408, avg loss=12.898, last=none, best=none, next=1000, rate=0.00064109, load 64=1.3 seconds, train=2.5 seconds, 53632 images, time remaining=8.3 hours
839: loss=12.433, avg loss=12.852, last=none, best=none, next=1000, rate=0.00064416, load 64=1.5 seconds, train=2.7 seconds, 53696 images, time remaining=8.3 hours
840: loss=11.240, avg loss=12.691, last=none, best=none, next=1000, rate=0.00064723, load 64=1.6 seconds, train=2.6 seconds, 53760 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
841: loss=14.903, avg loss=12.912, last=none, best=none, next=1000, rate=0.00065032, load 64=1.5 seconds, train=4.8 seconds, 53824 images, time remaining=8.3 hours
842: loss=13.704, avg loss=12.991, last=none, best=none, next=1000, rate=0.00065342, load 64=1.6 seconds, train=4.9 seconds, 53888 images, time remaining=8.3 hours
843: loss=12.990, avg loss=12.991, last=none, best=none, next=1000, rate=0.00065653, load 64=1.9 seconds, train=4.9 seconds, 53952 images, time remaining=8.3 hours
844: loss=14.946, avg loss=13.186, last=none, best=none, next=1000, rate=0.00065965, load 64=1.4 seconds, train=5.0 seconds, 54016 images, time remaining=8.3 hours
845: loss=12.246, avg loss=13.092, last=none, best=none, next=1000, rate=0.00066278, load 64=1.5 seconds, train=4.7 seconds, 54080 images, time remaining=8.3 hours
846: loss=12.468, avg loss=13.030, last=none, best=none, next=1000, rate=0.00066592, load 64=1.4 seconds, train=4.8 seconds, 54144 images, time remaining=8.3 hours
847: loss=13.970, avg loss=13.124, last=none, best=none, next=1000, rate=0.00066908, load 64=1.6 seconds, train=4.9 seconds, 54208 images, time remaining=8.3 hours
848: loss=13.470, avg loss=13.159, last=none, best=none, next=1000, rate=0.00067224, load 64=1.5 seconds, train=4.9 seconds, 54272 images, time remaining=8.3 hours
849: loss=14.580, avg loss=13.301, last=none, best=none, next=1000, rate=0.00067542, load 64=1.5 seconds, train=4.9 seconds, 54336 images, time remaining=8.3 hours
850: loss=12.932, avg loss=13.264, last=none, best=none, next=1000, rate=0.00067861, load 64=1.8 seconds, train=4.8 seconds, 54400 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b562400000
851: loss=13.915, avg loss=13.329, last=none, best=none, next=1000, rate=0.00068181, load 64=1.5 seconds, train=2.7 seconds, 54464 images, time remaining=8.3 hours
852: loss=12.673, avg loss=13.263, last=none, best=none, next=1000, rate=0.00068502, load 64=1.6 seconds, train=2.6 seconds, 54528 images, time remaining=8.3 hours
853: loss=11.208, avg loss=13.058, last=none, best=none, next=1000, rate=0.00068824, load 64=1.9 seconds, train=2.6 seconds, 54592 images, time remaining=8.3 hours
854: loss=12.386, avg loss=12.991, last=none, best=none, next=1000, rate=0.00069147, load 64=1.5 seconds, train=2.7 seconds, 54656 images, time remaining=8.2 hours
855: loss=13.424, avg loss=13.034, last=none, best=none, next=1000, rate=0.00069472, load 64=1.4 seconds, train=2.7 seconds, 54720 images, time remaining=8.2 hours
856: loss=11.324, avg loss=12.863, last=none, best=none, next=1000, rate=0.00069797, load 64=1.6 seconds, train=2.7 seconds, 54784 images, time remaining=8.2 hours
857: loss=13.337, avg loss=12.910, last=none, best=none, next=1000, rate=0.00070124, load 64=1.3 seconds, train=2.7 seconds, 54848 images, time remaining=8.2 hours
858: loss=12.617, avg loss=12.881, last=none, best=none, next=1000, rate=0.00070452, load 64=1.5 seconds, train=2.7 seconds, 54912 images, time remaining=8.2 hours
859: loss=14.271, avg loss=13.020, last=none, best=none, next=1000, rate=0.00070781, load 64=1.6 seconds, train=2.6 seconds, 54976 images, time remaining=8.2 hours
860: loss=12.482, avg loss=12.966, last=none, best=none, next=1000, rate=0.00071111, load 64=1.3 seconds, train=2.7 seconds, 55040 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b4b4000000
861: loss=12.646, avg loss=12.934, last=none, best=none, next=1000, rate=0.00071442, load 64=1.1 seconds, train=2.1 seconds, 55104 images, time remaining=8.2 hours
862: loss=12.607, avg loss=12.902, last=none, best=none, next=1000, rate=0.00071775, load 64=1.2 seconds, train=2.1 seconds, 55168 images, time remaining=8.2 hours
863: loss=13.984, avg loss=13.010, last=none, best=none, next=1000, rate=0.00072109, load 64=1.3 seconds, train=2.1 seconds, 55232 images, time remaining=8.2 hours
864: loss=10.900, avg loss=12.799, last=none, best=none, next=1000, rate=0.00072443, load 64=1.5 seconds, train=2.1 seconds, 55296 images, time remaining=8.2 hours
865: loss=13.974, avg loss=12.916, last=none, best=none, next=1000, rate=0.00072779, load 64=1.4 seconds, train=2.1 seconds, 55360 images, time remaining=8.2 hours
866: loss=12.017, avg loss=12.826, last=none, best=none, next=1000, rate=0.00073116, load 64=1.4 seconds, train=2.2 seconds, 55424 images, time remaining=8.2 hours
867: loss=10.365, avg loss=12.580, last=none, best=none, next=1000, rate=0.00073455, load 64=1.1 seconds, train=2.1 seconds, 55488 images, time remaining=8.2 hours
868: loss=11.551, avg loss=12.477, last=none, best=none, next=1000, rate=0.00073794, load 64=1.3 seconds, train=2.1 seconds, 55552 images, time remaining=8.2 hours
869: loss=12.647, avg loss=12.494, last=none, best=none, next=1000, rate=0.00074135, load 64=1.2 seconds, train=2.1 seconds, 55616 images, time remaining=8.2 hours
870: loss=12.635, avg loss=12.508, last=none, best=none, next=1000, rate=0.00074477, load 64=1.9 seconds, train=2.2 seconds, 55680 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
871: loss=19.885, avg loss=13.246, last=none, best=none, next=1000, rate=0.00074820, load 64=1.5 seconds, train=5.5 seconds, 55744 images, time remaining=8.2 hours
872: loss=14.170, avg loss=13.338, last=none, best=none, next=1000, rate=0.00075164, load 64=1.7 seconds, train=5.4 seconds, 55808 images, time remaining=8.2 hours
873: loss=14.633, avg loss=13.468, last=none, best=none, next=1000, rate=0.00075509, load 64=1.7 seconds, train=5.2 seconds, 55872 images, time remaining=8.2 hours
874: loss=16.561, avg loss=13.777, last=none, best=none, next=1000, rate=0.00075856, load 64=1.7 seconds, train=5.3 seconds, 55936 images, time remaining=8.2 hours
875: loss=14.585, avg loss=13.858, last=none, best=none, next=1000, rate=0.00076204, load 64=1.8 seconds, train=5.2 seconds, 56000 images, time remaining=8.2 hours
876: loss=14.211, avg loss=13.893, last=none, best=none, next=1000, rate=0.00076553, load 64=1.6 seconds, train=5.3 seconds, 56064 images, time remaining=8.2 hours
877: loss=15.471, avg loss=14.051, last=none, best=none, next=1000, rate=0.00076903, load 64=1.7 seconds, train=5.4 seconds, 56128 images, time remaining=8.2 hours
878: loss=14.374, avg loss=14.083, last=none, best=none, next=1000, rate=0.00077254, load 64=1.6 seconds, train=5.3 seconds, 56192 images, time remaining=8.2 hours
879: loss=14.552, avg loss=14.130, last=none, best=none, next=1000, rate=0.00077607, load 64=1.6 seconds, train=5.3 seconds, 56256 images, time remaining=8.2 hours
880: loss=15.141, avg loss=14.231, last=none, best=none, next=1000, rate=0.00077960, load 64=1.6 seconds, train=5.3 seconds, 56320 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
881: loss=14.562, avg loss=14.264, last=none, best=none, next=1000, rate=0.00078315, load 64=1.7 seconds, train=4.1 seconds, 56384 images, time remaining=8.2 hours
882: loss=14.525, avg loss=14.290, last=none, best=none, next=1000, rate=0.00078672, load 64=1.5 seconds, train=4.1 seconds, 56448 images, time remaining=8.2 hours
883: loss=16.646, avg loss=14.526, last=none, best=none, next=1000, rate=0.00079029, load 64=1.6 seconds, train=4.1 seconds, 56512 images, time remaining=8.2 hours
884: loss=13.541, avg loss=14.428, last=none, best=none, next=1000, rate=0.00079388, load 64=1.4 seconds, train=4.0 seconds, 56576 images, time remaining=8.2 hours
885: loss=14.190, avg loss=14.404, last=none, best=none, next=1000, rate=0.00079747, load 64=1.8 seconds, train=4.0 seconds, 56640 images, time remaining=8.2 hours
886: loss=13.323, avg loss=14.296, last=none, best=none, next=1000, rate=0.00080108, load 64=1.5 seconds, train=4.0 seconds, 56704 images, time remaining=8.2 hours
887: loss=12.429, avg loss=14.109, last=none, best=none, next=1000, rate=0.00080471, load 64=2.1 seconds, train=4.0 seconds, 56768 images, time remaining=8.2 hours
888: loss=11.761, avg loss=13.874, last=none, best=none, next=1000, rate=0.00080834, load 64=1.6 seconds, train=4.0 seconds, 56832 images, time remaining=8.2 hours
889: loss=11.603, avg loss=13.647, last=none, best=none, next=1000, rate=0.00081199, load 64=1.4 seconds, train=4.0 seconds, 56896 images, time remaining=8.2 hours
890: loss=12.679, avg loss=13.550, last=none, best=none, next=1000, rate=0.00081565, load 64=1.4 seconds, train=4.0 seconds, 56960 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b6c3a00000
891: loss=13.620, avg loss=13.557, last=none, best=none, next=1000, rate=0.00081932, load 64=1.2 seconds, train=2.2 seconds, 57024 images, time remaining=8.2 hours
892: loss=11.524, avg loss=13.354, last=none, best=none, next=1000, rate=0.00082301, load 64=1.3 seconds, train=2.3 seconds, 57088 images, time remaining=8.2 hours
893: loss=14.170, avg loss=13.436, last=none, best=none, next=1000, rate=0.00082670, load 64=1.4 seconds, train=2.3 seconds, 57152 images, time remaining=8.2 hours
894: loss=12.773, avg loss=13.369, last=none, best=none, next=1000, rate=0.00083041, load 64=1.3 seconds, train=2.4 seconds, 57216 images, time remaining=8.2 hours
895: loss=12.964, avg loss=13.329, last=none, best=none, next=1000, rate=0.00083413, load 64=1.4 seconds, train=2.3 seconds, 57280 images, time remaining=8.2 hours
896: loss=14.150, avg loss=13.411, last=none, best=none, next=1000, rate=0.00083787, load 64=1.7 seconds, train=2.3 seconds, 57344 images, time remaining=8.2 hours
897: loss=11.710, avg loss=13.241, last=none, best=none, next=1000, rate=0.00084161, load 64=1.3 seconds, train=2.2 seconds, 57408 images, time remaining=8.2 hours
898: loss=12.922, avg loss=13.209, last=none, best=none, next=1000, rate=0.00084537, load 64=1.5 seconds, train=2.3 seconds, 57472 images, time remaining=8.1 hours
899: loss=13.257, avg loss=13.214, last=none, best=none, next=1000, rate=0.00084915, load 64=1.5 seconds, train=2.3 seconds, 57536 images, time remaining=8.1 hours
900: loss=13.697, avg loss=13.262, last=none, best=none, next=1000, rate=0.00085293, load 64=1.4 seconds, train=2.3 seconds, 57600 images, time remaining=8.1 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
901: loss=17.455, avg loss=13.681, last=none, best=none, next=1000, rate=0.00085673, load 64=1.6 seconds, train=6.0 seconds, 57664 images, time remaining=8.2 hours
902: loss=17.319, avg loss=14.045, last=none, best=none, next=1000, rate=0.00086054, load 64=1.9 seconds, train=6.0 seconds, 57728 images, time remaining=8.2 hours
903: loss=16.261, avg loss=14.267, last=none, best=none, next=1000, rate=0.00086436, load 64=2.0 seconds, train=6.1 seconds, 57792 images, time remaining=8.2 hours
904: loss=15.732, avg loss=14.413, last=none, best=none, next=1000, rate=0.00086819, load 64=1.8 seconds, train=6.0 seconds, 57856 images, time remaining=8.2 hours
905: loss=13.598, avg loss=14.332, last=none, best=none, next=1000, rate=0.00087204, load 64=1.9 seconds, train=5.9 seconds, 57920 images, time remaining=8.2 hours
906: loss=17.696, avg loss=14.668, last=none, best=none, next=1000, rate=0.00087590, load 64=1.9 seconds, train=6.1 seconds, 57984 images, time remaining=8.2 hours
907: loss=16.415, avg loss=14.843, last=none, best=none, next=1000, rate=0.00087978, load 64=1.9 seconds, train=6.0 seconds, 58048 images, time remaining=8.2 hours
908: loss=17.253, avg loss=15.084, last=none, best=none, next=1000, rate=0.00088366, load 64=1.7 seconds, train=6.1 seconds, 58112 images, time remaining=8.2 hours
909: loss=14.985, avg loss=15.074, last=none, best=none, next=1000, rate=0.00088756, load 64=2.1 seconds, train=6.1 seconds, 58176 images, time remaining=8.2 hours
910: loss=14.935, avg loss=15.060, last=none, best=none, next=1000, rate=0.00089147, load 64=1.8 seconds, train=6.0 seconds, 58240 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b5a5000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
911: loss=17.095, avg loss=15.263, last=none, best=none, next=1000, rate=0.00089540, load 64=3.6 seconds, train=1.9 seconds, 58304 images, time remaining=8.2 hours
912: loss=15.511, avg loss=15.288, last=none, best=none, next=1000, rate=0.00089934, load 64=1.5 seconds, train=1.9 seconds, 58368 images, time remaining=8.2 hours
913: loss=13.417, avg loss=15.101, last=none, best=none, next=1000, rate=0.00090329, load 64=1.6 seconds, train=2.0 seconds, 58432 images, time remaining=8.2 hours
914: loss=15.919, avg loss=15.183, last=none, best=none, next=1000, rate=0.00090725, load 64=1.3 seconds, train=1.9 seconds, 58496 images, time remaining=8.2 hours
915: loss=14.979, avg loss=15.162, last=none, best=none, next=1000, rate=0.00091123, load 64=1.5 seconds, train=1.8 seconds, 58560 images, time remaining=8.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
916: loss=14.448, avg loss=15.091, last=none, best=none, next=1000, rate=0.00091522, load 64=2.3 seconds, train=1.8 seconds, 58624 images, time remaining=8.2 hours
917: loss=14.552, avg loss=15.037, last=none, best=none, next=1000, rate=0.00091922, load 64=1.7 seconds, train=1.9 seconds, 58688 images, time remaining=8.1 hours
918: loss=15.935, avg loss=15.127, last=none, best=none, next=1000, rate=0.00092324, load 64=1.3 seconds, train=1.7 seconds, 58752 images, time remaining=8.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
919: loss=16.443, avg loss=15.259, last=none, best=none, next=1000, rate=0.00092727, load 64=4.4 seconds, train=1.9 seconds, 58816 images, time remaining=8.1 hours
920: loss=13.258, avg loss=15.058, last=none, best=none, next=1000, rate=0.00093131, load 64=1.6 seconds, train=1.9 seconds, 58880 images, time remaining=8.1 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
921: loss=18.311, avg loss=15.384, last=none, best=none, next=1000, rate=0.00093537, load 64=1.7 seconds, train=5.3 seconds, 58944 images, time remaining=8.1 hours
922: loss=15.367, avg loss=15.382, last=none, best=none, next=1000, rate=0.00093944, load 64=1.8 seconds, train=5.2 seconds, 59008 images, time remaining=8.1 hours
923: loss=17.100, avg loss=15.554, last=none, best=none, next=1000, rate=0.00094352, load 64=2.0 seconds, train=5.3 seconds, 59072 images, time remaining=8.2 hours
924: loss=15.555, avg loss=15.554, last=none, best=none, next=1000, rate=0.00094761, load 64=2.2 seconds, train=5.2 seconds, 59136 images, time remaining=8.2 hours
925: loss=17.497, avg loss=15.748, last=none, best=none, next=1000, rate=0.00095172, load 64=1.6 seconds, train=5.3 seconds, 59200 images, time remaining=8.2 hours
926: loss=16.619, avg loss=15.835, last=none, best=none, next=1000, rate=0.00095584, load 64=2.6 seconds, train=5.1 seconds, 59264 images, time remaining=8.2 hours
927: loss=13.964, avg loss=15.648, last=none, best=none, next=1000, rate=0.00095998, load 64=2.0 seconds, train=5.2 seconds, 59328 images, time remaining=8.2 hours
928: loss=16.553, avg loss=15.739, last=none, best=none, next=1000, rate=0.00096413, load 64=1.6 seconds, train=5.2 seconds, 59392 images, time remaining=8.2 hours
929: loss=17.393, avg loss=15.904, last=none, best=none, next=1000, rate=0.00096829, load 64=2.1 seconds, train=5.2 seconds, 59456 images, time remaining=8.2 hours
930: loss=17.394, avg loss=16.053, last=none, best=none, next=1000, rate=0.00097247, load 64=1.7 seconds, train=5.2 seconds, 59520 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
931: loss=14.285, avg loss=15.876, last=none, best=none, next=1000, rate=0.00097666, load 64=1.6 seconds, train=4.7 seconds, 59584 images, time remaining=8.2 hours
932: loss=16.190, avg loss=15.908, last=none, best=none, next=1000, rate=0.00098086, load 64=1.6 seconds, train=4.7 seconds, 59648 images, time remaining=8.2 hours
933: loss=12.690, avg loss=15.586, last=none, best=none, next=1000, rate=0.00098508, load 64=2.0 seconds, train=4.6 seconds, 59712 images, time remaining=8.2 hours
934: loss=14.629, avg loss=15.490, last=none, best=none, next=1000, rate=0.00098931, load 64=1.6 seconds, train=4.6 seconds, 59776 images, time remaining=8.2 hours
935: loss=13.572, avg loss=15.298, last=none, best=none, next=1000, rate=0.00099355, load 64=1.6 seconds, train=4.7 seconds, 59840 images, time remaining=8.2 hours
936: loss=13.655, avg loss=15.134, last=none, best=none, next=1000, rate=0.00099781, load 64=1.6 seconds, train=4.6 seconds, 59904 images, time remaining=8.2 hours
937: loss=15.497, avg loss=15.170, last=none, best=none, next=1000, rate=0.00100208, load 64=2.3 seconds, train=4.7 seconds, 59968 images, time remaining=8.2 hours
938: loss=14.277, avg loss=15.081, last=none, best=none, next=1000, rate=0.00100636, load 64=1.6 seconds, train=4.7 seconds, 60032 images, time remaining=8.2 hours
939: loss=12.054, avg loss=14.778, last=none, best=none, next=1000, rate=0.00101066, load 64=2.0 seconds, train=4.7 seconds, 60096 images, time remaining=8.2 hours
940: loss=13.038, avg loss=14.604, last=none, best=none, next=1000, rate=0.00101497, load 64=1.6 seconds, train=4.7 seconds, 60160 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
941: loss=12.731, avg loss=14.417, last=none, best=none, next=1000, rate=0.00101930, load 64=2.0 seconds, train=6.0 seconds, 60224 images, time remaining=8.2 hours
942: loss=14.948, avg loss=14.470, last=none, best=none, next=1000, rate=0.00102364, load 64=1.9 seconds, train=5.9 seconds, 60288 images, time remaining=8.2 hours
943: loss=14.663, avg loss=14.489, last=none, best=none, next=1000, rate=0.00102799, load 64=2.1 seconds, train=6.2 seconds, 60352 images, time remaining=8.2 hours
944: loss=15.487, avg loss=14.589, last=none, best=none, next=1000, rate=0.00103236, load 64=1.8 seconds, train=5.9 seconds, 60416 images, time remaining=8.2 hours
945: loss=15.367, avg loss=14.667, last=none, best=none, next=1000, rate=0.00103674, load 64=1.9 seconds, train=5.9 seconds, 60480 images, time remaining=8.2 hours
946: loss=11.948, avg loss=14.395, last=none, best=none, next=1000, rate=0.00104114, load 64=1.9 seconds, train=5.7 seconds, 60544 images, time remaining=8.2 hours
947: loss=13.641, avg loss=14.320, last=none, best=none, next=1000, rate=0.00104555, load 64=1.7 seconds, train=5.9 seconds, 60608 images, time remaining=8.2 hours
948: loss=14.008, avg loss=14.288, last=none, best=none, next=1000, rate=0.00104997, load 64=1.8 seconds, train=5.9 seconds, 60672 images, time remaining=8.2 hours
949: loss=14.557, avg loss=14.315, last=none, best=none, next=1000, rate=0.00105441, load 64=1.7 seconds, train=5.9 seconds, 60736 images, time remaining=8.2 hours
950: loss=14.268, avg loss=14.311, last=none, best=none, next=1000, rate=0.00105886, load 64=1.8 seconds, train=5.9 seconds, 60800 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
951: loss=13.911, avg loss=14.271, last=none, best=none, next=1000, rate=0.00106332, load 64=1.7 seconds, train=4.0 seconds, 60864 images, time remaining=8.2 hours
952: loss=11.679, avg loss=14.011, last=none, best=none, next=1000, rate=0.00106780, load 64=1.5 seconds, train=3.9 seconds, 60928 images, time remaining=8.2 hours
953: loss=12.118, avg loss=13.822, last=none, best=none, next=1000, rate=0.00107230, load 64=1.3 seconds, train=3.9 seconds, 60992 images, time remaining=8.2 hours
954: loss=11.879, avg loss=13.628, last=none, best=none, next=1000, rate=0.00107680, load 64=1.3 seconds, train=3.9 seconds, 61056 images, time remaining=8.2 hours
955: loss=13.064, avg loss=13.571, last=none, best=none, next=1000, rate=0.00108133, load 64=1.3 seconds, train=3.9 seconds, 61120 images, time remaining=8.2 hours
956: loss=13.965, avg loss=13.611, last=none, best=none, next=1000, rate=0.00108586, load 64=3.2 seconds, train=3.9 seconds, 61184 images, time remaining=8.2 hours
957: loss=12.370, avg loss=13.487, last=none, best=none, next=1000, rate=0.00109041, load 64=1.4 seconds, train=4.0 seconds, 61248 images, time remaining=8.2 hours
958: loss=11.282, avg loss=13.266, last=none, best=none, next=1000, rate=0.00109498, load 64=1.4 seconds, train=4.0 seconds, 61312 images, time remaining=8.2 hours
959: loss=11.091, avg loss=13.049, last=none, best=none, next=1000, rate=0.00109956, load 64=1.4 seconds, train=3.9 seconds, 61376 images, time remaining=8.2 hours
960: loss=12.803, avg loss=13.024, last=none, best=none, next=1000, rate=0.00110415, load 64=1.6 seconds, train=4.0 seconds, 61440 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b78d800000
961: loss=13.119, avg loss=13.034, last=none, best=none, next=1000, rate=0.00110876, load 64=1.3 seconds, train=1.9 seconds, 61504 images, time remaining=8.2 hours
962: loss=12.499, avg loss=12.980, last=none, best=none, next=1000, rate=0.00111338, load 64=1.5 seconds, train=2.0 seconds, 61568 images, time remaining=8.2 hours
963: loss=11.753, avg loss=12.857, last=none, best=none, next=1000, rate=0.00111802, load 64=1.5 seconds, train=1.9 seconds, 61632 images, time remaining=8.2 hours
964: loss=13.343, avg loss=12.906, last=none, best=none, next=1000, rate=0.00112267, load 64=1.3 seconds, train=2.0 seconds, 61696 images, time remaining=8.2 hours
965: loss=11.440, avg loss=12.759, last=none, best=none, next=1000, rate=0.00112733, load 64=1.2 seconds, train=1.8 seconds, 61760 images, time remaining=8.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
966: loss=13.405, avg loss=12.824, last=none, best=none, next=1000, rate=0.00113201, load 64=2.0 seconds, train=1.6 seconds, 61824 images, time remaining=8.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
967: loss=13.441, avg loss=12.886, last=none, best=none, next=1000, rate=0.00113671, load 64=3.1 seconds, train=1.9 seconds, 61888 images, time remaining=8.1 hours
968: loss=12.079, avg loss=12.805, last=none, best=none, next=1000, rate=0.00114142, load 64=1.4 seconds, train=1.9 seconds, 61952 images, time remaining=8.1 hours
969: loss=13.278, avg loss=12.852, last=none, best=none, next=1000, rate=0.00114614, load 64=1.3 seconds, train=2.0 seconds, 62016 images, time remaining=8.1 hours
970: loss=11.842, avg loss=12.751, last=none, best=none, next=1000, rate=0.00115088, load 64=1.9 seconds, train=1.9 seconds, 62080 images, time remaining=8.1 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2b6000000
971: loss=11.758, avg loss=12.652, last=none, best=none, next=1000, rate=0.00115563, load 64=2.1 seconds, train=2.7 seconds, 62144 images, time remaining=8.1 hours
972: loss=11.823, avg loss=12.569, last=none, best=none, next=1000, rate=0.00116040, load 64=1.3 seconds, train=2.6 seconds, 62208 images, time remaining=8.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
973: loss=12.809, avg loss=12.593, last=none, best=none, next=1000, rate=0.00116518, load 64=3.7 seconds, train=2.6 seconds, 62272 images, time remaining=8.1 hours
974: loss=12.091, avg loss=12.543, last=none, best=none, next=1000, rate=0.00116998, load 64=1.7 seconds, train=2.6 seconds, 62336 images, time remaining=8.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
975: loss=12.372, avg loss=12.526, last=none, best=none, next=1000, rate=0.00117479, load 64=4.0 seconds, train=2.7 seconds, 62400 images, time remaining=8.1 hours
976: loss=11.591, avg loss=12.432, last=none, best=none, next=1000, rate=0.00117962, load 64=1.5 seconds, train=2.7 seconds, 62464 images, time remaining=8.1 hours
977: loss=12.292, avg loss=12.418, last=none, best=none, next=1000, rate=0.00118446, load 64=1.5 seconds, train=2.6 seconds, 62528 images, time remaining=8.1 hours
978: loss=11.660, avg loss=12.342, last=none, best=none, next=1000, rate=0.00118932, load 64=1.3 seconds, train=2.6 seconds, 62592 images, time remaining=8.1 hours
979: loss=11.075, avg loss=12.216, last=none, best=none, next=1000, rate=0.00119419, load 64=1.6 seconds, train=2.5 seconds, 62656 images, time remaining=8.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
980: loss=11.691, avg loss=12.163, last=none, best=none, next=1000, rate=0.00119908, load 64=3.8 seconds, train=2.6 seconds, 62720 images, time remaining=8.1 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
981: loss=14.203, avg loss=12.367, last=none, best=none, next=1000, rate=0.00120398, load 64=6.6 seconds, train=5.3 seconds, 62784 images, time remaining=8.1 hours
982: loss=13.947, avg loss=12.525, last=none, best=none, next=1000, rate=0.00120890, load 64=2.5 seconds, train=5.3 seconds, 62848 images, time remaining=8.1 hours
983: loss=13.653, avg loss=12.638, last=none, best=none, next=1000, rate=0.00121383, load 64=1.6 seconds, train=5.4 seconds, 62912 images, time remaining=8.1 hours
984: loss=13.116, avg loss=12.686, last=none, best=none, next=1000, rate=0.00121878, load 64=1.6 seconds, train=5.3 seconds, 62976 images, time remaining=8.1 hours
985: loss=13.135, avg loss=12.731, last=none, best=none, next=1000, rate=0.00122374, load 64=1.7 seconds, train=5.3 seconds, 63040 images, time remaining=8.1 hours
986: loss=14.322, avg loss=12.890, last=none, best=none, next=1000, rate=0.00122871, load 64=1.8 seconds, train=5.3 seconds, 63104 images, time remaining=8.1 hours
987: loss=11.452, avg loss=12.746, last=none, best=none, next=1000, rate=0.00123371, load 64=1.8 seconds, train=5.3 seconds, 63168 images, time remaining=8.1 hours
988: loss=13.482, avg loss=12.820, last=none, best=none, next=1000, rate=0.00123871, load 64=1.6 seconds, train=5.4 seconds, 63232 images, time remaining=8.1 hours
989: loss=12.116, avg loss=12.749, last=none, best=none, next=1000, rate=0.00124374, load 64=1.6 seconds, train=5.3 seconds, 63296 images, time remaining=8.1 hours
990: loss=11.984, avg loss=12.673, last=none, best=none, next=1000, rate=0.00124877, load 64=2.5 seconds, train=5.3 seconds, 63360 images, time remaining=8.1 hours
Resizing, random_coef=1.40, batch=4, 992x768
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
991: loss=11.953, avg loss=12.601, last=none, best=none, next=1000, rate=0.00125383, load 64=1.6 seconds, train=3.7 seconds, 63424 images, time remaining=8.1 hours
992: loss=12.415, avg loss=12.582, last=none, best=none, next=1000, rate=0.00125890, load 64=1.7 seconds, train=3.8 seconds, 63488 images, time remaining=8.1 hours
993: loss=12.278, avg loss=12.552, last=none, best=none, next=1000, rate=0.00126398, load 64=1.7 seconds, train=3.7 seconds, 63552 images, time remaining=8.1 hours
994: loss=13.024, avg loss=12.599, last=none, best=none, next=1000, rate=0.00126908, load 64=2.3 seconds, train=3.8 seconds, 63616 images, time remaining=8.1 hours
995: loss=13.001, avg loss=12.639, last=none, best=none, next=1000, rate=0.00127419, load 64=1.4 seconds, train=4.0 seconds, 63680 images, time remaining=8.1 hours
996: loss=11.417, avg loss=12.517, last=none, best=none, next=1000, rate=0.00127932, load 64=1.5 seconds, train=3.9 seconds, 63744 images, time remaining=8.1 hours
997: loss=11.362, avg loss=12.402, last=none, best=none, next=1000, rate=0.00128447, load 64=1.3 seconds, train=3.7 seconds, 63808 images, time remaining=8.1 hours
998: loss=12.741, avg loss=12.435, last=none, best=none, next=1000, rate=0.00128963, load 64=1.5 seconds, train=3.8 seconds, 63872 images, time remaining=8.1 hours
999: loss=12.172, avg loss=12.409, last=none, best=none, next=1000, rate=0.00129481, load 64=1.8 seconds, train=3.9 seconds, 63936 images, time remaining=8.1 hours
1000: loss=11.172, avg loss=12.286, last=none, best=none, next=1000, rate=0.00130000, load 64=1.5 seconds, train=3.7 seconds, 64000 images, time remaining=8.1 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2b6000000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=585260, unique_truth_count=57264
rank=0 of ranks=585260rank=100 of ranks=585260rank=200 of ranks=585260rank=300 of ranks=585260rank=400 of ranks=585260rank=500 of ranks=585260rank=600 of ranks=585260rank=700 of ranks=585260rank=800 of ranks=585260rank=900 of ranks=585260rank=1000 of ranks=585260rank=1100 of ranks=585260rank=1200 of ranks=585260rank=1300 of ranks=585260rank=1400 of ranks=585260rank=1500 of ranks=585260rank=1600 of ranks=585260rank=1700 of ranks=585260rank=1800 of ranks=585260rank=1900 of ranks=585260rank=2000 of ranks=585260rank=2100 of ranks=585260rank=2200 of ranks=585260rank=2300 of ranks=585260rank=2400 of ranks=585260rank=2500 of ranks=585260rank=2600 of ranks=585260rank=2700 of ranks=585260rank=2800 of ranks=585260rank=2900 of ranks=585260rank=3000 of ranks=585260rank=3100 of ranks=585260rank=3200 of ranks=585260rank=3300 of ranks=585260rank=3400 of ranks=585260rank=3500 of ranks=585260rank=3600 of ranks=585260rank=3700 of ranks=585260rank=3800 of ranks=585260rank=3900 of ranks=585260rank=4000 of ranks=585260rank=4100 of ranks=585260rank=4200 of ranks=585260rank=4300 of ranks=585260rank=4400 of ranks=585260rank=4500 of ranks=585260rank=4600 of ranks=585260rank=4700 of ranks=585260rank=4800 of ranks=585260rank=4900 of ranks=585260rank=5000 of ranks=585260rank=5100 of ranks=585260rank=5200 of ranks=585260rank=5300 of ranks=585260rank=5400 of ranks=585260rank=5500 of ranks=585260rank=5600 of ranks=585260rank=5700 of ranks=585260rank=5800 of ranks=585260rank=5900 of ranks=585260rank=6000 of ranks=585260rank=6100 of ranks=585260rank=6200 of ranks=585260rank=6300 of ranks=585260rank=6400 of ranks=585260rank=6500 of ranks=585260rank=6600 of ranks=585260rank=6700 of ranks=585260rank=6800 of ranks=585260rank=6900 of ranks=585260rank=7000 of ranks=585260rank=7100 of ranks=585260rank=7200 of ranks=585260rank=7300 of ranks=585260rank=7400 of ranks=585260rank=7500 of ranks=585260rank=7600 of ranks=585260rank=7700 of ranks=585260rank=7800 of ranks=585260rank=7900 of ranks=585260rank=8000 of ranks=585260rank=8100 of ranks=585260rank=8200 of ranks=585260rank=8300 of ranks=585260rank=8400 of ranks=585260rank=8500 of ranks=585260rank=8600 of ranks=585260rank=8700 of ranks=585260rank=8800 of ranks=585260rank=8900 of ranks=585260rank=9000 of ranks=585260rank=9100 of ranks=585260rank=9200 of ranks=585260rank=9300 of ranks=585260rank=9400 of ranks=585260rank=9500 of ranks=585260rank=9600 of ranks=585260rank=9700 of ranks=585260rank=9800 of ranks=585260rank=9900 of ranks=585260rank=10000 of ranks=585260rank=10100 of ranks=585260rank=10200 of ranks=585260rank=10300 of ranks=585260rank=10400 of ranks=585260rank=10500 of ranks=585260rank=10600 of ranks=585260rank=10700 of ranks=585260rank=10800 of ranks=585260rank=10900 of ranks=585260rank=11000 of ranks=585260rank=11100 of ranks=585260rank=11200 of ranks=585260rank=11300 of ranks=585260rank=11400 of ranks=585260rank=11500 of ranks=585260rank=11600 of ranks=585260rank=11700 of ranks=585260rank=11800 of ranks=585260rank=11900 of ranks=585260rank=12000 of ranks=585260rank=12100 of ranks=585260rank=12200 of ranks=585260rank=12300 of ranks=585260rank=12400 of ranks=585260rank=12500 of ranks=585260rank=12600 of ranks=585260rank=12700 of ranks=585260rank=12800 of ranks=585260rank=12900 of ranks=585260rank=13000 of ranks=585260rank=13100 of ranks=585260rank=13200 of ranks=585260rank=13300 of ranks=585260rank=13400 of ranks=585260rank=13500 of ranks=585260rank=13600 of ranks=585260rank=13700 of ranks=585260rank=13800 of ranks=585260rank=13900 of ranks=585260rank=14000 of ranks=585260rank=14100 of ranks=585260rank=14200 of ranks=585260rank=14300 of ranks=585260rank=14400 of ranks=585260rank=14500 of ranks=585260rank=14600 of ranks=585260rank=14700 of ranks=585260rank=14800 of ranks=585260rank=14900 of ranks=585260rank=15000 of ranks=585260rank=15100 of ranks=585260rank=15200 of ranks=585260rank=15300 of ranks=585260rank=15400 of ranks=585260rank=15500 of ranks=585260rank=15600 of ranks=585260rank=15700 of ranks=585260rank=15800 of ranks=585260rank=15900 of ranks=585260rank=16000 of ranks=585260rank=16100 of ranks=585260rank=16200 of ranks=585260rank=16300 of ranks=585260rank=16400 of ranks=585260rank=16500 of ranks=585260rank=16600 of ranks=585260rank=16700 of ranks=585260rank=16800 of ranks=585260rank=16900 of ranks=585260rank=17000 of ranks=585260rank=17100 of ranks=585260rank=17200 of ranks=585260rank=17300 of ranks=585260rank=17400 of ranks=585260rank=17500 of ranks=585260rank=17600 of ranks=585260rank=17700 of ranks=585260rank=17800 of ranks=585260rank=17900 of ranks=585260rank=18000 of ranks=585260rank=18100 of ranks=585260rank=18200 of ranks=585260rank=18300 of ranks=585260rank=18400 of ranks=585260rank=18500 of ranks=585260rank=18600 of ranks=585260rank=18700 of ranks=585260rank=18800 of ranks=585260rank=18900 of ranks=585260rank=19000 of ranks=585260rank=19100 of ranks=585260rank=19200 of ranks=585260rank=19300 of ranks=585260rank=19400 of ranks=585260rank=19500 of ranks=585260rank=19600 of ranks=585260rank=19700 of ranks=585260rank=19800 of ranks=585260rank=19900 of ranks=585260rank=20000 of ranks=585260rank=20100 of ranks=585260rank=20200 of ranks=585260rank=20300 of ranks=585260rank=20400 of ranks=585260rank=20500 of ranks=585260rank=20600 of ranks=585260rank=20700 of ranks=585260rank=20800 of ranks=585260rank=20900 of ranks=585260rank=21000 of ranks=585260rank=21100 of ranks=585260rank=21200 of ranks=585260rank=21300 of ranks=585260rank=21400 of ranks=585260rank=21500 of ranks=585260rank=21600 of ranks=585260rank=21700 of ranks=585260rank=21800 of ranks=585260rank=21900 of ranks=585260rank=22000 of ranks=585260rank=22100 of ranks=585260rank=22200 of ranks=585260rank=22300 of ranks=585260rank=22400 of ranks=585260rank=22500 of ranks=585260rank=22600 of ranks=585260rank=22700 of ranks=585260rank=22800 of ranks=585260rank=22900 of ranks=585260rank=23000 of ranks=585260rank=23100 of ranks=585260rank=23200 of ranks=585260rank=23300 of ranks=585260rank=23400 of ranks=585260rank=23500 of ranks=585260rank=23600 of ranks=585260rank=23700 of ranks=585260rank=23800 of ranks=585260rank=23900 of ranks=585260rank=24000 of ranks=585260rank=24100 of ranks=585260rank=24200 of ranks=585260rank=24300 of ranks=585260rank=24400 of ranks=585260rank=24500 of ranks=585260rank=24600 of ranks=585260rank=24700 of ranks=585260rank=24800 of ranks=585260rank=24900 of ranks=585260rank=25000 of ranks=585260rank=25100 of ranks=585260rank=25200 of ranks=585260rank=25300 of ranks=585260rank=25400 of ranks=585260rank=25500 of ranks=585260rank=25600 of ranks=585260rank=25700 of ranks=585260rank=25800 of ranks=585260rank=25900 of ranks=585260rank=26000 of ranks=585260rank=26100 of ranks=585260rank=26200 of ranks=585260rank=26300 of ranks=585260rank=26400 of ranks=585260rank=26500 of ranks=585260rank=26600 of ranks=585260rank=26700 of ranks=585260rank=26800 of ranks=585260rank=26900 of ranks=585260rank=27000 of ranks=585260rank=27100 of ranks=585260rank=27200 of ranks=585260rank=27300 of ranks=585260rank=27400 of ranks=585260rank=27500 of ranks=585260rank=27600 of ranks=585260rank=27700 of ranks=585260rank=27800 of ranks=585260rank=27900 of ranks=585260rank=28000 of ranks=585260rank=28100 of ranks=585260rank=28200 of ranks=585260rank=28300 of ranks=585260rank=28400 of ranks=585260rank=28500 of ranks=585260rank=28600 of ranks=585260rank=28700 of ranks=585260rank=28800 of ranks=585260rank=28900 of ranks=585260rank=29000 of ranks=585260rank=29100 of ranks=585260rank=29200 of ranks=585260rank=29300 of ranks=585260rank=29400 of ranks=585260rank=29500 of ranks=585260rank=29600 of ranks=585260rank=29700 of ranks=585260rank=29800 of ranks=585260rank=29900 of ranks=585260rank=30000 of ranks=585260rank=30100 of ranks=585260rank=30200 of ranks=585260rank=30300 of ranks=585260rank=30400 of ranks=585260rank=30500 of ranks=585260rank=30600 of ranks=585260rank=30700 of ranks=585260rank=30800 of ranks=585260rank=30900 of ranks=585260rank=31000 of ranks=585260rank=31100 of ranks=585260rank=31200 of ranks=585260rank=31300 of ranks=585260rank=31400 of ranks=585260rank=31500 of ranks=585260rank=31600 of ranks=585260rank=31700 of ranks=585260rank=31800 of ranks=585260rank=31900 of ranks=585260rank=32000 of ranks=585260rank=32100 of ranks=585260rank=32200 of ranks=585260rank=32300 of ranks=585260rank=32400 of ranks=585260rank=32500 of ranks=585260rank=32600 of ranks=585260rank=32700 of ranks=585260rank=32800 of ranks=585260rank=32900 of ranks=585260rank=33000 of ranks=585260rank=33100 of ranks=585260rank=33200 of ranks=585260rank=33300 of ranks=585260rank=33400 of ranks=585260rank=33500 of ranks=585260rank=33600 of ranks=585260rank=33700 of ranks=585260rank=33800 of ranks=585260rank=33900 of ranks=585260rank=34000 of ranks=585260rank=34100 of ranks=585260rank=34200 of ranks=585260rank=34300 of ranks=585260rank=34400 of ranks=585260rank=34500 of ranks=585260rank=34600 of ranks=585260rank=34700 of ranks=585260rank=34800 of ranks=585260rank=34900 of ranks=585260rank=35000 of ranks=585260rank=35100 of ranks=585260rank=35200 of ranks=585260rank=35300 of ranks=585260rank=35400 of ranks=585260rank=35500 of ranks=585260rank=35600 of ranks=585260rank=35700 of ranks=585260rank=35800 of ranks=585260rank=35900 of ranks=585260rank=36000 of ranks=585260rank=36100 of ranks=585260rank=36200 of ranks=585260rank=36300 of ranks=585260rank=36400 of ranks=585260rank=36500 of ranks=585260rank=36600 of ranks=585260rank=36700 of ranks=585260rank=36800 of ranks=585260rank=36900 of ranks=585260rank=37000 of ranks=585260rank=37100 of ranks=585260rank=37200 of ranks=585260rank=37300 of ranks=585260rank=37400 of ranks=585260rank=37500 of ranks=585260rank=37600 of ranks=585260rank=37700 of ranks=585260rank=37800 of ranks=585260rank=37900 of ranks=585260rank=38000 of ranks=585260rank=38100 of ranks=585260rank=38200 of ranks=585260rank=38300 of ranks=585260rank=38400 of ranks=585260rank=38500 of ranks=585260rank=38600 of ranks=585260rank=38700 of ranks=585260rank=38800 of ranks=585260rank=38900 of ranks=585260rank=39000 of ranks=585260rank=39100 of ranks=585260rank=39200 of ranks=585260rank=39300 of ranks=585260rank=39400 of ranks=585260rank=39500 of ranks=585260rank=39600 of ranks=585260rank=39700 of ranks=585260rank=39800 of ranks=585260rank=39900 of ranks=585260rank=40000 of ranks=585260rank=40100 of ranks=585260rank=40200 of ranks=585260rank=40300 of ranks=585260rank=40400 of ranks=585260rank=40500 of ranks=585260rank=40600 of ranks=585260rank=40700 of ranks=585260rank=40800 of ranks=585260rank=40900 of ranks=585260rank=41000 of ranks=585260rank=41100 of ranks=585260rank=41200 of ranks=585260rank=41300 of ranks=585260rank=41400 of ranks=585260rank=41500 of ranks=585260rank=41600 of ranks=585260rank=41700 of ranks=585260rank=41800 of ranks=585260rank=41900 of ranks=585260rank=42000 of ranks=585260rank=42100 of ranks=585260rank=42200 of ranks=585260rank=42300 of ranks=585260rank=42400 of ranks=585260rank=42500 of ranks=585260rank=42600 of ranks=585260rank=42700 of ranks=585260rank=42800 of ranks=585260rank=42900 of ranks=585260rank=43000 of ranks=585260rank=43100 of ranks=585260rank=43200 of ranks=585260rank=43300 of ranks=585260rank=43400 of ranks=585260rank=43500 of ranks=585260rank=43600 of ranks=585260rank=43700 of ranks=585260rank=43800 of ranks=585260rank=43900 of ranks=585260rank=44000 of ranks=585260rank=44100 of ranks=585260rank=44200 of ranks=585260rank=44300 of ranks=585260rank=44400 of ranks=585260rank=44500 of ranks=585260rank=44600 of ranks=585260rank=44700 of ranks=585260rank=44800 of ranks=585260rank=44900 of ranks=585260rank=45000 of ranks=585260rank=45100 of ranks=585260rank=45200 of ranks=585260rank=45300 of ranks=585260rank=45400 of ranks=585260rank=45500 of ranks=585260rank=45600 of ranks=585260rank=45700 of ranks=585260rank=45800 of ranks=585260rank=45900 of ranks=585260rank=46000 of ranks=585260rank=46100 of ranks=585260rank=46200 of ranks=585260rank=46300 of ranks=585260rank=46400 of ranks=585260rank=46500 of ranks=585260rank=46600 of ranks=585260rank=46700 of ranks=585260rank=46800 of ranks=585260rank=46900 of ranks=585260rank=47000 of ranks=585260rank=47100 of ranks=585260rank=47200 of ranks=585260rank=47300 of ranks=585260rank=47400 of ranks=585260rank=47500 of ranks=585260rank=47600 of ranks=585260rank=47700 of ranks=585260rank=47800 of ranks=585260rank=47900 of ranks=585260rank=48000 of ranks=585260rank=48100 of ranks=585260rank=48200 of ranks=585260rank=48300 of ranks=585260rank=48400 of ranks=585260rank=48500 of ranks=585260rank=48600 of ranks=585260rank=48700 of ranks=585260rank=48800 of ranks=585260rank=48900 of ranks=585260rank=49000 of ranks=585260rank=49100 of ranks=585260rank=49200 of ranks=585260rank=49300 of ranks=585260rank=49400 of ranks=585260rank=49500 of ranks=585260rank=49600 of ranks=585260rank=49700 of ranks=585260rank=49800 of ranks=585260rank=49900 of ranks=585260rank=50000 of ranks=585260rank=50100 of ranks=585260rank=50200 of ranks=585260rank=50300 of ranks=585260rank=50400 of ranks=585260rank=50500 of ranks=585260rank=50600 of ranks=585260rank=50700 of ranks=585260rank=50800 of ranks=585260rank=50900 of ranks=585260rank=51000 of ranks=585260rank=51100 of ranks=585260rank=51200 of ranks=585260rank=51300 of ranks=585260rank=51400 of ranks=585260rank=51500 of ranks=585260rank=51600 of ranks=585260rank=51700 of ranks=585260rank=51800 of ranks=585260rank=51900 of ranks=585260rank=52000 of ranks=585260rank=52100 of ranks=585260rank=52200 of ranks=585260rank=52300 of ranks=585260rank=52400 of ranks=585260rank=52500 of ranks=585260rank=52600 of ranks=585260rank=52700 of ranks=585260rank=52800 of ranks=585260rank=52900 of ranks=585260rank=53000 of ranks=585260rank=53100 of ranks=585260rank=53200 of ranks=585260rank=53300 of ranks=585260rank=53400 of ranks=585260rank=53500 of ranks=585260rank=53600 of ranks=585260rank=53700 of ranks=585260rank=53800 of ranks=585260rank=53900 of ranks=585260rank=54000 of ranks=585260rank=54100 of ranks=585260rank=54200 of ranks=585260rank=54300 of ranks=585260rank=54400 of ranks=585260rank=54500 of ranks=585260rank=54600 of ranks=585260rank=54700 of ranks=585260rank=54800 of ranks=585260rank=54900 of ranks=585260rank=55000 of ranks=585260rank=55100 of ranks=585260rank=55200 of ranks=585260rank=55300 of ranks=585260rank=55400 of ranks=585260rank=55500 of ranks=585260rank=55600 of ranks=585260rank=55700 of ranks=585260rank=55800 of ranks=585260rank=55900 of ranks=585260rank=56000 of ranks=585260rank=56100 of ranks=585260rank=56200 of ranks=585260rank=56300 of ranks=585260rank=56400 of ranks=585260rank=56500 of ranks=585260rank=56600 of ranks=585260rank=56700 of ranks=585260rank=56800 of ranks=585260rank=56900 of ranks=585260rank=57000 of ranks=585260rank=57100 of ranks=585260rank=57200 of ranks=585260rank=57300 of ranks=585260rank=57400 of ranks=585260rank=57500 of ranks=585260rank=57600 of ranks=585260rank=57700 of ranks=585260rank=57800 of ranks=585260rank=57900 of ranks=585260rank=58000 of ranks=585260rank=58100 of ranks=585260rank=58200 of ranks=585260rank=58300 of ranks=585260rank=58400 of ranks=585260rank=58500 of ranks=585260rank=58600 of ranks=585260rank=58700 of ranks=585260rank=58800 of ranks=585260rank=58900 of ranks=585260rank=59000 of ranks=585260rank=59100 of ranks=585260rank=59200 of ranks=585260rank=59300 of ranks=585260rank=59400 of ranks=585260rank=59500 of ranks=585260rank=59600 of ranks=585260rank=59700 of ranks=585260rank=59800 of ranks=585260rank=59900 of ranks=585260rank=60000 of ranks=585260rank=60100 of ranks=585260rank=60200 of ranks=585260rank=60300 of ranks=585260rank=60400 of ranks=585260rank=60500 of ranks=585260rank=60600 of ranks=585260rank=60700 of ranks=585260rank=60800 of ranks=585260rank=60900 of ranks=585260rank=61000 of ranks=585260rank=61100 of ranks=585260rank=61200 of ranks=585260rank=61300 of ranks=585260rank=61400 of ranks=585260rank=61500 of ranks=585260rank=61600 of ranks=585260rank=61700 of ranks=585260rank=61800 of ranks=585260rank=61900 of ranks=585260rank=62000 of ranks=585260rank=62100 of ranks=585260rank=62200 of ranks=585260rank=62300 of ranks=585260rank=62400 of ranks=585260rank=62500 of ranks=585260rank=62600 of ranks=585260rank=62700 of ranks=585260rank=62800 of ranks=585260rank=62900 of ranks=585260rank=63000 of ranks=585260rank=63100 of ranks=585260rank=63200 of ranks=585260rank=63300 of ranks=585260rank=63400 of ranks=585260rank=63500 of ranks=585260rank=63600 of ranks=585260rank=63700 of ranks=585260rank=63800 of ranks=585260rank=63900 of ranks=585260rank=64000 of ranks=585260rank=64100 of ranks=585260rank=64200 of ranks=585260rank=64300 of ranks=585260rank=64400 of ranks=585260rank=64500 of ranks=585260rank=64600 of ranks=585260rank=64700 of ranks=585260rank=64800 of ranks=585260rank=64900 of ranks=585260rank=65000 of ranks=585260rank=65100 of ranks=585260rank=65200 of ranks=585260rank=65300 of ranks=585260rank=65400 of ranks=585260rank=65500 of ranks=585260rank=65600 of ranks=585260rank=65700 of ranks=585260rank=65800 of ranks=585260rank=65900 of ranks=585260rank=66000 of ranks=585260rank=66100 of ranks=585260rank=66200 of ranks=585260rank=66300 of ranks=585260rank=66400 of ranks=585260rank=66500 of ranks=585260rank=66600 of ranks=585260rank=66700 of ranks=585260rank=66800 of ranks=585260rank=66900 of ranks=585260rank=67000 of ranks=585260rank=67100 of ranks=585260rank=67200 of ranks=585260rank=67300 of ranks=585260rank=67400 of ranks=585260rank=67500 of ranks=585260rank=67600 of ranks=585260rank=67700 of ranks=585260rank=67800 of ranks=585260rank=67900 of ranks=585260rank=68000 of ranks=585260rank=68100 of ranks=585260rank=68200 of ranks=585260rank=68300 of ranks=585260rank=68400 of ranks=585260rank=68500 of ranks=585260rank=68600 of ranks=585260rank=68700 of ranks=585260rank=68800 of ranks=585260rank=68900 of ranks=585260rank=69000 of ranks=585260rank=69100 of ranks=585260rank=69200 of ranks=585260rank=69300 of ranks=585260rank=69400 of ranks=585260rank=69500 of ranks=585260rank=69600 of ranks=585260rank=69700 of ranks=585260rank=69800 of ranks=585260rank=69900 of ranks=585260rank=70000 of ranks=585260rank=70100 of ranks=585260rank=70200 of ranks=585260rank=70300 of ranks=585260rank=70400 of ranks=585260rank=70500 of ranks=585260rank=70600 of ranks=585260rank=70700 of ranks=585260rank=70800 of ranks=585260rank=70900 of ranks=585260rank=71000 of ranks=585260rank=71100 of ranks=585260rank=71200 of ranks=585260rank=71300 of ranks=585260rank=71400 of ranks=585260rank=71500 of ranks=585260rank=71600 of ranks=585260rank=71700 of ranks=585260rank=71800 of ranks=585260rank=71900 of ranks=585260rank=72000 of ranks=585260rank=72100 of ranks=585260rank=72200 of ranks=585260rank=72300 of ranks=585260rank=72400 of ranks=585260rank=72500 of ranks=585260rank=72600 of ranks=585260rank=72700 of ranks=585260rank=72800 of ranks=585260rank=72900 of ranks=585260rank=73000 of ranks=585260rank=73100 of ranks=585260rank=73200 of ranks=585260rank=73300 of ranks=585260rank=73400 of ranks=585260rank=73500 of ranks=585260rank=73600 of ranks=585260rank=73700 of ranks=585260rank=73800 of ranks=585260rank=73900 of ranks=585260rank=74000 of ranks=585260rank=74100 of ranks=585260rank=74200 of ranks=585260rank=74300 of ranks=585260rank=74400 of ranks=585260rank=74500 of ranks=585260rank=74600 of ranks=585260rank=74700 of ranks=585260rank=74800 of ranks=585260rank=74900 of ranks=585260rank=75000 of ranks=585260rank=75100 of ranks=585260rank=75200 of ranks=585260rank=75300 of ranks=585260rank=75400 of ranks=585260rank=75500 of ranks=585260rank=75600 of ranks=585260rank=75700 of ranks=585260rank=75800 of ranks=585260rank=75900 of ranks=585260rank=76000 of ranks=585260rank=76100 of ranks=585260rank=76200 of ranks=585260rank=76300 of ranks=585260rank=76400 of ranks=585260rank=76500 of ranks=585260rank=76600 of ranks=585260rank=76700 of ranks=585260rank=76800 of ranks=585260rank=76900 of ranks=585260rank=77000 of ranks=585260rank=77100 of ranks=585260rank=77200 of ranks=585260rank=77300 of ranks=585260rank=77400 of ranks=585260rank=77500 of ranks=585260rank=77600 of ranks=585260rank=77700 of ranks=585260rank=77800 of ranks=585260rank=77900 of ranks=585260rank=78000 of ranks=585260rank=78100 of ranks=585260rank=78200 of ranks=585260rank=78300 of ranks=585260rank=78400 of ranks=585260rank=78500 of ranks=585260rank=78600 of ranks=585260rank=78700 of ranks=585260rank=78800 of ranks=585260rank=78900 of ranks=585260rank=79000 of ranks=585260rank=79100 of ranks=585260rank=79200 of ranks=585260rank=79300 of ranks=585260rank=79400 of ranks=585260rank=79500 of ranks=585260rank=79600 of ranks=585260rank=79700 of ranks=585260rank=79800 of ranks=585260rank=79900 of ranks=585260rank=80000 of ranks=585260rank=80100 of ranks=585260rank=80200 of ranks=585260rank=80300 of ranks=585260rank=80400 of ranks=585260rank=80500 of ranks=585260rank=80600 of ranks=585260rank=80700 of ranks=585260rank=80800 of ranks=585260rank=80900 of ranks=585260rank=81000 of ranks=585260rank=81100 of ranks=585260rank=81200 of ranks=585260rank=81300 of ranks=585260rank=81400 of ranks=585260rank=81500 of ranks=585260rank=81600 of ranks=585260rank=81700 of ranks=585260rank=81800 of ranks=585260rank=81900 of ranks=585260rank=82000 of ranks=585260rank=82100 of ranks=585260rank=82200 of ranks=585260rank=82300 of ranks=585260rank=82400 of ranks=585260rank=82500 of ranks=585260rank=82600 of ranks=585260rank=82700 of ranks=585260rank=82800 of ranks=585260rank=82900 of ranks=585260rank=83000 of ranks=585260rank=83100 of ranks=585260rank=83200 of ranks=585260rank=83300 of ranks=585260rank=83400 of ranks=585260rank=83500 of ranks=585260rank=83600 of ranks=585260rank=83700 of ranks=585260rank=83800 of ranks=585260rank=83900 of ranks=585260rank=84000 of ranks=585260rank=84100 of ranks=585260rank=84200 of ranks=585260rank=84300 of ranks=585260rank=84400 of ranks=585260rank=84500 of ranks=585260rank=84600 of ranks=585260rank=84700 of ranks=585260rank=84800 of ranks=585260rank=84900 of ranks=585260rank=85000 of ranks=585260rank=85100 of ranks=585260rank=85200 of ranks=585260rank=85300 of ranks=585260rank=85400 of ranks=585260rank=85500 of ranks=585260rank=85600 of ranks=585260rank=85700 of ranks=585260rank=85800 of ranks=585260rank=85900 of ranks=585260rank=86000 of ranks=585260rank=86100 of ranks=585260rank=86200 of ranks=585260rank=86300 of ranks=585260rank=86400 of ranks=585260rank=86500 of ranks=585260rank=86600 of ranks=585260rank=86700 of ranks=585260rank=86800 of ranks=585260rank=86900 of ranks=585260rank=87000 of ranks=585260rank=87100 of ranks=585260rank=87200 of ranks=585260rank=87300 of ranks=585260rank=87400 of ranks=585260rank=87500 of ranks=585260rank=87600 of ranks=585260rank=87700 of ranks=585260rank=87800 of ranks=585260rank=87900 of ranks=585260rank=88000 of ranks=585260rank=88100 of ranks=585260rank=88200 of ranks=585260rank=88300 of ranks=585260rank=88400 of ranks=585260rank=88500 of ranks=585260rank=88600 of ranks=585260rank=88700 of ranks=585260rank=88800 of ranks=585260rank=88900 of ranks=585260rank=89000 of ranks=585260rank=89100 of ranks=585260rank=89200 of ranks=585260rank=89300 of ranks=585260rank=89400 of ranks=585260rank=89500 of ranks=585260rank=89600 of ranks=585260rank=89700 of ranks=585260rank=89800 of ranks=585260rank=89900 of ranks=585260rank=90000 of ranks=585260rank=90100 of ranks=585260rank=90200 of ranks=585260rank=90300 of ranks=585260rank=90400 of ranks=585260rank=90500 of ranks=585260rank=90600 of ranks=585260rank=90700 of ranks=585260rank=90800 of ranks=585260rank=90900 of ranks=585260rank=91000 of ranks=585260rank=91100 of ranks=585260rank=91200 of ranks=585260rank=91300 of ranks=585260rank=91400 of ranks=585260rank=91500 of ranks=585260rank=91600 of ranks=585260rank=91700 of ranks=585260rank=91800 of ranks=585260rank=91900 of ranks=585260rank=92000 of ranks=585260rank=92100 of ranks=585260rank=92200 of ranks=585260rank=92300 of ranks=585260rank=92400 of ranks=585260rank=92500 of ranks=585260rank=92600 of ranks=585260rank=92700 of ranks=585260rank=92800 of ranks=585260rank=92900 of ranks=585260rank=93000 of ranks=585260rank=93100 of ranks=585260rank=93200 of ranks=585260rank=93300 of ranks=585260rank=93400 of ranks=585260rank=93500 of ranks=585260rank=93600 of ranks=585260rank=93700 of ranks=585260rank=93800 of ranks=585260rank=93900 of ranks=585260rank=94000 of ranks=585260rank=94100 of ranks=585260rank=94200 of ranks=585260rank=94300 of ranks=585260rank=94400 of ranks=585260rank=94500 of ranks=585260rank=94600 of ranks=585260rank=94700 of ranks=585260rank=94800 of ranks=585260rank=94900 of ranks=585260rank=95000 of ranks=585260rank=95100 of ranks=585260rank=95200 of ranks=585260rank=95300 of ranks=585260rank=95400 of ranks=585260rank=95500 of ranks=585260rank=95600 of ranks=585260rank=95700 of ranks=585260rank=95800 of ranks=585260rank=95900 of ranks=585260rank=96000 of ranks=585260rank=96100 of ranks=585260rank=96200 of ranks=585260rank=96300 of ranks=585260rank=96400 of ranks=585260rank=96500 of ranks=585260rank=96600 of ranks=585260rank=96700 of ranks=585260rank=96800 of ranks=585260rank=96900 of ranks=585260rank=97000 of ranks=585260rank=97100 of ranks=585260rank=97200 of ranks=585260rank=97300 of ranks=585260rank=97400 of ranks=585260rank=97500 of ranks=585260rank=97600 of ranks=585260rank=97700 of ranks=585260rank=97800 of ranks=585260rank=97900 of ranks=585260rank=98000 of ranks=585260rank=98100 of ranks=585260rank=98200 of ranks=585260rank=98300 of ranks=585260rank=98400 of ranks=585260rank=98500 of ranks=585260rank=98600 of ranks=585260rank=98700 of ranks=585260rank=98800 of ranks=585260rank=98900 of ranks=585260rank=99000 of ranks=585260rank=99100 of ranks=585260rank=99200 of ranks=585260rank=99300 of ranks=585260rank=99400 of ranks=585260rank=99500 of ranks=585260rank=99600 of ranks=585260rank=99700 of ranks=585260rank=99800 of ranks=585260rank=99900 of ranks=585260rank=100000 of ranks=585260rank=100100 of ranks=585260rank=100200 of ranks=585260rank=100300 of ranks=585260rank=100400 of ranks=585260rank=100500 of ranks=585260rank=100600 of ranks=585260rank=100700 of ranks=585260rank=100800 of ranks=585260rank=100900 of ranks=585260rank=101000 of ranks=585260rank=101100 of ranks=585260rank=101200 of ranks=585260rank=101300 of ranks=585260rank=101400 of ranks=585260rank=101500 of ranks=585260rank=101600 of ranks=585260rank=101700 of ranks=585260rank=101800 of ranks=585260rank=101900 of ranks=585260rank=102000 of ranks=585260rank=102100 of ranks=585260rank=102200 of ranks=585260rank=102300 of ranks=585260rank=102400 of ranks=585260rank=102500 of ranks=585260rank=102600 of ranks=585260rank=102700 of ranks=585260rank=102800 of ranks=585260rank=102900 of ranks=585260rank=103000 of ranks=585260rank=103100 of ranks=585260rank=103200 of ranks=585260rank=103300 of ranks=585260rank=103400 of ranks=585260rank=103500 of ranks=585260rank=103600 of ranks=585260rank=103700 of ranks=585260rank=103800 of ranks=585260rank=103900 of ranks=585260rank=104000 of ranks=585260rank=104100 of ranks=585260rank=104200 of ranks=585260rank=104300 of ranks=585260rank=104400 of ranks=585260rank=104500 of ranks=585260rank=104600 of ranks=585260rank=104700 of ranks=585260rank=104800 of ranks=585260rank=104900 of ranks=585260rank=105000 of ranks=585260rank=105100 of ranks=585260rank=105200 of ranks=585260rank=105300 of ranks=585260rank=105400 of ranks=585260rank=105500 of ranks=585260rank=105600 of ranks=585260rank=105700 of ranks=585260rank=105800 of ranks=585260rank=105900 of ranks=585260rank=106000 of ranks=585260rank=106100 of ranks=585260rank=106200 of ranks=585260rank=106300 of ranks=585260rank=106400 of ranks=585260rank=106500 of ranks=585260rank=106600 of ranks=585260rank=106700 of ranks=585260rank=106800 of ranks=585260rank=106900 of ranks=585260rank=107000 of ranks=585260rank=107100 of ranks=585260rank=107200 of ranks=585260rank=107300 of ranks=585260rank=107400 of ranks=585260rank=107500 of ranks=585260rank=107600 of ranks=585260rank=107700 of ranks=585260rank=107800 of ranks=585260rank=107900 of ranks=585260rank=108000 of ranks=585260rank=108100 of ranks=585260rank=108200 of ranks=585260rank=108300 of ranks=585260rank=108400 of ranks=585260rank=108500 of ranks=585260rank=108600 of ranks=585260rank=108700 of ranks=585260rank=108800 of ranks=585260rank=108900 of ranks=585260rank=109000 of ranks=585260rank=109100 of ranks=585260rank=109200 of ranks=585260rank=109300 of ranks=585260rank=109400 of ranks=585260rank=109500 of ranks=585260rank=109600 of ranks=585260rank=109700 of ranks=585260rank=109800 of ranks=585260rank=109900 of ranks=585260rank=110000 of ranks=585260rank=110100 of ranks=585260rank=110200 of ranks=585260rank=110300 of ranks=585260rank=110400 of ranks=585260rank=110500 of ranks=585260rank=110600 of ranks=585260rank=110700 of ranks=585260rank=110800 of ranks=585260rank=110900 of ranks=585260rank=111000 of ranks=585260rank=111100 of ranks=585260rank=111200 of ranks=585260rank=111300 of ranks=585260rank=111400 of ranks=585260rank=111500 of ranks=585260rank=111600 of ranks=585260rank=111700 of ranks=585260rank=111800 of ranks=585260rank=111900 of ranks=585260rank=112000 of ranks=585260rank=112100 of ranks=585260rank=112200 of ranks=585260rank=112300 of ranks=585260rank=112400 of ranks=585260rank=112500 of ranks=585260rank=112600 of ranks=585260rank=112700 of ranks=585260rank=112800 of ranks=585260rank=112900 of ranks=585260rank=113000 of ranks=585260rank=113100 of ranks=585260rank=113200 of ranks=585260rank=113300 of ranks=585260rank=113400 of ranks=585260rank=113500 of ranks=585260rank=113600 of ranks=585260rank=113700 of ranks=585260rank=113800 of ranks=585260rank=113900 of ranks=585260rank=114000 of ranks=585260rank=114100 of ranks=585260rank=114200 of ranks=585260rank=114300 of ranks=585260rank=114400 of ranks=585260rank=114500 of ranks=585260rank=114600 of ranks=585260rank=114700 of ranks=585260rank=114800 of ranks=585260rank=114900 of ranks=585260rank=115000 of ranks=585260rank=115100 of ranks=585260rank=115200 of ranks=585260rank=115300 of ranks=585260rank=115400 of ranks=585260rank=115500 of ranks=585260rank=115600 of ranks=585260rank=115700 of ranks=585260rank=115800 of ranks=585260rank=115900 of ranks=585260rank=116000 of ranks=585260rank=116100 of ranks=585260rank=116200 of ranks=585260rank=116300 of ranks=585260rank=116400 of ranks=585260rank=116500 of ranks=585260rank=116600 of ranks=585260rank=116700 of ranks=585260rank=116800 of ranks=585260rank=116900 of ranks=585260rank=117000 of ranks=585260rank=117100 of ranks=585260rank=117200 of ranks=585260rank=117300 of ranks=585260rank=117400 of ranks=585260rank=117500 of ranks=585260rank=117600 of ranks=585260rank=117700 of ranks=585260rank=117800 of ranks=585260rank=117900 of ranks=585260rank=118000 of ranks=585260rank=118100 of ranks=585260rank=118200 of ranks=585260rank=118300 of ranks=585260rank=118400 of ranks=585260rank=118500 of ranks=585260rank=118600 of ranks=585260rank=118700 of ranks=585260rank=118800 of ranks=585260rank=118900 of ranks=585260rank=119000 of ranks=585260rank=119100 of ranks=585260rank=119200 of ranks=585260rank=119300 of ranks=585260rank=119400 of ranks=585260rank=119500 of ranks=585260rank=119600 of ranks=585260rank=119700 of ranks=585260rank=119800 of ranks=585260rank=119900 of ranks=585260rank=120000 of ranks=585260rank=120100 of ranks=585260rank=120200 of ranks=585260rank=120300 of ranks=585260rank=120400 of ranks=585260rank=120500 of ranks=585260rank=120600 of ranks=585260rank=120700 of ranks=585260rank=120800 of ranks=585260rank=120900 of ranks=585260rank=121000 of ranks=585260rank=121100 of ranks=585260rank=121200 of ranks=585260rank=121300 of ranks=585260rank=121400 of ranks=585260rank=121500 of ranks=585260rank=121600 of ranks=585260rank=121700 of ranks=585260rank=121800 of ranks=585260rank=121900 of ranks=585260rank=122000 of ranks=585260rank=122100 of ranks=585260rank=122200 of ranks=585260rank=122300 of ranks=585260rank=122400 of ranks=585260rank=122500 of ranks=585260rank=122600 of ranks=585260rank=122700 of ranks=585260rank=122800 of ranks=585260rank=122900 of ranks=585260rank=123000 of ranks=585260rank=123100 of ranks=585260rank=123200 of ranks=585260rank=123300 of ranks=585260rank=123400 of ranks=585260rank=123500 of ranks=585260rank=123600 of ranks=585260rank=123700 of ranks=585260rank=123800 of ranks=585260rank=123900 of ranks=585260rank=124000 of ranks=585260rank=124100 of ranks=585260rank=124200 of ranks=585260rank=124300 of ranks=585260rank=124400 of ranks=585260rank=124500 of ranks=585260rank=124600 of ranks=585260rank=124700 of ranks=585260rank=124800 of ranks=585260rank=124900 of ranks=585260rank=125000 of ranks=585260rank=125100 of ranks=585260rank=125200 of ranks=585260rank=125300 of ranks=585260rank=125400 of ranks=585260rank=125500 of ranks=585260rank=125600 of ranks=585260rank=125700 of ranks=585260rank=125800 of ranks=585260rank=125900 of ranks=585260rank=126000 of ranks=585260rank=126100 of ranks=585260rank=126200 of ranks=585260rank=126300 of ranks=585260rank=126400 of ranks=585260rank=126500 of ranks=585260rank=126600 of ranks=585260rank=126700 of ranks=585260rank=126800 of ranks=585260rank=126900 of ranks=585260rank=127000 of ranks=585260rank=127100 of ranks=585260rank=127200 of ranks=585260rank=127300 of ranks=585260rank=127400 of ranks=585260rank=127500 of ranks=585260rank=127600 of ranks=585260rank=127700 of ranks=585260rank=127800 of ranks=585260rank=127900 of ranks=585260rank=128000 of ranks=585260rank=128100 of ranks=585260rank=128200 of ranks=585260rank=128300 of ranks=585260rank=128400 of ranks=585260rank=128500 of ranks=585260rank=128600 of ranks=585260rank=128700 of ranks=585260rank=128800 of ranks=585260rank=128900 of ranks=585260rank=129000 of ranks=585260rank=129100 of ranks=585260rank=129200 of ranks=585260rank=129300 of ranks=585260rank=129400 of ranks=585260rank=129500 of ranks=585260rank=129600 of ranks=585260rank=129700 of ranks=585260rank=129800 of ranks=585260rank=129900 of ranks=585260rank=130000 of ranks=585260rank=130100 of ranks=585260rank=130200 of ranks=585260rank=130300 of ranks=585260rank=130400 of ranks=585260rank=130500 of ranks=585260rank=130600 of ranks=585260rank=130700 of ranks=585260rank=130800 of ranks=585260rank=130900 of ranks=585260rank=131000 of ranks=585260rank=131100 of ranks=585260rank=131200 of ranks=585260rank=131300 of ranks=585260rank=131400 of ranks=585260rank=131500 of ranks=585260rank=131600 of ranks=585260rank=131700 of ranks=585260rank=131800 of ranks=585260rank=131900 of ranks=585260rank=132000 of ranks=585260rank=132100 of ranks=585260rank=132200 of ranks=585260rank=132300 of ranks=585260rank=132400 of ranks=585260rank=132500 of ranks=585260rank=132600 of ranks=585260rank=132700 of ranks=585260rank=132800 of ranks=585260rank=132900 of ranks=585260rank=133000 of ranks=585260rank=133100 of ranks=585260rank=133200 of ranks=585260rank=133300 of ranks=585260rank=133400 of ranks=585260rank=133500 of ranks=585260rank=133600 of ranks=585260rank=133700 of ranks=585260rank=133800 of ranks=585260rank=133900 of ranks=585260rank=134000 of ranks=585260rank=134100 of ranks=585260rank=134200 of ranks=585260rank=134300 of ranks=585260rank=134400 of ranks=585260rank=134500 of ranks=585260rank=134600 of ranks=585260rank=134700 of ranks=585260rank=134800 of ranks=585260rank=134900 of ranks=585260rank=135000 of ranks=585260rank=135100 of ranks=585260rank=135200 of ranks=585260rank=135300 of ranks=585260rank=135400 of ranks=585260rank=135500 of ranks=585260rank=135600 of ranks=585260rank=135700 of ranks=585260rank=135800 of ranks=585260rank=135900 of ranks=585260rank=136000 of ranks=585260rank=136100 of ranks=585260rank=136200 of ranks=585260rank=136300 of ranks=585260rank=136400 of ranks=585260rank=136500 of ranks=585260rank=136600 of ranks=585260rank=136700 of ranks=585260rank=136800 of ranks=585260rank=136900 of ranks=585260rank=137000 of ranks=585260rank=137100 of ranks=585260rank=137200 of ranks=585260rank=137300 of ranks=585260rank=137400 of ranks=585260rank=137500 of ranks=585260rank=137600 of ranks=585260rank=137700 of ranks=585260rank=137800 of ranks=585260rank=137900 of ranks=585260rank=138000 of ranks=585260rank=138100 of ranks=585260rank=138200 of ranks=585260rank=138300 of ranks=585260rank=138400 of ranks=585260rank=138500 of ranks=585260rank=138600 of ranks=585260rank=138700 of ranks=585260rank=138800 of ranks=585260rank=138900 of ranks=585260rank=139000 of ranks=585260rank=139100 of ranks=585260rank=139200 of ranks=585260rank=139300 of ranks=585260rank=139400 of ranks=585260rank=139500 of ranks=585260rank=139600 of ranks=585260rank=139700 of ranks=585260rank=139800 of ranks=585260rank=139900 of ranks=585260rank=140000 of ranks=585260rank=140100 of ranks=585260rank=140200 of ranks=585260rank=140300 of ranks=585260rank=140400 of ranks=585260rank=140500 of ranks=585260rank=140600 of ranks=585260rank=140700 of ranks=585260rank=140800 of ranks=585260rank=140900 of ranks=585260rank=141000 of ranks=585260rank=141100 of ranks=585260rank=141200 of ranks=585260rank=141300 of ranks=585260rank=141400 of ranks=585260rank=141500 of ranks=585260rank=141600 of ranks=585260rank=141700 of ranks=585260rank=141800 of ranks=585260rank=141900 of ranks=585260rank=142000 of ranks=585260rank=142100 of ranks=585260rank=142200 of ranks=585260rank=142300 of ranks=585260rank=142400 of ranks=585260rank=142500 of ranks=585260rank=142600 of ranks=585260rank=142700 of ranks=585260rank=142800 of ranks=585260rank=142900 of ranks=585260rank=143000 of ranks=585260rank=143100 of ranks=585260rank=143200 of ranks=585260rank=143300 of ranks=585260rank=143400 of ranks=585260rank=143500 of ranks=585260rank=143600 of ranks=585260rank=143700 of ranks=585260rank=143800 of ranks=585260rank=143900 of ranks=585260rank=144000 of ranks=585260rank=144100 of ranks=585260rank=144200 of ranks=585260rank=144300 of ranks=585260rank=144400 of ranks=585260rank=144500 of ranks=585260rank=144600 of ranks=585260rank=144700 of ranks=585260rank=144800 of ranks=585260rank=144900 of ranks=585260rank=145000 of ranks=585260rank=145100 of ranks=585260rank=145200 of ranks=585260rank=145300 of ranks=585260rank=145400 of ranks=585260rank=145500 of ranks=585260rank=145600 of ranks=585260rank=145700 of ranks=585260rank=145800 of ranks=585260rank=145900 of ranks=585260rank=146000 of ranks=585260rank=146100 of ranks=585260rank=146200 of ranks=585260rank=146300 of ranks=585260rank=146400 of ranks=585260rank=146500 of ranks=585260rank=146600 of ranks=585260rank=146700 of ranks=585260rank=146800 of ranks=585260rank=146900 of ranks=585260rank=147000 of ranks=585260rank=147100 of ranks=585260rank=147200 of ranks=585260rank=147300 of ranks=585260rank=147400 of ranks=585260rank=147500 of ranks=585260rank=147600 of ranks=585260rank=147700 of ranks=585260rank=147800 of ranks=585260rank=147900 of ranks=585260rank=148000 of ranks=585260rank=148100 of ranks=585260rank=148200 of ranks=585260rank=148300 of ranks=585260rank=148400 of ranks=585260rank=148500 of ranks=585260rank=148600 of ranks=585260rank=148700 of ranks=585260rank=148800 of ranks=585260rank=148900 of ranks=585260rank=149000 of ranks=585260rank=149100 of ranks=585260rank=149200 of ranks=585260rank=149300 of ranks=585260rank=149400 of ranks=585260rank=149500 of ranks=585260rank=149600 of ranks=585260rank=149700 of ranks=585260rank=149800 of ranks=585260rank=149900 of ranks=585260rank=150000 of ranks=585260rank=150100 of ranks=585260rank=150200 of ranks=585260rank=150300 of ranks=585260rank=150400 of ranks=585260rank=150500 of ranks=585260rank=150600 of ranks=585260rank=150700 of ranks=585260rank=150800 of ranks=585260rank=150900 of ranks=585260rank=151000 of ranks=585260rank=151100 of ranks=585260rank=151200 of ranks=585260rank=151300 of ranks=585260rank=151400 of ranks=585260rank=151500 of ranks=585260rank=151600 of ranks=585260rank=151700 of ranks=585260rank=151800 of ranks=585260rank=151900 of ranks=585260rank=152000 of ranks=585260rank=152100 of ranks=585260rank=152200 of ranks=585260rank=152300 of ranks=585260rank=152400 of ranks=585260rank=152500 of ranks=585260rank=152600 of ranks=585260rank=152700 of ranks=585260rank=152800 of ranks=585260rank=152900 of ranks=585260rank=153000 of ranks=585260rank=153100 of ranks=585260rank=153200 of ranks=585260rank=153300 of ranks=585260rank=153400 of ranks=585260rank=153500 of ranks=585260rank=153600 of ranks=585260rank=153700 of ranks=585260rank=153800 of ranks=585260rank=153900 of ranks=585260rank=154000 of ranks=585260rank=154100 of ranks=585260rank=154200 of ranks=585260rank=154300 of ranks=585260rank=154400 of ranks=585260rank=154500 of ranks=585260rank=154600 of ranks=585260rank=154700 of ranks=585260rank=154800 of ranks=585260rank=154900 of ranks=585260rank=155000 of ranks=585260rank=155100 of ranks=585260rank=155200 of ranks=585260rank=155300 of ranks=585260rank=155400 of ranks=585260rank=155500 of ranks=585260rank=155600 of ranks=585260rank=155700 of ranks=585260rank=155800 of ranks=585260rank=155900 of ranks=585260rank=156000 of ranks=585260rank=156100 of ranks=585260rank=156200 of ranks=585260rank=156300 of ranks=585260rank=156400 of ranks=585260rank=156500 of ranks=585260rank=156600 of ranks=585260rank=156700 of ranks=585260rank=156800 of ranks=585260rank=156900 of ranks=585260rank=157000 of ranks=585260rank=157100 of ranks=585260rank=157200 of ranks=585260rank=157300 of ranks=585260rank=157400 of ranks=585260rank=157500 of ranks=585260rank=157600 of ranks=585260rank=157700 of ranks=585260rank=157800 of ranks=585260rank=157900 of ranks=585260rank=158000 of ranks=585260rank=158100 of ranks=585260rank=158200 of ranks=585260rank=158300 of ranks=585260rank=158400 of ranks=585260rank=158500 of ranks=585260rank=158600 of ranks=585260rank=158700 of ranks=585260rank=158800 of ranks=585260rank=158900 of ranks=585260rank=159000 of ranks=585260rank=159100 of ranks=585260rank=159200 of ranks=585260rank=159300 of ranks=585260rank=159400 of ranks=585260rank=159500 of ranks=585260rank=159600 of ranks=585260rank=159700 of ranks=585260rank=159800 of ranks=585260rank=159900 of ranks=585260rank=160000 of ranks=585260rank=160100 of ranks=585260rank=160200 of ranks=585260rank=160300 of ranks=585260rank=160400 of ranks=585260rank=160500 of ranks=585260rank=160600 of ranks=585260rank=160700 of ranks=585260rank=160800 of ranks=585260rank=160900 of ranks=585260rank=161000 of ranks=585260rank=161100 of ranks=585260rank=161200 of ranks=585260rank=161300 of ranks=585260rank=161400 of ranks=585260rank=161500 of ranks=585260rank=161600 of ranks=585260rank=161700 of ranks=585260rank=161800 of ranks=585260rank=161900 of ranks=585260rank=162000 of ranks=585260rank=162100 of ranks=585260rank=162200 of ranks=585260rank=162300 of ranks=585260rank=162400 of ranks=585260rank=162500 of ranks=585260rank=162600 of ranks=585260rank=162700 of ranks=585260rank=162800 of ranks=585260rank=162900 of ranks=585260rank=163000 of ranks=585260rank=163100 of ranks=585260rank=163200 of ranks=585260rank=163300 of ranks=585260rank=163400 of ranks=585260rank=163500 of ranks=585260rank=163600 of ranks=585260rank=163700 of ranks=585260rank=163800 of ranks=585260rank=163900 of ranks=585260rank=164000 of ranks=585260rank=164100 of ranks=585260rank=164200 of ranks=585260rank=164300 of ranks=585260rank=164400 of ranks=585260rank=164500 of ranks=585260rank=164600 of ranks=585260rank=164700 of ranks=585260rank=164800 of ranks=585260rank=164900 of ranks=585260rank=165000 of ranks=585260rank=165100 of ranks=585260rank=165200 of ranks=585260rank=165300 of ranks=585260rank=165400 of ranks=585260rank=165500 of ranks=585260rank=165600 of ranks=585260rank=165700 of ranks=585260rank=165800 of ranks=585260rank=165900 of ranks=585260rank=166000 of ranks=585260rank=166100 of ranks=585260rank=166200 of ranks=585260rank=166300 of ranks=585260rank=166400 of ranks=585260rank=166500 of ranks=585260rank=166600 of ranks=585260rank=166700 of ranks=585260rank=166800 of ranks=585260rank=166900 of ranks=585260rank=167000 of ranks=585260rank=167100 of ranks=585260rank=167200 of ranks=585260rank=167300 of ranks=585260rank=167400 of ranks=585260rank=167500 of ranks=585260rank=167600 of ranks=585260rank=167700 of ranks=585260rank=167800 of ranks=585260rank=167900 of ranks=585260rank=168000 of ranks=585260rank=168100 of ranks=585260rank=168200 of ranks=585260rank=168300 of ranks=585260rank=168400 of ranks=585260rank=168500 of ranks=585260rank=168600 of ranks=585260rank=168700 of ranks=585260rank=168800 of ranks=585260rank=168900 of ranks=585260rank=169000 of ranks=585260rank=169100 of ranks=585260rank=169200 of ranks=585260rank=169300 of ranks=585260rank=169400 of ranks=585260rank=169500 of ranks=585260rank=169600 of ranks=585260rank=169700 of ranks=585260rank=169800 of ranks=585260rank=169900 of ranks=585260rank=170000 of ranks=585260rank=170100 of ranks=585260rank=170200 of ranks=585260rank=170300 of ranks=585260rank=170400 of ranks=585260rank=170500 of ranks=585260rank=170600 of ranks=585260rank=170700 of ranks=585260rank=170800 of ranks=585260rank=170900 of ranks=585260rank=171000 of ranks=585260rank=171100 of ranks=585260rank=171200 of ranks=585260rank=171300 of ranks=585260rank=171400 of ranks=585260rank=171500 of ranks=585260rank=171600 of ranks=585260rank=171700 of ranks=585260rank=171800 of ranks=585260rank=171900 of ranks=585260rank=172000 of ranks=585260rank=172100 of ranks=585260rank=172200 of ranks=585260rank=172300 of ranks=585260rank=172400 of ranks=585260rank=172500 of ranks=585260rank=172600 of ranks=585260rank=172700 of ranks=585260rank=172800 of ranks=585260rank=172900 of ranks=585260rank=173000 of ranks=585260rank=173100 of ranks=585260rank=173200 of ranks=585260rank=173300 of ranks=585260rank=173400 of ranks=585260rank=173500 of ranks=585260rank=173600 of ranks=585260rank=173700 of ranks=585260rank=173800 of ranks=585260rank=173900 of ranks=585260rank=174000 of ranks=585260rank=174100 of ranks=585260rank=174200 of ranks=585260rank=174300 of ranks=585260rank=174400 of ranks=585260rank=174500 of ranks=585260rank=174600 of ranks=585260rank=174700 of ranks=585260rank=174800 of ranks=585260rank=174900 of ranks=585260rank=175000 of ranks=585260rank=175100 of ranks=585260rank=175200 of ranks=585260rank=175300 of ranks=585260rank=175400 of ranks=585260rank=175500 of ranks=585260rank=175600 of ranks=585260rank=175700 of ranks=585260rank=175800 of ranks=585260rank=175900 of ranks=585260rank=176000 of ranks=585260rank=176100 of ranks=585260rank=176200 of ranks=585260rank=176300 of ranks=585260rank=176400 of ranks=585260rank=176500 of ranks=585260rank=176600 of ranks=585260rank=176700 of ranks=585260rank=176800 of ranks=585260rank=176900 of ranks=585260rank=177000 of ranks=585260rank=177100 of ranks=585260rank=177200 of ranks=585260rank=177300 of ranks=585260rank=177400 of ranks=585260rank=177500 of ranks=585260rank=177600 of ranks=585260rank=177700 of ranks=585260rank=177800 of ranks=585260rank=177900 of ranks=585260rank=178000 of ranks=585260rank=178100 of ranks=585260rank=178200 of ranks=585260rank=178300 of ranks=585260rank=178400 of ranks=585260rank=178500 of ranks=585260rank=178600 of ranks=585260rank=178700 of ranks=585260rank=178800 of ranks=585260rank=178900 of ranks=585260rank=179000 of ranks=585260rank=179100 of ranks=585260rank=179200 of ranks=585260rank=179300 of ranks=585260rank=179400 of ranks=585260rank=179500 of ranks=585260rank=179600 of ranks=585260rank=179700 of ranks=585260rank=179800 of ranks=585260rank=179900 of ranks=585260rank=180000 of ranks=585260rank=180100 of ranks=585260rank=180200 of ranks=585260rank=180300 of ranks=585260rank=180400 of ranks=585260rank=180500 of ranks=585260rank=180600 of ranks=585260rank=180700 of ranks=585260rank=180800 of ranks=585260rank=180900 of ranks=585260rank=181000 of ranks=585260rank=181100 of ranks=585260rank=181200 of ranks=585260rank=181300 of ranks=585260rank=181400 of ranks=585260rank=181500 of ranks=585260rank=181600 of ranks=585260rank=181700 of ranks=585260rank=181800 of ranks=585260rank=181900 of ranks=585260rank=182000 of ranks=585260rank=182100 of ranks=585260rank=182200 of ranks=585260rank=182300 of ranks=585260rank=182400 of ranks=585260rank=182500 of ranks=585260rank=182600 of ranks=585260rank=182700 of ranks=585260rank=182800 of ranks=585260rank=182900 of ranks=585260rank=183000 of ranks=585260rank=183100 of ranks=585260rank=183200 of ranks=585260rank=183300 of ranks=585260rank=183400 of ranks=585260rank=183500 of ranks=585260rank=183600 of ranks=585260rank=183700 of ranks=585260rank=183800 of ranks=585260rank=183900 of ranks=585260rank=184000 of ranks=585260rank=184100 of ranks=585260rank=184200 of ranks=585260rank=184300 of ranks=585260rank=184400 of ranks=585260rank=184500 of ranks=585260rank=184600 of ranks=585260rank=184700 of ranks=585260rank=184800 of ranks=585260rank=184900 of ranks=585260rank=185000 of ranks=585260rank=185100 of ranks=585260rank=185200 of ranks=585260rank=185300 of ranks=585260rank=185400 of ranks=585260rank=185500 of ranks=585260rank=185600 of ranks=585260rank=185700 of ranks=585260rank=185800 of ranks=585260rank=185900 of ranks=585260rank=186000 of ranks=585260rank=186100 of ranks=585260rank=186200 of ranks=585260rank=186300 of ranks=585260rank=186400 of ranks=585260rank=186500 of ranks=585260rank=186600 of ranks=585260rank=186700 of ranks=585260rank=186800 of ranks=585260rank=186900 of ranks=585260rank=187000 of ranks=585260rank=187100 of ranks=585260rank=187200 of ranks=585260rank=187300 of ranks=585260rank=187400 of ranks=585260rank=187500 of ranks=585260rank=187600 of ranks=585260rank=187700 of ranks=585260rank=187800 of ranks=585260rank=187900 of ranks=585260rank=188000 of ranks=585260rank=188100 of ranks=585260rank=188200 of ranks=585260rank=188300 of ranks=585260rank=188400 of ranks=585260rank=188500 of ranks=585260rank=188600 of ranks=585260rank=188700 of ranks=585260rank=188800 of ranks=585260rank=188900 of ranks=585260rank=189000 of ranks=585260rank=189100 of ranks=585260rank=189200 of ranks=585260rank=189300 of ranks=585260rank=189400 of ranks=585260rank=189500 of ranks=585260rank=189600 of ranks=585260rank=189700 of ranks=585260rank=189800 of ranks=585260rank=189900 of ranks=585260rank=190000 of ranks=585260rank=190100 of ranks=585260rank=190200 of ranks=585260rank=190300 of ranks=585260rank=190400 of ranks=585260rank=190500 of ranks=585260rank=190600 of ranks=585260rank=190700 of ranks=585260rank=190800 of ranks=585260rank=190900 of ranks=585260rank=191000 of ranks=585260rank=191100 of ranks=585260rank=191200 of ranks=585260rank=191300 of ranks=585260rank=191400 of ranks=585260rank=191500 of ranks=585260rank=191600 of ranks=585260rank=191700 of ranks=585260rank=191800 of ranks=585260rank=191900 of ranks=585260rank=192000 of ranks=585260rank=192100 of ranks=585260rank=192200 of ranks=585260rank=192300 of ranks=585260rank=192400 of ranks=585260rank=192500 of ranks=585260rank=192600 of ranks=585260rank=192700 of ranks=585260rank=192800 of ranks=585260rank=192900 of ranks=585260rank=193000 of ranks=585260rank=193100 of ranks=585260rank=193200 of ranks=585260rank=193300 of ranks=585260rank=193400 of ranks=585260rank=193500 of ranks=585260rank=193600 of ranks=585260rank=193700 of ranks=585260rank=193800 of ranks=585260rank=193900 of ranks=585260rank=194000 of ranks=585260rank=194100 of ranks=585260rank=194200 of ranks=585260rank=194300 of ranks=585260rank=194400 of ranks=585260rank=194500 of ranks=585260rank=194600 of ranks=585260rank=194700 of ranks=585260rank=194800 of ranks=585260rank=194900 of ranks=585260rank=195000 of ranks=585260rank=195100 of ranks=585260rank=195200 of ranks=585260rank=195300 of ranks=585260rank=195400 of ranks=585260rank=195500 of ranks=585260rank=195600 of ranks=585260rank=195700 of ranks=585260rank=195800 of ranks=585260rank=195900 of ranks=585260rank=196000 of ranks=585260rank=196100 of ranks=585260rank=196200 of ranks=585260rank=196300 of ranks=585260rank=196400 of ranks=585260rank=196500 of ranks=585260rank=196600 of ranks=585260rank=196700 of ranks=585260rank=196800 of ranks=585260rank=196900 of ranks=585260rank=197000 of ranks=585260rank=197100 of ranks=585260rank=197200 of ranks=585260rank=197300 of ranks=585260rank=197400 of ranks=585260rank=197500 of ranks=585260rank=197600 of ranks=585260rank=197700 of ranks=585260rank=197800 of ranks=585260rank=197900 of ranks=585260rank=198000 of ranks=585260rank=198100 of ranks=585260rank=198200 of ranks=585260rank=198300 of ranks=585260rank=198400 of ranks=585260rank=198500 of ranks=585260rank=198600 of ranks=585260rank=198700 of ranks=585260rank=198800 of ranks=585260rank=198900 of ranks=585260rank=199000 of ranks=585260rank=199100 of ranks=585260rank=199200 of ranks=585260rank=199300 of ranks=585260rank=199400 of ranks=585260rank=199500 of ranks=585260rank=199600 of ranks=585260rank=199700 of ranks=585260rank=199800 of ranks=585260rank=199900 of ranks=585260rank=200000 of ranks=585260rank=200100 of ranks=585260rank=200200 of ranks=585260rank=200300 of ranks=585260rank=200400 of ranks=585260rank=200500 of ranks=585260rank=200600 of ranks=585260rank=200700 of ranks=585260rank=200800 of ranks=585260rank=200900 of ranks=585260rank=201000 of ranks=585260rank=201100 of ranks=585260rank=201200 of ranks=585260rank=201300 of ranks=585260rank=201400 of ranks=585260rank=201500 of ranks=585260rank=201600 of ranks=585260rank=201700 of ranks=585260rank=201800 of ranks=585260rank=201900 of ranks=585260rank=202000 of ranks=585260rank=202100 of ranks=585260rank=202200 of ranks=585260rank=202300 of ranks=585260rank=202400 of ranks=585260rank=202500 of ranks=585260rank=202600 of ranks=585260rank=202700 of ranks=585260rank=202800 of ranks=585260rank=202900 of ranks=585260rank=203000 of ranks=585260rank=203100 of ranks=585260rank=203200 of ranks=585260rank=203300 of ranks=585260rank=203400 of ranks=585260rank=203500 of ranks=585260rank=203600 of ranks=585260rank=203700 of ranks=585260rank=203800 of ranks=585260rank=203900 of ranks=585260rank=204000 of ranks=585260rank=204100 of ranks=585260rank=204200 of ranks=585260rank=204300 of ranks=585260rank=204400 of ranks=585260rank=204500 of ranks=585260rank=204600 of ranks=585260rank=204700 of ranks=585260rank=204800 of ranks=585260rank=204900 of ranks=585260rank=205000 of ranks=585260rank=205100 of ranks=585260rank=205200 of ranks=585260rank=205300 of ranks=585260rank=205400 of ranks=585260rank=205500 of ranks=585260rank=205600 of ranks=585260rank=205700 of ranks=585260rank=205800 of ranks=585260rank=205900 of ranks=585260rank=206000 of ranks=585260rank=206100 of ranks=585260rank=206200 of ranks=585260rank=206300 of ranks=585260rank=206400 of ranks=585260rank=206500 of ranks=585260rank=206600 of ranks=585260rank=206700 of ranks=585260rank=206800 of ranks=585260rank=206900 of ranks=585260rank=207000 of ranks=585260rank=207100 of ranks=585260rank=207200 of ranks=585260rank=207300 of ranks=585260rank=207400 of ranks=585260rank=207500 of ranks=585260rank=207600 of ranks=585260rank=207700 of ranks=585260rank=207800 of ranks=585260rank=207900 of ranks=585260rank=208000 of ranks=585260rank=208100 of ranks=585260rank=208200 of ranks=585260rank=208300 of ranks=585260rank=208400 of ranks=585260rank=208500 of ranks=585260rank=208600 of ranks=585260rank=208700 of ranks=585260rank=208800 of ranks=585260rank=208900 of ranks=585260rank=209000 of ranks=585260rank=209100 of ranks=585260rank=209200 of ranks=585260rank=209300 of ranks=585260rank=209400 of ranks=585260rank=209500 of ranks=585260rank=209600 of ranks=585260rank=209700 of ranks=585260rank=209800 of ranks=585260rank=209900 of ranks=585260rank=210000 of ranks=585260rank=210100 of ranks=585260rank=210200 of ranks=585260rank=210300 of ranks=585260rank=210400 of ranks=585260rank=210500 of ranks=585260rank=210600 of ranks=585260rank=210700 of ranks=585260rank=210800 of ranks=585260rank=210900 of ranks=585260rank=211000 of ranks=585260rank=211100 of ranks=585260rank=211200 of ranks=585260rank=211300 of ranks=585260rank=211400 of ranks=585260rank=211500 of ranks=585260rank=211600 of ranks=585260rank=211700 of ranks=585260rank=211800 of ranks=585260rank=211900 of ranks=585260rank=212000 of ranks=585260rank=212100 of ranks=585260rank=212200 of ranks=585260rank=212300 of ranks=585260rank=212400 of ranks=585260rank=212500 of ranks=585260rank=212600 of ranks=585260rank=212700 of ranks=585260rank=212800 of ranks=585260rank=212900 of ranks=585260rank=213000 of ranks=585260rank=213100 of ranks=585260rank=213200 of ranks=585260rank=213300 of ranks=585260rank=213400 of ranks=585260rank=213500 of ranks=585260rank=213600 of ranks=585260rank=213700 of ranks=585260rank=213800 of ranks=585260rank=213900 of ranks=585260rank=214000 of ranks=585260rank=214100 of ranks=585260rank=214200 of ranks=585260rank=214300 of ranks=585260rank=214400 of ranks=585260rank=214500 of ranks=585260rank=214600 of ranks=585260rank=214700 of ranks=585260rank=214800 of ranks=585260rank=214900 of ranks=585260rank=215000 of ranks=585260rank=215100 of ranks=585260rank=215200 of ranks=585260rank=215300 of ranks=585260rank=215400 of ranks=585260rank=215500 of ranks=585260rank=215600 of ranks=585260rank=215700 of ranks=585260rank=215800 of ranks=585260rank=215900 of ranks=585260rank=216000 of ranks=585260rank=216100 of ranks=585260rank=216200 of ranks=585260rank=216300 of ranks=585260rank=216400 of ranks=585260rank=216500 of ranks=585260rank=216600 of ranks=585260rank=216700 of ranks=585260rank=216800 of ranks=585260rank=216900 of ranks=585260rank=217000 of ranks=585260rank=217100 of ranks=585260rank=217200 of ranks=585260rank=217300 of ranks=585260rank=217400 of ranks=585260rank=217500 of ranks=585260rank=217600 of ranks=585260rank=217700 of ranks=585260rank=217800 of ranks=585260rank=217900 of ranks=585260rank=218000 of ranks=585260rank=218100 of ranks=585260rank=218200 of ranks=585260rank=218300 of ranks=585260rank=218400 of ranks=585260rank=218500 of ranks=585260rank=218600 of ranks=585260rank=218700 of ranks=585260rank=218800 of ranks=585260rank=218900 of ranks=585260rank=219000 of ranks=585260rank=219100 of ranks=585260rank=219200 of ranks=585260rank=219300 of ranks=585260rank=219400 of ranks=585260rank=219500 of ranks=585260rank=219600 of ranks=585260rank=219700 of ranks=585260rank=219800 of ranks=585260rank=219900 of ranks=585260rank=220000 of ranks=585260rank=220100 of ranks=585260rank=220200 of ranks=585260rank=220300 of ranks=585260rank=220400 of ranks=585260rank=220500 of ranks=585260rank=220600 of ranks=585260rank=220700 of ranks=585260rank=220800 of ranks=585260rank=220900 of ranks=585260rank=221000 of ranks=585260rank=221100 of ranks=585260rank=221200 of ranks=585260rank=221300 of ranks=585260rank=221400 of ranks=585260rank=221500 of ranks=585260rank=221600 of ranks=585260rank=221700 of ranks=585260rank=221800 of ranks=585260rank=221900 of ranks=585260rank=222000 of ranks=585260rank=222100 of ranks=585260rank=222200 of ranks=585260rank=222300 of ranks=585260rank=222400 of ranks=585260rank=222500 of ranks=585260rank=222600 of ranks=585260rank=222700 of ranks=585260rank=222800 of ranks=585260rank=222900 of ranks=585260rank=223000 of ranks=585260rank=223100 of ranks=585260rank=223200 of ranks=585260rank=223300 of ranks=585260rank=223400 of ranks=585260rank=223500 of ranks=585260rank=223600 of ranks=585260rank=223700 of ranks=585260rank=223800 of ranks=585260rank=223900 of ranks=585260rank=224000 of ranks=585260rank=224100 of ranks=585260rank=224200 of ranks=585260rank=224300 of ranks=585260rank=224400 of ranks=585260rank=224500 of ranks=585260rank=224600 of ranks=585260rank=224700 of ranks=585260rank=224800 of ranks=585260rank=224900 of ranks=585260rank=225000 of ranks=585260rank=225100 of ranks=585260rank=225200 of ranks=585260rank=225300 of ranks=585260rank=225400 of ranks=585260rank=225500 of ranks=585260rank=225600 of ranks=585260rank=225700 of ranks=585260rank=225800 of ranks=585260rank=225900 of ranks=585260rank=226000 of ranks=585260rank=226100 of ranks=585260rank=226200 of ranks=585260rank=226300 of ranks=585260rank=226400 of ranks=585260rank=226500 of ranks=585260rank=226600 of ranks=585260rank=226700 of ranks=585260rank=226800 of ranks=585260rank=226900 of ranks=585260rank=227000 of ranks=585260rank=227100 of ranks=585260rank=227200 of ranks=585260rank=227300 of ranks=585260rank=227400 of ranks=585260rank=227500 of ranks=585260rank=227600 of ranks=585260rank=227700 of ranks=585260rank=227800 of ranks=585260rank=227900 of ranks=585260rank=228000 of ranks=585260rank=228100 of ranks=585260rank=228200 of ranks=585260rank=228300 of ranks=585260rank=228400 of ranks=585260rank=228500 of ranks=585260rank=228600 of ranks=585260rank=228700 of ranks=585260rank=228800 of ranks=585260rank=228900 of ranks=585260rank=229000 of ranks=585260rank=229100 of ranks=585260rank=229200 of ranks=585260rank=229300 of ranks=585260rank=229400 of ranks=585260rank=229500 of ranks=585260rank=229600 of ranks=585260rank=229700 of ranks=585260rank=229800 of ranks=585260rank=229900 of ranks=585260rank=230000 of ranks=585260rank=230100 of ranks=585260rank=230200 of ranks=585260rank=230300 of ranks=585260rank=230400 of ranks=585260rank=230500 of ranks=585260rank=230600 of ranks=585260rank=230700 of ranks=585260rank=230800 of ranks=585260rank=230900 of ranks=585260rank=231000 of ranks=585260rank=231100 of ranks=585260rank=231200 of ranks=585260rank=231300 of ranks=585260rank=231400 of ranks=585260rank=231500 of ranks=585260rank=231600 of ranks=585260rank=231700 of ranks=585260rank=231800 of ranks=585260rank=231900 of ranks=585260rank=232000 of ranks=585260rank=232100 of ranks=585260rank=232200 of ranks=585260rank=232300 of ranks=585260rank=232400 of ranks=585260rank=232500 of ranks=585260rank=232600 of ranks=585260rank=232700 of ranks=585260rank=232800 of ranks=585260rank=232900 of ranks=585260rank=233000 of ranks=585260rank=233100 of ranks=585260rank=233200 of ranks=585260rank=233300 of ranks=585260rank=233400 of ranks=585260rank=233500 of ranks=585260rank=233600 of ranks=585260rank=233700 of ranks=585260rank=233800 of ranks=585260rank=233900 of ranks=585260rank=234000 of ranks=585260rank=234100 of ranks=585260rank=234200 of ranks=585260rank=234300 of ranks=585260rank=234400 of ranks=585260rank=234500 of ranks=585260rank=234600 of ranks=585260rank=234700 of ranks=585260rank=234800 of ranks=585260rank=234900 of ranks=585260rank=235000 of ranks=585260rank=235100 of ranks=585260rank=235200 of ranks=585260rank=235300 of ranks=585260rank=235400 of ranks=585260rank=235500 of ranks=585260rank=235600 of ranks=585260rank=235700 of ranks=585260rank=235800 of ranks=585260rank=235900 of ranks=585260rank=236000 of ranks=585260rank=236100 of ranks=585260rank=236200 of ranks=585260rank=236300 of ranks=585260rank=236400 of ranks=585260rank=236500 of ranks=585260rank=236600 of ranks=585260rank=236700 of ranks=585260rank=236800 of ranks=585260rank=236900 of ranks=585260rank=237000 of ranks=585260rank=237100 of ranks=585260rank=237200 of ranks=585260rank=237300 of ranks=585260rank=237400 of ranks=585260rank=237500 of ranks=585260rank=237600 of ranks=585260rank=237700 of ranks=585260rank=237800 of ranks=585260rank=237900 of ranks=585260rank=238000 of ranks=585260rank=238100 of ranks=585260rank=238200 of ranks=585260rank=238300 of ranks=585260rank=238400 of ranks=585260rank=238500 of ranks=585260rank=238600 of ranks=585260rank=238700 of ranks=585260rank=238800 of ranks=585260rank=238900 of ranks=585260rank=239000 of ranks=585260rank=239100 of ranks=585260rank=239200 of ranks=585260rank=239300 of ranks=585260rank=239400 of ranks=585260rank=239500 of ranks=585260rank=239600 of ranks=585260rank=239700 of ranks=585260rank=239800 of ranks=585260rank=239900 of ranks=585260rank=240000 of ranks=585260rank=240100 of ranks=585260rank=240200 of ranks=585260rank=240300 of ranks=585260rank=240400 of ranks=585260rank=240500 of ranks=585260rank=240600 of ranks=585260rank=240700 of ranks=585260rank=240800 of ranks=585260rank=240900 of ranks=585260rank=241000 of ranks=585260rank=241100 of ranks=585260rank=241200 of ranks=585260rank=241300 of ranks=585260rank=241400 of ranks=585260rank=241500 of ranks=585260rank=241600 of ranks=585260rank=241700 of ranks=585260rank=241800 of ranks=585260rank=241900 of ranks=585260rank=242000 of ranks=585260rank=242100 of ranks=585260rank=242200 of ranks=585260rank=242300 of ranks=585260rank=242400 of ranks=585260rank=242500 of ranks=585260rank=242600 of ranks=585260rank=242700 of ranks=585260rank=242800 of ranks=585260rank=242900 of ranks=585260rank=243000 of ranks=585260rank=243100 of ranks=585260rank=243200 of ranks=585260rank=243300 of ranks=585260rank=243400 of ranks=585260rank=243500 of ranks=585260rank=243600 of ranks=585260rank=243700 of ranks=585260rank=243800 of ranks=585260rank=243900 of ranks=585260rank=244000 of ranks=585260rank=244100 of ranks=585260rank=244200 of ranks=585260rank=244300 of ranks=585260rank=244400 of ranks=585260rank=244500 of ranks=585260rank=244600 of ranks=585260rank=244700 of ranks=585260rank=244800 of ranks=585260rank=244900 of ranks=585260rank=245000 of ranks=585260rank=245100 of ranks=585260rank=245200 of ranks=585260rank=245300 of ranks=585260rank=245400 of ranks=585260rank=245500 of ranks=585260rank=245600 of ranks=585260rank=245700 of ranks=585260rank=245800 of ranks=585260rank=245900 of ranks=585260rank=246000 of ranks=585260rank=246100 of ranks=585260rank=246200 of ranks=585260rank=246300 of ranks=585260rank=246400 of ranks=585260rank=246500 of ranks=585260rank=246600 of ranks=585260rank=246700 of ranks=585260rank=246800 of ranks=585260rank=246900 of ranks=585260rank=247000 of ranks=585260rank=247100 of ranks=585260rank=247200 of ranks=585260rank=247300 of ranks=585260rank=247400 of ranks=585260rank=247500 of ranks=585260rank=247600 of ranks=585260rank=247700 of ranks=585260rank=247800 of ranks=585260rank=247900 of ranks=585260rank=248000 of ranks=585260rank=248100 of ranks=585260rank=248200 of ranks=585260rank=248300 of ranks=585260rank=248400 of ranks=585260rank=248500 of ranks=585260rank=248600 of ranks=585260rank=248700 of ranks=585260rank=248800 of ranks=585260rank=248900 of ranks=585260rank=249000 of ranks=585260rank=249100 of ranks=585260rank=249200 of ranks=585260rank=249300 of ranks=585260rank=249400 of ranks=585260rank=249500 of ranks=585260rank=249600 of ranks=585260rank=249700 of ranks=585260rank=249800 of ranks=585260rank=249900 of ranks=585260rank=250000 of ranks=585260rank=250100 of ranks=585260rank=250200 of ranks=585260rank=250300 of ranks=585260rank=250400 of ranks=585260rank=250500 of ranks=585260rank=250600 of ranks=585260rank=250700 of ranks=585260rank=250800 of ranks=585260rank=250900 of ranks=585260rank=251000 of ranks=585260rank=251100 of ranks=585260rank=251200 of ranks=585260rank=251300 of ranks=585260rank=251400 of ranks=585260rank=251500 of ranks=585260rank=251600 of ranks=585260rank=251700 of ranks=585260rank=251800 of ranks=585260rank=251900 of ranks=585260rank=252000 of ranks=585260rank=252100 of ranks=585260rank=252200 of ranks=585260rank=252300 of ranks=585260rank=252400 of ranks=585260rank=252500 of ranks=585260rank=252600 of ranks=585260rank=252700 of ranks=585260rank=252800 of ranks=585260rank=252900 of ranks=585260rank=253000 of ranks=585260rank=253100 of ranks=585260rank=253200 of ranks=585260rank=253300 of ranks=585260rank=253400 of ranks=585260rank=253500 of ranks=585260rank=253600 of ranks=585260rank=253700 of ranks=585260rank=253800 of ranks=585260rank=253900 of ranks=585260rank=254000 of ranks=585260rank=254100 of ranks=585260rank=254200 of ranks=585260rank=254300 of ranks=585260rank=254400 of ranks=585260rank=254500 of ranks=585260rank=254600 of ranks=585260rank=254700 of ranks=585260rank=254800 of ranks=585260rank=254900 of ranks=585260rank=255000 of ranks=585260rank=255100 of ranks=585260rank=255200 of ranks=585260rank=255300 of ranks=585260rank=255400 of ranks=585260rank=255500 of ranks=585260rank=255600 of ranks=585260rank=255700 of ranks=585260rank=255800 of ranks=585260rank=255900 of ranks=585260rank=256000 of ranks=585260rank=256100 of ranks=585260rank=256200 of ranks=585260rank=256300 of ranks=585260rank=256400 of ranks=585260rank=256500 of ranks=585260rank=256600 of ranks=585260rank=256700 of ranks=585260rank=256800 of ranks=585260rank=256900 of ranks=585260rank=257000 of ranks=585260rank=257100 of ranks=585260rank=257200 of ranks=585260rank=257300 of ranks=585260rank=257400 of ranks=585260rank=257500 of ranks=585260rank=257600 of ranks=585260rank=257700 of ranks=585260rank=257800 of ranks=585260rank=257900 of ranks=585260rank=258000 of ranks=585260rank=258100 of ranks=585260rank=258200 of ranks=585260rank=258300 of ranks=585260rank=258400 of ranks=585260rank=258500 of ranks=585260rank=258600 of ranks=585260rank=258700 of ranks=585260rank=258800 of ranks=585260rank=258900 of ranks=585260rank=259000 of ranks=585260rank=259100 of ranks=585260rank=259200 of ranks=585260rank=259300 of ranks=585260rank=259400 of ranks=585260rank=259500 of ranks=585260rank=259600 of ranks=585260rank=259700 of ranks=585260rank=259800 of ranks=585260rank=259900 of ranks=585260rank=260000 of ranks=585260rank=260100 of ranks=585260rank=260200 of ranks=585260rank=260300 of ranks=585260rank=260400 of ranks=585260rank=260500 of ranks=585260rank=260600 of ranks=585260rank=260700 of ranks=585260rank=260800 of ranks=585260rank=260900 of ranks=585260rank=261000 of ranks=585260rank=261100 of ranks=585260rank=261200 of ranks=585260rank=261300 of ranks=585260rank=261400 of ranks=585260rank=261500 of ranks=585260rank=261600 of ranks=585260rank=261700 of ranks=585260rank=261800 of ranks=585260rank=261900 of ranks=585260rank=262000 of ranks=585260rank=262100 of ranks=585260rank=262200 of ranks=585260rank=262300 of ranks=585260rank=262400 of ranks=585260rank=262500 of ranks=585260rank=262600 of ranks=585260rank=262700 of ranks=585260rank=262800 of ranks=585260rank=262900 of ranks=585260rank=263000 of ranks=585260rank=263100 of ranks=585260rank=263200 of ranks=585260rank=263300 of ranks=585260rank=263400 of ranks=585260rank=263500 of ranks=585260rank=263600 of ranks=585260rank=263700 of ranks=585260rank=263800 of ranks=585260rank=263900 of ranks=585260rank=264000 of ranks=585260rank=264100 of ranks=585260rank=264200 of ranks=585260rank=264300 of ranks=585260rank=264400 of ranks=585260rank=264500 of ranks=585260rank=264600 of ranks=585260rank=264700 of ranks=585260rank=264800 of ranks=585260rank=264900 of ranks=585260rank=265000 of ranks=585260rank=265100 of ranks=585260rank=265200 of ranks=585260rank=265300 of ranks=585260rank=265400 of ranks=585260rank=265500 of ranks=585260rank=265600 of ranks=585260rank=265700 of ranks=585260rank=265800 of ranks=585260rank=265900 of ranks=585260rank=266000 of ranks=585260rank=266100 of ranks=585260rank=266200 of ranks=585260rank=266300 of ranks=585260rank=266400 of ranks=585260rank=266500 of ranks=585260rank=266600 of ranks=585260rank=266700 of ranks=585260rank=266800 of ranks=585260rank=266900 of ranks=585260rank=267000 of ranks=585260rank=267100 of ranks=585260rank=267200 of ranks=585260rank=267300 of ranks=585260rank=267400 of ranks=585260rank=267500 of ranks=585260rank=267600 of ranks=585260rank=267700 of ranks=585260rank=267800 of ranks=585260rank=267900 of ranks=585260rank=268000 of ranks=585260rank=268100 of ranks=585260rank=268200 of ranks=585260rank=268300 of ranks=585260rank=268400 of ranks=585260rank=268500 of ranks=585260rank=268600 of ranks=585260rank=268700 of ranks=585260rank=268800 of ranks=585260rank=268900 of ranks=585260rank=269000 of ranks=585260rank=269100 of ranks=585260rank=269200 of ranks=585260rank=269300 of ranks=585260rank=269400 of ranks=585260rank=269500 of ranks=585260rank=269600 of ranks=585260rank=269700 of ranks=585260rank=269800 of ranks=585260rank=269900 of ranks=585260rank=270000 of ranks=585260rank=270100 of ranks=585260rank=270200 of ranks=585260rank=270300 of ranks=585260rank=270400 of ranks=585260rank=270500 of ranks=585260rank=270600 of ranks=585260rank=270700 of ranks=585260rank=270800 of ranks=585260rank=270900 of ranks=585260rank=271000 of ranks=585260rank=271100 of ranks=585260rank=271200 of ranks=585260rank=271300 of ranks=585260rank=271400 of ranks=585260rank=271500 of ranks=585260rank=271600 of ranks=585260rank=271700 of ranks=585260rank=271800 of ranks=585260rank=271900 of ranks=585260rank=272000 of ranks=585260rank=272100 of ranks=585260rank=272200 of ranks=585260rank=272300 of ranks=585260rank=272400 of ranks=585260rank=272500 of ranks=585260rank=272600 of ranks=585260rank=272700 of ranks=585260rank=272800 of ranks=585260rank=272900 of ranks=585260rank=273000 of ranks=585260rank=273100 of ranks=585260rank=273200 of ranks=585260rank=273300 of ranks=585260rank=273400 of ranks=585260rank=273500 of ranks=585260rank=273600 of ranks=585260rank=273700 of ranks=585260rank=273800 of ranks=585260rank=273900 of ranks=585260rank=274000 of ranks=585260rank=274100 of ranks=585260rank=274200 of ranks=585260rank=274300 of ranks=585260rank=274400 of ranks=585260rank=274500 of ranks=585260rank=274600 of ranks=585260rank=274700 of ranks=585260rank=274800 of ranks=585260rank=274900 of ranks=585260rank=275000 of ranks=585260rank=275100 of ranks=585260rank=275200 of ranks=585260rank=275300 of ranks=585260rank=275400 of ranks=585260rank=275500 of ranks=585260rank=275600 of ranks=585260rank=275700 of ranks=585260rank=275800 of ranks=585260rank=275900 of ranks=585260rank=276000 of ranks=585260rank=276100 of ranks=585260rank=276200 of ranks=585260rank=276300 of ranks=585260rank=276400 of ranks=585260rank=276500 of ranks=585260rank=276600 of ranks=585260rank=276700 of ranks=585260rank=276800 of ranks=585260rank=276900 of ranks=585260rank=277000 of ranks=585260rank=277100 of ranks=585260rank=277200 of ranks=585260rank=277300 of ranks=585260rank=277400 of ranks=585260rank=277500 of ranks=585260rank=277600 of ranks=585260rank=277700 of ranks=585260rank=277800 of ranks=585260rank=277900 of ranks=585260rank=278000 of ranks=585260rank=278100 of ranks=585260rank=278200 of ranks=585260rank=278300 of ranks=585260rank=278400 of ranks=585260rank=278500 of ranks=585260rank=278600 of ranks=585260rank=278700 of ranks=585260rank=278800 of ranks=585260rank=278900 of ranks=585260rank=279000 of ranks=585260rank=279100 of ranks=585260rank=279200 of ranks=585260rank=279300 of ranks=585260rank=279400 of ranks=585260rank=279500 of ranks=585260rank=279600 of ranks=585260rank=279700 of ranks=585260rank=279800 of ranks=585260rank=279900 of ranks=585260rank=280000 of ranks=585260rank=280100 of ranks=585260rank=280200 of ranks=585260rank=280300 of ranks=585260rank=280400 of ranks=585260rank=280500 of ranks=585260rank=280600 of ranks=585260rank=280700 of ranks=585260rank=280800 of ranks=585260rank=280900 of ranks=585260rank=281000 of ranks=585260rank=281100 of ranks=585260rank=281200 of ranks=585260rank=281300 of ranks=585260rank=281400 of ranks=585260rank=281500 of ranks=585260rank=281600 of ranks=585260rank=281700 of ranks=585260rank=281800 of ranks=585260rank=281900 of ranks=585260rank=282000 of ranks=585260rank=282100 of ranks=585260rank=282200 of ranks=585260rank=282300 of ranks=585260rank=282400 of ranks=585260rank=282500 of ranks=585260rank=282600 of ranks=585260rank=282700 of ranks=585260rank=282800 of ranks=585260rank=282900 of ranks=585260rank=283000 of ranks=585260rank=283100 of ranks=585260rank=283200 of ranks=585260rank=283300 of ranks=585260rank=283400 of ranks=585260rank=283500 of ranks=585260rank=283600 of ranks=585260rank=283700 of ranks=585260rank=283800 of ranks=585260rank=283900 of ranks=585260rank=284000 of ranks=585260rank=284100 of ranks=585260rank=284200 of ranks=585260rank=284300 of ranks=585260rank=284400 of ranks=585260rank=284500 of ranks=585260rank=284600 of ranks=585260rank=284700 of ranks=585260rank=284800 of ranks=585260rank=284900 of ranks=585260rank=285000 of ranks=585260rank=285100 of ranks=585260rank=285200 of ranks=585260rank=285300 of ranks=585260rank=285400 of ranks=585260rank=285500 of ranks=585260rank=285600 of ranks=585260rank=285700 of ranks=585260rank=285800 of ranks=585260rank=285900 of ranks=585260rank=286000 of ranks=585260rank=286100 of ranks=585260rank=286200 of ranks=585260rank=286300 of ranks=585260rank=286400 of ranks=585260rank=286500 of ranks=585260rank=286600 of ranks=585260rank=286700 of ranks=585260rank=286800 of ranks=585260rank=286900 of ranks=585260rank=287000 of ranks=585260rank=287100 of ranks=585260rank=287200 of ranks=585260rank=287300 of ranks=585260rank=287400 of ranks=585260rank=287500 of ranks=585260rank=287600 of ranks=585260rank=287700 of ranks=585260rank=287800 of ranks=585260rank=287900 of ranks=585260rank=288000 of ranks=585260rank=288100 of ranks=585260rank=288200 of ranks=585260rank=288300 of ranks=585260rank=288400 of ranks=585260rank=288500 of ranks=585260rank=288600 of ranks=585260rank=288700 of ranks=585260rank=288800 of ranks=585260rank=288900 of ranks=585260rank=289000 of ranks=585260rank=289100 of ranks=585260rank=289200 of ranks=585260rank=289300 of ranks=585260rank=289400 of ranks=585260rank=289500 of ranks=585260rank=289600 of ranks=585260rank=289700 of ranks=585260rank=289800 of ranks=585260rank=289900 of ranks=585260rank=290000 of ranks=585260rank=290100 of ranks=585260rank=290200 of ranks=585260rank=290300 of ranks=585260rank=290400 of ranks=585260rank=290500 of ranks=585260rank=290600 of ranks=585260rank=290700 of ranks=585260rank=290800 of ranks=585260rank=290900 of ranks=585260rank=291000 of ranks=585260rank=291100 of ranks=585260rank=291200 of ranks=585260rank=291300 of ranks=585260rank=291400 of ranks=585260rank=291500 of ranks=585260rank=291600 of ranks=585260rank=291700 of ranks=585260rank=291800 of ranks=585260rank=291900 of ranks=585260rank=292000 of ranks=585260rank=292100 of ranks=585260rank=292200 of ranks=585260rank=292300 of ranks=585260rank=292400 of ranks=585260rank=292500 of ranks=585260rank=292600 of ranks=585260rank=292700 of ranks=585260rank=292800 of ranks=585260rank=292900 of ranks=585260rank=293000 of ranks=585260rank=293100 of ranks=585260rank=293200 of ranks=585260rank=293300 of ranks=585260rank=293400 of ranks=585260rank=293500 of ranks=585260rank=293600 of ranks=585260rank=293700 of ranks=585260rank=293800 of ranks=585260rank=293900 of ranks=585260rank=294000 of ranks=585260rank=294100 of ranks=585260rank=294200 of ranks=585260rank=294300 of ranks=585260rank=294400 of ranks=585260rank=294500 of ranks=585260rank=294600 of ranks=585260rank=294700 of ranks=585260rank=294800 of ranks=585260rank=294900 of ranks=585260rank=295000 of ranks=585260rank=295100 of ranks=585260rank=295200 of ranks=585260rank=295300 of ranks=585260rank=295400 of ranks=585260rank=295500 of ranks=585260rank=295600 of ranks=585260rank=295700 of ranks=585260rank=295800 of ranks=585260rank=295900 of ranks=585260rank=296000 of ranks=585260rank=296100 of ranks=585260rank=296200 of ranks=585260rank=296300 of ranks=585260rank=296400 of ranks=585260rank=296500 of ranks=585260rank=296600 of ranks=585260rank=296700 of ranks=585260rank=296800 of ranks=585260rank=296900 of ranks=585260rank=297000 of ranks=585260rank=297100 of ranks=585260rank=297200 of ranks=585260rank=297300 of ranks=585260rank=297400 of ranks=585260rank=297500 of ranks=585260rank=297600 of ranks=585260rank=297700 of ranks=585260rank=297800 of ranks=585260rank=297900 of ranks=585260rank=298000 of ranks=585260rank=298100 of ranks=585260rank=298200 of ranks=585260rank=298300 of ranks=585260rank=298400 of ranks=585260rank=298500 of ranks=585260rank=298600 of ranks=585260rank=298700 of ranks=585260rank=298800 of ranks=585260rank=298900 of ranks=585260rank=299000 of ranks=585260rank=299100 of ranks=585260rank=299200 of ranks=585260rank=299300 of ranks=585260rank=299400 of ranks=585260rank=299500 of ranks=585260rank=299600 of ranks=585260rank=299700 of ranks=585260rank=299800 of ranks=585260rank=299900 of ranks=585260rank=300000 of ranks=585260rank=300100 of ranks=585260rank=300200 of ranks=585260rank=300300 of ranks=585260rank=300400 of ranks=585260rank=300500 of ranks=585260rank=300600 of ranks=585260rank=300700 of ranks=585260rank=300800 of ranks=585260rank=300900 of ranks=585260rank=301000 of ranks=585260rank=301100 of ranks=585260rank=301200 of ranks=585260rank=301300 of ranks=585260rank=301400 of ranks=585260rank=301500 of ranks=585260rank=301600 of ranks=585260rank=301700 of ranks=585260rank=301800 of ranks=585260rank=301900 of ranks=585260rank=302000 of ranks=585260rank=302100 of ranks=585260rank=302200 of ranks=585260rank=302300 of ranks=585260rank=302400 of ranks=585260rank=302500 of ranks=585260rank=302600 of ranks=585260rank=302700 of ranks=585260rank=302800 of ranks=585260rank=302900 of ranks=585260rank=303000 of ranks=585260rank=303100 of ranks=585260rank=303200 of ranks=585260rank=303300 of ranks=585260rank=303400 of ranks=585260rank=303500 of ranks=585260rank=303600 of ranks=585260rank=303700 of ranks=585260rank=303800 of ranks=585260rank=303900 of ranks=585260rank=304000 of ranks=585260rank=304100 of ranks=585260rank=304200 of ranks=585260rank=304300 of ranks=585260rank=304400 of ranks=585260rank=304500 of ranks=585260rank=304600 of ranks=585260rank=304700 of ranks=585260rank=304800 of ranks=585260rank=304900 of ranks=585260rank=305000 of ranks=585260rank=305100 of ranks=585260rank=305200 of ranks=585260rank=305300 of ranks=585260rank=305400 of ranks=585260rank=305500 of ranks=585260rank=305600 of ranks=585260rank=305700 of ranks=585260rank=305800 of ranks=585260rank=305900 of ranks=585260rank=306000 of ranks=585260rank=306100 of ranks=585260rank=306200 of ranks=585260rank=306300 of ranks=585260rank=306400 of ranks=585260rank=306500 of ranks=585260rank=306600 of ranks=585260rank=306700 of ranks=585260rank=306800 of ranks=585260rank=306900 of ranks=585260rank=307000 of ranks=585260rank=307100 of ranks=585260rank=307200 of ranks=585260rank=307300 of ranks=585260rank=307400 of ranks=585260rank=307500 of ranks=585260rank=307600 of ranks=585260rank=307700 of ranks=585260rank=307800 of ranks=585260rank=307900 of ranks=585260rank=308000 of ranks=585260rank=308100 of ranks=585260rank=308200 of ranks=585260rank=308300 of ranks=585260rank=308400 of ranks=585260rank=308500 of ranks=585260rank=308600 of ranks=585260rank=308700 of ranks=585260rank=308800 of ranks=585260rank=308900 of ranks=585260rank=309000 of ranks=585260rank=309100 of ranks=585260rank=309200 of ranks=585260rank=309300 of ranks=585260rank=309400 of ranks=585260rank=309500 of ranks=585260rank=309600 of ranks=585260rank=309700 of ranks=585260rank=309800 of ranks=585260rank=309900 of ranks=585260rank=310000 of ranks=585260rank=310100 of ranks=585260rank=310200 of ranks=585260rank=310300 of ranks=585260rank=310400 of ranks=585260rank=310500 of ranks=585260rank=310600 of ranks=585260rank=310700 of ranks=585260rank=310800 of ranks=585260rank=310900 of ranks=585260rank=311000 of ranks=585260rank=311100 of ranks=585260rank=311200 of ranks=585260rank=311300 of ranks=585260rank=311400 of ranks=585260rank=311500 of ranks=585260rank=311600 of ranks=585260rank=311700 of ranks=585260rank=311800 of ranks=585260rank=311900 of ranks=585260rank=312000 of ranks=585260rank=312100 of ranks=585260rank=312200 of ranks=585260rank=312300 of ranks=585260rank=312400 of ranks=585260rank=312500 of ranks=585260rank=312600 of ranks=585260rank=312700 of ranks=585260rank=312800 of ranks=585260rank=312900 of ranks=585260rank=313000 of ranks=585260rank=313100 of ranks=585260rank=313200 of ranks=585260rank=313300 of ranks=585260rank=313400 of ranks=585260rank=313500 of ranks=585260rank=313600 of ranks=585260rank=313700 of ranks=585260rank=313800 of ranks=585260rank=313900 of ranks=585260rank=314000 of ranks=585260rank=314100 of ranks=585260rank=314200 of ranks=585260rank=314300 of ranks=585260rank=314400 of ranks=585260rank=314500 of ranks=585260rank=314600 of ranks=585260rank=314700 of ranks=585260rank=314800 of ranks=585260rank=314900 of ranks=585260rank=315000 of ranks=585260rank=315100 of ranks=585260rank=315200 of ranks=585260rank=315300 of ranks=585260rank=315400 of ranks=585260rank=315500 of ranks=585260rank=315600 of ranks=585260rank=315700 of ranks=585260rank=315800 of ranks=585260rank=315900 of ranks=585260rank=316000 of ranks=585260rank=316100 of ranks=585260rank=316200 of ranks=585260rank=316300 of ranks=585260rank=316400 of ranks=585260rank=316500 of ranks=585260rank=316600 of ranks=585260rank=316700 of ranks=585260rank=316800 of ranks=585260rank=316900 of ranks=585260rank=317000 of ranks=585260rank=317100 of ranks=585260rank=317200 of ranks=585260rank=317300 of ranks=585260rank=317400 of ranks=585260rank=317500 of ranks=585260rank=317600 of ranks=585260rank=317700 of ranks=585260rank=317800 of ranks=585260rank=317900 of ranks=585260rank=318000 of ranks=585260rank=318100 of ranks=585260rank=318200 of ranks=585260rank=318300 of ranks=585260rank=318400 of ranks=585260rank=318500 of ranks=585260rank=318600 of ranks=585260rank=318700 of ranks=585260rank=318800 of ranks=585260rank=318900 of ranks=585260rank=319000 of ranks=585260rank=319100 of ranks=585260rank=319200 of ranks=585260rank=319300 of ranks=585260rank=319400 of ranks=585260rank=319500 of ranks=585260rank=319600 of ranks=585260rank=319700 of ranks=585260rank=319800 of ranks=585260rank=319900 of ranks=585260rank=320000 of ranks=585260rank=320100 of ranks=585260rank=320200 of ranks=585260rank=320300 of ranks=585260rank=320400 of ranks=585260rank=320500 of ranks=585260rank=320600 of ranks=585260rank=320700 of ranks=585260rank=320800 of ranks=585260rank=320900 of ranks=585260rank=321000 of ranks=585260rank=321100 of ranks=585260rank=321200 of ranks=585260rank=321300 of ranks=585260rank=321400 of ranks=585260rank=321500 of ranks=585260rank=321600 of ranks=585260rank=321700 of ranks=585260rank=321800 of ranks=585260rank=321900 of ranks=585260rank=322000 of ranks=585260rank=322100 of ranks=585260rank=322200 of ranks=585260rank=322300 of ranks=585260rank=322400 of ranks=585260rank=322500 of ranks=585260rank=322600 of ranks=585260rank=322700 of ranks=585260rank=322800 of ranks=585260rank=322900 of ranks=585260rank=323000 of ranks=585260rank=323100 of ranks=585260rank=323200 of ranks=585260rank=323300 of ranks=585260rank=323400 of ranks=585260rank=323500 of ranks=585260rank=323600 of ranks=585260rank=323700 of ranks=585260rank=323800 of ranks=585260rank=323900 of ranks=585260rank=324000 of ranks=585260rank=324100 of ranks=585260rank=324200 of ranks=585260rank=324300 of ranks=585260rank=324400 of ranks=585260rank=324500 of ranks=585260rank=324600 of ranks=585260rank=324700 of ranks=585260rank=324800 of ranks=585260rank=324900 of ranks=585260rank=325000 of ranks=585260rank=325100 of ranks=585260rank=325200 of ranks=585260rank=325300 of ranks=585260rank=325400 of ranks=585260rank=325500 of ranks=585260rank=325600 of ranks=585260rank=325700 of ranks=585260rank=325800 of ranks=585260rank=325900 of ranks=585260rank=326000 of ranks=585260rank=326100 of ranks=585260rank=326200 of ranks=585260rank=326300 of ranks=585260rank=326400 of ranks=585260rank=326500 of ranks=585260rank=326600 of ranks=585260rank=326700 of ranks=585260rank=326800 of ranks=585260rank=326900 of ranks=585260rank=327000 of ranks=585260rank=327100 of ranks=585260rank=327200 of ranks=585260rank=327300 of ranks=585260rank=327400 of ranks=585260rank=327500 of ranks=585260rank=327600 of ranks=585260rank=327700 of ranks=585260rank=327800 of ranks=585260rank=327900 of ranks=585260rank=328000 of ranks=585260rank=328100 of ranks=585260rank=328200 of ranks=585260rank=328300 of ranks=585260rank=328400 of ranks=585260rank=328500 of ranks=585260rank=328600 of ranks=585260rank=328700 of ranks=585260rank=328800 of ranks=585260rank=328900 of ranks=585260rank=329000 of ranks=585260rank=329100 of ranks=585260rank=329200 of ranks=585260rank=329300 of ranks=585260rank=329400 of ranks=585260rank=329500 of ranks=585260rank=329600 of ranks=585260rank=329700 of ranks=585260rank=329800 of ranks=585260rank=329900 of ranks=585260rank=330000 of ranks=585260rank=330100 of ranks=585260rank=330200 of ranks=585260rank=330300 of ranks=585260rank=330400 of ranks=585260rank=330500 of ranks=585260rank=330600 of ranks=585260rank=330700 of ranks=585260rank=330800 of ranks=585260rank=330900 of ranks=585260rank=331000 of ranks=585260rank=331100 of ranks=585260rank=331200 of ranks=585260rank=331300 of ranks=585260rank=331400 of ranks=585260rank=331500 of ranks=585260rank=331600 of ranks=585260rank=331700 of ranks=585260rank=331800 of ranks=585260rank=331900 of ranks=585260rank=332000 of ranks=585260rank=332100 of ranks=585260rank=332200 of ranks=585260rank=332300 of ranks=585260rank=332400 of ranks=585260rank=332500 of ranks=585260rank=332600 of ranks=585260rank=332700 of ranks=585260rank=332800 of ranks=585260rank=332900 of ranks=585260rank=333000 of ranks=585260rank=333100 of ranks=585260rank=333200 of ranks=585260rank=333300 of ranks=585260rank=333400 of ranks=585260rank=333500 of ranks=585260rank=333600 of ranks=585260rank=333700 of ranks=585260rank=333800 of ranks=585260rank=333900 of ranks=585260rank=334000 of ranks=585260rank=334100 of ranks=585260rank=334200 of ranks=585260rank=334300 of ranks=585260rank=334400 of ranks=585260rank=334500 of ranks=585260rank=334600 of ranks=585260rank=334700 of ranks=585260rank=334800 of ranks=585260rank=334900 of ranks=585260rank=335000 of ranks=585260rank=335100 of ranks=585260rank=335200 of ranks=585260rank=335300 of ranks=585260rank=335400 of ranks=585260rank=335500 of ranks=585260rank=335600 of ranks=585260rank=335700 of ranks=585260rank=335800 of ranks=585260rank=335900 of ranks=585260rank=336000 of ranks=585260rank=336100 of ranks=585260rank=336200 of ranks=585260rank=336300 of ranks=585260rank=336400 of ranks=585260rank=336500 of ranks=585260rank=336600 of ranks=585260rank=336700 of ranks=585260rank=336800 of ranks=585260rank=336900 of ranks=585260rank=337000 of ranks=585260rank=337100 of ranks=585260rank=337200 of ranks=585260rank=337300 of ranks=585260rank=337400 of ranks=585260rank=337500 of ranks=585260rank=337600 of ranks=585260rank=337700 of ranks=585260rank=337800 of ranks=585260rank=337900 of ranks=585260rank=338000 of ranks=585260rank=338100 of ranks=585260rank=338200 of ranks=585260rank=338300 of ranks=585260rank=338400 of ranks=585260rank=338500 of ranks=585260rank=338600 of ranks=585260rank=338700 of ranks=585260rank=338800 of ranks=585260rank=338900 of ranks=585260rank=339000 of ranks=585260rank=339100 of ranks=585260rank=339200 of ranks=585260rank=339300 of ranks=585260rank=339400 of ranks=585260rank=339500 of ranks=585260rank=339600 of ranks=585260rank=339700 of ranks=585260rank=339800 of ranks=585260rank=339900 of ranks=585260rank=340000 of ranks=585260rank=340100 of ranks=585260rank=340200 of ranks=585260rank=340300 of ranks=585260rank=340400 of ranks=585260rank=340500 of ranks=585260rank=340600 of ranks=585260rank=340700 of ranks=585260rank=340800 of ranks=585260rank=340900 of ranks=585260rank=341000 of ranks=585260rank=341100 of ranks=585260rank=341200 of ranks=585260rank=341300 of ranks=585260rank=341400 of ranks=585260rank=341500 of ranks=585260rank=341600 of ranks=585260rank=341700 of ranks=585260rank=341800 of ranks=585260rank=341900 of ranks=585260rank=342000 of ranks=585260rank=342100 of ranks=585260rank=342200 of ranks=585260rank=342300 of ranks=585260rank=342400 of ranks=585260rank=342500 of ranks=585260rank=342600 of ranks=585260rank=342700 of ranks=585260rank=342800 of ranks=585260rank=342900 of ranks=585260rank=343000 of ranks=585260rank=343100 of ranks=585260rank=343200 of ranks=585260rank=343300 of ranks=585260rank=343400 of ranks=585260rank=343500 of ranks=585260rank=343600 of ranks=585260rank=343700 of ranks=585260rank=343800 of ranks=585260rank=343900 of ranks=585260rank=344000 of ranks=585260rank=344100 of ranks=585260rank=344200 of ranks=585260rank=344300 of ranks=585260rank=344400 of ranks=585260rank=344500 of ranks=585260rank=344600 of ranks=585260rank=344700 of ranks=585260rank=344800 of ranks=585260rank=344900 of ranks=585260rank=345000 of ranks=585260rank=345100 of ranks=585260rank=345200 of ranks=585260rank=345300 of ranks=585260rank=345400 of ranks=585260rank=345500 of ranks=585260rank=345600 of ranks=585260rank=345700 of ranks=585260rank=345800 of ranks=585260rank=345900 of ranks=585260rank=346000 of ranks=585260rank=346100 of ranks=585260rank=346200 of ranks=585260rank=346300 of ranks=585260rank=346400 of ranks=585260rank=346500 of ranks=585260rank=346600 of ranks=585260rank=346700 of ranks=585260rank=346800 of ranks=585260rank=346900 of ranks=585260rank=347000 of ranks=585260rank=347100 of ranks=585260rank=347200 of ranks=585260rank=347300 of ranks=585260rank=347400 of ranks=585260rank=347500 of ranks=585260rank=347600 of ranks=585260rank=347700 of ranks=585260rank=347800 of ranks=585260rank=347900 of ranks=585260rank=348000 of ranks=585260rank=348100 of ranks=585260rank=348200 of ranks=585260rank=348300 of ranks=585260rank=348400 of ranks=585260rank=348500 of ranks=585260rank=348600 of ranks=585260rank=348700 of ranks=585260rank=348800 of ranks=585260rank=348900 of ranks=585260rank=349000 of ranks=585260rank=349100 of ranks=585260rank=349200 of ranks=585260rank=349300 of ranks=585260rank=349400 of ranks=585260rank=349500 of ranks=585260rank=349600 of ranks=585260rank=349700 of ranks=585260rank=349800 of ranks=585260rank=349900 of ranks=585260rank=350000 of ranks=585260rank=350100 of ranks=585260rank=350200 of ranks=585260rank=350300 of ranks=585260rank=350400 of ranks=585260rank=350500 of ranks=585260rank=350600 of ranks=585260rank=350700 of ranks=585260rank=350800 of ranks=585260rank=350900 of ranks=585260rank=351000 of ranks=585260rank=351100 of ranks=585260rank=351200 of ranks=585260rank=351300 of ranks=585260rank=351400 of ranks=585260rank=351500 of ranks=585260rank=351600 of ranks=585260rank=351700 of ranks=585260rank=351800 of ranks=585260rank=351900 of ranks=585260rank=352000 of ranks=585260rank=352100 of ranks=585260rank=352200 of ranks=585260rank=352300 of ranks=585260rank=352400 of ranks=585260rank=352500 of ranks=585260rank=352600 of ranks=585260rank=352700 of ranks=585260rank=352800 of ranks=585260rank=352900 of ranks=585260rank=353000 of ranks=585260rank=353100 of ranks=585260rank=353200 of ranks=585260rank=353300 of ranks=585260rank=353400 of ranks=585260rank=353500 of ranks=585260rank=353600 of ranks=585260rank=353700 of ranks=585260rank=353800 of ranks=585260rank=353900 of ranks=585260rank=354000 of ranks=585260rank=354100 of ranks=585260rank=354200 of ranks=585260rank=354300 of ranks=585260rank=354400 of ranks=585260rank=354500 of ranks=585260rank=354600 of ranks=585260rank=354700 of ranks=585260rank=354800 of ranks=585260rank=354900 of ranks=585260rank=355000 of ranks=585260rank=355100 of ranks=585260rank=355200 of ranks=585260rank=355300 of ranks=585260rank=355400 of ranks=585260rank=355500 of ranks=585260rank=355600 of ranks=585260rank=355700 of ranks=585260rank=355800 of ranks=585260rank=355900 of ranks=585260rank=356000 of ranks=585260rank=356100 of ranks=585260rank=356200 of ranks=585260rank=356300 of ranks=585260rank=356400 of ranks=585260rank=356500 of ranks=585260rank=356600 of ranks=585260rank=356700 of ranks=585260rank=356800 of ranks=585260rank=356900 of ranks=585260rank=357000 of ranks=585260rank=357100 of ranks=585260rank=357200 of ranks=585260rank=357300 of ranks=585260rank=357400 of ranks=585260rank=357500 of ranks=585260rank=357600 of ranks=585260rank=357700 of ranks=585260rank=357800 of ranks=585260rank=357900 of ranks=585260rank=358000 of ranks=585260rank=358100 of ranks=585260rank=358200 of ranks=585260rank=358300 of ranks=585260rank=358400 of ranks=585260rank=358500 of ranks=585260rank=358600 of ranks=585260rank=358700 of ranks=585260rank=358800 of ranks=585260rank=358900 of ranks=585260rank=359000 of ranks=585260rank=359100 of ranks=585260rank=359200 of ranks=585260rank=359300 of ranks=585260rank=359400 of ranks=585260rank=359500 of ranks=585260rank=359600 of ranks=585260rank=359700 of ranks=585260rank=359800 of ranks=585260rank=359900 of ranks=585260rank=360000 of ranks=585260rank=360100 of ranks=585260rank=360200 of ranks=585260rank=360300 of ranks=585260rank=360400 of ranks=585260rank=360500 of ranks=585260rank=360600 of ranks=585260rank=360700 of ranks=585260rank=360800 of ranks=585260rank=360900 of ranks=585260rank=361000 of ranks=585260rank=361100 of ranks=585260rank=361200 of ranks=585260rank=361300 of ranks=585260rank=361400 of ranks=585260rank=361500 of ranks=585260rank=361600 of ranks=585260rank=361700 of ranks=585260rank=361800 of ranks=585260rank=361900 of ranks=585260rank=362000 of ranks=585260rank=362100 of ranks=585260rank=362200 of ranks=585260rank=362300 of ranks=585260rank=362400 of ranks=585260rank=362500 of ranks=585260rank=362600 of ranks=585260rank=362700 of ranks=585260rank=362800 of ranks=585260rank=362900 of ranks=585260rank=363000 of ranks=585260rank=363100 of ranks=585260rank=363200 of ranks=585260rank=363300 of ranks=585260rank=363400 of ranks=585260rank=363500 of ranks=585260rank=363600 of ranks=585260rank=363700 of ranks=585260rank=363800 of ranks=585260rank=363900 of ranks=585260rank=364000 of ranks=585260rank=364100 of ranks=585260rank=364200 of ranks=585260rank=364300 of ranks=585260rank=364400 of ranks=585260rank=364500 of ranks=585260rank=364600 of ranks=585260rank=364700 of ranks=585260rank=364800 of ranks=585260rank=364900 of ranks=585260rank=365000 of ranks=585260rank=365100 of ranks=585260rank=365200 of ranks=585260rank=365300 of ranks=585260rank=365400 of ranks=585260rank=365500 of ranks=585260rank=365600 of ranks=585260rank=365700 of ranks=585260rank=365800 of ranks=585260rank=365900 of ranks=585260rank=366000 of ranks=585260rank=366100 of ranks=585260rank=366200 of ranks=585260rank=366300 of ranks=585260rank=366400 of ranks=585260rank=366500 of ranks=585260rank=366600 of ranks=585260rank=366700 of ranks=585260rank=366800 of ranks=585260rank=366900 of ranks=585260rank=367000 of ranks=585260rank=367100 of ranks=585260rank=367200 of ranks=585260rank=367300 of ranks=585260rank=367400 of ranks=585260rank=367500 of ranks=585260rank=367600 of ranks=585260rank=367700 of ranks=585260rank=367800 of ranks=585260rank=367900 of ranks=585260rank=368000 of ranks=585260rank=368100 of ranks=585260rank=368200 of ranks=585260rank=368300 of ranks=585260rank=368400 of ranks=585260rank=368500 of ranks=585260rank=368600 of ranks=585260rank=368700 of ranks=585260rank=368800 of ranks=585260rank=368900 of ranks=585260rank=369000 of ranks=585260rank=369100 of ranks=585260rank=369200 of ranks=585260rank=369300 of ranks=585260rank=369400 of ranks=585260rank=369500 of ranks=585260rank=369600 of ranks=585260rank=369700 of ranks=585260rank=369800 of ranks=585260rank=369900 of ranks=585260rank=370000 of ranks=585260rank=370100 of ranks=585260rank=370200 of ranks=585260rank=370300 of ranks=585260rank=370400 of ranks=585260rank=370500 of ranks=585260rank=370600 of ranks=585260rank=370700 of ranks=585260rank=370800 of ranks=585260rank=370900 of ranks=585260rank=371000 of ranks=585260rank=371100 of ranks=585260rank=371200 of ranks=585260rank=371300 of ranks=585260rank=371400 of ranks=585260rank=371500 of ranks=585260rank=371600 of ranks=585260rank=371700 of ranks=585260rank=371800 of ranks=585260rank=371900 of ranks=585260rank=372000 of ranks=585260rank=372100 of ranks=585260rank=372200 of ranks=585260rank=372300 of ranks=585260rank=372400 of ranks=585260rank=372500 of ranks=585260rank=372600 of ranks=585260rank=372700 of ranks=585260rank=372800 of ranks=585260rank=372900 of ranks=585260rank=373000 of ranks=585260rank=373100 of ranks=585260rank=373200 of ranks=585260rank=373300 of ranks=585260rank=373400 of ranks=585260rank=373500 of ranks=585260rank=373600 of ranks=585260rank=373700 of ranks=585260rank=373800 of ranks=585260rank=373900 of ranks=585260rank=374000 of ranks=585260rank=374100 of ranks=585260rank=374200 of ranks=585260rank=374300 of ranks=585260rank=374400 of ranks=585260rank=374500 of ranks=585260rank=374600 of ranks=585260rank=374700 of ranks=585260rank=374800 of ranks=585260rank=374900 of ranks=585260rank=375000 of ranks=585260rank=375100 of ranks=585260rank=375200 of ranks=585260rank=375300 of ranks=585260rank=375400 of ranks=585260rank=375500 of ranks=585260rank=375600 of ranks=585260rank=375700 of ranks=585260rank=375800 of ranks=585260rank=375900 of ranks=585260rank=376000 of ranks=585260rank=376100 of ranks=585260rank=376200 of ranks=585260rank=376300 of ranks=585260rank=376400 of ranks=585260rank=376500 of ranks=585260rank=376600 of ranks=585260rank=376700 of ranks=585260rank=376800 of ranks=585260rank=376900 of ranks=585260rank=377000 of ranks=585260rank=377100 of ranks=585260rank=377200 of ranks=585260rank=377300 of ranks=585260rank=377400 of ranks=585260rank=377500 of ranks=585260rank=377600 of ranks=585260rank=377700 of ranks=585260rank=377800 of ranks=585260rank=377900 of ranks=585260rank=378000 of ranks=585260rank=378100 of ranks=585260rank=378200 of ranks=585260rank=378300 of ranks=585260rank=378400 of ranks=585260rank=378500 of ranks=585260rank=378600 of ranks=585260rank=378700 of ranks=585260rank=378800 of ranks=585260rank=378900 of ranks=585260rank=379000 of ranks=585260rank=379100 of ranks=585260rank=379200 of ranks=585260rank=379300 of ranks=585260rank=379400 of ranks=585260rank=379500 of ranks=585260rank=379600 of ranks=585260rank=379700 of ranks=585260rank=379800 of ranks=585260rank=379900 of ranks=585260rank=380000 of ranks=585260rank=380100 of ranks=585260rank=380200 of ranks=585260rank=380300 of ranks=585260rank=380400 of ranks=585260rank=380500 of ranks=585260rank=380600 of ranks=585260rank=380700 of ranks=585260rank=380800 of ranks=585260rank=380900 of ranks=585260rank=381000 of ranks=585260rank=381100 of ranks=585260rank=381200 of ranks=585260rank=381300 of ranks=585260rank=381400 of ranks=585260rank=381500 of ranks=585260rank=381600 of ranks=585260rank=381700 of ranks=585260rank=381800 of ranks=585260rank=381900 of ranks=585260rank=382000 of ranks=585260rank=382100 of ranks=585260rank=382200 of ranks=585260rank=382300 of ranks=585260rank=382400 of ranks=585260rank=382500 of ranks=585260rank=382600 of ranks=585260rank=382700 of ranks=585260rank=382800 of ranks=585260rank=382900 of ranks=585260rank=383000 of ranks=585260rank=383100 of ranks=585260rank=383200 of ranks=585260rank=383300 of ranks=585260rank=383400 of ranks=585260rank=383500 of ranks=585260rank=383600 of ranks=585260rank=383700 of ranks=585260rank=383800 of ranks=585260rank=383900 of ranks=585260rank=384000 of ranks=585260rank=384100 of ranks=585260rank=384200 of ranks=585260rank=384300 of ranks=585260rank=384400 of ranks=585260rank=384500 of ranks=585260rank=384600 of ranks=585260rank=384700 of ranks=585260rank=384800 of ranks=585260rank=384900 of ranks=585260rank=385000 of ranks=585260rank=385100 of ranks=585260rank=385200 of ranks=585260rank=385300 of ranks=585260rank=385400 of ranks=585260rank=385500 of ranks=585260rank=385600 of ranks=585260rank=385700 of ranks=585260rank=385800 of ranks=585260rank=385900 of ranks=585260rank=386000 of ranks=585260rank=386100 of ranks=585260rank=386200 of ranks=585260rank=386300 of ranks=585260rank=386400 of ranks=585260rank=386500 of ranks=585260rank=386600 of ranks=585260rank=386700 of ranks=585260rank=386800 of ranks=585260rank=386900 of ranks=585260rank=387000 of ranks=585260rank=387100 of ranks=585260rank=387200 of ranks=585260rank=387300 of ranks=585260rank=387400 of ranks=585260rank=387500 of ranks=585260rank=387600 of ranks=585260rank=387700 of ranks=585260rank=387800 of ranks=585260rank=387900 of ranks=585260rank=388000 of ranks=585260rank=388100 of ranks=585260rank=388200 of ranks=585260rank=388300 of ranks=585260rank=388400 of ranks=585260rank=388500 of ranks=585260rank=388600 of ranks=585260rank=388700 of ranks=585260rank=388800 of ranks=585260rank=388900 of ranks=585260rank=389000 of ranks=585260rank=389100 of ranks=585260rank=389200 of ranks=585260rank=389300 of ranks=585260rank=389400 of ranks=585260rank=389500 of ranks=585260rank=389600 of ranks=585260rank=389700 of ranks=585260rank=389800 of ranks=585260rank=389900 of ranks=585260rank=390000 of ranks=585260rank=390100 of ranks=585260rank=390200 of ranks=585260rank=390300 of ranks=585260rank=390400 of ranks=585260rank=390500 of ranks=585260rank=390600 of ranks=585260rank=390700 of ranks=585260rank=390800 of ranks=585260rank=390900 of ranks=585260rank=391000 of ranks=585260rank=391100 of ranks=585260rank=391200 of ranks=585260rank=391300 of ranks=585260rank=391400 of ranks=585260rank=391500 of ranks=585260rank=391600 of ranks=585260rank=391700 of ranks=585260rank=391800 of ranks=585260rank=391900 of ranks=585260rank=392000 of ranks=585260rank=392100 of ranks=585260rank=392200 of ranks=585260rank=392300 of ranks=585260rank=392400 of ranks=585260rank=392500 of ranks=585260rank=392600 of ranks=585260rank=392700 of ranks=585260rank=392800 of ranks=585260rank=392900 of ranks=585260rank=393000 of ranks=585260rank=393100 of ranks=585260rank=393200 of ranks=585260rank=393300 of ranks=585260rank=393400 of ranks=585260rank=393500 of ranks=585260rank=393600 of ranks=585260rank=393700 of ranks=585260rank=393800 of ranks=585260rank=393900 of ranks=585260rank=394000 of ranks=585260rank=394100 of ranks=585260rank=394200 of ranks=585260rank=394300 of ranks=585260rank=394400 of ranks=585260rank=394500 of ranks=585260rank=394600 of ranks=585260rank=394700 of ranks=585260rank=394800 of ranks=585260rank=394900 of ranks=585260rank=395000 of ranks=585260rank=395100 of ranks=585260rank=395200 of ranks=585260rank=395300 of ranks=585260rank=395400 of ranks=585260rank=395500 of ranks=585260rank=395600 of ranks=585260rank=395700 of ranks=585260rank=395800 of ranks=585260rank=395900 of ranks=585260rank=396000 of ranks=585260rank=396100 of ranks=585260rank=396200 of ranks=585260rank=396300 of ranks=585260rank=396400 of ranks=585260rank=396500 of ranks=585260rank=396600 of ranks=585260rank=396700 of ranks=585260rank=396800 of ranks=585260rank=396900 of ranks=585260rank=397000 of ranks=585260rank=397100 of ranks=585260rank=397200 of ranks=585260rank=397300 of ranks=585260rank=397400 of ranks=585260rank=397500 of ranks=585260rank=397600 of ranks=585260rank=397700 of ranks=585260rank=397800 of ranks=585260rank=397900 of ranks=585260rank=398000 of ranks=585260rank=398100 of ranks=585260rank=398200 of ranks=585260rank=398300 of ranks=585260rank=398400 of ranks=585260rank=398500 of ranks=585260rank=398600 of ranks=585260rank=398700 of ranks=585260rank=398800 of ranks=585260rank=398900 of ranks=585260rank=399000 of ranks=585260rank=399100 of ranks=585260rank=399200 of ranks=585260rank=399300 of ranks=585260rank=399400 of ranks=585260rank=399500 of ranks=585260rank=399600 of ranks=585260rank=399700 of ranks=585260rank=399800 of ranks=585260rank=399900 of ranks=585260rank=400000 of ranks=585260rank=400100 of ranks=585260rank=400200 of ranks=585260rank=400300 of ranks=585260rank=400400 of ranks=585260rank=400500 of ranks=585260rank=400600 of ranks=585260rank=400700 of ranks=585260rank=400800 of ranks=585260rank=400900 of ranks=585260rank=401000 of ranks=585260rank=401100 of ranks=585260rank=401200 of ranks=585260rank=401300 of ranks=585260rank=401400 of ranks=585260rank=401500 of ranks=585260rank=401600 of ranks=585260rank=401700 of ranks=585260rank=401800 of ranks=585260rank=401900 of ranks=585260rank=402000 of ranks=585260rank=402100 of ranks=585260rank=402200 of ranks=585260rank=402300 of ranks=585260rank=402400 of ranks=585260rank=402500 of ranks=585260rank=402600 of ranks=585260rank=402700 of ranks=585260rank=402800 of ranks=585260rank=402900 of ranks=585260rank=403000 of ranks=585260rank=403100 of ranks=585260rank=403200 of ranks=585260rank=403300 of ranks=585260rank=403400 of ranks=585260rank=403500 of ranks=585260rank=403600 of ranks=585260rank=403700 of ranks=585260rank=403800 of ranks=585260rank=403900 of ranks=585260rank=404000 of ranks=585260rank=404100 of ranks=585260rank=404200 of ranks=585260rank=404300 of ranks=585260rank=404400 of ranks=585260rank=404500 of ranks=585260rank=404600 of ranks=585260rank=404700 of ranks=585260rank=404800 of ranks=585260rank=404900 of ranks=585260rank=405000 of ranks=585260rank=405100 of ranks=585260rank=405200 of ranks=585260rank=405300 of ranks=585260rank=405400 of ranks=585260rank=405500 of ranks=585260rank=405600 of ranks=585260rank=405700 of ranks=585260rank=405800 of ranks=585260rank=405900 of ranks=585260rank=406000 of ranks=585260rank=406100 of ranks=585260rank=406200 of ranks=585260rank=406300 of ranks=585260rank=406400 of ranks=585260rank=406500 of ranks=585260rank=406600 of ranks=585260rank=406700 of ranks=585260rank=406800 of ranks=585260rank=406900 of ranks=585260rank=407000 of ranks=585260rank=407100 of ranks=585260rank=407200 of ranks=585260rank=407300 of ranks=585260rank=407400 of ranks=585260rank=407500 of ranks=585260rank=407600 of ranks=585260rank=407700 of ranks=585260rank=407800 of ranks=585260rank=407900 of ranks=585260rank=408000 of ranks=585260rank=408100 of ranks=585260rank=408200 of ranks=585260rank=408300 of ranks=585260rank=408400 of ranks=585260rank=408500 of ranks=585260rank=408600 of ranks=585260rank=408700 of ranks=585260rank=408800 of ranks=585260rank=408900 of ranks=585260rank=409000 of ranks=585260rank=409100 of ranks=585260rank=409200 of ranks=585260rank=409300 of ranks=585260rank=409400 of ranks=585260rank=409500 of ranks=585260rank=409600 of ranks=585260rank=409700 of ranks=585260rank=409800 of ranks=585260rank=409900 of ranks=585260rank=410000 of ranks=585260rank=410100 of ranks=585260rank=410200 of ranks=585260rank=410300 of ranks=585260rank=410400 of ranks=585260rank=410500 of ranks=585260rank=410600 of ranks=585260rank=410700 of ranks=585260rank=410800 of ranks=585260rank=410900 of ranks=585260rank=411000 of ranks=585260rank=411100 of ranks=585260rank=411200 of ranks=585260rank=411300 of ranks=585260rank=411400 of ranks=585260rank=411500 of ranks=585260rank=411600 of ranks=585260rank=411700 of ranks=585260rank=411800 of ranks=585260rank=411900 of ranks=585260rank=412000 of ranks=585260rank=412100 of ranks=585260rank=412200 of ranks=585260rank=412300 of ranks=585260rank=412400 of ranks=585260rank=412500 of ranks=585260rank=412600 of ranks=585260rank=412700 of ranks=585260rank=412800 of ranks=585260rank=412900 of ranks=585260rank=413000 of ranks=585260rank=413100 of ranks=585260rank=413200 of ranks=585260rank=413300 of ranks=585260rank=413400 of ranks=585260rank=413500 of ranks=585260rank=413600 of ranks=585260rank=413700 of ranks=585260rank=413800 of ranks=585260rank=413900 of ranks=585260rank=414000 of ranks=585260rank=414100 of ranks=585260rank=414200 of ranks=585260rank=414300 of ranks=585260rank=414400 of ranks=585260rank=414500 of ranks=585260rank=414600 of ranks=585260rank=414700 of ranks=585260rank=414800 of ranks=585260rank=414900 of ranks=585260rank=415000 of ranks=585260rank=415100 of ranks=585260rank=415200 of ranks=585260rank=415300 of ranks=585260rank=415400 of ranks=585260rank=415500 of ranks=585260rank=415600 of ranks=585260rank=415700 of ranks=585260rank=415800 of ranks=585260rank=415900 of ranks=585260rank=416000 of ranks=585260rank=416100 of ranks=585260rank=416200 of ranks=585260rank=416300 of ranks=585260rank=416400 of ranks=585260rank=416500 of ranks=585260rank=416600 of ranks=585260rank=416700 of ranks=585260rank=416800 of ranks=585260rank=416900 of ranks=585260rank=417000 of ranks=585260rank=417100 of ranks=585260rank=417200 of ranks=585260rank=417300 of ranks=585260rank=417400 of ranks=585260rank=417500 of ranks=585260rank=417600 of ranks=585260rank=417700 of ranks=585260rank=417800 of ranks=585260rank=417900 of ranks=585260rank=418000 of ranks=585260rank=418100 of ranks=585260rank=418200 of ranks=585260rank=418300 of ranks=585260rank=418400 of ranks=585260rank=418500 of ranks=585260rank=418600 of ranks=585260rank=418700 of ranks=585260rank=418800 of ranks=585260rank=418900 of ranks=585260rank=419000 of ranks=585260rank=419100 of ranks=585260rank=419200 of ranks=585260rank=419300 of ranks=585260rank=419400 of ranks=585260rank=419500 of ranks=585260rank=419600 of ranks=585260rank=419700 of ranks=585260rank=419800 of ranks=585260rank=419900 of ranks=585260rank=420000 of ranks=585260rank=420100 of ranks=585260rank=420200 of ranks=585260rank=420300 of ranks=585260rank=420400 of ranks=585260rank=420500 of ranks=585260rank=420600 of ranks=585260rank=420700 of ranks=585260rank=420800 of ranks=585260rank=420900 of ranks=585260rank=421000 of ranks=585260rank=421100 of ranks=585260rank=421200 of ranks=585260rank=421300 of ranks=585260rank=421400 of ranks=585260rank=421500 of ranks=585260rank=421600 of ranks=585260rank=421700 of ranks=585260rank=421800 of ranks=585260rank=421900 of ranks=585260rank=422000 of ranks=585260rank=422100 of ranks=585260rank=422200 of ranks=585260rank=422300 of ranks=585260rank=422400 of ranks=585260rank=422500 of ranks=585260rank=422600 of ranks=585260rank=422700 of ranks=585260rank=422800 of ranks=585260rank=422900 of ranks=585260rank=423000 of ranks=585260rank=423100 of ranks=585260rank=423200 of ranks=585260rank=423300 of ranks=585260rank=423400 of ranks=585260rank=423500 of ranks=585260rank=423600 of ranks=585260rank=423700 of ranks=585260rank=423800 of ranks=585260rank=423900 of ranks=585260rank=424000 of ranks=585260rank=424100 of ranks=585260rank=424200 of ranks=585260rank=424300 of ranks=585260rank=424400 of ranks=585260rank=424500 of ranks=585260rank=424600 of ranks=585260rank=424700 of ranks=585260rank=424800 of ranks=585260rank=424900 of ranks=585260rank=425000 of ranks=585260rank=425100 of ranks=585260rank=425200 of ranks=585260rank=425300 of ranks=585260rank=425400 of ranks=585260rank=425500 of ranks=585260rank=425600 of ranks=585260rank=425700 of ranks=585260rank=425800 of ranks=585260rank=425900 of ranks=585260rank=426000 of ranks=585260rank=426100 of ranks=585260rank=426200 of ranks=585260rank=426300 of ranks=585260rank=426400 of ranks=585260rank=426500 of ranks=585260rank=426600 of ranks=585260rank=426700 of ranks=585260rank=426800 of ranks=585260rank=426900 of ranks=585260rank=427000 of ranks=585260rank=427100 of ranks=585260rank=427200 of ranks=585260rank=427300 of ranks=585260rank=427400 of ranks=585260rank=427500 of ranks=585260rank=427600 of ranks=585260rank=427700 of ranks=585260rank=427800 of ranks=585260rank=427900 of ranks=585260rank=428000 of ranks=585260rank=428100 of ranks=585260rank=428200 of ranks=585260rank=428300 of ranks=585260rank=428400 of ranks=585260rank=428500 of ranks=585260rank=428600 of ranks=585260rank=428700 of ranks=585260rank=428800 of ranks=585260rank=428900 of ranks=585260rank=429000 of ranks=585260rank=429100 of ranks=585260rank=429200 of ranks=585260rank=429300 of ranks=585260rank=429400 of ranks=585260rank=429500 of ranks=585260rank=429600 of ranks=585260rank=429700 of ranks=585260rank=429800 of ranks=585260rank=429900 of ranks=585260rank=430000 of ranks=585260rank=430100 of ranks=585260rank=430200 of ranks=585260rank=430300 of ranks=585260rank=430400 of ranks=585260rank=430500 of ranks=585260rank=430600 of ranks=585260rank=430700 of ranks=585260rank=430800 of ranks=585260rank=430900 of ranks=585260rank=431000 of ranks=585260rank=431100 of ranks=585260rank=431200 of ranks=585260rank=431300 of ranks=585260rank=431400 of ranks=585260rank=431500 of ranks=585260rank=431600 of ranks=585260rank=431700 of ranks=585260rank=431800 of ranks=585260rank=431900 of ranks=585260rank=432000 of ranks=585260rank=432100 of ranks=585260rank=432200 of ranks=585260rank=432300 of ranks=585260rank=432400 of ranks=585260rank=432500 of ranks=585260rank=432600 of ranks=585260rank=432700 of ranks=585260rank=432800 of ranks=585260rank=432900 of ranks=585260rank=433000 of ranks=585260rank=433100 of ranks=585260rank=433200 of ranks=585260rank=433300 of ranks=585260rank=433400 of ranks=585260rank=433500 of ranks=585260rank=433600 of ranks=585260rank=433700 of ranks=585260rank=433800 of ranks=585260rank=433900 of ranks=585260rank=434000 of ranks=585260rank=434100 of ranks=585260rank=434200 of ranks=585260rank=434300 of ranks=585260rank=434400 of ranks=585260rank=434500 of ranks=585260rank=434600 of ranks=585260rank=434700 of ranks=585260rank=434800 of ranks=585260rank=434900 of ranks=585260rank=435000 of ranks=585260rank=435100 of ranks=585260rank=435200 of ranks=585260rank=435300 of ranks=585260rank=435400 of ranks=585260rank=435500 of ranks=585260rank=435600 of ranks=585260rank=435700 of ranks=585260rank=435800 of ranks=585260rank=435900 of ranks=585260rank=436000 of ranks=585260rank=436100 of ranks=585260rank=436200 of ranks=585260rank=436300 of ranks=585260rank=436400 of ranks=585260rank=436500 of ranks=585260rank=436600 of ranks=585260rank=436700 of ranks=585260rank=436800 of ranks=585260rank=436900 of ranks=585260rank=437000 of ranks=585260rank=437100 of ranks=585260rank=437200 of ranks=585260rank=437300 of ranks=585260rank=437400 of ranks=585260rank=437500 of ranks=585260rank=437600 of ranks=585260rank=437700 of ranks=585260rank=437800 of ranks=585260rank=437900 of ranks=585260rank=438000 of ranks=585260rank=438100 of ranks=585260rank=438200 of ranks=585260rank=438300 of ranks=585260rank=438400 of ranks=585260rank=438500 of ranks=585260rank=438600 of ranks=585260rank=438700 of ranks=585260rank=438800 of ranks=585260rank=438900 of ranks=585260rank=439000 of ranks=585260rank=439100 of ranks=585260rank=439200 of ranks=585260rank=439300 of ranks=585260rank=439400 of ranks=585260rank=439500 of ranks=585260rank=439600 of ranks=585260rank=439700 of ranks=585260rank=439800 of ranks=585260rank=439900 of ranks=585260rank=440000 of ranks=585260rank=440100 of ranks=585260rank=440200 of ranks=585260rank=440300 of ranks=585260rank=440400 of ranks=585260rank=440500 of ranks=585260rank=440600 of ranks=585260rank=440700 of ranks=585260rank=440800 of ranks=585260rank=440900 of ranks=585260rank=441000 of ranks=585260rank=441100 of ranks=585260rank=441200 of ranks=585260rank=441300 of ranks=585260rank=441400 of ranks=585260rank=441500 of ranks=585260rank=441600 of ranks=585260rank=441700 of ranks=585260rank=441800 of ranks=585260rank=441900 of ranks=585260rank=442000 of ranks=585260rank=442100 of ranks=585260rank=442200 of ranks=585260rank=442300 of ranks=585260rank=442400 of ranks=585260rank=442500 of ranks=585260rank=442600 of ranks=585260rank=442700 of ranks=585260rank=442800 of ranks=585260rank=442900 of ranks=585260rank=443000 of ranks=585260rank=443100 of ranks=585260rank=443200 of ranks=585260rank=443300 of ranks=585260rank=443400 of ranks=585260rank=443500 of ranks=585260rank=443600 of ranks=585260rank=443700 of ranks=585260rank=443800 of ranks=585260rank=443900 of ranks=585260rank=444000 of ranks=585260rank=444100 of ranks=585260rank=444200 of ranks=585260rank=444300 of ranks=585260rank=444400 of ranks=585260rank=444500 of ranks=585260rank=444600 of ranks=585260rank=444700 of ranks=585260rank=444800 of ranks=585260rank=444900 of ranks=585260rank=445000 of ranks=585260rank=445100 of ranks=585260rank=445200 of ranks=585260rank=445300 of ranks=585260rank=445400 of ranks=585260rank=445500 of ranks=585260rank=445600 of ranks=585260rank=445700 of ranks=585260rank=445800 of ranks=585260rank=445900 of ranks=585260rank=446000 of ranks=585260rank=446100 of ranks=585260rank=446200 of ranks=585260rank=446300 of ranks=585260rank=446400 of ranks=585260rank=446500 of ranks=585260rank=446600 of ranks=585260rank=446700 of ranks=585260rank=446800 of ranks=585260rank=446900 of ranks=585260rank=447000 of ranks=585260rank=447100 of ranks=585260rank=447200 of ranks=585260rank=447300 of ranks=585260rank=447400 of ranks=585260rank=447500 of ranks=585260rank=447600 of ranks=585260rank=447700 of ranks=585260rank=447800 of ranks=585260rank=447900 of ranks=585260rank=448000 of ranks=585260rank=448100 of ranks=585260rank=448200 of ranks=585260rank=448300 of ranks=585260rank=448400 of ranks=585260rank=448500 of ranks=585260rank=448600 of ranks=585260rank=448700 of ranks=585260rank=448800 of ranks=585260rank=448900 of ranks=585260rank=449000 of ranks=585260rank=449100 of ranks=585260rank=449200 of ranks=585260rank=449300 of ranks=585260rank=449400 of ranks=585260rank=449500 of ranks=585260rank=449600 of ranks=585260rank=449700 of ranks=585260rank=449800 of ranks=585260rank=449900 of ranks=585260rank=450000 of ranks=585260rank=450100 of ranks=585260rank=450200 of ranks=585260rank=450300 of ranks=585260rank=450400 of ranks=585260rank=450500 of ranks=585260rank=450600 of ranks=585260rank=450700 of ranks=585260rank=450800 of ranks=585260rank=450900 of ranks=585260rank=451000 of ranks=585260rank=451100 of ranks=585260rank=451200 of ranks=585260rank=451300 of ranks=585260rank=451400 of ranks=585260rank=451500 of ranks=585260rank=451600 of ranks=585260rank=451700 of ranks=585260rank=451800 of ranks=585260rank=451900 of ranks=585260rank=452000 of ranks=585260rank=452100 of ranks=585260rank=452200 of ranks=585260rank=452300 of ranks=585260rank=452400 of ranks=585260rank=452500 of ranks=585260rank=452600 of ranks=585260rank=452700 of ranks=585260rank=452800 of ranks=585260rank=452900 of ranks=585260rank=453000 of ranks=585260rank=453100 of ranks=585260rank=453200 of ranks=585260rank=453300 of ranks=585260rank=453400 of ranks=585260rank=453500 of ranks=585260rank=453600 of ranks=585260rank=453700 of ranks=585260rank=453800 of ranks=585260rank=453900 of ranks=585260rank=454000 of ranks=585260rank=454100 of ranks=585260rank=454200 of ranks=585260rank=454300 of ranks=585260rank=454400 of ranks=585260rank=454500 of ranks=585260rank=454600 of ranks=585260rank=454700 of ranks=585260rank=454800 of ranks=585260rank=454900 of ranks=585260rank=455000 of ranks=585260rank=455100 of ranks=585260rank=455200 of ranks=585260rank=455300 of ranks=585260rank=455400 of ranks=585260rank=455500 of ranks=585260rank=455600 of ranks=585260rank=455700 of ranks=585260rank=455800 of ranks=585260rank=455900 of ranks=585260rank=456000 of ranks=585260rank=456100 of ranks=585260rank=456200 of ranks=585260rank=456300 of ranks=585260rank=456400 of ranks=585260rank=456500 of ranks=585260rank=456600 of ranks=585260rank=456700 of ranks=585260rank=456800 of ranks=585260rank=456900 of ranks=585260rank=457000 of ranks=585260rank=457100 of ranks=585260rank=457200 of ranks=585260rank=457300 of ranks=585260rank=457400 of ranks=585260rank=457500 of ranks=585260rank=457600 of ranks=585260rank=457700 of ranks=585260rank=457800 of ranks=585260rank=457900 of ranks=585260rank=458000 of ranks=585260rank=458100 of ranks=585260rank=458200 of ranks=585260rank=458300 of ranks=585260rank=458400 of ranks=585260rank=458500 of ranks=585260rank=458600 of ranks=585260rank=458700 of ranks=585260rank=458800 of ranks=585260rank=458900 of ranks=585260rank=459000 of ranks=585260rank=459100 of ranks=585260rank=459200 of ranks=585260rank=459300 of ranks=585260rank=459400 of ranks=585260rank=459500 of ranks=585260rank=459600 of ranks=585260rank=459700 of ranks=585260rank=459800 of ranks=585260rank=459900 of ranks=585260rank=460000 of ranks=585260rank=460100 of ranks=585260rank=460200 of ranks=585260rank=460300 of ranks=585260rank=460400 of ranks=585260rank=460500 of ranks=585260rank=460600 of ranks=585260rank=460700 of ranks=585260rank=460800 of ranks=585260rank=460900 of ranks=585260rank=461000 of ranks=585260rank=461100 of ranks=585260rank=461200 of ranks=585260rank=461300 of ranks=585260rank=461400 of ranks=585260rank=461500 of ranks=585260rank=461600 of ranks=585260rank=461700 of ranks=585260rank=461800 of ranks=585260rank=461900 of ranks=585260rank=462000 of ranks=585260rank=462100 of ranks=585260rank=462200 of ranks=585260rank=462300 of ranks=585260rank=462400 of ranks=585260rank=462500 of ranks=585260rank=462600 of ranks=585260rank=462700 of ranks=585260rank=462800 of ranks=585260rank=462900 of ranks=585260rank=463000 of ranks=585260rank=463100 of ranks=585260rank=463200 of ranks=585260rank=463300 of ranks=585260rank=463400 of ranks=585260rank=463500 of ranks=585260rank=463600 of ranks=585260rank=463700 of ranks=585260rank=463800 of ranks=585260rank=463900 of ranks=585260rank=464000 of ranks=585260rank=464100 of ranks=585260rank=464200 of ranks=585260rank=464300 of ranks=585260rank=464400 of ranks=585260rank=464500 of ranks=585260rank=464600 of ranks=585260rank=464700 of ranks=585260rank=464800 of ranks=585260rank=464900 of ranks=585260rank=465000 of ranks=585260rank=465100 of ranks=585260rank=465200 of ranks=585260rank=465300 of ranks=585260rank=465400 of ranks=585260rank=465500 of ranks=585260rank=465600 of ranks=585260rank=465700 of ranks=585260rank=465800 of ranks=585260rank=465900 of ranks=585260rank=466000 of ranks=585260rank=466100 of ranks=585260rank=466200 of ranks=585260rank=466300 of ranks=585260rank=466400 of ranks=585260rank=466500 of ranks=585260rank=466600 of ranks=585260rank=466700 of ranks=585260rank=466800 of ranks=585260rank=466900 of ranks=585260rank=467000 of ranks=585260rank=467100 of ranks=585260rank=467200 of ranks=585260rank=467300 of ranks=585260rank=467400 of ranks=585260rank=467500 of ranks=585260rank=467600 of ranks=585260rank=467700 of ranks=585260rank=467800 of ranks=585260rank=467900 of ranks=585260rank=468000 of ranks=585260rank=468100 of ranks=585260rank=468200 of ranks=585260rank=468300 of ranks=585260rank=468400 of ranks=585260rank=468500 of ranks=585260rank=468600 of ranks=585260rank=468700 of ranks=585260rank=468800 of ranks=585260rank=468900 of ranks=585260rank=469000 of ranks=585260rank=469100 of ranks=585260rank=469200 of ranks=585260rank=469300 of ranks=585260rank=469400 of ranks=585260rank=469500 of ranks=585260rank=469600 of ranks=585260rank=469700 of ranks=585260rank=469800 of ranks=585260rank=469900 of ranks=585260rank=470000 of ranks=585260rank=470100 of ranks=585260rank=470200 of ranks=585260rank=470300 of ranks=585260rank=470400 of ranks=585260rank=470500 of ranks=585260rank=470600 of ranks=585260rank=470700 of ranks=585260rank=470800 of ranks=585260rank=470900 of ranks=585260rank=471000 of ranks=585260rank=471100 of ranks=585260rank=471200 of ranks=585260rank=471300 of ranks=585260rank=471400 of ranks=585260rank=471500 of ranks=585260rank=471600 of ranks=585260rank=471700 of ranks=585260rank=471800 of ranks=585260rank=471900 of ranks=585260rank=472000 of ranks=585260rank=472100 of ranks=585260rank=472200 of ranks=585260rank=472300 of ranks=585260rank=472400 of ranks=585260rank=472500 of ranks=585260rank=472600 of ranks=585260rank=472700 of ranks=585260rank=472800 of ranks=585260rank=472900 of ranks=585260rank=473000 of ranks=585260rank=473100 of ranks=585260rank=473200 of ranks=585260rank=473300 of ranks=585260rank=473400 of ranks=585260rank=473500 of ranks=585260rank=473600 of ranks=585260rank=473700 of ranks=585260rank=473800 of ranks=585260rank=473900 of ranks=585260rank=474000 of ranks=585260rank=474100 of ranks=585260rank=474200 of ranks=585260rank=474300 of ranks=585260rank=474400 of ranks=585260rank=474500 of ranks=585260rank=474600 of ranks=585260rank=474700 of ranks=585260rank=474800 of ranks=585260rank=474900 of ranks=585260rank=475000 of ranks=585260rank=475100 of ranks=585260rank=475200 of ranks=585260rank=475300 of ranks=585260rank=475400 of ranks=585260rank=475500 of ranks=585260rank=475600 of ranks=585260rank=475700 of ranks=585260rank=475800 of ranks=585260rank=475900 of ranks=585260rank=476000 of ranks=585260rank=476100 of ranks=585260rank=476200 of ranks=585260rank=476300 of ranks=585260rank=476400 of ranks=585260rank=476500 of ranks=585260rank=476600 of ranks=585260rank=476700 of ranks=585260rank=476800 of ranks=585260rank=476900 of ranks=585260rank=477000 of ranks=585260rank=477100 of ranks=585260rank=477200 of ranks=585260rank=477300 of ranks=585260rank=477400 of ranks=585260rank=477500 of ranks=585260rank=477600 of ranks=585260rank=477700 of ranks=585260rank=477800 of ranks=585260rank=477900 of ranks=585260rank=478000 of ranks=585260rank=478100 of ranks=585260rank=478200 of ranks=585260rank=478300 of ranks=585260rank=478400 of ranks=585260rank=478500 of ranks=585260rank=478600 of ranks=585260rank=478700 of ranks=585260rank=478800 of ranks=585260rank=478900 of ranks=585260rank=479000 of ranks=585260rank=479100 of ranks=585260rank=479200 of ranks=585260rank=479300 of ranks=585260rank=479400 of ranks=585260rank=479500 of ranks=585260rank=479600 of ranks=585260rank=479700 of ranks=585260rank=479800 of ranks=585260rank=479900 of ranks=585260rank=480000 of ranks=585260rank=480100 of ranks=585260rank=480200 of ranks=585260rank=480300 of ranks=585260rank=480400 of ranks=585260rank=480500 of ranks=585260rank=480600 of ranks=585260rank=480700 of ranks=585260rank=480800 of ranks=585260rank=480900 of ranks=585260rank=481000 of ranks=585260rank=481100 of ranks=585260rank=481200 of ranks=585260rank=481300 of ranks=585260rank=481400 of ranks=585260rank=481500 of ranks=585260rank=481600 of ranks=585260rank=481700 of ranks=585260rank=481800 of ranks=585260rank=481900 of ranks=585260rank=482000 of ranks=585260rank=482100 of ranks=585260rank=482200 of ranks=585260rank=482300 of ranks=585260rank=482400 of ranks=585260rank=482500 of ranks=585260rank=482600 of ranks=585260rank=482700 of ranks=585260rank=482800 of ranks=585260rank=482900 of ranks=585260rank=483000 of ranks=585260rank=483100 of ranks=585260rank=483200 of ranks=585260rank=483300 of ranks=585260rank=483400 of ranks=585260rank=483500 of ranks=585260rank=483600 of ranks=585260rank=483700 of ranks=585260rank=483800 of ranks=585260rank=483900 of ranks=585260rank=484000 of ranks=585260rank=484100 of ranks=585260rank=484200 of ranks=585260rank=484300 of ranks=585260rank=484400 of ranks=585260rank=484500 of ranks=585260rank=484600 of ranks=585260rank=484700 of ranks=585260rank=484800 of ranks=585260rank=484900 of ranks=585260rank=485000 of ranks=585260rank=485100 of ranks=585260rank=485200 of ranks=585260rank=485300 of ranks=585260rank=485400 of ranks=585260rank=485500 of ranks=585260rank=485600 of ranks=585260rank=485700 of ranks=585260rank=485800 of ranks=585260rank=485900 of ranks=585260rank=486000 of ranks=585260rank=486100 of ranks=585260rank=486200 of ranks=585260rank=486300 of ranks=585260rank=486400 of ranks=585260rank=486500 of ranks=585260rank=486600 of ranks=585260rank=486700 of ranks=585260rank=486800 of ranks=585260rank=486900 of ranks=585260rank=487000 of ranks=585260rank=487100 of ranks=585260rank=487200 of ranks=585260rank=487300 of ranks=585260rank=487400 of ranks=585260rank=487500 of ranks=585260rank=487600 of ranks=585260rank=487700 of ranks=585260rank=487800 of ranks=585260rank=487900 of ranks=585260rank=488000 of ranks=585260rank=488100 of ranks=585260rank=488200 of ranks=585260rank=488300 of ranks=585260rank=488400 of ranks=585260rank=488500 of ranks=585260rank=488600 of ranks=585260rank=488700 of ranks=585260rank=488800 of ranks=585260rank=488900 of ranks=585260rank=489000 of ranks=585260rank=489100 of ranks=585260rank=489200 of ranks=585260rank=489300 of ranks=585260rank=489400 of ranks=585260rank=489500 of ranks=585260rank=489600 of ranks=585260rank=489700 of ranks=585260rank=489800 of ranks=585260rank=489900 of ranks=585260rank=490000 of ranks=585260rank=490100 of ranks=585260rank=490200 of ranks=585260rank=490300 of ranks=585260rank=490400 of ranks=585260rank=490500 of ranks=585260rank=490600 of ranks=585260rank=490700 of ranks=585260rank=490800 of ranks=585260rank=490900 of ranks=585260rank=491000 of ranks=585260rank=491100 of ranks=585260rank=491200 of ranks=585260rank=491300 of ranks=585260rank=491400 of ranks=585260rank=491500 of ranks=585260rank=491600 of ranks=585260rank=491700 of ranks=585260rank=491800 of ranks=585260rank=491900 of ranks=585260rank=492000 of ranks=585260rank=492100 of ranks=585260rank=492200 of ranks=585260rank=492300 of ranks=585260rank=492400 of ranks=585260rank=492500 of ranks=585260rank=492600 of ranks=585260rank=492700 of ranks=585260rank=492800 of ranks=585260rank=492900 of ranks=585260rank=493000 of ranks=585260rank=493100 of ranks=585260rank=493200 of ranks=585260rank=493300 of ranks=585260rank=493400 of ranks=585260rank=493500 of ranks=585260rank=493600 of ranks=585260rank=493700 of ranks=585260rank=493800 of ranks=585260rank=493900 of ranks=585260rank=494000 of ranks=585260rank=494100 of ranks=585260rank=494200 of ranks=585260rank=494300 of ranks=585260rank=494400 of ranks=585260rank=494500 of ranks=585260rank=494600 of ranks=585260rank=494700 of ranks=585260rank=494800 of ranks=585260rank=494900 of ranks=585260rank=495000 of ranks=585260rank=495100 of ranks=585260rank=495200 of ranks=585260rank=495300 of ranks=585260rank=495400 of ranks=585260rank=495500 of ranks=585260rank=495600 of ranks=585260rank=495700 of ranks=585260rank=495800 of ranks=585260rank=495900 of ranks=585260rank=496000 of ranks=585260rank=496100 of ranks=585260rank=496200 of ranks=585260rank=496300 of ranks=585260rank=496400 of ranks=585260rank=496500 of ranks=585260rank=496600 of ranks=585260rank=496700 of ranks=585260rank=496800 of ranks=585260rank=496900 of ranks=585260rank=497000 of ranks=585260rank=497100 of ranks=585260rank=497200 of ranks=585260rank=497300 of ranks=585260rank=497400 of ranks=585260rank=497500 of ranks=585260rank=497600 of ranks=585260rank=497700 of ranks=585260rank=497800 of ranks=585260rank=497900 of ranks=585260rank=498000 of ranks=585260rank=498100 of ranks=585260rank=498200 of ranks=585260rank=498300 of ranks=585260rank=498400 of ranks=585260rank=498500 of ranks=585260rank=498600 of ranks=585260rank=498700 of ranks=585260rank=498800 of ranks=585260rank=498900 of ranks=585260rank=499000 of ranks=585260rank=499100 of ranks=585260rank=499200 of ranks=585260rank=499300 of ranks=585260rank=499400 of ranks=585260rank=499500 of ranks=585260rank=499600 of ranks=585260rank=499700 of ranks=585260rank=499800 of ranks=585260rank=499900 of ranks=585260rank=500000 of ranks=585260rank=500100 of ranks=585260rank=500200 of ranks=585260rank=500300 of ranks=585260rank=500400 of ranks=585260rank=500500 of ranks=585260rank=500600 of ranks=585260rank=500700 of ranks=585260rank=500800 of ranks=585260rank=500900 of ranks=585260rank=501000 of ranks=585260rank=501100 of ranks=585260rank=501200 of ranks=585260rank=501300 of ranks=585260rank=501400 of ranks=585260rank=501500 of ranks=585260rank=501600 of ranks=585260rank=501700 of ranks=585260rank=501800 of ranks=585260rank=501900 of ranks=585260rank=502000 of ranks=585260rank=502100 of ranks=585260rank=502200 of ranks=585260rank=502300 of ranks=585260rank=502400 of ranks=585260rank=502500 of ranks=585260rank=502600 of ranks=585260rank=502700 of ranks=585260rank=502800 of ranks=585260rank=502900 of ranks=585260rank=503000 of ranks=585260rank=503100 of ranks=585260rank=503200 of ranks=585260rank=503300 of ranks=585260rank=503400 of ranks=585260rank=503500 of ranks=585260rank=503600 of ranks=585260rank=503700 of ranks=585260rank=503800 of ranks=585260rank=503900 of ranks=585260rank=504000 of ranks=585260rank=504100 of ranks=585260rank=504200 of ranks=585260rank=504300 of ranks=585260rank=504400 of ranks=585260rank=504500 of ranks=585260rank=504600 of ranks=585260rank=504700 of ranks=585260rank=504800 of ranks=585260rank=504900 of ranks=585260rank=505000 of ranks=585260rank=505100 of ranks=585260rank=505200 of ranks=585260rank=505300 of ranks=585260rank=505400 of ranks=585260rank=505500 of ranks=585260rank=505600 of ranks=585260rank=505700 of ranks=585260rank=505800 of ranks=585260rank=505900 of ranks=585260rank=506000 of ranks=585260rank=506100 of ranks=585260rank=506200 of ranks=585260rank=506300 of ranks=585260rank=506400 of ranks=585260rank=506500 of ranks=585260rank=506600 of ranks=585260rank=506700 of ranks=585260rank=506800 of ranks=585260rank=506900 of ranks=585260rank=507000 of ranks=585260rank=507100 of ranks=585260rank=507200 of ranks=585260rank=507300 of ranks=585260rank=507400 of ranks=585260rank=507500 of ranks=585260rank=507600 of ranks=585260rank=507700 of ranks=585260rank=507800 of ranks=585260rank=507900 of ranks=585260rank=508000 of ranks=585260rank=508100 of ranks=585260rank=508200 of ranks=585260rank=508300 of ranks=585260rank=508400 of ranks=585260rank=508500 of ranks=585260rank=508600 of ranks=585260rank=508700 of ranks=585260rank=508800 of ranks=585260rank=508900 of ranks=585260rank=509000 of ranks=585260rank=509100 of ranks=585260rank=509200 of ranks=585260rank=509300 of ranks=585260rank=509400 of ranks=585260rank=509500 of ranks=585260rank=509600 of ranks=585260rank=509700 of ranks=585260rank=509800 of ranks=585260rank=509900 of ranks=585260rank=510000 of ranks=585260rank=510100 of ranks=585260rank=510200 of ranks=585260rank=510300 of ranks=585260rank=510400 of ranks=585260rank=510500 of ranks=585260rank=510600 of ranks=585260rank=510700 of ranks=585260rank=510800 of ranks=585260rank=510900 of ranks=585260rank=511000 of ranks=585260rank=511100 of ranks=585260rank=511200 of ranks=585260rank=511300 of ranks=585260rank=511400 of ranks=585260rank=511500 of ranks=585260rank=511600 of ranks=585260rank=511700 of ranks=585260rank=511800 of ranks=585260rank=511900 of ranks=585260rank=512000 of ranks=585260rank=512100 of ranks=585260rank=512200 of ranks=585260rank=512300 of ranks=585260rank=512400 of ranks=585260rank=512500 of ranks=585260rank=512600 of ranks=585260rank=512700 of ranks=585260rank=512800 of ranks=585260rank=512900 of ranks=585260rank=513000 of ranks=585260rank=513100 of ranks=585260rank=513200 of ranks=585260rank=513300 of ranks=585260rank=513400 of ranks=585260rank=513500 of ranks=585260rank=513600 of ranks=585260rank=513700 of ranks=585260rank=513800 of ranks=585260rank=513900 of ranks=585260rank=514000 of ranks=585260rank=514100 of ranks=585260rank=514200 of ranks=585260rank=514300 of ranks=585260rank=514400 of ranks=585260rank=514500 of ranks=585260rank=514600 of ranks=585260rank=514700 of ranks=585260rank=514800 of ranks=585260rank=514900 of ranks=585260rank=515000 of ranks=585260rank=515100 of ranks=585260rank=515200 of ranks=585260rank=515300 of ranks=585260rank=515400 of ranks=585260rank=515500 of ranks=585260rank=515600 of ranks=585260rank=515700 of ranks=585260rank=515800 of ranks=585260rank=515900 of ranks=585260rank=516000 of ranks=585260rank=516100 of ranks=585260rank=516200 of ranks=585260rank=516300 of ranks=585260rank=516400 of ranks=585260rank=516500 of ranks=585260rank=516600 of ranks=585260rank=516700 of ranks=585260rank=516800 of ranks=585260rank=516900 of ranks=585260rank=517000 of ranks=585260rank=517100 of ranks=585260rank=517200 of ranks=585260rank=517300 of ranks=585260rank=517400 of ranks=585260rank=517500 of ranks=585260rank=517600 of ranks=585260rank=517700 of ranks=585260rank=517800 of ranks=585260rank=517900 of ranks=585260rank=518000 of ranks=585260rank=518100 of ranks=585260rank=518200 of ranks=585260rank=518300 of ranks=585260rank=518400 of ranks=585260rank=518500 of ranks=585260rank=518600 of ranks=585260rank=518700 of ranks=585260rank=518800 of ranks=585260rank=518900 of ranks=585260rank=519000 of ranks=585260rank=519100 of ranks=585260rank=519200 of ranks=585260rank=519300 of ranks=585260rank=519400 of ranks=585260rank=519500 of ranks=585260rank=519600 of ranks=585260rank=519700 of ranks=585260rank=519800 of ranks=585260rank=519900 of ranks=585260rank=520000 of ranks=585260rank=520100 of ranks=585260rank=520200 of ranks=585260rank=520300 of ranks=585260rank=520400 of ranks=585260rank=520500 of ranks=585260rank=520600 of ranks=585260rank=520700 of ranks=585260rank=520800 of ranks=585260rank=520900 of ranks=585260rank=521000 of ranks=585260rank=521100 of ranks=585260rank=521200 of ranks=585260rank=521300 of ranks=585260rank=521400 of ranks=585260rank=521500 of ranks=585260rank=521600 of ranks=585260rank=521700 of ranks=585260rank=521800 of ranks=585260rank=521900 of ranks=585260rank=522000 of ranks=585260rank=522100 of ranks=585260rank=522200 of ranks=585260rank=522300 of ranks=585260rank=522400 of ranks=585260rank=522500 of ranks=585260rank=522600 of ranks=585260rank=522700 of ranks=585260rank=522800 of ranks=585260rank=522900 of ranks=585260rank=523000 of ranks=585260rank=523100 of ranks=585260rank=523200 of ranks=585260rank=523300 of ranks=585260rank=523400 of ranks=585260rank=523500 of ranks=585260rank=523600 of ranks=585260rank=523700 of ranks=585260rank=523800 of ranks=585260rank=523900 of ranks=585260rank=524000 of ranks=585260rank=524100 of ranks=585260rank=524200 of ranks=585260rank=524300 of ranks=585260rank=524400 of ranks=585260rank=524500 of ranks=585260rank=524600 of ranks=585260rank=524700 of ranks=585260rank=524800 of ranks=585260rank=524900 of ranks=585260rank=525000 of ranks=585260rank=525100 of ranks=585260rank=525200 of ranks=585260rank=525300 of ranks=585260rank=525400 of ranks=585260rank=525500 of ranks=585260rank=525600 of ranks=585260rank=525700 of ranks=585260rank=525800 of ranks=585260rank=525900 of ranks=585260rank=526000 of ranks=585260rank=526100 of ranks=585260rank=526200 of ranks=585260rank=526300 of ranks=585260rank=526400 of ranks=585260rank=526500 of ranks=585260rank=526600 of ranks=585260rank=526700 of ranks=585260rank=526800 of ranks=585260rank=526900 of ranks=585260rank=527000 of ranks=585260rank=527100 of ranks=585260rank=527200 of ranks=585260rank=527300 of ranks=585260rank=527400 of ranks=585260rank=527500 of ranks=585260rank=527600 of ranks=585260rank=527700 of ranks=585260rank=527800 of ranks=585260rank=527900 of ranks=585260rank=528000 of ranks=585260rank=528100 of ranks=585260rank=528200 of ranks=585260rank=528300 of ranks=585260rank=528400 of ranks=585260rank=528500 of ranks=585260rank=528600 of ranks=585260rank=528700 of ranks=585260rank=528800 of ranks=585260rank=528900 of ranks=585260rank=529000 of ranks=585260rank=529100 of ranks=585260rank=529200 of ranks=585260rank=529300 of ranks=585260rank=529400 of ranks=585260rank=529500 of ranks=585260rank=529600 of ranks=585260rank=529700 of ranks=585260rank=529800 of ranks=585260rank=529900 of ranks=585260rank=530000 of ranks=585260rank=530100 of ranks=585260rank=530200 of ranks=585260rank=530300 of ranks=585260rank=530400 of ranks=585260rank=530500 of ranks=585260rank=530600 of ranks=585260rank=530700 of ranks=585260rank=530800 of ranks=585260rank=530900 of ranks=585260rank=531000 of ranks=585260rank=531100 of ranks=585260rank=531200 of ranks=585260rank=531300 of ranks=585260rank=531400 of ranks=585260rank=531500 of ranks=585260rank=531600 of ranks=585260rank=531700 of ranks=585260rank=531800 of ranks=585260rank=531900 of ranks=585260rank=532000 of ranks=585260rank=532100 of ranks=585260rank=532200 of ranks=585260rank=532300 of ranks=585260rank=532400 of ranks=585260rank=532500 of ranks=585260rank=532600 of ranks=585260rank=532700 of ranks=585260rank=532800 of ranks=585260rank=532900 of ranks=585260rank=533000 of ranks=585260rank=533100 of ranks=585260rank=533200 of ranks=585260rank=533300 of ranks=585260rank=533400 of ranks=585260rank=533500 of ranks=585260rank=533600 of ranks=585260rank=533700 of ranks=585260rank=533800 of ranks=585260rank=533900 of ranks=585260rank=534000 of ranks=585260rank=534100 of ranks=585260rank=534200 of ranks=585260rank=534300 of ranks=585260rank=534400 of ranks=585260rank=534500 of ranks=585260rank=534600 of ranks=585260rank=534700 of ranks=585260rank=534800 of ranks=585260rank=534900 of ranks=585260rank=535000 of ranks=585260rank=535100 of ranks=585260rank=535200 of ranks=585260rank=535300 of ranks=585260rank=535400 of ranks=585260rank=535500 of ranks=585260rank=535600 of ranks=585260rank=535700 of ranks=585260rank=535800 of ranks=585260rank=535900 of ranks=585260rank=536000 of ranks=585260rank=536100 of ranks=585260rank=536200 of ranks=585260rank=536300 of ranks=585260rank=536400 of ranks=585260rank=536500 of ranks=585260rank=536600 of ranks=585260rank=536700 of ranks=585260rank=536800 of ranks=585260rank=536900 of ranks=585260rank=537000 of ranks=585260rank=537100 of ranks=585260rank=537200 of ranks=585260rank=537300 of ranks=585260rank=537400 of ranks=585260rank=537500 of ranks=585260rank=537600 of ranks=585260rank=537700 of ranks=585260rank=537800 of ranks=585260rank=537900 of ranks=585260rank=538000 of ranks=585260rank=538100 of ranks=585260rank=538200 of ranks=585260rank=538300 of ranks=585260rank=538400 of ranks=585260rank=538500 of ranks=585260rank=538600 of ranks=585260rank=538700 of ranks=585260rank=538800 of ranks=585260rank=538900 of ranks=585260rank=539000 of ranks=585260rank=539100 of ranks=585260rank=539200 of ranks=585260rank=539300 of ranks=585260rank=539400 of ranks=585260rank=539500 of ranks=585260rank=539600 of ranks=585260rank=539700 of ranks=585260rank=539800 of ranks=585260rank=539900 of ranks=585260rank=540000 of ranks=585260rank=540100 of ranks=585260rank=540200 of ranks=585260rank=540300 of ranks=585260rank=540400 of ranks=585260rank=540500 of ranks=585260rank=540600 of ranks=585260rank=540700 of ranks=585260rank=540800 of ranks=585260rank=540900 of ranks=585260rank=541000 of ranks=585260rank=541100 of ranks=585260rank=541200 of ranks=585260rank=541300 of ranks=585260rank=541400 of ranks=585260rank=541500 of ranks=585260rank=541600 of ranks=585260rank=541700 of ranks=585260rank=541800 of ranks=585260rank=541900 of ranks=585260rank=542000 of ranks=585260rank=542100 of ranks=585260rank=542200 of ranks=585260rank=542300 of ranks=585260rank=542400 of ranks=585260rank=542500 of ranks=585260rank=542600 of ranks=585260rank=542700 of ranks=585260rank=542800 of ranks=585260rank=542900 of ranks=585260rank=543000 of ranks=585260rank=543100 of ranks=585260rank=543200 of ranks=585260rank=543300 of ranks=585260rank=543400 of ranks=585260rank=543500 of ranks=585260rank=543600 of ranks=585260rank=543700 of ranks=585260rank=543800 of ranks=585260rank=543900 of ranks=585260rank=544000 of ranks=585260rank=544100 of ranks=585260rank=544200 of ranks=585260rank=544300 of ranks=585260rank=544400 of ranks=585260rank=544500 of ranks=585260rank=544600 of ranks=585260rank=544700 of ranks=585260rank=544800 of ranks=585260rank=544900 of ranks=585260rank=545000 of ranks=585260rank=545100 of ranks=585260rank=545200 of ranks=585260rank=545300 of ranks=585260rank=545400 of ranks=585260rank=545500 of ranks=585260rank=545600 of ranks=585260rank=545700 of ranks=585260rank=545800 of ranks=585260rank=545900 of ranks=585260rank=546000 of ranks=585260rank=546100 of ranks=585260rank=546200 of ranks=585260rank=546300 of ranks=585260rank=546400 of ranks=585260rank=546500 of ranks=585260rank=546600 of ranks=585260rank=546700 of ranks=585260rank=546800 of ranks=585260rank=546900 of ranks=585260rank=547000 of ranks=585260rank=547100 of ranks=585260rank=547200 of ranks=585260rank=547300 of ranks=585260rank=547400 of ranks=585260rank=547500 of ranks=585260rank=547600 of ranks=585260rank=547700 of ranks=585260rank=547800 of ranks=585260rank=547900 of ranks=585260rank=548000 of ranks=585260rank=548100 of ranks=585260rank=548200 of ranks=585260rank=548300 of ranks=585260rank=548400 of ranks=585260rank=548500 of ranks=585260rank=548600 of ranks=585260rank=548700 of ranks=585260rank=548800 of ranks=585260rank=548900 of ranks=585260rank=549000 of ranks=585260rank=549100 of ranks=585260rank=549200 of ranks=585260rank=549300 of ranks=585260rank=549400 of ranks=585260rank=549500 of ranks=585260rank=549600 of ranks=585260rank=549700 of ranks=585260rank=549800 of ranks=585260rank=549900 of ranks=585260rank=550000 of ranks=585260rank=550100 of ranks=585260rank=550200 of ranks=585260rank=550300 of ranks=585260rank=550400 of ranks=585260rank=550500 of ranks=585260rank=550600 of ranks=585260rank=550700 of ranks=585260rank=550800 of ranks=585260rank=550900 of ranks=585260rank=551000 of ranks=585260rank=551100 of ranks=585260rank=551200 of ranks=585260rank=551300 of ranks=585260rank=551400 of ranks=585260rank=551500 of ranks=585260rank=551600 of ranks=585260rank=551700 of ranks=585260rank=551800 of ranks=585260rank=551900 of ranks=585260rank=552000 of ranks=585260rank=552100 of ranks=585260rank=552200 of ranks=585260rank=552300 of ranks=585260rank=552400 of ranks=585260rank=552500 of ranks=585260rank=552600 of ranks=585260rank=552700 of ranks=585260rank=552800 of ranks=585260rank=552900 of ranks=585260rank=553000 of ranks=585260rank=553100 of ranks=585260rank=553200 of ranks=585260rank=553300 of ranks=585260rank=553400 of ranks=585260rank=553500 of ranks=585260rank=553600 of ranks=585260rank=553700 of ranks=585260rank=553800 of ranks=585260rank=553900 of ranks=585260rank=554000 of ranks=585260rank=554100 of ranks=585260rank=554200 of ranks=585260rank=554300 of ranks=585260rank=554400 of ranks=585260rank=554500 of ranks=585260rank=554600 of ranks=585260rank=554700 of ranks=585260rank=554800 of ranks=585260rank=554900 of ranks=585260rank=555000 of ranks=585260rank=555100 of ranks=585260rank=555200 of ranks=585260rank=555300 of ranks=585260rank=555400 of ranks=585260rank=555500 of ranks=585260rank=555600 of ranks=585260rank=555700 of ranks=585260rank=555800 of ranks=585260rank=555900 of ranks=585260rank=556000 of ranks=585260rank=556100 of ranks=585260rank=556200 of ranks=585260rank=556300 of ranks=585260rank=556400 of ranks=585260rank=556500 of ranks=585260rank=556600 of ranks=585260rank=556700 of ranks=585260rank=556800 of ranks=585260rank=556900 of ranks=585260rank=557000 of ranks=585260rank=557100 of ranks=585260rank=557200 of ranks=585260rank=557300 of ranks=585260rank=557400 of ranks=585260rank=557500 of ranks=585260rank=557600 of ranks=585260rank=557700 of ranks=585260rank=557800 of ranks=585260rank=557900 of ranks=585260rank=558000 of ranks=585260rank=558100 of ranks=585260rank=558200 of ranks=585260rank=558300 of ranks=585260rank=558400 of ranks=585260rank=558500 of ranks=585260rank=558600 of ranks=585260rank=558700 of ranks=585260rank=558800 of ranks=585260rank=558900 of ranks=585260rank=559000 of ranks=585260rank=559100 of ranks=585260rank=559200 of ranks=585260rank=559300 of ranks=585260rank=559400 of ranks=585260rank=559500 of ranks=585260rank=559600 of ranks=585260rank=559700 of ranks=585260rank=559800 of ranks=585260rank=559900 of ranks=585260rank=560000 of ranks=585260rank=560100 of ranks=585260rank=560200 of ranks=585260rank=560300 of ranks=585260rank=560400 of ranks=585260rank=560500 of ranks=585260rank=560600 of ranks=585260rank=560700 of ranks=585260rank=560800 of ranks=585260rank=560900 of ranks=585260rank=561000 of ranks=585260rank=561100 of ranks=585260rank=561200 of ranks=585260rank=561300 of ranks=585260rank=561400 of ranks=585260rank=561500 of ranks=585260rank=561600 of ranks=585260rank=561700 of ranks=585260rank=561800 of ranks=585260rank=561900 of ranks=585260rank=562000 of ranks=585260rank=562100 of ranks=585260rank=562200 of ranks=585260rank=562300 of ranks=585260rank=562400 of ranks=585260rank=562500 of ranks=585260rank=562600 of ranks=585260rank=562700 of ranks=585260rank=562800 of ranks=585260rank=562900 of ranks=585260rank=563000 of ranks=585260rank=563100 of ranks=585260rank=563200 of ranks=585260rank=563300 of ranks=585260rank=563400 of ranks=585260rank=563500 of ranks=585260rank=563600 of ranks=585260rank=563700 of ranks=585260rank=563800 of ranks=585260rank=563900 of ranks=585260rank=564000 of ranks=585260rank=564100 of ranks=585260rank=564200 of ranks=585260rank=564300 of ranks=585260rank=564400 of ranks=585260rank=564500 of ranks=585260rank=564600 of ranks=585260rank=564700 of ranks=585260rank=564800 of ranks=585260rank=564900 of ranks=585260rank=565000 of ranks=585260rank=565100 of ranks=585260rank=565200 of ranks=585260rank=565300 of ranks=585260rank=565400 of ranks=585260rank=565500 of ranks=585260rank=565600 of ranks=585260rank=565700 of ranks=585260rank=565800 of ranks=585260rank=565900 of ranks=585260rank=566000 of ranks=585260rank=566100 of ranks=585260rank=566200 of ranks=585260rank=566300 of ranks=585260rank=566400 of ranks=585260rank=566500 of ranks=585260rank=566600 of ranks=585260rank=566700 of ranks=585260rank=566800 of ranks=585260rank=566900 of ranks=585260rank=567000 of ranks=585260rank=567100 of ranks=585260rank=567200 of ranks=585260rank=567300 of ranks=585260rank=567400 of ranks=585260rank=567500 of ranks=585260rank=567600 of ranks=585260rank=567700 of ranks=585260rank=567800 of ranks=585260rank=567900 of ranks=585260rank=568000 of ranks=585260rank=568100 of ranks=585260rank=568200 of ranks=585260rank=568300 of ranks=585260rank=568400 of ranks=585260rank=568500 of ranks=585260rank=568600 of ranks=585260rank=568700 of ranks=585260rank=568800 of ranks=585260rank=568900 of ranks=585260rank=569000 of ranks=585260rank=569100 of ranks=585260rank=569200 of ranks=585260rank=569300 of ranks=585260rank=569400 of ranks=585260rank=569500 of ranks=585260rank=569600 of ranks=585260rank=569700 of ranks=585260rank=569800 of ranks=585260rank=569900 of ranks=585260rank=570000 of ranks=585260rank=570100 of ranks=585260rank=570200 of ranks=585260rank=570300 of ranks=585260rank=570400 of ranks=585260rank=570500 of ranks=585260rank=570600 of ranks=585260rank=570700 of ranks=585260rank=570800 of ranks=585260rank=570900 of ranks=585260rank=571000 of ranks=585260rank=571100 of ranks=585260rank=571200 of ranks=585260rank=571300 of ranks=585260rank=571400 of ranks=585260rank=571500 of ranks=585260rank=571600 of ranks=585260rank=571700 of ranks=585260rank=571800 of ranks=585260rank=571900 of ranks=585260rank=572000 of ranks=585260rank=572100 of ranks=585260rank=572200 of ranks=585260rank=572300 of ranks=585260rank=572400 of ranks=585260rank=572500 of ranks=585260rank=572600 of ranks=585260rank=572700 of ranks=585260rank=572800 of ranks=585260rank=572900 of ranks=585260rank=573000 of ranks=585260rank=573100 of ranks=585260rank=573200 of ranks=585260rank=573300 of ranks=585260rank=573400 of ranks=585260rank=573500 of ranks=585260rank=573600 of ranks=585260rank=573700 of ranks=585260rank=573800 of ranks=585260rank=573900 of ranks=585260rank=574000 of ranks=585260rank=574100 of ranks=585260rank=574200 of ranks=585260rank=574300 of ranks=585260rank=574400 of ranks=585260rank=574500 of ranks=585260rank=574600 of ranks=585260rank=574700 of ranks=585260rank=574800 of ranks=585260rank=574900 of ranks=585260rank=575000 of ranks=585260rank=575100 of ranks=585260rank=575200 of ranks=585260rank=575300 of ranks=585260rank=575400 of ranks=585260rank=575500 of ranks=585260rank=575600 of ranks=585260rank=575700 of ranks=585260rank=575800 of ranks=585260rank=575900 of ranks=585260rank=576000 of ranks=585260rank=576100 of ranks=585260rank=576200 of ranks=585260rank=576300 of ranks=585260rank=576400 of ranks=585260rank=576500 of ranks=585260rank=576600 of ranks=585260rank=576700 of ranks=585260rank=576800 of ranks=585260rank=576900 of ranks=585260rank=577000 of ranks=585260rank=577100 of ranks=585260rank=577200 of ranks=585260rank=577300 of ranks=585260rank=577400 of ranks=585260rank=577500 of ranks=585260rank=577600 of ranks=585260rank=577700 of ranks=585260rank=577800 of ranks=585260rank=577900 of ranks=585260rank=578000 of ranks=585260rank=578100 of ranks=585260rank=578200 of ranks=585260rank=578300 of ranks=585260rank=578400 of ranks=585260rank=578500 of ranks=585260rank=578600 of ranks=585260rank=578700 of ranks=585260rank=578800 of ranks=585260rank=578900 of ranks=585260rank=579000 of ranks=585260rank=579100 of ranks=585260rank=579200 of ranks=585260rank=579300 of ranks=585260rank=579400 of ranks=585260rank=579500 of ranks=585260rank=579600 of ranks=585260rank=579700 of ranks=585260rank=579800 of ranks=585260rank=579900 of ranks=585260rank=580000 of ranks=585260rank=580100 of ranks=585260rank=580200 of ranks=585260rank=580300 of ranks=585260rank=580400 of ranks=585260rank=580500 of ranks=585260rank=580600 of ranks=585260rank=580700 of ranks=585260rank=580800 of ranks=585260rank=580900 of ranks=585260rank=581000 of ranks=585260rank=581100 of ranks=585260rank=581200 of ranks=585260rank=581300 of ranks=585260rank=581400 of ranks=585260rank=581500 of ranks=585260rank=581600 of ranks=585260rank=581700 of ranks=585260rank=581800 of ranks=585260rank=581900 of ranks=585260rank=582000 of ranks=585260rank=582100 of ranks=585260rank=582200 of ranks=585260rank=582300 of ranks=585260rank=582400 of ranks=585260rank=582500 of ranks=585260rank=582600 of ranks=585260rank=582700 of ranks=585260rank=582800 of ranks=585260rank=582900 of ranks=585260rank=583000 of ranks=585260rank=583100 of ranks=585260rank=583200 of ranks=585260rank=583300 of ranks=585260rank=583400 of ranks=585260rank=583500 of ranks=585260rank=583600 of ranks=585260rank=583700 of ranks=585260rank=583800 of ranks=585260rank=583900 of ranks=585260rank=584000 of ranks=585260rank=584100 of ranks=585260rank=584200 of ranks=585260rank=584300 of ranks=585260rank=584400 of ranks=585260rank=584500 of ranks=585260rank=584600 of ranks=585260rank=584700 of ranks=585260rank=584800 of ranks=585260rank=584900 of ranks=585260rank=585000 of ranks=585260rank=585100 of ranks=585260rank=585200 of ranks=585260

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              18.1362    365  59800    133    498           73.3688
   1 car                    88.4868  48919 226312   1397  50316           54.3396
   2 truck                  33.6236   1585 100612    240   1825           31.8425
   3 bus                    10.3630    274  58355     92    366           29.7190
   4 pedestrian             38.8762   2930  86108   1329   4259           39.3517

for conf_thresh=0.25, precision=0.69, recall=0.76, F1 score=0.72
for conf_thresh=0.25, TP=43371, FP=19495, FN=13893, average IoU=53.30%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=37.90%
Total detection time: 150 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
New best mAP, saving weights!
Saving weights to /workspace/.cache/splits/combined_best.weights
Saving weights to /workspace/.cache/splits/combined_1000.weights
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1001: loss=13.937, avg loss=12.451, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.6 seconds, train=5.9 seconds, 64064 images, time remaining=8.4 hours
1002: loss=11.473, avg loss=12.353, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=5.7 seconds, 64128 images, time remaining=8.4 hours
1003: loss=12.382, avg loss=12.356, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 64192 images, time remaining=8.4 hours
1004: loss=13.808, avg loss=12.501, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 64256 images, time remaining=8.4 hours
1005: loss=10.689, avg loss=12.320, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=3.4 seconds, train=5.8 seconds, 64320 images, time remaining=8.4 hours
1006: loss=14.419, avg loss=12.530, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 64384 images, time remaining=8.4 hours
1007: loss=14.735, avg loss=12.750, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.8 seconds, train=5.9 seconds, 64448 images, time remaining=8.4 hours
1008: loss=15.211, avg loss=12.996, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 64512 images, time remaining=8.4 hours
1009: loss=13.339, avg loss=13.031, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 64576 images, time remaining=8.4 hours
1010: loss=12.183, avg loss=12.946, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.7 seconds, train=5.6 seconds, 64640 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b88bc00000
1011: loss=13.564, avg loss=13.008, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.4 seconds, 64704 images, time remaining=8.4 hours
1012: loss=12.521, avg loss=12.959, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 64768 images, time remaining=8.4 hours
1013: loss=14.124, avg loss=13.076, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 64832 images, time remaining=8.4 hours
1014: loss=14.149, avg loss=13.183, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 64896 images, time remaining=8.4 hours
1015: loss=13.927, avg loss=13.257, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.5 seconds, 64960 images, time remaining=8.4 hours
1016: loss=12.120, avg loss=13.144, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 65024 images, time remaining=8.4 hours
1017: loss=11.552, avg loss=12.984, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 65088 images, time remaining=8.4 hours
1018: loss=11.393, avg loss=12.825, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 65152 images, time remaining=8.4 hours
1019: loss=10.541, avg loss=12.597, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 65216 images, time remaining=8.4 hours
1020: loss=12.072, avg loss=12.544, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.5 seconds, 65280 images, time remaining=8.4 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b88bc00000
1021: loss=10.858, avg loss=12.376, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 65344 images, time remaining=8.4 hours
1022: loss=10.995, avg loss=12.238, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 65408 images, time remaining=8.4 hours
1023: loss=11.935, avg loss=12.207, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 65472 images, time remaining=8.4 hours
1024: loss=10.711, avg loss=12.058, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 65536 images, time remaining=8.4 hours
1025: loss=10.524, avg loss=11.904, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 65600 images, time remaining=8.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1026: loss=12.124, avg loss=11.926, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=3.1 seconds, train=2.1 seconds, 65664 images, time remaining=8.4 hours
1027: loss=12.130, avg loss=11.947, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 65728 images, time remaining=8.4 hours
1028: loss=11.549, avg loss=11.907, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 65792 images, time remaining=8.4 hours
1029: loss=9.815, avg loss=11.698, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 65856 images, time remaining=8.3 hours
1030: loss=12.267, avg loss=11.755, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 65920 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1031: loss=13.279, avg loss=11.907, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=4.2 seconds, 65984 images, time remaining=8.3 hours
1032: loss=10.916, avg loss=11.808, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 66048 images, time remaining=8.3 hours
1033: loss=11.134, avg loss=11.741, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 66112 images, time remaining=8.3 hours
1034: loss=12.399, avg loss=11.806, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 66176 images, time remaining=8.3 hours
1035: loss=11.500, avg loss=11.776, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 66240 images, time remaining=8.3 hours
1036: loss=12.553, avg loss=11.853, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 66304 images, time remaining=8.3 hours
1037: loss=12.446, avg loss=11.913, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.7 seconds, train=4.0 seconds, 66368 images, time remaining=8.3 hours
1038: loss=11.432, avg loss=11.865, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 66432 images, time remaining=8.3 hours
1039: loss=12.325, avg loss=11.911, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 66496 images, time remaining=8.3 hours
1040: loss=11.216, avg loss=11.841, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 66560 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b865600000
1041: loss=12.650, avg loss=11.922, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 66624 images, time remaining=8.3 hours
1042: loss=12.900, avg loss=12.020, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.2 seconds, train=2.3 seconds, 66688 images, time remaining=8.3 hours
1043: loss=10.582, avg loss=11.876, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 66752 images, time remaining=8.3 hours
1044: loss=11.959, avg loss=11.884, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 66816 images, time remaining=8.3 hours
1045: loss=11.834, avg loss=11.879, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 66880 images, time remaining=8.3 hours
1046: loss=10.607, avg loss=11.752, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 66944 images, time remaining=8.3 hours
1047: loss=10.261, avg loss=11.603, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 67008 images, time remaining=8.3 hours
1048: loss=11.383, avg loss=11.581, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 67072 images, time remaining=8.3 hours
1049: loss=9.613, avg loss=11.384, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 67136 images, time remaining=8.3 hours
1050: loss=10.805, avg loss=11.326, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 67200 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b865600000
1051: loss=11.306, avg loss=11.324, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 67264 images, time remaining=8.3 hours
1052: loss=11.410, avg loss=11.333, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 67328 images, time remaining=8.3 hours
1053: loss=10.353, avg loss=11.235, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 67392 images, time remaining=8.3 hours
1054: loss=11.443, avg loss=11.256, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 67456 images, time remaining=8.3 hours
1055: loss=10.978, avg loss=11.228, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 67520 images, time remaining=8.3 hours
1056: loss=10.878, avg loss=11.193, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 67584 images, time remaining=8.3 hours
1057: loss=8.622, avg loss=10.936, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 67648 images, time remaining=8.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1058: loss=10.853, avg loss=10.927, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.4 seconds, train=2.1 seconds, 67712 images, time remaining=8.2 hours
1059: loss=11.345, avg loss=10.969, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 67776 images, time remaining=8.2 hours
1060: loss=9.037, avg loss=10.776, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=2.1 seconds, 67840 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1061: loss=13.954, avg loss=11.094, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 67904 images, time remaining=8.2 hours
1062: loss=12.757, avg loss=11.260, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 67968 images, time remaining=8.2 hours
1063: loss=13.408, avg loss=11.475, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 68032 images, time remaining=8.2 hours
1064: loss=10.710, avg loss=11.398, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=4.7 seconds, 68096 images, time remaining=8.2 hours
1065: loss=11.404, avg loss=11.399, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 68160 images, time remaining=8.2 hours
1066: loss=11.503, avg loss=11.409, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 68224 images, time remaining=8.2 hours
1067: loss=10.957, avg loss=11.364, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 68288 images, time remaining=8.2 hours
1068: loss=11.859, avg loss=11.414, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 68352 images, time remaining=8.2 hours
1069: loss=9.632, avg loss=11.236, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 68416 images, time remaining=8.2 hours
1070: loss=11.233, avg loss=11.235, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.4 seconds, train=4.7 seconds, 68480 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1071: loss=12.175, avg loss=11.329, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=5.7 seconds, 68544 images, time remaining=8.2 hours
1072: loss=13.154, avg loss=11.512, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.8 seconds, train=5.8 seconds, 68608 images, time remaining=8.2 hours
1073: loss=12.419, avg loss=11.602, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 68672 images, time remaining=8.3 hours
1074: loss=10.310, avg loss=11.473, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 68736 images, time remaining=8.3 hours
1075: loss=12.618, avg loss=11.588, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 68800 images, time remaining=8.3 hours
1076: loss=10.181, avg loss=11.447, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 68864 images, time remaining=8.3 hours
1077: loss=11.642, avg loss=11.467, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 68928 images, time remaining=8.3 hours
1078: loss=10.102, avg loss=11.330, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=5.7 seconds, 68992 images, time remaining=8.3 hours
1079: loss=11.825, avg loss=11.380, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 69056 images, time remaining=8.3 hours
1080: loss=11.183, avg loss=11.360, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 69120 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1081: loss=9.623, avg loss=11.186, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=5.7 seconds, 69184 images, time remaining=8.3 hours
1082: loss=12.810, avg loss=11.349, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.6 seconds, 69248 images, time remaining=8.3 hours
1083: loss=11.325, avg loss=11.346, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.6 seconds, train=5.7 seconds, 69312 images, time remaining=8.3 hours
1084: loss=11.508, avg loss=11.362, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 69376 images, time remaining=8.3 hours
1085: loss=11.849, avg loss=11.411, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 69440 images, time remaining=8.3 hours
1086: loss=11.588, avg loss=11.429, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 69504 images, time remaining=8.3 hours
1087: loss=11.089, avg loss=11.395, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 69568 images, time remaining=8.3 hours
1088: loss=10.545, avg loss=11.310, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 69632 images, time remaining=8.3 hours
1089: loss=11.884, avg loss=11.367, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 69696 images, time remaining=8.3 hours
1090: loss=10.170, avg loss=11.248, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=5.6 seconds, 69760 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1091: loss=11.228, avg loss=11.246, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 69824 images, time remaining=8.3 hours
1092: loss=12.167, avg loss=11.338, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 69888 images, time remaining=8.3 hours
1093: loss=11.341, avg loss=11.338, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 69952 images, time remaining=8.3 hours
1094: loss=11.583, avg loss=11.362, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.8 seconds, train=5.9 seconds, 70016 images, time remaining=8.3 hours
1095: loss=10.272, avg loss=11.253, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 70080 images, time remaining=8.3 hours
1096: loss=11.554, avg loss=11.283, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=5.8 seconds, 70144 images, time remaining=8.3 hours
1097: loss=12.096, avg loss=11.365, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 70208 images, time remaining=8.3 hours
1098: loss=12.611, avg loss=11.489, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=5.9 seconds, 70272 images, time remaining=8.3 hours
1099: loss=10.975, avg loss=11.438, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 70336 images, time remaining=8.3 hours
1100: loss=11.481, avg loss=11.442, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 70400 images, time remaining=8.3 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 896x672
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2b6000000
1101: loss=15.415, avg loss=11.840, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=2.5 seconds, 70464 images, time remaining=8.3 hours
1102: loss=12.435, avg loss=11.899, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 70528 images, time remaining=8.3 hours
1103: loss=11.032, avg loss=11.812, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 70592 images, time remaining=8.3 hours
1104: loss=11.309, avg loss=11.762, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 70656 images, time remaining=8.3 hours
1105: loss=13.007, avg loss=11.887, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 70720 images, time remaining=8.3 hours
1106: loss=12.201, avg loss=11.918, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.5 seconds, 70784 images, time remaining=8.3 hours
1107: loss=11.043, avg loss=11.831, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 70848 images, time remaining=8.3 hours
1108: loss=10.709, avg loss=11.718, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 70912 images, time remaining=8.3 hours
1109: loss=11.511, avg loss=11.698, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 70976 images, time remaining=8.3 hours
1110: loss=10.959, avg loss=11.624, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=2.7 seconds, 71040 images, time remaining=8.3 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2b6000000
1111: loss=9.906, avg loss=11.452, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.2 seconds, train=2.5 seconds, 71104 images, time remaining=8.3 hours
1112: loss=10.111, avg loss=11.318, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=2.7 seconds, 71168 images, time remaining=8.3 hours
1113: loss=11.917, avg loss=11.378, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 71232 images, time remaining=8.3 hours
1114: loss=10.851, avg loss=11.325, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 71296 images, time remaining=8.2 hours
1115: loss=10.645, avg loss=11.257, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 71360 images, time remaining=8.2 hours
1116: loss=10.190, avg loss=11.150, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 71424 images, time remaining=8.2 hours
1117: loss=8.977, avg loss=10.933, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=2.6 seconds, 71488 images, time remaining=8.2 hours
1118: loss=11.283, avg loss=10.968, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 71552 images, time remaining=8.2 hours
1119: loss=11.027, avg loss=10.974, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 71616 images, time remaining=8.2 hours
1120: loss=9.367, avg loss=10.813, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=2.6 seconds, 71680 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1121: loss=9.345, avg loss=10.666, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 71744 images, time remaining=8.2 hours
1122: loss=11.786, avg loss=10.778, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 71808 images, time remaining=8.2 hours
1123: loss=10.039, avg loss=10.704, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 71872 images, time remaining=8.2 hours
1124: loss=10.810, avg loss=10.715, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 71936 images, time remaining=8.2 hours
1125: loss=10.084, avg loss=10.652, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=4.8 seconds, 72000 images, time remaining=8.2 hours
1126: loss=8.731, avg loss=10.460, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.2 seconds, train=4.9 seconds, 72064 images, time remaining=8.2 hours
1127: loss=11.089, avg loss=10.523, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 72128 images, time remaining=8.2 hours
1128: loss=11.493, avg loss=10.620, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=4.9 seconds, 72192 images, time remaining=8.2 hours
1129: loss=10.507, avg loss=10.608, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 72256 images, time remaining=8.2 hours
1130: loss=9.580, avg loss=10.506, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 72320 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1131: loss=9.532, avg loss=10.408, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 72384 images, time remaining=8.2 hours
1132: loss=9.099, avg loss=10.277, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 72448 images, time remaining=8.2 hours
1133: loss=10.080, avg loss=10.258, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 72512 images, time remaining=8.2 hours
1134: loss=11.616, avg loss=10.393, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 72576 images, time remaining=8.2 hours
1135: loss=9.044, avg loss=10.258, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 72640 images, time remaining=8.2 hours
1136: loss=9.641, avg loss=10.197, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=4.0 seconds, 72704 images, time remaining=8.2 hours
1137: loss=10.829, avg loss=10.260, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=4.0 seconds, 72768 images, time remaining=8.2 hours
1138: loss=10.158, avg loss=10.250, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.4 seconds, train=4.1 seconds, 72832 images, time remaining=8.2 hours
1139: loss=9.108, avg loss=10.136, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 72896 images, time remaining=8.2 hours
1140: loss=10.981, avg loss=10.220, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 72960 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 896x672
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b5c8800000
1141: loss=9.386, avg loss=10.137, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 73024 images, time remaining=8.2 hours
1142: loss=8.433, avg loss=9.966, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 73088 images, time remaining=8.2 hours
1143: loss=11.417, avg loss=10.111, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 73152 images, time remaining=8.2 hours
1144: loss=9.175, avg loss=10.018, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 73216 images, time remaining=8.2 hours
1145: loss=10.210, avg loss=10.037, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=2.5 seconds, 73280 images, time remaining=8.2 hours
1146: loss=10.077, avg loss=10.041, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=2.6 seconds, 73344 images, time remaining=8.2 hours
1147: loss=9.939, avg loss=10.031, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 73408 images, time remaining=8.2 hours
1148: loss=7.789, avg loss=9.807, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.5 seconds, 73472 images, time remaining=8.2 hours
1149: loss=9.694, avg loss=9.795, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 73536 images, time remaining=8.2 hours
1150: loss=9.714, avg loss=9.787, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.6 seconds, 73600 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1151: loss=11.817, avg loss=9.990, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 73664 images, time remaining=8.2 hours
1152: loss=11.891, avg loss=10.180, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.5 seconds, train=4.8 seconds, 73728 images, time remaining=8.2 hours
1153: loss=10.361, avg loss=10.198, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 73792 images, time remaining=8.2 hours
1154: loss=10.801, avg loss=10.259, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 73856 images, time remaining=8.2 hours
1155: loss=10.423, avg loss=10.275, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=4.7 seconds, 73920 images, time remaining=8.2 hours
1156: loss=9.362, avg loss=10.184, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.4 seconds, train=4.6 seconds, 73984 images, time remaining=8.2 hours
1157: loss=9.542, avg loss=10.120, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 74048 images, time remaining=8.2 hours
1158: loss=9.623, avg loss=10.070, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 74112 images, time remaining=8.2 hours
1159: loss=9.944, avg loss=10.057, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=4.7 seconds, 74176 images, time remaining=8.2 hours
1160: loss=10.950, avg loss=10.147, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 74240 images, time remaining=8.2 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2b6000000
1161: loss=10.238, avg loss=10.156, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 74304 images, time remaining=8.2 hours
1162: loss=10.990, avg loss=10.239, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 74368 images, time remaining=8.2 hours
1163: loss=8.397, avg loss=10.055, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 74432 images, time remaining=8.2 hours
1164: loss=10.314, avg loss=10.081, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 74496 images, time remaining=8.2 hours
1165: loss=9.589, avg loss=10.032, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 74560 images, time remaining=8.2 hours
1166: loss=8.647, avg loss=9.893, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 74624 images, time remaining=8.2 hours
1167: loss=9.186, avg loss=9.822, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 74688 images, time remaining=8.2 hours
1168: loss=7.839, avg loss=9.624, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 74752 images, time remaining=8.2 hours
1169: loss=8.579, avg loss=9.520, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 74816 images, time remaining=8.1 hours
1170: loss=8.234, avg loss=9.391, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 74880 images, time remaining=8.1 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b2be000000
1171: loss=9.317, avg loss=9.384, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 74944 images, time remaining=8.1 hours
1172: loss=9.274, avg loss=9.373, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 75008 images, time remaining=8.1 hours
1173: loss=9.102, avg loss=9.346, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 75072 images, time remaining=8.1 hours
1174: loss=10.560, avg loss=9.467, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 75136 images, time remaining=8.1 hours
1175: loss=9.344, avg loss=9.455, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 75200 images, time remaining=8.1 hours
1176: loss=9.971, avg loss=9.506, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 75264 images, time remaining=8.1 hours
1177: loss=8.630, avg loss=9.419, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 75328 images, time remaining=8.1 hours
1178: loss=8.370, avg loss=9.314, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 75392 images, time remaining=8.1 hours
1179: loss=8.349, avg loss=9.217, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 75456 images, time remaining=8.1 hours
1180: loss=8.190, avg loss=9.115, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 75520 images, time remaining=8.1 hours
Resizing, random_coef=1.40, batch=4, 1216x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1181: loss=13.792, avg loss=9.582, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 75584 images, time remaining=8.1 hours
1182: loss=10.064, avg loss=9.630, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 75648 images, time remaining=8.1 hours
1183: loss=10.728, avg loss=9.740, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.2 seconds, 75712 images, time remaining=8.1 hours
1184: loss=12.313, avg loss=9.997, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 75776 images, time remaining=8.1 hours
1185: loss=12.227, avg loss=10.220, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 75840 images, time remaining=8.1 hours
1186: loss=10.876, avg loss=10.286, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.2 seconds, 75904 images, time remaining=8.1 hours
1187: loss=11.502, avg loss=10.408, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 75968 images, time remaining=8.1 hours
1188: loss=11.954, avg loss=10.562, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 76032 images, time remaining=8.1 hours
1189: loss=11.650, avg loss=10.671, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 76096 images, time remaining=8.1 hours
1190: loss=10.191, avg loss=10.623, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=5.3 seconds, 76160 images, time remaining=8.1 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1191: loss=12.182, avg loss=10.779, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=5.4 seconds, 76224 images, time remaining=8.1 hours
1192: loss=10.628, avg loss=10.764, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 76288 images, time remaining=8.1 hours
1193: loss=10.530, avg loss=10.740, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.2 seconds, train=5.4 seconds, 76352 images, time remaining=8.1 hours
1194: loss=8.453, avg loss=10.512, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 76416 images, time remaining=8.1 hours
1195: loss=10.355, avg loss=10.496, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.2 seconds, 76480 images, time remaining=8.1 hours
1196: loss=11.919, avg loss=10.638, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=5.3 seconds, 76544 images, time remaining=8.1 hours
1197: loss=10.919, avg loss=10.666, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=5.3 seconds, 76608 images, time remaining=8.1 hours
1198: loss=9.567, avg loss=10.556, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 76672 images, time remaining=8.1 hours
1199: loss=9.056, avg loss=10.406, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 76736 images, time remaining=8.1 hours
1200: loss=10.744, avg loss=10.440, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=5.4 seconds, 76800 images, time remaining=8.1 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b4b4000000
1201: loss=11.365, avg loss=10.533, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 76864 images, time remaining=8.1 hours
1202: loss=8.314, avg loss=10.311, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 76928 images, time remaining=8.1 hours
1203: loss=9.509, avg loss=10.231, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 76992 images, time remaining=8.1 hours
1204: loss=10.458, avg loss=10.253, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 77056 images, time remaining=8.1 hours
1205: loss=9.508, avg loss=10.179, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 77120 images, time remaining=8.1 hours
1206: loss=11.050, avg loss=10.266, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 77184 images, time remaining=8.1 hours
1207: loss=8.190, avg loss=10.058, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 77248 images, time remaining=8.1 hours
1208: loss=10.731, avg loss=10.126, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 77312 images, time remaining=8.1 hours
1209: loss=9.654, avg loss=10.078, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 77376 images, time remaining=8.1 hours
1210: loss=7.898, avg loss=9.860, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 77440 images, time remaining=8.1 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1211: loss=12.700, avg loss=10.144, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=5.9 seconds, 77504 images, time remaining=8.1 hours
1212: loss=11.053, avg loss=10.235, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.4 seconds, train=5.9 seconds, 77568 images, time remaining=8.1 hours
1213: loss=10.523, avg loss=10.264, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=5.8 seconds, 77632 images, time remaining=8.1 hours
1214: loss=11.082, avg loss=10.346, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 77696 images, time remaining=8.1 hours
1215: loss=10.401, avg loss=10.351, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 77760 images, time remaining=8.1 hours
1216: loss=11.739, avg loss=10.490, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 77824 images, time remaining=8.1 hours
1217: loss=11.725, avg loss=10.614, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 77888 images, time remaining=8.1 hours
1218: loss=12.708, avg loss=10.823, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 77952 images, time remaining=8.1 hours
1219: loss=10.847, avg loss=10.825, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 78016 images, time remaining=8.1 hours
1220: loss=10.230, avg loss=10.766, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 78080 images, time remaining=8.1 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1221: loss=10.543, avg loss=10.744, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 78144 images, time remaining=8.1 hours
1222: loss=10.634, avg loss=10.733, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 78208 images, time remaining=8.1 hours
1223: loss=9.696, avg loss=10.629, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=4.9 seconds, 78272 images, time remaining=8.1 hours
1224: loss=9.382, avg loss=10.504, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 78336 images, time remaining=8.1 hours
1225: loss=7.873, avg loss=10.241, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 78400 images, time remaining=8.1 hours
1226: loss=10.104, avg loss=10.228, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=5.0 seconds, 78464 images, time remaining=8.1 hours
1227: loss=11.273, avg loss=10.332, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.8 seconds, train=4.8 seconds, 78528 images, time remaining=8.1 hours
1228: loss=8.310, avg loss=10.130, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=4.8 seconds, 78592 images, time remaining=8.1 hours
1229: loss=9.382, avg loss=10.055, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=4.9 seconds, 78656 images, time remaining=8.1 hours
1230: loss=10.772, avg loss=10.127, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=5.0 seconds, 78720 images, time remaining=8.1 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2b6000000
1231: loss=8.851, avg loss=9.999, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=2.7 seconds, 78784 images, time remaining=8.1 hours
1232: loss=9.993, avg loss=9.999, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=2.7 seconds, 78848 images, time remaining=8.1 hours
1233: loss=8.878, avg loss=9.886, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=2.7 seconds, 78912 images, time remaining=8.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1234: loss=8.880, avg loss=9.786, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.8 seconds, train=2.8 seconds, 78976 images, time remaining=8.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1235: loss=8.959, avg loss=9.703, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.9 seconds, train=2.7 seconds, 79040 images, time remaining=8.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1236: loss=9.191, avg loss=9.652, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.9 seconds, train=2.8 seconds, 79104 images, time remaining=8.1 hours
1237: loss=10.023, avg loss=9.689, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=2.8 seconds, 79168 images, time remaining=8.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1238: loss=9.077, avg loss=9.628, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=3.0 seconds, train=2.8 seconds, 79232 images, time remaining=8.1 hours
1239: loss=8.675, avg loss=9.533, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=2.7 seconds, 79296 images, time remaining=8.1 hours
1240: loss=9.327, avg loss=9.512, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=2.8 seconds, 79360 images, time remaining=8.1 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1241: loss=10.400, avg loss=9.601, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.2 seconds, train=5.3 seconds, 79424 images, time remaining=8.1 hours
1242: loss=9.088, avg loss=9.550, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 79488 images, time remaining=8.1 hours
1243: loss=10.188, avg loss=9.613, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 79552 images, time remaining=8.1 hours
1244: loss=9.109, avg loss=9.563, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.2 seconds, 79616 images, time remaining=8.1 hours
1245: loss=9.199, avg loss=9.527, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=3.1 seconds, train=5.2 seconds, 79680 images, time remaining=8.1 hours
1246: loss=9.177, avg loss=9.492, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.7 seconds, train=5.3 seconds, 79744 images, time remaining=8.1 hours
1247: loss=9.416, avg loss=9.484, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.9 seconds, train=5.3 seconds, 79808 images, time remaining=8.1 hours
1248: loss=8.834, avg loss=9.419, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.5 seconds, train=5.2 seconds, 79872 images, time remaining=8.1 hours
1249: loss=10.237, avg loss=9.501, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.2 seconds, train=5.3 seconds, 79936 images, time remaining=8.1 hours
1250: loss=10.172, avg loss=9.568, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 80000 images, time remaining=8.1 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2b6000000
1251: loss=9.070, avg loss=9.518, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 80064 images, time remaining=8.1 hours
1252: loss=8.954, avg loss=9.462, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.5 seconds, 80128 images, time remaining=8.1 hours
1253: loss=9.873, avg loss=9.503, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=2.5 seconds, 80192 images, time remaining=8.1 hours
1254: loss=9.653, avg loss=9.518, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.5 seconds, 80256 images, time remaining=8.1 hours
1255: loss=9.934, avg loss=9.560, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=2.6 seconds, 80320 images, time remaining=8.1 hours
1256: loss=8.887, avg loss=9.492, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=2.4 seconds, 80384 images, time remaining=8.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1257: loss=9.821, avg loss=9.525, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=4.7 seconds, train=2.5 seconds, 80448 images, time remaining=8.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1258: loss=8.977, avg loss=9.470, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.7 seconds, train=2.5 seconds, 80512 images, time remaining=8.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1259: loss=8.845, avg loss=9.408, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=3.1 seconds, train=2.6 seconds, 80576 images, time remaining=8.1 hours
1260: loss=9.115, avg loss=9.379, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=2.5 seconds, 80640 images, time remaining=8 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b626a00000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1261: loss=8.268, avg loss=9.267, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.7 seconds, train=2.1 seconds, 80704 images, time remaining=8.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1262: loss=7.435, avg loss=9.084, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.9 seconds, train=2.0 seconds, 80768 images, time remaining=8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1263: loss=9.096, avg loss=9.085, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=5.2 seconds, train=2.2 seconds, 80832 images, time remaining=8 hours
1264: loss=9.446, avg loss=9.121, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=2.2 seconds, 80896 images, time remaining=8 hours
1265: loss=8.478, avg loss=9.057, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 80960 images, time remaining=8 hours
1266: loss=8.803, avg loss=9.032, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=2.1 seconds, 81024 images, time remaining=8 hours
1267: loss=7.922, avg loss=8.921, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 81088 images, time remaining=8 hours
1268: loss=8.119, avg loss=8.841, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 81152 images, time remaining=8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1269: loss=7.885, avg loss=8.745, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=3.5 seconds, train=2.2 seconds, 81216 images, time remaining=8 hours
1270: loss=9.101, avg loss=8.781, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 81280 images, time remaining=8 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1271: loss=11.532, avg loss=9.056, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.7 seconds, train=5.4 seconds, 81344 images, time remaining=8 hours
1272: loss=10.432, avg loss=9.193, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.2 seconds, train=5.3 seconds, 81408 images, time remaining=8 hours
1273: loss=9.376, avg loss=9.212, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=5.3 seconds, 81472 images, time remaining=8 hours
1274: loss=10.097, avg loss=9.300, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.2 seconds, train=5.3 seconds, 81536 images, time remaining=8 hours
1275: loss=11.736, avg loss=9.544, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 81600 images, time remaining=8 hours
1276: loss=10.299, avg loss=9.619, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=5.3 seconds, 81664 images, time remaining=8 hours
1277: loss=12.770, avg loss=9.934, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 81728 images, time remaining=8 hours
1278: loss=9.723, avg loss=9.913, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 81792 images, time remaining=8 hours
1279: loss=10.132, avg loss=9.935, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 81856 images, time remaining=8 hours
1280: loss=9.473, avg loss=9.889, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 81920 images, time remaining=8 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b56c000000
1281: loss=12.422, avg loss=10.142, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 81984 images, time remaining=8 hours
1282: loss=9.809, avg loss=10.109, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 82048 images, time remaining=8 hours
1283: loss=9.149, avg loss=10.013, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=1.8 seconds, 82112 images, time remaining=8 hours
1284: loss=9.821, avg loss=9.994, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 82176 images, time remaining=8 hours
1285: loss=9.155, avg loss=9.910, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 82240 images, time remaining=8 hours
1286: loss=11.532, avg loss=10.072, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 82304 images, time remaining=8 hours
1287: loss=9.978, avg loss=10.063, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 82368 images, time remaining=8 hours
1288: loss=8.686, avg loss=9.925, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 82432 images, time remaining=8 hours
1289: loss=9.583, avg loss=9.891, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.2 seconds, train=1.8 seconds, 82496 images, time remaining=8 hours
1290: loss=7.928, avg loss=9.694, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 82560 images, time remaining=8 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afa4000000
1291: loss=11.480, avg loss=9.873, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=4.1 seconds, 82624 images, time remaining=8 hours
1292: loss=10.498, avg loss=9.935, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=4.1 seconds, 82688 images, time remaining=8 hours
1293: loss=10.211, avg loss=9.963, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=4.1 seconds, 82752 images, time remaining=8 hours
1294: loss=10.402, avg loss=10.007, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=3.5 seconds, train=4.0 seconds, 82816 images, time remaining=8 hours
1295: loss=9.858, avg loss=9.992, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=4.2 seconds, 82880 images, time remaining=8 hours
1296: loss=10.126, avg loss=10.005, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=4.2 seconds, 82944 images, time remaining=8 hours
1297: loss=9.595, avg loss=9.964, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 83008 images, time remaining=8 hours
1298: loss=9.193, avg loss=9.887, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=4.0 seconds, train=4.0 seconds, 83072 images, time remaining=8 hours
1299: loss=9.572, avg loss=9.856, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=3.0 seconds, train=4.0 seconds, 83136 images, time remaining=8 hours
1300: loss=9.194, avg loss=9.790, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.5 seconds, train=4.1 seconds, 83200 images, time remaining=8 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b606600000
1301: loss=8.897, avg loss=9.700, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 83264 images, time remaining=8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1302: loss=9.548, avg loss=9.685, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=1.9 seconds, 83328 images, time remaining=8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1303: loss=10.076, avg loss=9.724, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=1.9 seconds, 83392 images, time remaining=8 hours
1304: loss=8.975, avg loss=9.649, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 83456 images, time remaining=8 hours
1305: loss=9.009, avg loss=9.585, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 83520 images, time remaining=8 hours
1306: loss=8.073, avg loss=9.434, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 83584 images, time remaining=8 hours
1307: loss=8.658, avg loss=9.356, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 83648 images, time remaining=7.9 hours
1308: loss=8.357, avg loss=9.256, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 83712 images, time remaining=7.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1309: loss=9.441, avg loss=9.275, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=1.9 seconds, 83776 images, time remaining=7.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1310: loss=7.769, avg loss=9.124, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=1.9 seconds, 83840 images, time remaining=7.9 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b62bc00000
1311: loss=8.757, avg loss=9.088, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=2.1 seconds, 83904 images, time remaining=7.9 hours
1312: loss=8.053, avg loss=8.984, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 83968 images, time remaining=7.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1313: loss=8.097, avg loss=8.895, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.7 seconds, train=2.0 seconds, 84032 images, time remaining=7.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1314: loss=8.355, avg loss=8.841, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=2.1 seconds, 84096 images, time remaining=7.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1315: loss=8.003, avg loss=8.758, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=2.0 seconds, 84160 images, time remaining=7.9 hours
1316: loss=8.674, avg loss=8.749, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 84224 images, time remaining=7.9 hours
1317: loss=9.402, avg loss=8.814, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.0 seconds, 84288 images, time remaining=7.9 hours
1318: loss=8.559, avg loss=8.789, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.2 seconds, train=2.2 seconds, 84352 images, time remaining=7.9 hours
1319: loss=8.309, avg loss=8.741, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 84416 images, time remaining=7.9 hours
1320: loss=8.053, avg loss=8.672, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 84480 images, time remaining=7.9 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b5a4a00000
1321: loss=7.690, avg loss=8.574, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.1 seconds, train=1.8 seconds, 84544 images, time remaining=7.9 hours
1322: loss=8.948, avg loss=8.611, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 84608 images, time remaining=7.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1323: loss=8.510, avg loss=8.601, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.6 seconds, train=1.9 seconds, 84672 images, time remaining=7.9 hours
1324: loss=8.280, avg loss=8.569, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 84736 images, time remaining=7.9 hours
1325: loss=9.247, avg loss=8.637, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 84800 images, time remaining=7.9 hours
1326: loss=8.383, avg loss=8.612, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 84864 images, time remaining=7.9 hours
1327: loss=7.518, avg loss=8.502, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.3 seconds, train=1.7 seconds, 84928 images, time remaining=7.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1328: loss=8.098, avg loss=8.462, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.6 seconds, train=1.9 seconds, 84992 images, time remaining=7.9 hours
1329: loss=8.106, avg loss=8.426, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 85056 images, time remaining=7.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1330: loss=7.420, avg loss=8.326, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=1.9 seconds, 85120 images, time remaining=7.9 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b62bc00000
1331: loss=8.104, avg loss=8.303, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 85184 images, time remaining=7.9 hours
1332: loss=7.243, avg loss=8.197, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=1.8 seconds, 85248 images, time remaining=7.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1333: loss=8.096, avg loss=8.187, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=1.9 seconds, 85312 images, time remaining=7.8 hours
1334: loss=6.770, avg loss=8.045, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 85376 images, time remaining=7.8 hours
1335: loss=8.180, avg loss=8.059, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 85440 images, time remaining=7.8 hours
1336: loss=8.233, avg loss=8.076, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 85504 images, time remaining=7.8 hours
1337: loss=7.054, avg loss=7.974, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 85568 images, time remaining=7.8 hours
1338: loss=7.389, avg loss=7.916, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=1.8 seconds, 85632 images, time remaining=7.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1339: loss=7.224, avg loss=7.846, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.2 seconds, train=1.9 seconds, 85696 images, time remaining=7.8 hours
1340: loss=7.434, avg loss=7.805, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.1 seconds, train=1.8 seconds, 85760 images, time remaining=7.8 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b4f2200000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1341: loss=8.103, avg loss=7.835, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=2.2 seconds, 85824 images, time remaining=7.8 hours
1342: loss=8.207, avg loss=7.872, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=2.4 seconds, 85888 images, time remaining=7.8 hours
1343: loss=7.991, avg loss=7.884, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.2 seconds, train=2.4 seconds, 85952 images, time remaining=7.8 hours
1344: loss=7.966, avg loss=7.892, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.2 seconds, train=2.3 seconds, 86016 images, time remaining=7.8 hours
1345: loss=7.630, avg loss=7.866, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 86080 images, time remaining=7.8 hours
1346: loss=7.556, avg loss=7.835, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=2.4 seconds, 86144 images, time remaining=7.8 hours
1347: loss=6.925, avg loss=7.744, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 86208 images, time remaining=7.8 hours
1348: loss=6.758, avg loss=7.645, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 86272 images, time remaining=7.8 hours
1349: loss=7.132, avg loss=7.594, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 86336 images, time remaining=7.8 hours
1350: loss=7.527, avg loss=7.587, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 86400 images, time remaining=7.8 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b4f2200000
1351: loss=6.863, avg loss=7.515, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 86464 images, time remaining=7.8 hours
1352: loss=7.327, avg loss=7.496, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=2.4 seconds, 86528 images, time remaining=7.8 hours
1353: loss=6.805, avg loss=7.427, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 86592 images, time remaining=7.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1354: loss=7.182, avg loss=7.403, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.4 seconds, train=2.2 seconds, 86656 images, time remaining=7.8 hours
1355: loss=7.420, avg loss=7.404, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=2.3 seconds, 86720 images, time remaining=7.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1356: loss=6.966, avg loss=7.360, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=2.3 seconds, 86784 images, time remaining=7.8 hours
1357: loss=6.990, avg loss=7.323, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 86848 images, time remaining=7.8 hours
1358: loss=8.192, avg loss=7.410, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=2.3 seconds, 86912 images, time remaining=7.8 hours
1359: loss=7.273, avg loss=7.397, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 86976 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1360: loss=6.683, avg loss=7.325, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.4 seconds, train=2.2 seconds, 87040 images, time remaining=7.7 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b4f2200000
1361: loss=6.357, avg loss=7.228, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 87104 images, time remaining=7.7 hours
1362: loss=7.721, avg loss=7.278, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 87168 images, time remaining=7.7 hours
1363: loss=6.302, avg loss=7.180, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 87232 images, time remaining=7.7 hours
1364: loss=6.950, avg loss=7.157, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 87296 images, time remaining=7.7 hours
1365: loss=6.782, avg loss=7.120, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.2 seconds, train=2.4 seconds, 87360 images, time remaining=7.7 hours
1366: loss=6.706, avg loss=7.078, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 87424 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1367: loss=6.646, avg loss=7.035, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.7 seconds, train=2.3 seconds, 87488 images, time remaining=7.7 hours
1368: loss=6.561, avg loss=6.988, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=2.3 seconds, 87552 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1369: loss=7.460, avg loss=7.035, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=2.3 seconds, 87616 images, time remaining=7.7 hours
1370: loss=7.117, avg loss=7.043, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=2.3 seconds, 87680 images, time remaining=7.7 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1371: loss=9.857, avg loss=7.324, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=5.8 seconds, 87744 images, time remaining=7.7 hours
1372: loss=9.428, avg loss=7.535, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.5 seconds, train=5.9 seconds, 87808 images, time remaining=7.7 hours
1373: loss=9.067, avg loss=7.688, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.7 seconds, train=5.7 seconds, 87872 images, time remaining=7.7 hours
1374: loss=11.379, avg loss=8.057, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.4 seconds, train=5.8 seconds, 87936 images, time remaining=7.7 hours
1375: loss=8.865, avg loss=8.138, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.7 seconds, train=5.8 seconds, 88000 images, time remaining=7.7 hours
1376: loss=9.256, avg loss=8.250, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.4 seconds, train=5.8 seconds, 88064 images, time remaining=7.7 hours
1377: loss=9.889, avg loss=8.414, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 88128 images, time remaining=7.7 hours
1378: loss=10.562, avg loss=8.628, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=5.7 seconds, 88192 images, time remaining=7.7 hours
1379: loss=9.008, avg loss=8.666, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.4 seconds, train=5.8 seconds, 88256 images, time remaining=7.7 hours
1380: loss=8.703, avg loss=8.670, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=5.7 seconds, 88320 images, time remaining=7.7 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1381: loss=10.336, avg loss=8.837, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 88384 images, time remaining=7.7 hours
1382: loss=9.994, avg loss=8.952, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=4.0 seconds, 88448 images, time remaining=7.7 hours
1383: loss=8.083, avg loss=8.865, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.7 seconds, train=4.0 seconds, 88512 images, time remaining=7.7 hours
1384: loss=8.324, avg loss=8.811, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=4.1 seconds, 88576 images, time remaining=7.7 hours
1385: loss=9.659, avg loss=8.896, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 88640 images, time remaining=7.7 hours
1386: loss=8.183, avg loss=8.825, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.4 seconds, train=4.0 seconds, 88704 images, time remaining=7.7 hours
1387: loss=6.944, avg loss=8.637, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=4.0 seconds, 88768 images, time remaining=7.7 hours
1388: loss=7.812, avg loss=8.554, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.4 seconds, train=4.0 seconds, 88832 images, time remaining=7.7 hours
1389: loss=8.353, avg loss=8.534, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 88896 images, time remaining=7.7 hours
1390: loss=8.307, avg loss=8.511, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.5 seconds, train=3.9 seconds, 88960 images, time remaining=7.7 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b6af600000
1391: loss=8.121, avg loss=8.472, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=1.8 seconds, 89024 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1392: loss=9.222, avg loss=8.547, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.7 seconds, train=1.7 seconds, 89088 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1393: loss=8.028, avg loss=8.495, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.8 seconds, train=1.9 seconds, 89152 images, time remaining=7.7 hours
1394: loss=8.673, avg loss=8.513, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.5 seconds, train=1.8 seconds, 89216 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1395: loss=8.353, avg loss=8.497, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=1.7 seconds, 89280 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1396: loss=8.349, avg loss=8.482, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.1 seconds, train=1.8 seconds, 89344 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1397: loss=8.563, avg loss=8.490, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=1.8 seconds, 89408 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1398: loss=7.633, avg loss=8.405, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=1.8 seconds, 89472 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1399: loss=8.009, avg loss=8.365, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=1.9 seconds, 89536 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1400: loss=7.795, avg loss=8.308, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.9 seconds, train=1.8 seconds, 89600 images, time remaining=7.7 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b6af600000
1401: loss=7.645, avg loss=8.242, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.4 seconds, train=1.8 seconds, 89664 images, time remaining=7.7 hours
1402: loss=7.039, avg loss=8.121, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=1.8 seconds, 89728 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1403: loss=8.003, avg loss=8.110, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.3 seconds, train=1.9 seconds, 89792 images, time remaining=7.7 hours
1404: loss=7.932, avg loss=8.092, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 89856 images, time remaining=7.7 hours
1405: loss=6.877, avg loss=7.970, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=1.6 seconds, train=1.8 seconds, 89920 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1406: loss=7.609, avg loss=7.934, last=37.90%, best=37.90%, next=1406, rate=0.00130000, load 64=2.0 seconds, train=1.8 seconds, 89984 images, time remaining=7.7 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=370021, unique_truth_count=57264
rank=0 of ranks=370021rank=100 of ranks=370021rank=200 of ranks=370021rank=300 of ranks=370021rank=400 of ranks=370021rank=500 of ranks=370021rank=600 of ranks=370021rank=700 of ranks=370021rank=800 of ranks=370021rank=900 of ranks=370021rank=1000 of ranks=370021rank=1100 of ranks=370021rank=1200 of ranks=370021rank=1300 of ranks=370021rank=1400 of ranks=370021rank=1500 of ranks=370021rank=1600 of ranks=370021rank=1700 of ranks=370021rank=1800 of ranks=370021rank=1900 of ranks=370021rank=2000 of ranks=370021rank=2100 of ranks=370021rank=2200 of ranks=370021rank=2300 of ranks=370021rank=2400 of ranks=370021rank=2500 of ranks=370021rank=2600 of ranks=370021rank=2700 of ranks=370021rank=2800 of ranks=370021rank=2900 of ranks=370021rank=3000 of ranks=370021rank=3100 of ranks=370021rank=3200 of ranks=370021rank=3300 of ranks=370021rank=3400 of ranks=370021rank=3500 of ranks=370021rank=3600 of ranks=370021rank=3700 of ranks=370021rank=3800 of ranks=370021rank=3900 of ranks=370021rank=4000 of ranks=370021rank=4100 of ranks=370021rank=4200 of ranks=370021rank=4300 of ranks=370021rank=4400 of ranks=370021rank=4500 of ranks=370021rank=4600 of ranks=370021rank=4700 of ranks=370021rank=4800 of ranks=370021rank=4900 of ranks=370021rank=5000 of ranks=370021rank=5100 of ranks=370021rank=5200 of ranks=370021rank=5300 of ranks=370021rank=5400 of ranks=370021rank=5500 of ranks=370021rank=5600 of ranks=370021rank=5700 of ranks=370021rank=5800 of ranks=370021rank=5900 of ranks=370021rank=6000 of ranks=370021rank=6100 of ranks=370021rank=6200 of ranks=370021rank=6300 of ranks=370021rank=6400 of ranks=370021rank=6500 of ranks=370021rank=6600 of ranks=370021rank=6700 of ranks=370021rank=6800 of ranks=370021rank=6900 of ranks=370021rank=7000 of ranks=370021rank=7100 of ranks=370021rank=7200 of ranks=370021rank=7300 of ranks=370021rank=7400 of ranks=370021rank=7500 of ranks=370021rank=7600 of ranks=370021rank=7700 of ranks=370021rank=7800 of ranks=370021rank=7900 of ranks=370021rank=8000 of ranks=370021rank=8100 of ranks=370021rank=8200 of ranks=370021rank=8300 of ranks=370021rank=8400 of ranks=370021rank=8500 of ranks=370021rank=8600 of ranks=370021rank=8700 of ranks=370021rank=8800 of ranks=370021rank=8900 of ranks=370021rank=9000 of ranks=370021rank=9100 of ranks=370021rank=9200 of ranks=370021rank=9300 of ranks=370021rank=9400 of ranks=370021rank=9500 of ranks=370021rank=9600 of ranks=370021rank=9700 of ranks=370021rank=9800 of ranks=370021rank=9900 of ranks=370021rank=10000 of ranks=370021rank=10100 of ranks=370021rank=10200 of ranks=370021rank=10300 of ranks=370021rank=10400 of ranks=370021rank=10500 of ranks=370021rank=10600 of ranks=370021rank=10700 of ranks=370021rank=10800 of ranks=370021rank=10900 of ranks=370021rank=11000 of ranks=370021rank=11100 of ranks=370021rank=11200 of ranks=370021rank=11300 of ranks=370021rank=11400 of ranks=370021rank=11500 of ranks=370021rank=11600 of ranks=370021rank=11700 of ranks=370021rank=11800 of ranks=370021rank=11900 of ranks=370021rank=12000 of ranks=370021rank=12100 of ranks=370021rank=12200 of ranks=370021rank=12300 of ranks=370021rank=12400 of ranks=370021rank=12500 of ranks=370021rank=12600 of ranks=370021rank=12700 of ranks=370021rank=12800 of ranks=370021rank=12900 of ranks=370021rank=13000 of ranks=370021rank=13100 of ranks=370021rank=13200 of ranks=370021rank=13300 of ranks=370021rank=13400 of ranks=370021rank=13500 of ranks=370021rank=13600 of ranks=370021rank=13700 of ranks=370021rank=13800 of ranks=370021rank=13900 of ranks=370021rank=14000 of ranks=370021rank=14100 of ranks=370021rank=14200 of ranks=370021rank=14300 of ranks=370021rank=14400 of ranks=370021rank=14500 of ranks=370021rank=14600 of ranks=370021rank=14700 of ranks=370021rank=14800 of ranks=370021rank=14900 of ranks=370021rank=15000 of ranks=370021rank=15100 of ranks=370021rank=15200 of ranks=370021rank=15300 of ranks=370021rank=15400 of ranks=370021rank=15500 of ranks=370021rank=15600 of ranks=370021rank=15700 of ranks=370021rank=15800 of ranks=370021rank=15900 of ranks=370021rank=16000 of ranks=370021rank=16100 of ranks=370021rank=16200 of ranks=370021rank=16300 of ranks=370021rank=16400 of ranks=370021rank=16500 of ranks=370021rank=16600 of ranks=370021rank=16700 of ranks=370021rank=16800 of ranks=370021rank=16900 of ranks=370021rank=17000 of ranks=370021rank=17100 of ranks=370021rank=17200 of ranks=370021rank=17300 of ranks=370021rank=17400 of ranks=370021rank=17500 of ranks=370021rank=17600 of ranks=370021rank=17700 of ranks=370021rank=17800 of ranks=370021rank=17900 of ranks=370021rank=18000 of ranks=370021rank=18100 of ranks=370021rank=18200 of ranks=370021rank=18300 of ranks=370021rank=18400 of ranks=370021rank=18500 of ranks=370021rank=18600 of ranks=370021rank=18700 of ranks=370021rank=18800 of ranks=370021rank=18900 of ranks=370021rank=19000 of ranks=370021rank=19100 of ranks=370021rank=19200 of ranks=370021rank=19300 of ranks=370021rank=19400 of ranks=370021rank=19500 of ranks=370021rank=19600 of ranks=370021rank=19700 of ranks=370021rank=19800 of ranks=370021rank=19900 of ranks=370021rank=20000 of ranks=370021rank=20100 of ranks=370021rank=20200 of ranks=370021rank=20300 of ranks=370021rank=20400 of ranks=370021rank=20500 of ranks=370021rank=20600 of ranks=370021rank=20700 of ranks=370021rank=20800 of ranks=370021rank=20900 of ranks=370021rank=21000 of ranks=370021rank=21100 of ranks=370021rank=21200 of ranks=370021rank=21300 of ranks=370021rank=21400 of ranks=370021rank=21500 of ranks=370021rank=21600 of ranks=370021rank=21700 of ranks=370021rank=21800 of ranks=370021rank=21900 of ranks=370021rank=22000 of ranks=370021rank=22100 of ranks=370021rank=22200 of ranks=370021rank=22300 of ranks=370021rank=22400 of ranks=370021rank=22500 of ranks=370021rank=22600 of ranks=370021rank=22700 of ranks=370021rank=22800 of ranks=370021rank=22900 of ranks=370021rank=23000 of ranks=370021rank=23100 of ranks=370021rank=23200 of ranks=370021rank=23300 of ranks=370021rank=23400 of ranks=370021rank=23500 of ranks=370021rank=23600 of ranks=370021rank=23700 of ranks=370021rank=23800 of ranks=370021rank=23900 of ranks=370021rank=24000 of ranks=370021rank=24100 of ranks=370021rank=24200 of ranks=370021rank=24300 of ranks=370021rank=24400 of ranks=370021rank=24500 of ranks=370021rank=24600 of ranks=370021rank=24700 of ranks=370021rank=24800 of ranks=370021rank=24900 of ranks=370021rank=25000 of ranks=370021rank=25100 of ranks=370021rank=25200 of ranks=370021rank=25300 of ranks=370021rank=25400 of ranks=370021rank=25500 of ranks=370021rank=25600 of ranks=370021rank=25700 of ranks=370021rank=25800 of ranks=370021rank=25900 of ranks=370021rank=26000 of ranks=370021rank=26100 of ranks=370021rank=26200 of ranks=370021rank=26300 of ranks=370021rank=26400 of ranks=370021rank=26500 of ranks=370021rank=26600 of ranks=370021rank=26700 of ranks=370021rank=26800 of ranks=370021rank=26900 of ranks=370021rank=27000 of ranks=370021rank=27100 of ranks=370021rank=27200 of ranks=370021rank=27300 of ranks=370021rank=27400 of ranks=370021rank=27500 of ranks=370021rank=27600 of ranks=370021rank=27700 of ranks=370021rank=27800 of ranks=370021rank=27900 of ranks=370021rank=28000 of ranks=370021rank=28100 of ranks=370021rank=28200 of ranks=370021rank=28300 of ranks=370021rank=28400 of ranks=370021rank=28500 of ranks=370021rank=28600 of ranks=370021rank=28700 of ranks=370021rank=28800 of ranks=370021rank=28900 of ranks=370021rank=29000 of ranks=370021rank=29100 of ranks=370021rank=29200 of ranks=370021rank=29300 of ranks=370021rank=29400 of ranks=370021rank=29500 of ranks=370021rank=29600 of ranks=370021rank=29700 of ranks=370021rank=29800 of ranks=370021rank=29900 of ranks=370021rank=30000 of ranks=370021rank=30100 of ranks=370021rank=30200 of ranks=370021rank=30300 of ranks=370021rank=30400 of ranks=370021rank=30500 of ranks=370021rank=30600 of ranks=370021rank=30700 of ranks=370021rank=30800 of ranks=370021rank=30900 of ranks=370021rank=31000 of ranks=370021rank=31100 of ranks=370021rank=31200 of ranks=370021rank=31300 of ranks=370021rank=31400 of ranks=370021rank=31500 of ranks=370021rank=31600 of ranks=370021rank=31700 of ranks=370021rank=31800 of ranks=370021rank=31900 of ranks=370021rank=32000 of ranks=370021rank=32100 of ranks=370021rank=32200 of ranks=370021rank=32300 of ranks=370021rank=32400 of ranks=370021rank=32500 of ranks=370021rank=32600 of ranks=370021rank=32700 of ranks=370021rank=32800 of ranks=370021rank=32900 of ranks=370021rank=33000 of ranks=370021rank=33100 of ranks=370021rank=33200 of ranks=370021rank=33300 of ranks=370021rank=33400 of ranks=370021rank=33500 of ranks=370021rank=33600 of ranks=370021rank=33700 of ranks=370021rank=33800 of ranks=370021rank=33900 of ranks=370021rank=34000 of ranks=370021rank=34100 of ranks=370021rank=34200 of ranks=370021rank=34300 of ranks=370021rank=34400 of ranks=370021rank=34500 of ranks=370021rank=34600 of ranks=370021rank=34700 of ranks=370021rank=34800 of ranks=370021rank=34900 of ranks=370021rank=35000 of ranks=370021rank=35100 of ranks=370021rank=35200 of ranks=370021rank=35300 of ranks=370021rank=35400 of ranks=370021rank=35500 of ranks=370021rank=35600 of ranks=370021rank=35700 of ranks=370021rank=35800 of ranks=370021rank=35900 of ranks=370021rank=36000 of ranks=370021rank=36100 of ranks=370021rank=36200 of ranks=370021rank=36300 of ranks=370021rank=36400 of ranks=370021rank=36500 of ranks=370021rank=36600 of ranks=370021rank=36700 of ranks=370021rank=36800 of ranks=370021rank=36900 of ranks=370021rank=37000 of ranks=370021rank=37100 of ranks=370021rank=37200 of ranks=370021rank=37300 of ranks=370021rank=37400 of ranks=370021rank=37500 of ranks=370021rank=37600 of ranks=370021rank=37700 of ranks=370021rank=37800 of ranks=370021rank=37900 of ranks=370021rank=38000 of ranks=370021rank=38100 of ranks=370021rank=38200 of ranks=370021rank=38300 of ranks=370021rank=38400 of ranks=370021rank=38500 of ranks=370021rank=38600 of ranks=370021rank=38700 of ranks=370021rank=38800 of ranks=370021rank=38900 of ranks=370021rank=39000 of ranks=370021rank=39100 of ranks=370021rank=39200 of ranks=370021rank=39300 of ranks=370021rank=39400 of ranks=370021rank=39500 of ranks=370021rank=39600 of ranks=370021rank=39700 of ranks=370021rank=39800 of ranks=370021rank=39900 of ranks=370021rank=40000 of ranks=370021rank=40100 of ranks=370021rank=40200 of ranks=370021rank=40300 of ranks=370021rank=40400 of ranks=370021rank=40500 of ranks=370021rank=40600 of ranks=370021rank=40700 of ranks=370021rank=40800 of ranks=370021rank=40900 of ranks=370021rank=41000 of ranks=370021rank=41100 of ranks=370021rank=41200 of ranks=370021rank=41300 of ranks=370021rank=41400 of ranks=370021rank=41500 of ranks=370021rank=41600 of ranks=370021rank=41700 of ranks=370021rank=41800 of ranks=370021rank=41900 of ranks=370021rank=42000 of ranks=370021rank=42100 of ranks=370021rank=42200 of ranks=370021rank=42300 of ranks=370021rank=42400 of ranks=370021rank=42500 of ranks=370021rank=42600 of ranks=370021rank=42700 of ranks=370021rank=42800 of ranks=370021rank=42900 of ranks=370021rank=43000 of ranks=370021rank=43100 of ranks=370021rank=43200 of ranks=370021rank=43300 of ranks=370021rank=43400 of ranks=370021rank=43500 of ranks=370021rank=43600 of ranks=370021rank=43700 of ranks=370021rank=43800 of ranks=370021rank=43900 of ranks=370021rank=44000 of ranks=370021rank=44100 of ranks=370021rank=44200 of ranks=370021rank=44300 of ranks=370021rank=44400 of ranks=370021rank=44500 of ranks=370021rank=44600 of ranks=370021rank=44700 of ranks=370021rank=44800 of ranks=370021rank=44900 of ranks=370021rank=45000 of ranks=370021rank=45100 of ranks=370021rank=45200 of ranks=370021rank=45300 of ranks=370021rank=45400 of ranks=370021rank=45500 of ranks=370021rank=45600 of ranks=370021rank=45700 of ranks=370021rank=45800 of ranks=370021rank=45900 of ranks=370021rank=46000 of ranks=370021rank=46100 of ranks=370021rank=46200 of ranks=370021rank=46300 of ranks=370021rank=46400 of ranks=370021rank=46500 of ranks=370021rank=46600 of ranks=370021rank=46700 of ranks=370021rank=46800 of ranks=370021rank=46900 of ranks=370021rank=47000 of ranks=370021rank=47100 of ranks=370021rank=47200 of ranks=370021rank=47300 of ranks=370021rank=47400 of ranks=370021rank=47500 of ranks=370021rank=47600 of ranks=370021rank=47700 of ranks=370021rank=47800 of ranks=370021rank=47900 of ranks=370021rank=48000 of ranks=370021rank=48100 of ranks=370021rank=48200 of ranks=370021rank=48300 of ranks=370021rank=48400 of ranks=370021rank=48500 of ranks=370021rank=48600 of ranks=370021rank=48700 of ranks=370021rank=48800 of ranks=370021rank=48900 of ranks=370021rank=49000 of ranks=370021rank=49100 of ranks=370021rank=49200 of ranks=370021rank=49300 of ranks=370021rank=49400 of ranks=370021rank=49500 of ranks=370021rank=49600 of ranks=370021rank=49700 of ranks=370021rank=49800 of ranks=370021rank=49900 of ranks=370021rank=50000 of ranks=370021rank=50100 of ranks=370021rank=50200 of ranks=370021rank=50300 of ranks=370021rank=50400 of ranks=370021rank=50500 of ranks=370021rank=50600 of ranks=370021rank=50700 of ranks=370021rank=50800 of ranks=370021rank=50900 of ranks=370021rank=51000 of ranks=370021rank=51100 of ranks=370021rank=51200 of ranks=370021rank=51300 of ranks=370021rank=51400 of ranks=370021rank=51500 of ranks=370021rank=51600 of ranks=370021rank=51700 of ranks=370021rank=51800 of ranks=370021rank=51900 of ranks=370021rank=52000 of ranks=370021rank=52100 of ranks=370021rank=52200 of ranks=370021rank=52300 of ranks=370021rank=52400 of ranks=370021rank=52500 of ranks=370021rank=52600 of ranks=370021rank=52700 of ranks=370021rank=52800 of ranks=370021rank=52900 of ranks=370021rank=53000 of ranks=370021rank=53100 of ranks=370021rank=53200 of ranks=370021rank=53300 of ranks=370021rank=53400 of ranks=370021rank=53500 of ranks=370021rank=53600 of ranks=370021rank=53700 of ranks=370021rank=53800 of ranks=370021rank=53900 of ranks=370021rank=54000 of ranks=370021rank=54100 of ranks=370021rank=54200 of ranks=370021rank=54300 of ranks=370021rank=54400 of ranks=370021rank=54500 of ranks=370021rank=54600 of ranks=370021rank=54700 of ranks=370021rank=54800 of ranks=370021rank=54900 of ranks=370021rank=55000 of ranks=370021rank=55100 of ranks=370021rank=55200 of ranks=370021rank=55300 of ranks=370021rank=55400 of ranks=370021rank=55500 of ranks=370021rank=55600 of ranks=370021rank=55700 of ranks=370021rank=55800 of ranks=370021rank=55900 of ranks=370021rank=56000 of ranks=370021rank=56100 of ranks=370021rank=56200 of ranks=370021rank=56300 of ranks=370021rank=56400 of ranks=370021rank=56500 of ranks=370021rank=56600 of ranks=370021rank=56700 of ranks=370021rank=56800 of ranks=370021rank=56900 of ranks=370021rank=57000 of ranks=370021rank=57100 of ranks=370021rank=57200 of ranks=370021rank=57300 of ranks=370021rank=57400 of ranks=370021rank=57500 of ranks=370021rank=57600 of ranks=370021rank=57700 of ranks=370021rank=57800 of ranks=370021rank=57900 of ranks=370021rank=58000 of ranks=370021rank=58100 of ranks=370021rank=58200 of ranks=370021rank=58300 of ranks=370021rank=58400 of ranks=370021rank=58500 of ranks=370021rank=58600 of ranks=370021rank=58700 of ranks=370021rank=58800 of ranks=370021rank=58900 of ranks=370021rank=59000 of ranks=370021rank=59100 of ranks=370021rank=59200 of ranks=370021rank=59300 of ranks=370021rank=59400 of ranks=370021rank=59500 of ranks=370021rank=59600 of ranks=370021rank=59700 of ranks=370021rank=59800 of ranks=370021rank=59900 of ranks=370021rank=60000 of ranks=370021rank=60100 of ranks=370021rank=60200 of ranks=370021rank=60300 of ranks=370021rank=60400 of ranks=370021rank=60500 of ranks=370021rank=60600 of ranks=370021rank=60700 of ranks=370021rank=60800 of ranks=370021rank=60900 of ranks=370021rank=61000 of ranks=370021rank=61100 of ranks=370021rank=61200 of ranks=370021rank=61300 of ranks=370021rank=61400 of ranks=370021rank=61500 of ranks=370021rank=61600 of ranks=370021rank=61700 of ranks=370021rank=61800 of ranks=370021rank=61900 of ranks=370021rank=62000 of ranks=370021rank=62100 of ranks=370021rank=62200 of ranks=370021rank=62300 of ranks=370021rank=62400 of ranks=370021rank=62500 of ranks=370021rank=62600 of ranks=370021rank=62700 of ranks=370021rank=62800 of ranks=370021rank=62900 of ranks=370021rank=63000 of ranks=370021rank=63100 of ranks=370021rank=63200 of ranks=370021rank=63300 of ranks=370021rank=63400 of ranks=370021rank=63500 of ranks=370021rank=63600 of ranks=370021rank=63700 of ranks=370021rank=63800 of ranks=370021rank=63900 of ranks=370021rank=64000 of ranks=370021rank=64100 of ranks=370021rank=64200 of ranks=370021rank=64300 of ranks=370021rank=64400 of ranks=370021rank=64500 of ranks=370021rank=64600 of ranks=370021rank=64700 of ranks=370021rank=64800 of ranks=370021rank=64900 of ranks=370021rank=65000 of ranks=370021rank=65100 of ranks=370021rank=65200 of ranks=370021rank=65300 of ranks=370021rank=65400 of ranks=370021rank=65500 of ranks=370021rank=65600 of ranks=370021rank=65700 of ranks=370021rank=65800 of ranks=370021rank=65900 of ranks=370021rank=66000 of ranks=370021rank=66100 of ranks=370021rank=66200 of ranks=370021rank=66300 of ranks=370021rank=66400 of ranks=370021rank=66500 of ranks=370021rank=66600 of ranks=370021rank=66700 of ranks=370021rank=66800 of ranks=370021rank=66900 of ranks=370021rank=67000 of ranks=370021rank=67100 of ranks=370021rank=67200 of ranks=370021rank=67300 of ranks=370021rank=67400 of ranks=370021rank=67500 of ranks=370021rank=67600 of ranks=370021rank=67700 of ranks=370021rank=67800 of ranks=370021rank=67900 of ranks=370021rank=68000 of ranks=370021rank=68100 of ranks=370021rank=68200 of ranks=370021rank=68300 of ranks=370021rank=68400 of ranks=370021rank=68500 of ranks=370021rank=68600 of ranks=370021rank=68700 of ranks=370021rank=68800 of ranks=370021rank=68900 of ranks=370021rank=69000 of ranks=370021rank=69100 of ranks=370021rank=69200 of ranks=370021rank=69300 of ranks=370021rank=69400 of ranks=370021rank=69500 of ranks=370021rank=69600 of ranks=370021rank=69700 of ranks=370021rank=69800 of ranks=370021rank=69900 of ranks=370021rank=70000 of ranks=370021rank=70100 of ranks=370021rank=70200 of ranks=370021rank=70300 of ranks=370021rank=70400 of ranks=370021rank=70500 of ranks=370021rank=70600 of ranks=370021rank=70700 of ranks=370021rank=70800 of ranks=370021rank=70900 of ranks=370021rank=71000 of ranks=370021rank=71100 of ranks=370021rank=71200 of ranks=370021rank=71300 of ranks=370021rank=71400 of ranks=370021rank=71500 of ranks=370021rank=71600 of ranks=370021rank=71700 of ranks=370021rank=71800 of ranks=370021rank=71900 of ranks=370021rank=72000 of ranks=370021rank=72100 of ranks=370021rank=72200 of ranks=370021rank=72300 of ranks=370021rank=72400 of ranks=370021rank=72500 of ranks=370021rank=72600 of ranks=370021rank=72700 of ranks=370021rank=72800 of ranks=370021rank=72900 of ranks=370021rank=73000 of ranks=370021rank=73100 of ranks=370021rank=73200 of ranks=370021rank=73300 of ranks=370021rank=73400 of ranks=370021rank=73500 of ranks=370021rank=73600 of ranks=370021rank=73700 of ranks=370021rank=73800 of ranks=370021rank=73900 of ranks=370021rank=74000 of ranks=370021rank=74100 of ranks=370021rank=74200 of ranks=370021rank=74300 of ranks=370021rank=74400 of ranks=370021rank=74500 of ranks=370021rank=74600 of ranks=370021rank=74700 of ranks=370021rank=74800 of ranks=370021rank=74900 of ranks=370021rank=75000 of ranks=370021rank=75100 of ranks=370021rank=75200 of ranks=370021rank=75300 of ranks=370021rank=75400 of ranks=370021rank=75500 of ranks=370021rank=75600 of ranks=370021rank=75700 of ranks=370021rank=75800 of ranks=370021rank=75900 of ranks=370021rank=76000 of ranks=370021rank=76100 of ranks=370021rank=76200 of ranks=370021rank=76300 of ranks=370021rank=76400 of ranks=370021rank=76500 of ranks=370021rank=76600 of ranks=370021rank=76700 of ranks=370021rank=76800 of ranks=370021rank=76900 of ranks=370021rank=77000 of ranks=370021rank=77100 of ranks=370021rank=77200 of ranks=370021rank=77300 of ranks=370021rank=77400 of ranks=370021rank=77500 of ranks=370021rank=77600 of ranks=370021rank=77700 of ranks=370021rank=77800 of ranks=370021rank=77900 of ranks=370021rank=78000 of ranks=370021rank=78100 of ranks=370021rank=78200 of ranks=370021rank=78300 of ranks=370021rank=78400 of ranks=370021rank=78500 of ranks=370021rank=78600 of ranks=370021rank=78700 of ranks=370021rank=78800 of ranks=370021rank=78900 of ranks=370021rank=79000 of ranks=370021rank=79100 of ranks=370021rank=79200 of ranks=370021rank=79300 of ranks=370021rank=79400 of ranks=370021rank=79500 of ranks=370021rank=79600 of ranks=370021rank=79700 of ranks=370021rank=79800 of ranks=370021rank=79900 of ranks=370021rank=80000 of ranks=370021rank=80100 of ranks=370021rank=80200 of ranks=370021rank=80300 of ranks=370021rank=80400 of ranks=370021rank=80500 of ranks=370021rank=80600 of ranks=370021rank=80700 of ranks=370021rank=80800 of ranks=370021rank=80900 of ranks=370021rank=81000 of ranks=370021rank=81100 of ranks=370021rank=81200 of ranks=370021rank=81300 of ranks=370021rank=81400 of ranks=370021rank=81500 of ranks=370021rank=81600 of ranks=370021rank=81700 of ranks=370021rank=81800 of ranks=370021rank=81900 of ranks=370021rank=82000 of ranks=370021rank=82100 of ranks=370021rank=82200 of ranks=370021rank=82300 of ranks=370021rank=82400 of ranks=370021rank=82500 of ranks=370021rank=82600 of ranks=370021rank=82700 of ranks=370021rank=82800 of ranks=370021rank=82900 of ranks=370021rank=83000 of ranks=370021rank=83100 of ranks=370021rank=83200 of ranks=370021rank=83300 of ranks=370021rank=83400 of ranks=370021rank=83500 of ranks=370021rank=83600 of ranks=370021rank=83700 of ranks=370021rank=83800 of ranks=370021rank=83900 of ranks=370021rank=84000 of ranks=370021rank=84100 of ranks=370021rank=84200 of ranks=370021rank=84300 of ranks=370021rank=84400 of ranks=370021rank=84500 of ranks=370021rank=84600 of ranks=370021rank=84700 of ranks=370021rank=84800 of ranks=370021rank=84900 of ranks=370021rank=85000 of ranks=370021rank=85100 of ranks=370021rank=85200 of ranks=370021rank=85300 of ranks=370021rank=85400 of ranks=370021rank=85500 of ranks=370021rank=85600 of ranks=370021rank=85700 of ranks=370021rank=85800 of ranks=370021rank=85900 of ranks=370021rank=86000 of ranks=370021rank=86100 of ranks=370021rank=86200 of ranks=370021rank=86300 of ranks=370021rank=86400 of ranks=370021rank=86500 of ranks=370021rank=86600 of ranks=370021rank=86700 of ranks=370021rank=86800 of ranks=370021rank=86900 of ranks=370021rank=87000 of ranks=370021rank=87100 of ranks=370021rank=87200 of ranks=370021rank=87300 of ranks=370021rank=87400 of ranks=370021rank=87500 of ranks=370021rank=87600 of ranks=370021rank=87700 of ranks=370021rank=87800 of ranks=370021rank=87900 of ranks=370021rank=88000 of ranks=370021rank=88100 of ranks=370021rank=88200 of ranks=370021rank=88300 of ranks=370021rank=88400 of ranks=370021rank=88500 of ranks=370021rank=88600 of ranks=370021rank=88700 of ranks=370021rank=88800 of ranks=370021rank=88900 of ranks=370021rank=89000 of ranks=370021rank=89100 of ranks=370021rank=89200 of ranks=370021rank=89300 of ranks=370021rank=89400 of ranks=370021rank=89500 of ranks=370021rank=89600 of ranks=370021rank=89700 of ranks=370021rank=89800 of ranks=370021rank=89900 of ranks=370021rank=90000 of ranks=370021rank=90100 of ranks=370021rank=90200 of ranks=370021rank=90300 of ranks=370021rank=90400 of ranks=370021rank=90500 of ranks=370021rank=90600 of ranks=370021rank=90700 of ranks=370021rank=90800 of ranks=370021rank=90900 of ranks=370021rank=91000 of ranks=370021rank=91100 of ranks=370021rank=91200 of ranks=370021rank=91300 of ranks=370021rank=91400 of ranks=370021rank=91500 of ranks=370021rank=91600 of ranks=370021rank=91700 of ranks=370021rank=91800 of ranks=370021rank=91900 of ranks=370021rank=92000 of ranks=370021rank=92100 of ranks=370021rank=92200 of ranks=370021rank=92300 of ranks=370021rank=92400 of ranks=370021rank=92500 of ranks=370021rank=92600 of ranks=370021rank=92700 of ranks=370021rank=92800 of ranks=370021rank=92900 of ranks=370021rank=93000 of ranks=370021rank=93100 of ranks=370021rank=93200 of ranks=370021rank=93300 of ranks=370021rank=93400 of ranks=370021rank=93500 of ranks=370021rank=93600 of ranks=370021rank=93700 of ranks=370021rank=93800 of ranks=370021rank=93900 of ranks=370021rank=94000 of ranks=370021rank=94100 of ranks=370021rank=94200 of ranks=370021rank=94300 of ranks=370021rank=94400 of ranks=370021rank=94500 of ranks=370021rank=94600 of ranks=370021rank=94700 of ranks=370021rank=94800 of ranks=370021rank=94900 of ranks=370021rank=95000 of ranks=370021rank=95100 of ranks=370021rank=95200 of ranks=370021rank=95300 of ranks=370021rank=95400 of ranks=370021rank=95500 of ranks=370021rank=95600 of ranks=370021rank=95700 of ranks=370021rank=95800 of ranks=370021rank=95900 of ranks=370021rank=96000 of ranks=370021rank=96100 of ranks=370021rank=96200 of ranks=370021rank=96300 of ranks=370021rank=96400 of ranks=370021rank=96500 of ranks=370021rank=96600 of ranks=370021rank=96700 of ranks=370021rank=96800 of ranks=370021rank=96900 of ranks=370021rank=97000 of ranks=370021rank=97100 of ranks=370021rank=97200 of ranks=370021rank=97300 of ranks=370021rank=97400 of ranks=370021rank=97500 of ranks=370021rank=97600 of ranks=370021rank=97700 of ranks=370021rank=97800 of ranks=370021rank=97900 of ranks=370021rank=98000 of ranks=370021rank=98100 of ranks=370021rank=98200 of ranks=370021rank=98300 of ranks=370021rank=98400 of ranks=370021rank=98500 of ranks=370021rank=98600 of ranks=370021rank=98700 of ranks=370021rank=98800 of ranks=370021rank=98900 of ranks=370021rank=99000 of ranks=370021rank=99100 of ranks=370021rank=99200 of ranks=370021rank=99300 of ranks=370021rank=99400 of ranks=370021rank=99500 of ranks=370021rank=99600 of ranks=370021rank=99700 of ranks=370021rank=99800 of ranks=370021rank=99900 of ranks=370021rank=100000 of ranks=370021rank=100100 of ranks=370021rank=100200 of ranks=370021rank=100300 of ranks=370021rank=100400 of ranks=370021rank=100500 of ranks=370021rank=100600 of ranks=370021rank=100700 of ranks=370021rank=100800 of ranks=370021rank=100900 of ranks=370021rank=101000 of ranks=370021rank=101100 of ranks=370021rank=101200 of ranks=370021rank=101300 of ranks=370021rank=101400 of ranks=370021rank=101500 of ranks=370021rank=101600 of ranks=370021rank=101700 of ranks=370021rank=101800 of ranks=370021rank=101900 of ranks=370021rank=102000 of ranks=370021rank=102100 of ranks=370021rank=102200 of ranks=370021rank=102300 of ranks=370021rank=102400 of ranks=370021rank=102500 of ranks=370021rank=102600 of ranks=370021rank=102700 of ranks=370021rank=102800 of ranks=370021rank=102900 of ranks=370021rank=103000 of ranks=370021rank=103100 of ranks=370021rank=103200 of ranks=370021rank=103300 of ranks=370021rank=103400 of ranks=370021rank=103500 of ranks=370021rank=103600 of ranks=370021rank=103700 of ranks=370021rank=103800 of ranks=370021rank=103900 of ranks=370021rank=104000 of ranks=370021rank=104100 of ranks=370021rank=104200 of ranks=370021rank=104300 of ranks=370021rank=104400 of ranks=370021rank=104500 of ranks=370021rank=104600 of ranks=370021rank=104700 of ranks=370021rank=104800 of ranks=370021rank=104900 of ranks=370021rank=105000 of ranks=370021rank=105100 of ranks=370021rank=105200 of ranks=370021rank=105300 of ranks=370021rank=105400 of ranks=370021rank=105500 of ranks=370021rank=105600 of ranks=370021rank=105700 of ranks=370021rank=105800 of ranks=370021rank=105900 of ranks=370021rank=106000 of ranks=370021rank=106100 of ranks=370021rank=106200 of ranks=370021rank=106300 of ranks=370021rank=106400 of ranks=370021rank=106500 of ranks=370021rank=106600 of ranks=370021rank=106700 of ranks=370021rank=106800 of ranks=370021rank=106900 of ranks=370021rank=107000 of ranks=370021rank=107100 of ranks=370021rank=107200 of ranks=370021rank=107300 of ranks=370021rank=107400 of ranks=370021rank=107500 of ranks=370021rank=107600 of ranks=370021rank=107700 of ranks=370021rank=107800 of ranks=370021rank=107900 of ranks=370021rank=108000 of ranks=370021rank=108100 of ranks=370021rank=108200 of ranks=370021rank=108300 of ranks=370021rank=108400 of ranks=370021rank=108500 of ranks=370021rank=108600 of ranks=370021rank=108700 of ranks=370021rank=108800 of ranks=370021rank=108900 of ranks=370021rank=109000 of ranks=370021rank=109100 of ranks=370021rank=109200 of ranks=370021rank=109300 of ranks=370021rank=109400 of ranks=370021rank=109500 of ranks=370021rank=109600 of ranks=370021rank=109700 of ranks=370021rank=109800 of ranks=370021rank=109900 of ranks=370021rank=110000 of ranks=370021rank=110100 of ranks=370021rank=110200 of ranks=370021rank=110300 of ranks=370021rank=110400 of ranks=370021rank=110500 of ranks=370021rank=110600 of ranks=370021rank=110700 of ranks=370021rank=110800 of ranks=370021rank=110900 of ranks=370021rank=111000 of ranks=370021rank=111100 of ranks=370021rank=111200 of ranks=370021rank=111300 of ranks=370021rank=111400 of ranks=370021rank=111500 of ranks=370021rank=111600 of ranks=370021rank=111700 of ranks=370021rank=111800 of ranks=370021rank=111900 of ranks=370021rank=112000 of ranks=370021rank=112100 of ranks=370021rank=112200 of ranks=370021rank=112300 of ranks=370021rank=112400 of ranks=370021rank=112500 of ranks=370021rank=112600 of ranks=370021rank=112700 of ranks=370021rank=112800 of ranks=370021rank=112900 of ranks=370021rank=113000 of ranks=370021rank=113100 of ranks=370021rank=113200 of ranks=370021rank=113300 of ranks=370021rank=113400 of ranks=370021rank=113500 of ranks=370021rank=113600 of ranks=370021rank=113700 of ranks=370021rank=113800 of ranks=370021rank=113900 of ranks=370021rank=114000 of ranks=370021rank=114100 of ranks=370021rank=114200 of ranks=370021rank=114300 of ranks=370021rank=114400 of ranks=370021rank=114500 of ranks=370021rank=114600 of ranks=370021rank=114700 of ranks=370021rank=114800 of ranks=370021rank=114900 of ranks=370021rank=115000 of ranks=370021rank=115100 of ranks=370021rank=115200 of ranks=370021rank=115300 of ranks=370021rank=115400 of ranks=370021rank=115500 of ranks=370021rank=115600 of ranks=370021rank=115700 of ranks=370021rank=115800 of ranks=370021rank=115900 of ranks=370021rank=116000 of ranks=370021rank=116100 of ranks=370021rank=116200 of ranks=370021rank=116300 of ranks=370021rank=116400 of ranks=370021rank=116500 of ranks=370021rank=116600 of ranks=370021rank=116700 of ranks=370021rank=116800 of ranks=370021rank=116900 of ranks=370021rank=117000 of ranks=370021rank=117100 of ranks=370021rank=117200 of ranks=370021rank=117300 of ranks=370021rank=117400 of ranks=370021rank=117500 of ranks=370021rank=117600 of ranks=370021rank=117700 of ranks=370021rank=117800 of ranks=370021rank=117900 of ranks=370021rank=118000 of ranks=370021rank=118100 of ranks=370021rank=118200 of ranks=370021rank=118300 of ranks=370021rank=118400 of ranks=370021rank=118500 of ranks=370021rank=118600 of ranks=370021rank=118700 of ranks=370021rank=118800 of ranks=370021rank=118900 of ranks=370021rank=119000 of ranks=370021rank=119100 of ranks=370021rank=119200 of ranks=370021rank=119300 of ranks=370021rank=119400 of ranks=370021rank=119500 of ranks=370021rank=119600 of ranks=370021rank=119700 of ranks=370021rank=119800 of ranks=370021rank=119900 of ranks=370021rank=120000 of ranks=370021rank=120100 of ranks=370021rank=120200 of ranks=370021rank=120300 of ranks=370021rank=120400 of ranks=370021rank=120500 of ranks=370021rank=120600 of ranks=370021rank=120700 of ranks=370021rank=120800 of ranks=370021rank=120900 of ranks=370021rank=121000 of ranks=370021rank=121100 of ranks=370021rank=121200 of ranks=370021rank=121300 of ranks=370021rank=121400 of ranks=370021rank=121500 of ranks=370021rank=121600 of ranks=370021rank=121700 of ranks=370021rank=121800 of ranks=370021rank=121900 of ranks=370021rank=122000 of ranks=370021rank=122100 of ranks=370021rank=122200 of ranks=370021rank=122300 of ranks=370021rank=122400 of ranks=370021rank=122500 of ranks=370021rank=122600 of ranks=370021rank=122700 of ranks=370021rank=122800 of ranks=370021rank=122900 of ranks=370021rank=123000 of ranks=370021rank=123100 of ranks=370021rank=123200 of ranks=370021rank=123300 of ranks=370021rank=123400 of ranks=370021rank=123500 of ranks=370021rank=123600 of ranks=370021rank=123700 of ranks=370021rank=123800 of ranks=370021rank=123900 of ranks=370021rank=124000 of ranks=370021rank=124100 of ranks=370021rank=124200 of ranks=370021rank=124300 of ranks=370021rank=124400 of ranks=370021rank=124500 of ranks=370021rank=124600 of ranks=370021rank=124700 of ranks=370021rank=124800 of ranks=370021rank=124900 of ranks=370021rank=125000 of ranks=370021rank=125100 of ranks=370021rank=125200 of ranks=370021rank=125300 of ranks=370021rank=125400 of ranks=370021rank=125500 of ranks=370021rank=125600 of ranks=370021rank=125700 of ranks=370021rank=125800 of ranks=370021rank=125900 of ranks=370021rank=126000 of ranks=370021rank=126100 of ranks=370021rank=126200 of ranks=370021rank=126300 of ranks=370021rank=126400 of ranks=370021rank=126500 of ranks=370021rank=126600 of ranks=370021rank=126700 of ranks=370021rank=126800 of ranks=370021rank=126900 of ranks=370021rank=127000 of ranks=370021rank=127100 of ranks=370021rank=127200 of ranks=370021rank=127300 of ranks=370021rank=127400 of ranks=370021rank=127500 of ranks=370021rank=127600 of ranks=370021rank=127700 of ranks=370021rank=127800 of ranks=370021rank=127900 of ranks=370021rank=128000 of ranks=370021rank=128100 of ranks=370021rank=128200 of ranks=370021rank=128300 of ranks=370021rank=128400 of ranks=370021rank=128500 of ranks=370021rank=128600 of ranks=370021rank=128700 of ranks=370021rank=128800 of ranks=370021rank=128900 of ranks=370021rank=129000 of ranks=370021rank=129100 of ranks=370021rank=129200 of ranks=370021rank=129300 of ranks=370021rank=129400 of ranks=370021rank=129500 of ranks=370021rank=129600 of ranks=370021rank=129700 of ranks=370021rank=129800 of ranks=370021rank=129900 of ranks=370021rank=130000 of ranks=370021rank=130100 of ranks=370021rank=130200 of ranks=370021rank=130300 of ranks=370021rank=130400 of ranks=370021rank=130500 of ranks=370021rank=130600 of ranks=370021rank=130700 of ranks=370021rank=130800 of ranks=370021rank=130900 of ranks=370021rank=131000 of ranks=370021rank=131100 of ranks=370021rank=131200 of ranks=370021rank=131300 of ranks=370021rank=131400 of ranks=370021rank=131500 of ranks=370021rank=131600 of ranks=370021rank=131700 of ranks=370021rank=131800 of ranks=370021rank=131900 of ranks=370021rank=132000 of ranks=370021rank=132100 of ranks=370021rank=132200 of ranks=370021rank=132300 of ranks=370021rank=132400 of ranks=370021rank=132500 of ranks=370021rank=132600 of ranks=370021rank=132700 of ranks=370021rank=132800 of ranks=370021rank=132900 of ranks=370021rank=133000 of ranks=370021rank=133100 of ranks=370021rank=133200 of ranks=370021rank=133300 of ranks=370021rank=133400 of ranks=370021rank=133500 of ranks=370021rank=133600 of ranks=370021rank=133700 of ranks=370021rank=133800 of ranks=370021rank=133900 of ranks=370021rank=134000 of ranks=370021rank=134100 of ranks=370021rank=134200 of ranks=370021rank=134300 of ranks=370021rank=134400 of ranks=370021rank=134500 of ranks=370021rank=134600 of ranks=370021rank=134700 of ranks=370021rank=134800 of ranks=370021rank=134900 of ranks=370021rank=135000 of ranks=370021rank=135100 of ranks=370021rank=135200 of ranks=370021rank=135300 of ranks=370021rank=135400 of ranks=370021rank=135500 of ranks=370021rank=135600 of ranks=370021rank=135700 of ranks=370021rank=135800 of ranks=370021rank=135900 of ranks=370021rank=136000 of ranks=370021rank=136100 of ranks=370021rank=136200 of ranks=370021rank=136300 of ranks=370021rank=136400 of ranks=370021rank=136500 of ranks=370021rank=136600 of ranks=370021rank=136700 of ranks=370021rank=136800 of ranks=370021rank=136900 of ranks=370021rank=137000 of ranks=370021rank=137100 of ranks=370021rank=137200 of ranks=370021rank=137300 of ranks=370021rank=137400 of ranks=370021rank=137500 of ranks=370021rank=137600 of ranks=370021rank=137700 of ranks=370021rank=137800 of ranks=370021rank=137900 of ranks=370021rank=138000 of ranks=370021rank=138100 of ranks=370021rank=138200 of ranks=370021rank=138300 of ranks=370021rank=138400 of ranks=370021rank=138500 of ranks=370021rank=138600 of ranks=370021rank=138700 of ranks=370021rank=138800 of ranks=370021rank=138900 of ranks=370021rank=139000 of ranks=370021rank=139100 of ranks=370021rank=139200 of ranks=370021rank=139300 of ranks=370021rank=139400 of ranks=370021rank=139500 of ranks=370021rank=139600 of ranks=370021rank=139700 of ranks=370021rank=139800 of ranks=370021rank=139900 of ranks=370021rank=140000 of ranks=370021rank=140100 of ranks=370021rank=140200 of ranks=370021rank=140300 of ranks=370021rank=140400 of ranks=370021rank=140500 of ranks=370021rank=140600 of ranks=370021rank=140700 of ranks=370021rank=140800 of ranks=370021rank=140900 of ranks=370021rank=141000 of ranks=370021rank=141100 of ranks=370021rank=141200 of ranks=370021rank=141300 of ranks=370021rank=141400 of ranks=370021rank=141500 of ranks=370021rank=141600 of ranks=370021rank=141700 of ranks=370021rank=141800 of ranks=370021rank=141900 of ranks=370021rank=142000 of ranks=370021rank=142100 of ranks=370021rank=142200 of ranks=370021rank=142300 of ranks=370021rank=142400 of ranks=370021rank=142500 of ranks=370021rank=142600 of ranks=370021rank=142700 of ranks=370021rank=142800 of ranks=370021rank=142900 of ranks=370021rank=143000 of ranks=370021rank=143100 of ranks=370021rank=143200 of ranks=370021rank=143300 of ranks=370021rank=143400 of ranks=370021rank=143500 of ranks=370021rank=143600 of ranks=370021rank=143700 of ranks=370021rank=143800 of ranks=370021rank=143900 of ranks=370021rank=144000 of ranks=370021rank=144100 of ranks=370021rank=144200 of ranks=370021rank=144300 of ranks=370021rank=144400 of ranks=370021rank=144500 of ranks=370021rank=144600 of ranks=370021rank=144700 of ranks=370021rank=144800 of ranks=370021rank=144900 of ranks=370021rank=145000 of ranks=370021rank=145100 of ranks=370021rank=145200 of ranks=370021rank=145300 of ranks=370021rank=145400 of ranks=370021rank=145500 of ranks=370021rank=145600 of ranks=370021rank=145700 of ranks=370021rank=145800 of ranks=370021rank=145900 of ranks=370021rank=146000 of ranks=370021rank=146100 of ranks=370021rank=146200 of ranks=370021rank=146300 of ranks=370021rank=146400 of ranks=370021rank=146500 of ranks=370021rank=146600 of ranks=370021rank=146700 of ranks=370021rank=146800 of ranks=370021rank=146900 of ranks=370021rank=147000 of ranks=370021rank=147100 of ranks=370021rank=147200 of ranks=370021rank=147300 of ranks=370021rank=147400 of ranks=370021rank=147500 of ranks=370021rank=147600 of ranks=370021rank=147700 of ranks=370021rank=147800 of ranks=370021rank=147900 of ranks=370021rank=148000 of ranks=370021rank=148100 of ranks=370021rank=148200 of ranks=370021rank=148300 of ranks=370021rank=148400 of ranks=370021rank=148500 of ranks=370021rank=148600 of ranks=370021rank=148700 of ranks=370021rank=148800 of ranks=370021rank=148900 of ranks=370021rank=149000 of ranks=370021rank=149100 of ranks=370021rank=149200 of ranks=370021rank=149300 of ranks=370021rank=149400 of ranks=370021rank=149500 of ranks=370021rank=149600 of ranks=370021rank=149700 of ranks=370021rank=149800 of ranks=370021rank=149900 of ranks=370021rank=150000 of ranks=370021rank=150100 of ranks=370021rank=150200 of ranks=370021rank=150300 of ranks=370021rank=150400 of ranks=370021rank=150500 of ranks=370021rank=150600 of ranks=370021rank=150700 of ranks=370021rank=150800 of ranks=370021rank=150900 of ranks=370021rank=151000 of ranks=370021rank=151100 of ranks=370021rank=151200 of ranks=370021rank=151300 of ranks=370021rank=151400 of ranks=370021rank=151500 of ranks=370021rank=151600 of ranks=370021rank=151700 of ranks=370021rank=151800 of ranks=370021rank=151900 of ranks=370021rank=152000 of ranks=370021rank=152100 of ranks=370021rank=152200 of ranks=370021rank=152300 of ranks=370021rank=152400 of ranks=370021rank=152500 of ranks=370021rank=152600 of ranks=370021rank=152700 of ranks=370021rank=152800 of ranks=370021rank=152900 of ranks=370021rank=153000 of ranks=370021rank=153100 of ranks=370021rank=153200 of ranks=370021rank=153300 of ranks=370021rank=153400 of ranks=370021rank=153500 of ranks=370021rank=153600 of ranks=370021rank=153700 of ranks=370021rank=153800 of ranks=370021rank=153900 of ranks=370021rank=154000 of ranks=370021rank=154100 of ranks=370021rank=154200 of ranks=370021rank=154300 of ranks=370021rank=154400 of ranks=370021rank=154500 of ranks=370021rank=154600 of ranks=370021rank=154700 of ranks=370021rank=154800 of ranks=370021rank=154900 of ranks=370021rank=155000 of ranks=370021rank=155100 of ranks=370021rank=155200 of ranks=370021rank=155300 of ranks=370021rank=155400 of ranks=370021rank=155500 of ranks=370021rank=155600 of ranks=370021rank=155700 of ranks=370021rank=155800 of ranks=370021rank=155900 of ranks=370021rank=156000 of ranks=370021rank=156100 of ranks=370021rank=156200 of ranks=370021rank=156300 of ranks=370021rank=156400 of ranks=370021rank=156500 of ranks=370021rank=156600 of ranks=370021rank=156700 of ranks=370021rank=156800 of ranks=370021rank=156900 of ranks=370021rank=157000 of ranks=370021rank=157100 of ranks=370021rank=157200 of ranks=370021rank=157300 of ranks=370021rank=157400 of ranks=370021rank=157500 of ranks=370021rank=157600 of ranks=370021rank=157700 of ranks=370021rank=157800 of ranks=370021rank=157900 of ranks=370021rank=158000 of ranks=370021rank=158100 of ranks=370021rank=158200 of ranks=370021rank=158300 of ranks=370021rank=158400 of ranks=370021rank=158500 of ranks=370021rank=158600 of ranks=370021rank=158700 of ranks=370021rank=158800 of ranks=370021rank=158900 of ranks=370021rank=159000 of ranks=370021rank=159100 of ranks=370021rank=159200 of ranks=370021rank=159300 of ranks=370021rank=159400 of ranks=370021rank=159500 of ranks=370021rank=159600 of ranks=370021rank=159700 of ranks=370021rank=159800 of ranks=370021rank=159900 of ranks=370021rank=160000 of ranks=370021rank=160100 of ranks=370021rank=160200 of ranks=370021rank=160300 of ranks=370021rank=160400 of ranks=370021rank=160500 of ranks=370021rank=160600 of ranks=370021rank=160700 of ranks=370021rank=160800 of ranks=370021rank=160900 of ranks=370021rank=161000 of ranks=370021rank=161100 of ranks=370021rank=161200 of ranks=370021rank=161300 of ranks=370021rank=161400 of ranks=370021rank=161500 of ranks=370021rank=161600 of ranks=370021rank=161700 of ranks=370021rank=161800 of ranks=370021rank=161900 of ranks=370021rank=162000 of ranks=370021rank=162100 of ranks=370021rank=162200 of ranks=370021rank=162300 of ranks=370021rank=162400 of ranks=370021rank=162500 of ranks=370021rank=162600 of ranks=370021rank=162700 of ranks=370021rank=162800 of ranks=370021rank=162900 of ranks=370021rank=163000 of ranks=370021rank=163100 of ranks=370021rank=163200 of ranks=370021rank=163300 of ranks=370021rank=163400 of ranks=370021rank=163500 of ranks=370021rank=163600 of ranks=370021rank=163700 of ranks=370021rank=163800 of ranks=370021rank=163900 of ranks=370021rank=164000 of ranks=370021rank=164100 of ranks=370021rank=164200 of ranks=370021rank=164300 of ranks=370021rank=164400 of ranks=370021rank=164500 of ranks=370021rank=164600 of ranks=370021rank=164700 of ranks=370021rank=164800 of ranks=370021rank=164900 of ranks=370021rank=165000 of ranks=370021rank=165100 of ranks=370021rank=165200 of ranks=370021rank=165300 of ranks=370021rank=165400 of ranks=370021rank=165500 of ranks=370021rank=165600 of ranks=370021rank=165700 of ranks=370021rank=165800 of ranks=370021rank=165900 of ranks=370021rank=166000 of ranks=370021rank=166100 of ranks=370021rank=166200 of ranks=370021rank=166300 of ranks=370021rank=166400 of ranks=370021rank=166500 of ranks=370021rank=166600 of ranks=370021rank=166700 of ranks=370021rank=166800 of ranks=370021rank=166900 of ranks=370021rank=167000 of ranks=370021rank=167100 of ranks=370021rank=167200 of ranks=370021rank=167300 of ranks=370021rank=167400 of ranks=370021rank=167500 of ranks=370021rank=167600 of ranks=370021rank=167700 of ranks=370021rank=167800 of ranks=370021rank=167900 of ranks=370021rank=168000 of ranks=370021rank=168100 of ranks=370021rank=168200 of ranks=370021rank=168300 of ranks=370021rank=168400 of ranks=370021rank=168500 of ranks=370021rank=168600 of ranks=370021rank=168700 of ranks=370021rank=168800 of ranks=370021rank=168900 of ranks=370021rank=169000 of ranks=370021rank=169100 of ranks=370021rank=169200 of ranks=370021rank=169300 of ranks=370021rank=169400 of ranks=370021rank=169500 of ranks=370021rank=169600 of ranks=370021rank=169700 of ranks=370021rank=169800 of ranks=370021rank=169900 of ranks=370021rank=170000 of ranks=370021rank=170100 of ranks=370021rank=170200 of ranks=370021rank=170300 of ranks=370021rank=170400 of ranks=370021rank=170500 of ranks=370021rank=170600 of ranks=370021rank=170700 of ranks=370021rank=170800 of ranks=370021rank=170900 of ranks=370021rank=171000 of ranks=370021rank=171100 of ranks=370021rank=171200 of ranks=370021rank=171300 of ranks=370021rank=171400 of ranks=370021rank=171500 of ranks=370021rank=171600 of ranks=370021rank=171700 of ranks=370021rank=171800 of ranks=370021rank=171900 of ranks=370021rank=172000 of ranks=370021rank=172100 of ranks=370021rank=172200 of ranks=370021rank=172300 of ranks=370021rank=172400 of ranks=370021rank=172500 of ranks=370021rank=172600 of ranks=370021rank=172700 of ranks=370021rank=172800 of ranks=370021rank=172900 of ranks=370021rank=173000 of ranks=370021rank=173100 of ranks=370021rank=173200 of ranks=370021rank=173300 of ranks=370021rank=173400 of ranks=370021rank=173500 of ranks=370021rank=173600 of ranks=370021rank=173700 of ranks=370021rank=173800 of ranks=370021rank=173900 of ranks=370021rank=174000 of ranks=370021rank=174100 of ranks=370021rank=174200 of ranks=370021rank=174300 of ranks=370021rank=174400 of ranks=370021rank=174500 of ranks=370021rank=174600 of ranks=370021rank=174700 of ranks=370021rank=174800 of ranks=370021rank=174900 of ranks=370021rank=175000 of ranks=370021rank=175100 of ranks=370021rank=175200 of ranks=370021rank=175300 of ranks=370021rank=175400 of ranks=370021rank=175500 of ranks=370021rank=175600 of ranks=370021rank=175700 of ranks=370021rank=175800 of ranks=370021rank=175900 of ranks=370021rank=176000 of ranks=370021rank=176100 of ranks=370021rank=176200 of ranks=370021rank=176300 of ranks=370021rank=176400 of ranks=370021rank=176500 of ranks=370021rank=176600 of ranks=370021rank=176700 of ranks=370021rank=176800 of ranks=370021rank=176900 of ranks=370021rank=177000 of ranks=370021rank=177100 of ranks=370021rank=177200 of ranks=370021rank=177300 of ranks=370021rank=177400 of ranks=370021rank=177500 of ranks=370021rank=177600 of ranks=370021rank=177700 of ranks=370021rank=177800 of ranks=370021rank=177900 of ranks=370021rank=178000 of ranks=370021rank=178100 of ranks=370021rank=178200 of ranks=370021rank=178300 of ranks=370021rank=178400 of ranks=370021rank=178500 of ranks=370021rank=178600 of ranks=370021rank=178700 of ranks=370021rank=178800 of ranks=370021rank=178900 of ranks=370021rank=179000 of ranks=370021rank=179100 of ranks=370021rank=179200 of ranks=370021rank=179300 of ranks=370021rank=179400 of ranks=370021rank=179500 of ranks=370021rank=179600 of ranks=370021rank=179700 of ranks=370021rank=179800 of ranks=370021rank=179900 of ranks=370021rank=180000 of ranks=370021rank=180100 of ranks=370021rank=180200 of ranks=370021rank=180300 of ranks=370021rank=180400 of ranks=370021rank=180500 of ranks=370021rank=180600 of ranks=370021rank=180700 of ranks=370021rank=180800 of ranks=370021rank=180900 of ranks=370021rank=181000 of ranks=370021rank=181100 of ranks=370021rank=181200 of ranks=370021rank=181300 of ranks=370021rank=181400 of ranks=370021rank=181500 of ranks=370021rank=181600 of ranks=370021rank=181700 of ranks=370021rank=181800 of ranks=370021rank=181900 of ranks=370021rank=182000 of ranks=370021rank=182100 of ranks=370021rank=182200 of ranks=370021rank=182300 of ranks=370021rank=182400 of ranks=370021rank=182500 of ranks=370021rank=182600 of ranks=370021rank=182700 of ranks=370021rank=182800 of ranks=370021rank=182900 of ranks=370021rank=183000 of ranks=370021rank=183100 of ranks=370021rank=183200 of ranks=370021rank=183300 of ranks=370021rank=183400 of ranks=370021rank=183500 of ranks=370021rank=183600 of ranks=370021rank=183700 of ranks=370021rank=183800 of ranks=370021rank=183900 of ranks=370021rank=184000 of ranks=370021rank=184100 of ranks=370021rank=184200 of ranks=370021rank=184300 of ranks=370021rank=184400 of ranks=370021rank=184500 of ranks=370021rank=184600 of ranks=370021rank=184700 of ranks=370021rank=184800 of ranks=370021rank=184900 of ranks=370021rank=185000 of ranks=370021rank=185100 of ranks=370021rank=185200 of ranks=370021rank=185300 of ranks=370021rank=185400 of ranks=370021rank=185500 of ranks=370021rank=185600 of ranks=370021rank=185700 of ranks=370021rank=185800 of ranks=370021rank=185900 of ranks=370021rank=186000 of ranks=370021rank=186100 of ranks=370021rank=186200 of ranks=370021rank=186300 of ranks=370021rank=186400 of ranks=370021rank=186500 of ranks=370021rank=186600 of ranks=370021rank=186700 of ranks=370021rank=186800 of ranks=370021rank=186900 of ranks=370021rank=187000 of ranks=370021rank=187100 of ranks=370021rank=187200 of ranks=370021rank=187300 of ranks=370021rank=187400 of ranks=370021rank=187500 of ranks=370021rank=187600 of ranks=370021rank=187700 of ranks=370021rank=187800 of ranks=370021rank=187900 of ranks=370021rank=188000 of ranks=370021rank=188100 of ranks=370021rank=188200 of ranks=370021rank=188300 of ranks=370021rank=188400 of ranks=370021rank=188500 of ranks=370021rank=188600 of ranks=370021rank=188700 of ranks=370021rank=188800 of ranks=370021rank=188900 of ranks=370021rank=189000 of ranks=370021rank=189100 of ranks=370021rank=189200 of ranks=370021rank=189300 of ranks=370021rank=189400 of ranks=370021rank=189500 of ranks=370021rank=189600 of ranks=370021rank=189700 of ranks=370021rank=189800 of ranks=370021rank=189900 of ranks=370021rank=190000 of ranks=370021rank=190100 of ranks=370021rank=190200 of ranks=370021rank=190300 of ranks=370021rank=190400 of ranks=370021rank=190500 of ranks=370021rank=190600 of ranks=370021rank=190700 of ranks=370021rank=190800 of ranks=370021rank=190900 of ranks=370021rank=191000 of ranks=370021rank=191100 of ranks=370021rank=191200 of ranks=370021rank=191300 of ranks=370021rank=191400 of ranks=370021rank=191500 of ranks=370021rank=191600 of ranks=370021rank=191700 of ranks=370021rank=191800 of ranks=370021rank=191900 of ranks=370021rank=192000 of ranks=370021rank=192100 of ranks=370021rank=192200 of ranks=370021rank=192300 of ranks=370021rank=192400 of ranks=370021rank=192500 of ranks=370021rank=192600 of ranks=370021rank=192700 of ranks=370021rank=192800 of ranks=370021rank=192900 of ranks=370021rank=193000 of ranks=370021rank=193100 of ranks=370021rank=193200 of ranks=370021rank=193300 of ranks=370021rank=193400 of ranks=370021rank=193500 of ranks=370021rank=193600 of ranks=370021rank=193700 of ranks=370021rank=193800 of ranks=370021rank=193900 of ranks=370021rank=194000 of ranks=370021rank=194100 of ranks=370021rank=194200 of ranks=370021rank=194300 of ranks=370021rank=194400 of ranks=370021rank=194500 of ranks=370021rank=194600 of ranks=370021rank=194700 of ranks=370021rank=194800 of ranks=370021rank=194900 of ranks=370021rank=195000 of ranks=370021rank=195100 of ranks=370021rank=195200 of ranks=370021rank=195300 of ranks=370021rank=195400 of ranks=370021rank=195500 of ranks=370021rank=195600 of ranks=370021rank=195700 of ranks=370021rank=195800 of ranks=370021rank=195900 of ranks=370021rank=196000 of ranks=370021rank=196100 of ranks=370021rank=196200 of ranks=370021rank=196300 of ranks=370021rank=196400 of ranks=370021rank=196500 of ranks=370021rank=196600 of ranks=370021rank=196700 of ranks=370021rank=196800 of ranks=370021rank=196900 of ranks=370021rank=197000 of ranks=370021rank=197100 of ranks=370021rank=197200 of ranks=370021rank=197300 of ranks=370021rank=197400 of ranks=370021rank=197500 of ranks=370021rank=197600 of ranks=370021rank=197700 of ranks=370021rank=197800 of ranks=370021rank=197900 of ranks=370021rank=198000 of ranks=370021rank=198100 of ranks=370021rank=198200 of ranks=370021rank=198300 of ranks=370021rank=198400 of ranks=370021rank=198500 of ranks=370021rank=198600 of ranks=370021rank=198700 of ranks=370021rank=198800 of ranks=370021rank=198900 of ranks=370021rank=199000 of ranks=370021rank=199100 of ranks=370021rank=199200 of ranks=370021rank=199300 of ranks=370021rank=199400 of ranks=370021rank=199500 of ranks=370021rank=199600 of ranks=370021rank=199700 of ranks=370021rank=199800 of ranks=370021rank=199900 of ranks=370021rank=200000 of ranks=370021rank=200100 of ranks=370021rank=200200 of ranks=370021rank=200300 of ranks=370021rank=200400 of ranks=370021rank=200500 of ranks=370021rank=200600 of ranks=370021rank=200700 of ranks=370021rank=200800 of ranks=370021rank=200900 of ranks=370021rank=201000 of ranks=370021rank=201100 of ranks=370021rank=201200 of ranks=370021rank=201300 of ranks=370021rank=201400 of ranks=370021rank=201500 of ranks=370021rank=201600 of ranks=370021rank=201700 of ranks=370021rank=201800 of ranks=370021rank=201900 of ranks=370021rank=202000 of ranks=370021rank=202100 of ranks=370021rank=202200 of ranks=370021rank=202300 of ranks=370021rank=202400 of ranks=370021rank=202500 of ranks=370021rank=202600 of ranks=370021rank=202700 of ranks=370021rank=202800 of ranks=370021rank=202900 of ranks=370021rank=203000 of ranks=370021rank=203100 of ranks=370021rank=203200 of ranks=370021rank=203300 of ranks=370021rank=203400 of ranks=370021rank=203500 of ranks=370021rank=203600 of ranks=370021rank=203700 of ranks=370021rank=203800 of ranks=370021rank=203900 of ranks=370021rank=204000 of ranks=370021rank=204100 of ranks=370021rank=204200 of ranks=370021rank=204300 of ranks=370021rank=204400 of ranks=370021rank=204500 of ranks=370021rank=204600 of ranks=370021rank=204700 of ranks=370021rank=204800 of ranks=370021rank=204900 of ranks=370021rank=205000 of ranks=370021rank=205100 of ranks=370021rank=205200 of ranks=370021rank=205300 of ranks=370021rank=205400 of ranks=370021rank=205500 of ranks=370021rank=205600 of ranks=370021rank=205700 of ranks=370021rank=205800 of ranks=370021rank=205900 of ranks=370021rank=206000 of ranks=370021rank=206100 of ranks=370021rank=206200 of ranks=370021rank=206300 of ranks=370021rank=206400 of ranks=370021rank=206500 of ranks=370021rank=206600 of ranks=370021rank=206700 of ranks=370021rank=206800 of ranks=370021rank=206900 of ranks=370021rank=207000 of ranks=370021rank=207100 of ranks=370021rank=207200 of ranks=370021rank=207300 of ranks=370021rank=207400 of ranks=370021rank=207500 of ranks=370021rank=207600 of ranks=370021rank=207700 of ranks=370021rank=207800 of ranks=370021rank=207900 of ranks=370021rank=208000 of ranks=370021rank=208100 of ranks=370021rank=208200 of ranks=370021rank=208300 of ranks=370021rank=208400 of ranks=370021rank=208500 of ranks=370021rank=208600 of ranks=370021rank=208700 of ranks=370021rank=208800 of ranks=370021rank=208900 of ranks=370021rank=209000 of ranks=370021rank=209100 of ranks=370021rank=209200 of ranks=370021rank=209300 of ranks=370021rank=209400 of ranks=370021rank=209500 of ranks=370021rank=209600 of ranks=370021rank=209700 of ranks=370021rank=209800 of ranks=370021rank=209900 of ranks=370021rank=210000 of ranks=370021rank=210100 of ranks=370021rank=210200 of ranks=370021rank=210300 of ranks=370021rank=210400 of ranks=370021rank=210500 of ranks=370021rank=210600 of ranks=370021rank=210700 of ranks=370021rank=210800 of ranks=370021rank=210900 of ranks=370021rank=211000 of ranks=370021rank=211100 of ranks=370021rank=211200 of ranks=370021rank=211300 of ranks=370021rank=211400 of ranks=370021rank=211500 of ranks=370021rank=211600 of ranks=370021rank=211700 of ranks=370021rank=211800 of ranks=370021rank=211900 of ranks=370021rank=212000 of ranks=370021rank=212100 of ranks=370021rank=212200 of ranks=370021rank=212300 of ranks=370021rank=212400 of ranks=370021rank=212500 of ranks=370021rank=212600 of ranks=370021rank=212700 of ranks=370021rank=212800 of ranks=370021rank=212900 of ranks=370021rank=213000 of ranks=370021rank=213100 of ranks=370021rank=213200 of ranks=370021rank=213300 of ranks=370021rank=213400 of ranks=370021rank=213500 of ranks=370021rank=213600 of ranks=370021rank=213700 of ranks=370021rank=213800 of ranks=370021rank=213900 of ranks=370021rank=214000 of ranks=370021rank=214100 of ranks=370021rank=214200 of ranks=370021rank=214300 of ranks=370021rank=214400 of ranks=370021rank=214500 of ranks=370021rank=214600 of ranks=370021rank=214700 of ranks=370021rank=214800 of ranks=370021rank=214900 of ranks=370021rank=215000 of ranks=370021rank=215100 of ranks=370021rank=215200 of ranks=370021rank=215300 of ranks=370021rank=215400 of ranks=370021rank=215500 of ranks=370021rank=215600 of ranks=370021rank=215700 of ranks=370021rank=215800 of ranks=370021rank=215900 of ranks=370021rank=216000 of ranks=370021rank=216100 of ranks=370021rank=216200 of ranks=370021rank=216300 of ranks=370021rank=216400 of ranks=370021rank=216500 of ranks=370021rank=216600 of ranks=370021rank=216700 of ranks=370021rank=216800 of ranks=370021rank=216900 of ranks=370021rank=217000 of ranks=370021rank=217100 of ranks=370021rank=217200 of ranks=370021rank=217300 of ranks=370021rank=217400 of ranks=370021rank=217500 of ranks=370021rank=217600 of ranks=370021rank=217700 of ranks=370021rank=217800 of ranks=370021rank=217900 of ranks=370021rank=218000 of ranks=370021rank=218100 of ranks=370021rank=218200 of ranks=370021rank=218300 of ranks=370021rank=218400 of ranks=370021rank=218500 of ranks=370021rank=218600 of ranks=370021rank=218700 of ranks=370021rank=218800 of ranks=370021rank=218900 of ranks=370021rank=219000 of ranks=370021rank=219100 of ranks=370021rank=219200 of ranks=370021rank=219300 of ranks=370021rank=219400 of ranks=370021rank=219500 of ranks=370021rank=219600 of ranks=370021rank=219700 of ranks=370021rank=219800 of ranks=370021rank=219900 of ranks=370021rank=220000 of ranks=370021rank=220100 of ranks=370021rank=220200 of ranks=370021rank=220300 of ranks=370021rank=220400 of ranks=370021rank=220500 of ranks=370021rank=220600 of ranks=370021rank=220700 of ranks=370021rank=220800 of ranks=370021rank=220900 of ranks=370021rank=221000 of ranks=370021rank=221100 of ranks=370021rank=221200 of ranks=370021rank=221300 of ranks=370021rank=221400 of ranks=370021rank=221500 of ranks=370021rank=221600 of ranks=370021rank=221700 of ranks=370021rank=221800 of ranks=370021rank=221900 of ranks=370021rank=222000 of ranks=370021rank=222100 of ranks=370021rank=222200 of ranks=370021rank=222300 of ranks=370021rank=222400 of ranks=370021rank=222500 of ranks=370021rank=222600 of ranks=370021rank=222700 of ranks=370021rank=222800 of ranks=370021rank=222900 of ranks=370021rank=223000 of ranks=370021rank=223100 of ranks=370021rank=223200 of ranks=370021rank=223300 of ranks=370021rank=223400 of ranks=370021rank=223500 of ranks=370021rank=223600 of ranks=370021rank=223700 of ranks=370021rank=223800 of ranks=370021rank=223900 of ranks=370021rank=224000 of ranks=370021rank=224100 of ranks=370021rank=224200 of ranks=370021rank=224300 of ranks=370021rank=224400 of ranks=370021rank=224500 of ranks=370021rank=224600 of ranks=370021rank=224700 of ranks=370021rank=224800 of ranks=370021rank=224900 of ranks=370021rank=225000 of ranks=370021rank=225100 of ranks=370021rank=225200 of ranks=370021rank=225300 of ranks=370021rank=225400 of ranks=370021rank=225500 of ranks=370021rank=225600 of ranks=370021rank=225700 of ranks=370021rank=225800 of ranks=370021rank=225900 of ranks=370021rank=226000 of ranks=370021rank=226100 of ranks=370021rank=226200 of ranks=370021rank=226300 of ranks=370021rank=226400 of ranks=370021rank=226500 of ranks=370021rank=226600 of ranks=370021rank=226700 of ranks=370021rank=226800 of ranks=370021rank=226900 of ranks=370021rank=227000 of ranks=370021rank=227100 of ranks=370021rank=227200 of ranks=370021rank=227300 of ranks=370021rank=227400 of ranks=370021rank=227500 of ranks=370021rank=227600 of ranks=370021rank=227700 of ranks=370021rank=227800 of ranks=370021rank=227900 of ranks=370021rank=228000 of ranks=370021rank=228100 of ranks=370021rank=228200 of ranks=370021rank=228300 of ranks=370021rank=228400 of ranks=370021rank=228500 of ranks=370021rank=228600 of ranks=370021rank=228700 of ranks=370021rank=228800 of ranks=370021rank=228900 of ranks=370021rank=229000 of ranks=370021rank=229100 of ranks=370021rank=229200 of ranks=370021rank=229300 of ranks=370021rank=229400 of ranks=370021rank=229500 of ranks=370021rank=229600 of ranks=370021rank=229700 of ranks=370021rank=229800 of ranks=370021rank=229900 of ranks=370021rank=230000 of ranks=370021rank=230100 of ranks=370021rank=230200 of ranks=370021rank=230300 of ranks=370021rank=230400 of ranks=370021rank=230500 of ranks=370021rank=230600 of ranks=370021rank=230700 of ranks=370021rank=230800 of ranks=370021rank=230900 of ranks=370021rank=231000 of ranks=370021rank=231100 of ranks=370021rank=231200 of ranks=370021rank=231300 of ranks=370021rank=231400 of ranks=370021rank=231500 of ranks=370021rank=231600 of ranks=370021rank=231700 of ranks=370021rank=231800 of ranks=370021rank=231900 of ranks=370021rank=232000 of ranks=370021rank=232100 of ranks=370021rank=232200 of ranks=370021rank=232300 of ranks=370021rank=232400 of ranks=370021rank=232500 of ranks=370021rank=232600 of ranks=370021rank=232700 of ranks=370021rank=232800 of ranks=370021rank=232900 of ranks=370021rank=233000 of ranks=370021rank=233100 of ranks=370021rank=233200 of ranks=370021rank=233300 of ranks=370021rank=233400 of ranks=370021rank=233500 of ranks=370021rank=233600 of ranks=370021rank=233700 of ranks=370021rank=233800 of ranks=370021rank=233900 of ranks=370021rank=234000 of ranks=370021rank=234100 of ranks=370021rank=234200 of ranks=370021rank=234300 of ranks=370021rank=234400 of ranks=370021rank=234500 of ranks=370021rank=234600 of ranks=370021rank=234700 of ranks=370021rank=234800 of ranks=370021rank=234900 of ranks=370021rank=235000 of ranks=370021rank=235100 of ranks=370021rank=235200 of ranks=370021rank=235300 of ranks=370021rank=235400 of ranks=370021rank=235500 of ranks=370021rank=235600 of ranks=370021rank=235700 of ranks=370021rank=235800 of ranks=370021rank=235900 of ranks=370021rank=236000 of ranks=370021rank=236100 of ranks=370021rank=236200 of ranks=370021rank=236300 of ranks=370021rank=236400 of ranks=370021rank=236500 of ranks=370021rank=236600 of ranks=370021rank=236700 of ranks=370021rank=236800 of ranks=370021rank=236900 of ranks=370021rank=237000 of ranks=370021rank=237100 of ranks=370021rank=237200 of ranks=370021rank=237300 of ranks=370021rank=237400 of ranks=370021rank=237500 of ranks=370021rank=237600 of ranks=370021rank=237700 of ranks=370021rank=237800 of ranks=370021rank=237900 of ranks=370021rank=238000 of ranks=370021rank=238100 of ranks=370021rank=238200 of ranks=370021rank=238300 of ranks=370021rank=238400 of ranks=370021rank=238500 of ranks=370021rank=238600 of ranks=370021rank=238700 of ranks=370021rank=238800 of ranks=370021rank=238900 of ranks=370021rank=239000 of ranks=370021rank=239100 of ranks=370021rank=239200 of ranks=370021rank=239300 of ranks=370021rank=239400 of ranks=370021rank=239500 of ranks=370021rank=239600 of ranks=370021rank=239700 of ranks=370021rank=239800 of ranks=370021rank=239900 of ranks=370021rank=240000 of ranks=370021rank=240100 of ranks=370021rank=240200 of ranks=370021rank=240300 of ranks=370021rank=240400 of ranks=370021rank=240500 of ranks=370021rank=240600 of ranks=370021rank=240700 of ranks=370021rank=240800 of ranks=370021rank=240900 of ranks=370021rank=241000 of ranks=370021rank=241100 of ranks=370021rank=241200 of ranks=370021rank=241300 of ranks=370021rank=241400 of ranks=370021rank=241500 of ranks=370021rank=241600 of ranks=370021rank=241700 of ranks=370021rank=241800 of ranks=370021rank=241900 of ranks=370021rank=242000 of ranks=370021rank=242100 of ranks=370021rank=242200 of ranks=370021rank=242300 of ranks=370021rank=242400 of ranks=370021rank=242500 of ranks=370021rank=242600 of ranks=370021rank=242700 of ranks=370021rank=242800 of ranks=370021rank=242900 of ranks=370021rank=243000 of ranks=370021rank=243100 of ranks=370021rank=243200 of ranks=370021rank=243300 of ranks=370021rank=243400 of ranks=370021rank=243500 of ranks=370021rank=243600 of ranks=370021rank=243700 of ranks=370021rank=243800 of ranks=370021rank=243900 of ranks=370021rank=244000 of ranks=370021rank=244100 of ranks=370021rank=244200 of ranks=370021rank=244300 of ranks=370021rank=244400 of ranks=370021rank=244500 of ranks=370021rank=244600 of ranks=370021rank=244700 of ranks=370021rank=244800 of ranks=370021rank=244900 of ranks=370021rank=245000 of ranks=370021rank=245100 of ranks=370021rank=245200 of ranks=370021rank=245300 of ranks=370021rank=245400 of ranks=370021rank=245500 of ranks=370021rank=245600 of ranks=370021rank=245700 of ranks=370021rank=245800 of ranks=370021rank=245900 of ranks=370021rank=246000 of ranks=370021rank=246100 of ranks=370021rank=246200 of ranks=370021rank=246300 of ranks=370021rank=246400 of ranks=370021rank=246500 of ranks=370021rank=246600 of ranks=370021rank=246700 of ranks=370021rank=246800 of ranks=370021rank=246900 of ranks=370021rank=247000 of ranks=370021rank=247100 of ranks=370021rank=247200 of ranks=370021rank=247300 of ranks=370021rank=247400 of ranks=370021rank=247500 of ranks=370021rank=247600 of ranks=370021rank=247700 of ranks=370021rank=247800 of ranks=370021rank=247900 of ranks=370021rank=248000 of ranks=370021rank=248100 of ranks=370021rank=248200 of ranks=370021rank=248300 of ranks=370021rank=248400 of ranks=370021rank=248500 of ranks=370021rank=248600 of ranks=370021rank=248700 of ranks=370021rank=248800 of ranks=370021rank=248900 of ranks=370021rank=249000 of ranks=370021rank=249100 of ranks=370021rank=249200 of ranks=370021rank=249300 of ranks=370021rank=249400 of ranks=370021rank=249500 of ranks=370021rank=249600 of ranks=370021rank=249700 of ranks=370021rank=249800 of ranks=370021rank=249900 of ranks=370021rank=250000 of ranks=370021rank=250100 of ranks=370021rank=250200 of ranks=370021rank=250300 of ranks=370021rank=250400 of ranks=370021rank=250500 of ranks=370021rank=250600 of ranks=370021rank=250700 of ranks=370021rank=250800 of ranks=370021rank=250900 of ranks=370021rank=251000 of ranks=370021rank=251100 of ranks=370021rank=251200 of ranks=370021rank=251300 of ranks=370021rank=251400 of ranks=370021rank=251500 of ranks=370021rank=251600 of ranks=370021rank=251700 of ranks=370021rank=251800 of ranks=370021rank=251900 of ranks=370021rank=252000 of ranks=370021rank=252100 of ranks=370021rank=252200 of ranks=370021rank=252300 of ranks=370021rank=252400 of ranks=370021rank=252500 of ranks=370021rank=252600 of ranks=370021rank=252700 of ranks=370021rank=252800 of ranks=370021rank=252900 of ranks=370021rank=253000 of ranks=370021rank=253100 of ranks=370021rank=253200 of ranks=370021rank=253300 of ranks=370021rank=253400 of ranks=370021rank=253500 of ranks=370021rank=253600 of ranks=370021rank=253700 of ranks=370021rank=253800 of ranks=370021rank=253900 of ranks=370021rank=254000 of ranks=370021rank=254100 of ranks=370021rank=254200 of ranks=370021rank=254300 of ranks=370021rank=254400 of ranks=370021rank=254500 of ranks=370021rank=254600 of ranks=370021rank=254700 of ranks=370021rank=254800 of ranks=370021rank=254900 of ranks=370021rank=255000 of ranks=370021rank=255100 of ranks=370021rank=255200 of ranks=370021rank=255300 of ranks=370021rank=255400 of ranks=370021rank=255500 of ranks=370021rank=255600 of ranks=370021rank=255700 of ranks=370021rank=255800 of ranks=370021rank=255900 of ranks=370021rank=256000 of ranks=370021rank=256100 of ranks=370021rank=256200 of ranks=370021rank=256300 of ranks=370021rank=256400 of ranks=370021rank=256500 of ranks=370021rank=256600 of ranks=370021rank=256700 of ranks=370021rank=256800 of ranks=370021rank=256900 of ranks=370021rank=257000 of ranks=370021rank=257100 of ranks=370021rank=257200 of ranks=370021rank=257300 of ranks=370021rank=257400 of ranks=370021rank=257500 of ranks=370021rank=257600 of ranks=370021rank=257700 of ranks=370021rank=257800 of ranks=370021rank=257900 of ranks=370021rank=258000 of ranks=370021rank=258100 of ranks=370021rank=258200 of ranks=370021rank=258300 of ranks=370021rank=258400 of ranks=370021rank=258500 of ranks=370021rank=258600 of ranks=370021rank=258700 of ranks=370021rank=258800 of ranks=370021rank=258900 of ranks=370021rank=259000 of ranks=370021rank=259100 of ranks=370021rank=259200 of ranks=370021rank=259300 of ranks=370021rank=259400 of ranks=370021rank=259500 of ranks=370021rank=259600 of ranks=370021rank=259700 of ranks=370021rank=259800 of ranks=370021rank=259900 of ranks=370021rank=260000 of ranks=370021rank=260100 of ranks=370021rank=260200 of ranks=370021rank=260300 of ranks=370021rank=260400 of ranks=370021rank=260500 of ranks=370021rank=260600 of ranks=370021rank=260700 of ranks=370021rank=260800 of ranks=370021rank=260900 of ranks=370021rank=261000 of ranks=370021rank=261100 of ranks=370021rank=261200 of ranks=370021rank=261300 of ranks=370021rank=261400 of ranks=370021rank=261500 of ranks=370021rank=261600 of ranks=370021rank=261700 of ranks=370021rank=261800 of ranks=370021rank=261900 of ranks=370021rank=262000 of ranks=370021rank=262100 of ranks=370021rank=262200 of ranks=370021rank=262300 of ranks=370021rank=262400 of ranks=370021rank=262500 of ranks=370021rank=262600 of ranks=370021rank=262700 of ranks=370021rank=262800 of ranks=370021rank=262900 of ranks=370021rank=263000 of ranks=370021rank=263100 of ranks=370021rank=263200 of ranks=370021rank=263300 of ranks=370021rank=263400 of ranks=370021rank=263500 of ranks=370021rank=263600 of ranks=370021rank=263700 of ranks=370021rank=263800 of ranks=370021rank=263900 of ranks=370021rank=264000 of ranks=370021rank=264100 of ranks=370021rank=264200 of ranks=370021rank=264300 of ranks=370021rank=264400 of ranks=370021rank=264500 of ranks=370021rank=264600 of ranks=370021rank=264700 of ranks=370021rank=264800 of ranks=370021rank=264900 of ranks=370021rank=265000 of ranks=370021rank=265100 of ranks=370021rank=265200 of ranks=370021rank=265300 of ranks=370021rank=265400 of ranks=370021rank=265500 of ranks=370021rank=265600 of ranks=370021rank=265700 of ranks=370021rank=265800 of ranks=370021rank=265900 of ranks=370021rank=266000 of ranks=370021rank=266100 of ranks=370021rank=266200 of ranks=370021rank=266300 of ranks=370021rank=266400 of ranks=370021rank=266500 of ranks=370021rank=266600 of ranks=370021rank=266700 of ranks=370021rank=266800 of ranks=370021rank=266900 of ranks=370021rank=267000 of ranks=370021rank=267100 of ranks=370021rank=267200 of ranks=370021rank=267300 of ranks=370021rank=267400 of ranks=370021rank=267500 of ranks=370021rank=267600 of ranks=370021rank=267700 of ranks=370021rank=267800 of ranks=370021rank=267900 of ranks=370021rank=268000 of ranks=370021rank=268100 of ranks=370021rank=268200 of ranks=370021rank=268300 of ranks=370021rank=268400 of ranks=370021rank=268500 of ranks=370021rank=268600 of ranks=370021rank=268700 of ranks=370021rank=268800 of ranks=370021rank=268900 of ranks=370021rank=269000 of ranks=370021rank=269100 of ranks=370021rank=269200 of ranks=370021rank=269300 of ranks=370021rank=269400 of ranks=370021rank=269500 of ranks=370021rank=269600 of ranks=370021rank=269700 of ranks=370021rank=269800 of ranks=370021rank=269900 of ranks=370021rank=270000 of ranks=370021rank=270100 of ranks=370021rank=270200 of ranks=370021rank=270300 of ranks=370021rank=270400 of ranks=370021rank=270500 of ranks=370021rank=270600 of ranks=370021rank=270700 of ranks=370021rank=270800 of ranks=370021rank=270900 of ranks=370021rank=271000 of ranks=370021rank=271100 of ranks=370021rank=271200 of ranks=370021rank=271300 of ranks=370021rank=271400 of ranks=370021rank=271500 of ranks=370021rank=271600 of ranks=370021rank=271700 of ranks=370021rank=271800 of ranks=370021rank=271900 of ranks=370021rank=272000 of ranks=370021rank=272100 of ranks=370021rank=272200 of ranks=370021rank=272300 of ranks=370021rank=272400 of ranks=370021rank=272500 of ranks=370021rank=272600 of ranks=370021rank=272700 of ranks=370021rank=272800 of ranks=370021rank=272900 of ranks=370021rank=273000 of ranks=370021rank=273100 of ranks=370021rank=273200 of ranks=370021rank=273300 of ranks=370021rank=273400 of ranks=370021rank=273500 of ranks=370021rank=273600 of ranks=370021rank=273700 of ranks=370021rank=273800 of ranks=370021rank=273900 of ranks=370021rank=274000 of ranks=370021rank=274100 of ranks=370021rank=274200 of ranks=370021rank=274300 of ranks=370021rank=274400 of ranks=370021rank=274500 of ranks=370021rank=274600 of ranks=370021rank=274700 of ranks=370021rank=274800 of ranks=370021rank=274900 of ranks=370021rank=275000 of ranks=370021rank=275100 of ranks=370021rank=275200 of ranks=370021rank=275300 of ranks=370021rank=275400 of ranks=370021rank=275500 of ranks=370021rank=275600 of ranks=370021rank=275700 of ranks=370021rank=275800 of ranks=370021rank=275900 of ranks=370021rank=276000 of ranks=370021rank=276100 of ranks=370021rank=276200 of ranks=370021rank=276300 of ranks=370021rank=276400 of ranks=370021rank=276500 of ranks=370021rank=276600 of ranks=370021rank=276700 of ranks=370021rank=276800 of ranks=370021rank=276900 of ranks=370021rank=277000 of ranks=370021rank=277100 of ranks=370021rank=277200 of ranks=370021rank=277300 of ranks=370021rank=277400 of ranks=370021rank=277500 of ranks=370021rank=277600 of ranks=370021rank=277700 of ranks=370021rank=277800 of ranks=370021rank=277900 of ranks=370021rank=278000 of ranks=370021rank=278100 of ranks=370021rank=278200 of ranks=370021rank=278300 of ranks=370021rank=278400 of ranks=370021rank=278500 of ranks=370021rank=278600 of ranks=370021rank=278700 of ranks=370021rank=278800 of ranks=370021rank=278900 of ranks=370021rank=279000 of ranks=370021rank=279100 of ranks=370021rank=279200 of ranks=370021rank=279300 of ranks=370021rank=279400 of ranks=370021rank=279500 of ranks=370021rank=279600 of ranks=370021rank=279700 of ranks=370021rank=279800 of ranks=370021rank=279900 of ranks=370021rank=280000 of ranks=370021rank=280100 of ranks=370021rank=280200 of ranks=370021rank=280300 of ranks=370021rank=280400 of ranks=370021rank=280500 of ranks=370021rank=280600 of ranks=370021rank=280700 of ranks=370021rank=280800 of ranks=370021rank=280900 of ranks=370021rank=281000 of ranks=370021rank=281100 of ranks=370021rank=281200 of ranks=370021rank=281300 of ranks=370021rank=281400 of ranks=370021rank=281500 of ranks=370021rank=281600 of ranks=370021rank=281700 of ranks=370021rank=281800 of ranks=370021rank=281900 of ranks=370021rank=282000 of ranks=370021rank=282100 of ranks=370021rank=282200 of ranks=370021rank=282300 of ranks=370021rank=282400 of ranks=370021rank=282500 of ranks=370021rank=282600 of ranks=370021rank=282700 of ranks=370021rank=282800 of ranks=370021rank=282900 of ranks=370021rank=283000 of ranks=370021rank=283100 of ranks=370021rank=283200 of ranks=370021rank=283300 of ranks=370021rank=283400 of ranks=370021rank=283500 of ranks=370021rank=283600 of ranks=370021rank=283700 of ranks=370021rank=283800 of ranks=370021rank=283900 of ranks=370021rank=284000 of ranks=370021rank=284100 of ranks=370021rank=284200 of ranks=370021rank=284300 of ranks=370021rank=284400 of ranks=370021rank=284500 of ranks=370021rank=284600 of ranks=370021rank=284700 of ranks=370021rank=284800 of ranks=370021rank=284900 of ranks=370021rank=285000 of ranks=370021rank=285100 of ranks=370021rank=285200 of ranks=370021rank=285300 of ranks=370021rank=285400 of ranks=370021rank=285500 of ranks=370021rank=285600 of ranks=370021rank=285700 of ranks=370021rank=285800 of ranks=370021rank=285900 of ranks=370021rank=286000 of ranks=370021rank=286100 of ranks=370021rank=286200 of ranks=370021rank=286300 of ranks=370021rank=286400 of ranks=370021rank=286500 of ranks=370021rank=286600 of ranks=370021rank=286700 of ranks=370021rank=286800 of ranks=370021rank=286900 of ranks=370021rank=287000 of ranks=370021rank=287100 of ranks=370021rank=287200 of ranks=370021rank=287300 of ranks=370021rank=287400 of ranks=370021rank=287500 of ranks=370021rank=287600 of ranks=370021rank=287700 of ranks=370021rank=287800 of ranks=370021rank=287900 of ranks=370021rank=288000 of ranks=370021rank=288100 of ranks=370021rank=288200 of ranks=370021rank=288300 of ranks=370021rank=288400 of ranks=370021rank=288500 of ranks=370021rank=288600 of ranks=370021rank=288700 of ranks=370021rank=288800 of ranks=370021rank=288900 of ranks=370021rank=289000 of ranks=370021rank=289100 of ranks=370021rank=289200 of ranks=370021rank=289300 of ranks=370021rank=289400 of ranks=370021rank=289500 of ranks=370021rank=289600 of ranks=370021rank=289700 of ranks=370021rank=289800 of ranks=370021rank=289900 of ranks=370021rank=290000 of ranks=370021rank=290100 of ranks=370021rank=290200 of ranks=370021rank=290300 of ranks=370021rank=290400 of ranks=370021rank=290500 of ranks=370021rank=290600 of ranks=370021rank=290700 of ranks=370021rank=290800 of ranks=370021rank=290900 of ranks=370021rank=291000 of ranks=370021rank=291100 of ranks=370021rank=291200 of ranks=370021rank=291300 of ranks=370021rank=291400 of ranks=370021rank=291500 of ranks=370021rank=291600 of ranks=370021rank=291700 of ranks=370021rank=291800 of ranks=370021rank=291900 of ranks=370021rank=292000 of ranks=370021rank=292100 of ranks=370021rank=292200 of ranks=370021rank=292300 of ranks=370021rank=292400 of ranks=370021rank=292500 of ranks=370021rank=292600 of ranks=370021rank=292700 of ranks=370021rank=292800 of ranks=370021rank=292900 of ranks=370021rank=293000 of ranks=370021rank=293100 of ranks=370021rank=293200 of ranks=370021rank=293300 of ranks=370021rank=293400 of ranks=370021rank=293500 of ranks=370021rank=293600 of ranks=370021rank=293700 of ranks=370021rank=293800 of ranks=370021rank=293900 of ranks=370021rank=294000 of ranks=370021rank=294100 of ranks=370021rank=294200 of ranks=370021rank=294300 of ranks=370021rank=294400 of ranks=370021rank=294500 of ranks=370021rank=294600 of ranks=370021rank=294700 of ranks=370021rank=294800 of ranks=370021rank=294900 of ranks=370021rank=295000 of ranks=370021rank=295100 of ranks=370021rank=295200 of ranks=370021rank=295300 of ranks=370021rank=295400 of ranks=370021rank=295500 of ranks=370021rank=295600 of ranks=370021rank=295700 of ranks=370021rank=295800 of ranks=370021rank=295900 of ranks=370021rank=296000 of ranks=370021rank=296100 of ranks=370021rank=296200 of ranks=370021rank=296300 of ranks=370021rank=296400 of ranks=370021rank=296500 of ranks=370021rank=296600 of ranks=370021rank=296700 of ranks=370021rank=296800 of ranks=370021rank=296900 of ranks=370021rank=297000 of ranks=370021rank=297100 of ranks=370021rank=297200 of ranks=370021rank=297300 of ranks=370021rank=297400 of ranks=370021rank=297500 of ranks=370021rank=297600 of ranks=370021rank=297700 of ranks=370021rank=297800 of ranks=370021rank=297900 of ranks=370021rank=298000 of ranks=370021rank=298100 of ranks=370021rank=298200 of ranks=370021rank=298300 of ranks=370021rank=298400 of ranks=370021rank=298500 of ranks=370021rank=298600 of ranks=370021rank=298700 of ranks=370021rank=298800 of ranks=370021rank=298900 of ranks=370021rank=299000 of ranks=370021rank=299100 of ranks=370021rank=299200 of ranks=370021rank=299300 of ranks=370021rank=299400 of ranks=370021rank=299500 of ranks=370021rank=299600 of ranks=370021rank=299700 of ranks=370021rank=299800 of ranks=370021rank=299900 of ranks=370021rank=300000 of ranks=370021rank=300100 of ranks=370021rank=300200 of ranks=370021rank=300300 of ranks=370021rank=300400 of ranks=370021rank=300500 of ranks=370021rank=300600 of ranks=370021rank=300700 of ranks=370021rank=300800 of ranks=370021rank=300900 of ranks=370021rank=301000 of ranks=370021rank=301100 of ranks=370021rank=301200 of ranks=370021rank=301300 of ranks=370021rank=301400 of ranks=370021rank=301500 of ranks=370021rank=301600 of ranks=370021rank=301700 of ranks=370021rank=301800 of ranks=370021rank=301900 of ranks=370021rank=302000 of ranks=370021rank=302100 of ranks=370021rank=302200 of ranks=370021rank=302300 of ranks=370021rank=302400 of ranks=370021rank=302500 of ranks=370021rank=302600 of ranks=370021rank=302700 of ranks=370021rank=302800 of ranks=370021rank=302900 of ranks=370021rank=303000 of ranks=370021rank=303100 of ranks=370021rank=303200 of ranks=370021rank=303300 of ranks=370021rank=303400 of ranks=370021rank=303500 of ranks=370021rank=303600 of ranks=370021rank=303700 of ranks=370021rank=303800 of ranks=370021rank=303900 of ranks=370021rank=304000 of ranks=370021rank=304100 of ranks=370021rank=304200 of ranks=370021rank=304300 of ranks=370021rank=304400 of ranks=370021rank=304500 of ranks=370021rank=304600 of ranks=370021rank=304700 of ranks=370021rank=304800 of ranks=370021rank=304900 of ranks=370021rank=305000 of ranks=370021rank=305100 of ranks=370021rank=305200 of ranks=370021rank=305300 of ranks=370021rank=305400 of ranks=370021rank=305500 of ranks=370021rank=305600 of ranks=370021rank=305700 of ranks=370021rank=305800 of ranks=370021rank=305900 of ranks=370021rank=306000 of ranks=370021rank=306100 of ranks=370021rank=306200 of ranks=370021rank=306300 of ranks=370021rank=306400 of ranks=370021rank=306500 of ranks=370021rank=306600 of ranks=370021rank=306700 of ranks=370021rank=306800 of ranks=370021rank=306900 of ranks=370021rank=307000 of ranks=370021rank=307100 of ranks=370021rank=307200 of ranks=370021rank=307300 of ranks=370021rank=307400 of ranks=370021rank=307500 of ranks=370021rank=307600 of ranks=370021rank=307700 of ranks=370021rank=307800 of ranks=370021rank=307900 of ranks=370021rank=308000 of ranks=370021rank=308100 of ranks=370021rank=308200 of ranks=370021rank=308300 of ranks=370021rank=308400 of ranks=370021rank=308500 of ranks=370021rank=308600 of ranks=370021rank=308700 of ranks=370021rank=308800 of ranks=370021rank=308900 of ranks=370021rank=309000 of ranks=370021rank=309100 of ranks=370021rank=309200 of ranks=370021rank=309300 of ranks=370021rank=309400 of ranks=370021rank=309500 of ranks=370021rank=309600 of ranks=370021rank=309700 of ranks=370021rank=309800 of ranks=370021rank=309900 of ranks=370021rank=310000 of ranks=370021rank=310100 of ranks=370021rank=310200 of ranks=370021rank=310300 of ranks=370021rank=310400 of ranks=370021rank=310500 of ranks=370021rank=310600 of ranks=370021rank=310700 of ranks=370021rank=310800 of ranks=370021rank=310900 of ranks=370021rank=311000 of ranks=370021rank=311100 of ranks=370021rank=311200 of ranks=370021rank=311300 of ranks=370021rank=311400 of ranks=370021rank=311500 of ranks=370021rank=311600 of ranks=370021rank=311700 of ranks=370021rank=311800 of ranks=370021rank=311900 of ranks=370021rank=312000 of ranks=370021rank=312100 of ranks=370021rank=312200 of ranks=370021rank=312300 of ranks=370021rank=312400 of ranks=370021rank=312500 of ranks=370021rank=312600 of ranks=370021rank=312700 of ranks=370021rank=312800 of ranks=370021rank=312900 of ranks=370021rank=313000 of ranks=370021rank=313100 of ranks=370021rank=313200 of ranks=370021rank=313300 of ranks=370021rank=313400 of ranks=370021rank=313500 of ranks=370021rank=313600 of ranks=370021rank=313700 of ranks=370021rank=313800 of ranks=370021rank=313900 of ranks=370021rank=314000 of ranks=370021rank=314100 of ranks=370021rank=314200 of ranks=370021rank=314300 of ranks=370021rank=314400 of ranks=370021rank=314500 of ranks=370021rank=314600 of ranks=370021rank=314700 of ranks=370021rank=314800 of ranks=370021rank=314900 of ranks=370021rank=315000 of ranks=370021rank=315100 of ranks=370021rank=315200 of ranks=370021rank=315300 of ranks=370021rank=315400 of ranks=370021rank=315500 of ranks=370021rank=315600 of ranks=370021rank=315700 of ranks=370021rank=315800 of ranks=370021rank=315900 of ranks=370021rank=316000 of ranks=370021rank=316100 of ranks=370021rank=316200 of ranks=370021rank=316300 of ranks=370021rank=316400 of ranks=370021rank=316500 of ranks=370021rank=316600 of ranks=370021rank=316700 of ranks=370021rank=316800 of ranks=370021rank=316900 of ranks=370021rank=317000 of ranks=370021rank=317100 of ranks=370021rank=317200 of ranks=370021rank=317300 of ranks=370021rank=317400 of ranks=370021rank=317500 of ranks=370021rank=317600 of ranks=370021rank=317700 of ranks=370021rank=317800 of ranks=370021rank=317900 of ranks=370021rank=318000 of ranks=370021rank=318100 of ranks=370021rank=318200 of ranks=370021rank=318300 of ranks=370021rank=318400 of ranks=370021rank=318500 of ranks=370021rank=318600 of ranks=370021rank=318700 of ranks=370021rank=318800 of ranks=370021rank=318900 of ranks=370021rank=319000 of ranks=370021rank=319100 of ranks=370021rank=319200 of ranks=370021rank=319300 of ranks=370021rank=319400 of ranks=370021rank=319500 of ranks=370021rank=319600 of ranks=370021rank=319700 of ranks=370021rank=319800 of ranks=370021rank=319900 of ranks=370021rank=320000 of ranks=370021rank=320100 of ranks=370021rank=320200 of ranks=370021rank=320300 of ranks=370021rank=320400 of ranks=370021rank=320500 of ranks=370021rank=320600 of ranks=370021rank=320700 of ranks=370021rank=320800 of ranks=370021rank=320900 of ranks=370021rank=321000 of ranks=370021rank=321100 of ranks=370021rank=321200 of ranks=370021rank=321300 of ranks=370021rank=321400 of ranks=370021rank=321500 of ranks=370021rank=321600 of ranks=370021rank=321700 of ranks=370021rank=321800 of ranks=370021rank=321900 of ranks=370021rank=322000 of ranks=370021rank=322100 of ranks=370021rank=322200 of ranks=370021rank=322300 of ranks=370021rank=322400 of ranks=370021rank=322500 of ranks=370021rank=322600 of ranks=370021rank=322700 of ranks=370021rank=322800 of ranks=370021rank=322900 of ranks=370021rank=323000 of ranks=370021rank=323100 of ranks=370021rank=323200 of ranks=370021rank=323300 of ranks=370021rank=323400 of ranks=370021rank=323500 of ranks=370021rank=323600 of ranks=370021rank=323700 of ranks=370021rank=323800 of ranks=370021rank=323900 of ranks=370021rank=324000 of ranks=370021rank=324100 of ranks=370021rank=324200 of ranks=370021rank=324300 of ranks=370021rank=324400 of ranks=370021rank=324500 of ranks=370021rank=324600 of ranks=370021rank=324700 of ranks=370021rank=324800 of ranks=370021rank=324900 of ranks=370021rank=325000 of ranks=370021rank=325100 of ranks=370021rank=325200 of ranks=370021rank=325300 of ranks=370021rank=325400 of ranks=370021rank=325500 of ranks=370021rank=325600 of ranks=370021rank=325700 of ranks=370021rank=325800 of ranks=370021rank=325900 of ranks=370021rank=326000 of ranks=370021rank=326100 of ranks=370021rank=326200 of ranks=370021rank=326300 of ranks=370021rank=326400 of ranks=370021rank=326500 of ranks=370021rank=326600 of ranks=370021rank=326700 of ranks=370021rank=326800 of ranks=370021rank=326900 of ranks=370021rank=327000 of ranks=370021rank=327100 of ranks=370021rank=327200 of ranks=370021rank=327300 of ranks=370021rank=327400 of ranks=370021rank=327500 of ranks=370021rank=327600 of ranks=370021rank=327700 of ranks=370021rank=327800 of ranks=370021rank=327900 of ranks=370021rank=328000 of ranks=370021rank=328100 of ranks=370021rank=328200 of ranks=370021rank=328300 of ranks=370021rank=328400 of ranks=370021rank=328500 of ranks=370021rank=328600 of ranks=370021rank=328700 of ranks=370021rank=328800 of ranks=370021rank=328900 of ranks=370021rank=329000 of ranks=370021rank=329100 of ranks=370021rank=329200 of ranks=370021rank=329300 of ranks=370021rank=329400 of ranks=370021rank=329500 of ranks=370021rank=329600 of ranks=370021rank=329700 of ranks=370021rank=329800 of ranks=370021rank=329900 of ranks=370021rank=330000 of ranks=370021rank=330100 of ranks=370021rank=330200 of ranks=370021rank=330300 of ranks=370021rank=330400 of ranks=370021rank=330500 of ranks=370021rank=330600 of ranks=370021rank=330700 of ranks=370021rank=330800 of ranks=370021rank=330900 of ranks=370021rank=331000 of ranks=370021rank=331100 of ranks=370021rank=331200 of ranks=370021rank=331300 of ranks=370021rank=331400 of ranks=370021rank=331500 of ranks=370021rank=331600 of ranks=370021rank=331700 of ranks=370021rank=331800 of ranks=370021rank=331900 of ranks=370021rank=332000 of ranks=370021rank=332100 of ranks=370021rank=332200 of ranks=370021rank=332300 of ranks=370021rank=332400 of ranks=370021rank=332500 of ranks=370021rank=332600 of ranks=370021rank=332700 of ranks=370021rank=332800 of ranks=370021rank=332900 of ranks=370021rank=333000 of ranks=370021rank=333100 of ranks=370021rank=333200 of ranks=370021rank=333300 of ranks=370021rank=333400 of ranks=370021rank=333500 of ranks=370021rank=333600 of ranks=370021rank=333700 of ranks=370021rank=333800 of ranks=370021rank=333900 of ranks=370021rank=334000 of ranks=370021rank=334100 of ranks=370021rank=334200 of ranks=370021rank=334300 of ranks=370021rank=334400 of ranks=370021rank=334500 of ranks=370021rank=334600 of ranks=370021rank=334700 of ranks=370021rank=334800 of ranks=370021rank=334900 of ranks=370021rank=335000 of ranks=370021rank=335100 of ranks=370021rank=335200 of ranks=370021rank=335300 of ranks=370021rank=335400 of ranks=370021rank=335500 of ranks=370021rank=335600 of ranks=370021rank=335700 of ranks=370021rank=335800 of ranks=370021rank=335900 of ranks=370021rank=336000 of ranks=370021rank=336100 of ranks=370021rank=336200 of ranks=370021rank=336300 of ranks=370021rank=336400 of ranks=370021rank=336500 of ranks=370021rank=336600 of ranks=370021rank=336700 of ranks=370021rank=336800 of ranks=370021rank=336900 of ranks=370021rank=337000 of ranks=370021rank=337100 of ranks=370021rank=337200 of ranks=370021rank=337300 of ranks=370021rank=337400 of ranks=370021rank=337500 of ranks=370021rank=337600 of ranks=370021rank=337700 of ranks=370021rank=337800 of ranks=370021rank=337900 of ranks=370021rank=338000 of ranks=370021rank=338100 of ranks=370021rank=338200 of ranks=370021rank=338300 of ranks=370021rank=338400 of ranks=370021rank=338500 of ranks=370021rank=338600 of ranks=370021rank=338700 of ranks=370021rank=338800 of ranks=370021rank=338900 of ranks=370021rank=339000 of ranks=370021rank=339100 of ranks=370021rank=339200 of ranks=370021rank=339300 of ranks=370021rank=339400 of ranks=370021rank=339500 of ranks=370021rank=339600 of ranks=370021rank=339700 of ranks=370021rank=339800 of ranks=370021rank=339900 of ranks=370021rank=340000 of ranks=370021rank=340100 of ranks=370021rank=340200 of ranks=370021rank=340300 of ranks=370021rank=340400 of ranks=370021rank=340500 of ranks=370021rank=340600 of ranks=370021rank=340700 of ranks=370021rank=340800 of ranks=370021rank=340900 of ranks=370021rank=341000 of ranks=370021rank=341100 of ranks=370021rank=341200 of ranks=370021rank=341300 of ranks=370021rank=341400 of ranks=370021rank=341500 of ranks=370021rank=341600 of ranks=370021rank=341700 of ranks=370021rank=341800 of ranks=370021rank=341900 of ranks=370021rank=342000 of ranks=370021rank=342100 of ranks=370021rank=342200 of ranks=370021rank=342300 of ranks=370021rank=342400 of ranks=370021rank=342500 of ranks=370021rank=342600 of ranks=370021rank=342700 of ranks=370021rank=342800 of ranks=370021rank=342900 of ranks=370021rank=343000 of ranks=370021rank=343100 of ranks=370021rank=343200 of ranks=370021rank=343300 of ranks=370021rank=343400 of ranks=370021rank=343500 of ranks=370021rank=343600 of ranks=370021rank=343700 of ranks=370021rank=343800 of ranks=370021rank=343900 of ranks=370021rank=344000 of ranks=370021rank=344100 of ranks=370021rank=344200 of ranks=370021rank=344300 of ranks=370021rank=344400 of ranks=370021rank=344500 of ranks=370021rank=344600 of ranks=370021rank=344700 of ranks=370021rank=344800 of ranks=370021rank=344900 of ranks=370021rank=345000 of ranks=370021rank=345100 of ranks=370021rank=345200 of ranks=370021rank=345300 of ranks=370021rank=345400 of ranks=370021rank=345500 of ranks=370021rank=345600 of ranks=370021rank=345700 of ranks=370021rank=345800 of ranks=370021rank=345900 of ranks=370021rank=346000 of ranks=370021rank=346100 of ranks=370021rank=346200 of ranks=370021rank=346300 of ranks=370021rank=346400 of ranks=370021rank=346500 of ranks=370021rank=346600 of ranks=370021rank=346700 of ranks=370021rank=346800 of ranks=370021rank=346900 of ranks=370021rank=347000 of ranks=370021rank=347100 of ranks=370021rank=347200 of ranks=370021rank=347300 of ranks=370021rank=347400 of ranks=370021rank=347500 of ranks=370021rank=347600 of ranks=370021rank=347700 of ranks=370021rank=347800 of ranks=370021rank=347900 of ranks=370021rank=348000 of ranks=370021rank=348100 of ranks=370021rank=348200 of ranks=370021rank=348300 of ranks=370021rank=348400 of ranks=370021rank=348500 of ranks=370021rank=348600 of ranks=370021rank=348700 of ranks=370021rank=348800 of ranks=370021rank=348900 of ranks=370021rank=349000 of ranks=370021rank=349100 of ranks=370021rank=349200 of ranks=370021rank=349300 of ranks=370021rank=349400 of ranks=370021rank=349500 of ranks=370021rank=349600 of ranks=370021rank=349700 of ranks=370021rank=349800 of ranks=370021rank=349900 of ranks=370021rank=350000 of ranks=370021rank=350100 of ranks=370021rank=350200 of ranks=370021rank=350300 of ranks=370021rank=350400 of ranks=370021rank=350500 of ranks=370021rank=350600 of ranks=370021rank=350700 of ranks=370021rank=350800 of ranks=370021rank=350900 of ranks=370021rank=351000 of ranks=370021rank=351100 of ranks=370021rank=351200 of ranks=370021rank=351300 of ranks=370021rank=351400 of ranks=370021rank=351500 of ranks=370021rank=351600 of ranks=370021rank=351700 of ranks=370021rank=351800 of ranks=370021rank=351900 of ranks=370021rank=352000 of ranks=370021rank=352100 of ranks=370021rank=352200 of ranks=370021rank=352300 of ranks=370021rank=352400 of ranks=370021rank=352500 of ranks=370021rank=352600 of ranks=370021rank=352700 of ranks=370021rank=352800 of ranks=370021rank=352900 of ranks=370021rank=353000 of ranks=370021rank=353100 of ranks=370021rank=353200 of ranks=370021rank=353300 of ranks=370021rank=353400 of ranks=370021rank=353500 of ranks=370021rank=353600 of ranks=370021rank=353700 of ranks=370021rank=353800 of ranks=370021rank=353900 of ranks=370021rank=354000 of ranks=370021rank=354100 of ranks=370021rank=354200 of ranks=370021rank=354300 of ranks=370021rank=354400 of ranks=370021rank=354500 of ranks=370021rank=354600 of ranks=370021rank=354700 of ranks=370021rank=354800 of ranks=370021rank=354900 of ranks=370021rank=355000 of ranks=370021rank=355100 of ranks=370021rank=355200 of ranks=370021rank=355300 of ranks=370021rank=355400 of ranks=370021rank=355500 of ranks=370021rank=355600 of ranks=370021rank=355700 of ranks=370021rank=355800 of ranks=370021rank=355900 of ranks=370021rank=356000 of ranks=370021rank=356100 of ranks=370021rank=356200 of ranks=370021rank=356300 of ranks=370021rank=356400 of ranks=370021rank=356500 of ranks=370021rank=356600 of ranks=370021rank=356700 of ranks=370021rank=356800 of ranks=370021rank=356900 of ranks=370021rank=357000 of ranks=370021rank=357100 of ranks=370021rank=357200 of ranks=370021rank=357300 of ranks=370021rank=357400 of ranks=370021rank=357500 of ranks=370021rank=357600 of ranks=370021rank=357700 of ranks=370021rank=357800 of ranks=370021rank=357900 of ranks=370021rank=358000 of ranks=370021rank=358100 of ranks=370021rank=358200 of ranks=370021rank=358300 of ranks=370021rank=358400 of ranks=370021rank=358500 of ranks=370021rank=358600 of ranks=370021rank=358700 of ranks=370021rank=358800 of ranks=370021rank=358900 of ranks=370021rank=359000 of ranks=370021rank=359100 of ranks=370021rank=359200 of ranks=370021rank=359300 of ranks=370021rank=359400 of ranks=370021rank=359500 of ranks=370021rank=359600 of ranks=370021rank=359700 of ranks=370021rank=359800 of ranks=370021rank=359900 of ranks=370021rank=360000 of ranks=370021rank=360100 of ranks=370021rank=360200 of ranks=370021rank=360300 of ranks=370021rank=360400 of ranks=370021rank=360500 of ranks=370021rank=360600 of ranks=370021rank=360700 of ranks=370021rank=360800 of ranks=370021rank=360900 of ranks=370021rank=361000 of ranks=370021rank=361100 of ranks=370021rank=361200 of ranks=370021rank=361300 of ranks=370021rank=361400 of ranks=370021rank=361500 of ranks=370021rank=361600 of ranks=370021rank=361700 of ranks=370021rank=361800 of ranks=370021rank=361900 of ranks=370021rank=362000 of ranks=370021rank=362100 of ranks=370021rank=362200 of ranks=370021rank=362300 of ranks=370021rank=362400 of ranks=370021rank=362500 of ranks=370021rank=362600 of ranks=370021rank=362700 of ranks=370021rank=362800 of ranks=370021rank=362900 of ranks=370021rank=363000 of ranks=370021rank=363100 of ranks=370021rank=363200 of ranks=370021rank=363300 of ranks=370021rank=363400 of ranks=370021rank=363500 of ranks=370021rank=363600 of ranks=370021rank=363700 of ranks=370021rank=363800 of ranks=370021rank=363900 of ranks=370021rank=364000 of ranks=370021rank=364100 of ranks=370021rank=364200 of ranks=370021rank=364300 of ranks=370021rank=364400 of ranks=370021rank=364500 of ranks=370021rank=364600 of ranks=370021rank=364700 of ranks=370021rank=364800 of ranks=370021rank=364900 of ranks=370021rank=365000 of ranks=370021rank=365100 of ranks=370021rank=365200 of ranks=370021rank=365300 of ranks=370021rank=365400 of ranks=370021rank=365500 of ranks=370021rank=365600 of ranks=370021rank=365700 of ranks=370021rank=365800 of ranks=370021rank=365900 of ranks=370021rank=366000 of ranks=370021rank=366100 of ranks=370021rank=366200 of ranks=370021rank=366300 of ranks=370021rank=366400 of ranks=370021rank=366500 of ranks=370021rank=366600 of ranks=370021rank=366700 of ranks=370021rank=366800 of ranks=370021rank=366900 of ranks=370021rank=367000 of ranks=370021rank=367100 of ranks=370021rank=367200 of ranks=370021rank=367300 of ranks=370021rank=367400 of ranks=370021rank=367500 of ranks=370021rank=367600 of ranks=370021rank=367700 of ranks=370021rank=367800 of ranks=370021rank=367900 of ranks=370021rank=368000 of ranks=370021rank=368100 of ranks=370021rank=368200 of ranks=370021rank=368300 of ranks=370021rank=368400 of ranks=370021rank=368500 of ranks=370021rank=368600 of ranks=370021rank=368700 of ranks=370021rank=368800 of ranks=370021rank=368900 of ranks=370021rank=369000 of ranks=370021rank=369100 of ranks=370021rank=369200 of ranks=370021rank=369300 of ranks=370021rank=369400 of ranks=370021rank=369500 of ranks=370021rank=369600 of ranks=370021rank=369700 of ranks=370021rank=369800 of ranks=370021rank=369900 of ranks=370021rank=370000 of ranks=370021

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              58.3750    453  43366     45    498           55.1183
   1 car                    94.3149  49583 114022    733  50316           59.6473
   2 truck                  56.2636   1716  61127    109   1825           30.1058
   3 bus                    21.9465    332  23280     34    366           18.8717
   4 pedestrian             74.7145   3869  72273    390   4259           39.9879

for conf_thresh=0.25, precision=0.69, recall=0.88, F1 score=0.77
for conf_thresh=0.25, TP=50247, FP=22176, FN=7017, average IoU=57.12%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=61.12%
Total detection time: 194 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
New best mAP, saving weights!
Saving weights to /workspace/.cache/splits/combined_best.weights
1407: loss=7.092, avg loss=7.850, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 90048 images, time remaining=7.9 hours
1408: loss=7.433, avg loss=7.808, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 90112 images, time remaining=7.9 hours
1409: loss=8.329, avg loss=7.860, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=2.9 seconds, 90176 images, time remaining=7.9 hours
1410: loss=8.014, avg loss=7.876, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 90240 images, time remaining=7.9 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b606c00000
1411: loss=7.726, avg loss=7.861, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 90304 images, time remaining=7.9 hours
1412: loss=7.573, avg loss=7.832, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 90368 images, time remaining=7.9 hours
1413: loss=7.135, avg loss=7.762, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=2.2 seconds, 90432 images, time remaining=7.9 hours
1414: loss=7.777, avg loss=7.764, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 90496 images, time remaining=7.9 hours
1415: loss=6.781, avg loss=7.665, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 90560 images, time remaining=7.9 hours
1416: loss=7.299, avg loss=7.629, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=2.3 seconds, 90624 images, time remaining=7.9 hours
1417: loss=8.502, avg loss=7.716, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 90688 images, time remaining=7.9 hours
1418: loss=7.615, avg loss=7.706, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 90752 images, time remaining=7.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1419: loss=6.713, avg loss=7.607, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=3.2 seconds, train=2.2 seconds, 90816 images, time remaining=7.9 hours
1420: loss=7.305, avg loss=7.577, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 90880 images, time remaining=7.9 hours
Resizing, random_coef=1.40, batch=4, 896x672
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b4c6800000
1421: loss=7.996, avg loss=7.618, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 90944 images, time remaining=7.9 hours
1422: loss=6.576, avg loss=7.514, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=2.6 seconds, 91008 images, time remaining=7.9 hours
1423: loss=6.677, avg loss=7.431, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=2.6 seconds, 91072 images, time remaining=7.9 hours
1424: loss=6.615, avg loss=7.349, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=2.6 seconds, 91136 images, time remaining=7.9 hours
1425: loss=7.956, avg loss=7.410, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 91200 images, time remaining=7.9 hours
1426: loss=8.293, avg loss=7.498, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.5 seconds, 91264 images, time remaining=7.8 hours
1427: loss=6.443, avg loss=7.393, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 91328 images, time remaining=7.8 hours
1428: loss=7.860, avg loss=7.439, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=2.6 seconds, 91392 images, time remaining=7.8 hours
1429: loss=6.914, avg loss=7.387, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 91456 images, time remaining=7.8 hours
1430: loss=7.262, avg loss=7.374, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=2.4 seconds, 91520 images, time remaining=7.8 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14c196000000
1431: loss=6.433, avg loss=7.280, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=1.6 seconds, 91584 images, time remaining=7.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1432: loss=6.588, avg loss=7.211, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.3 seconds, train=1.8 seconds, 91648 images, time remaining=7.8 hours
1433: loss=7.016, avg loss=7.191, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=1.8 seconds, 91712 images, time remaining=7.8 hours
1434: loss=6.384, avg loss=7.111, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 91776 images, time remaining=7.8 hours
1435: loss=6.539, avg loss=7.053, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 91840 images, time remaining=7.8 hours
1436: loss=5.874, avg loss=6.936, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 91904 images, time remaining=7.8 hours
1437: loss=7.050, avg loss=6.947, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 91968 images, time remaining=7.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1438: loss=7.655, avg loss=7.018, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=1.9 seconds, 92032 images, time remaining=7.8 hours
1439: loss=6.684, avg loss=6.984, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 92096 images, time remaining=7.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1440: loss=7.031, avg loss=6.989, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=1.9 seconds, 92160 images, time remaining=7.8 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1441: loss=9.959, avg loss=7.286, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 92224 images, time remaining=7.8 hours
1442: loss=7.927, avg loss=7.350, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.2 seconds, train=4.1 seconds, 92288 images, time remaining=7.8 hours
1443: loss=9.084, avg loss=7.524, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=4.1 seconds, 92352 images, time remaining=7.8 hours
1444: loss=7.740, avg loss=7.545, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.2 seconds, 92416 images, time remaining=7.8 hours
1445: loss=8.965, avg loss=7.687, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 92480 images, time remaining=7.8 hours
1446: loss=7.592, avg loss=7.678, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.5 seconds, train=4.0 seconds, 92544 images, time remaining=7.8 hours
1447: loss=7.056, avg loss=7.616, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.2 seconds, train=4.0 seconds, 92608 images, time remaining=7.8 hours
1448: loss=8.619, avg loss=7.716, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=4.1 seconds, 92672 images, time remaining=7.8 hours
1449: loss=7.747, avg loss=7.719, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 92736 images, time remaining=7.8 hours
1450: loss=7.351, avg loss=7.682, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 92800 images, time remaining=7.8 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b4bb000000
1451: loss=7.748, avg loss=7.689, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 92864 images, time remaining=7.8 hours
1452: loss=7.268, avg loss=7.647, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=2.5 seconds, 92928 images, time remaining=7.8 hours
1453: loss=8.451, avg loss=7.727, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 92992 images, time remaining=7.8 hours
1454: loss=6.523, avg loss=7.607, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 93056 images, time remaining=7.8 hours
1455: loss=8.136, avg loss=7.660, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=2.7 seconds, 93120 images, time remaining=7.8 hours
1456: loss=7.634, avg loss=7.657, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 93184 images, time remaining=7.8 hours
1457: loss=7.763, avg loss=7.668, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 93248 images, time remaining=7.8 hours
1458: loss=7.002, avg loss=7.601, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=2.7 seconds, 93312 images, time remaining=7.8 hours
1459: loss=7.892, avg loss=7.630, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 93376 images, time remaining=7.8 hours
1460: loss=7.199, avg loss=7.587, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 93440 images, time remaining=7.8 hours
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1461: loss=8.319, avg loss=7.660, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 93504 images, time remaining=7.8 hours
1462: loss=7.070, avg loss=7.601, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 93568 images, time remaining=7.8 hours
1463: loss=7.120, avg loss=7.553, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 93632 images, time remaining=7.8 hours
1464: loss=7.359, avg loss=7.534, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.4 seconds, train=4.0 seconds, 93696 images, time remaining=7.8 hours
1465: loss=6.283, avg loss=7.409, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=4.0 seconds, 93760 images, time remaining=7.8 hours
1466: loss=7.765, avg loss=7.444, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 93824 images, time remaining=7.8 hours
1467: loss=7.769, avg loss=7.477, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 93888 images, time remaining=7.7 hours
1468: loss=7.628, avg loss=7.492, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 93952 images, time remaining=7.7 hours
1469: loss=7.545, avg loss=7.497, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 94016 images, time remaining=7.7 hours
1470: loss=7.160, avg loss=7.463, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=3.8 seconds, 94080 images, time remaining=7.7 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b698000000
1471: loss=6.603, avg loss=7.377, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 94144 images, time remaining=7.7 hours
1472: loss=8.278, avg loss=7.467, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 94208 images, time remaining=7.7 hours
1473: loss=7.357, avg loss=7.456, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 94272 images, time remaining=7.7 hours
1474: loss=6.855, avg loss=7.396, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 94336 images, time remaining=7.7 hours
1475: loss=7.240, avg loss=7.381, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 94400 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1476: loss=8.558, avg loss=7.498, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=1.8 seconds, 94464 images, time remaining=7.7 hours
1477: loss=9.179, avg loss=7.666, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 94528 images, time remaining=7.7 hours
1478: loss=7.183, avg loss=7.618, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 94592 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1479: loss=6.628, avg loss=7.519, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.3 seconds, train=1.9 seconds, 94656 images, time remaining=7.7 hours
1480: loss=7.115, avg loss=7.479, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 94720 images, time remaining=7.7 hours
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1481: loss=8.663, avg loss=7.597, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 94784 images, time remaining=7.7 hours
1482: loss=9.496, avg loss=7.787, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 94848 images, time remaining=7.7 hours
1483: loss=7.564, avg loss=7.765, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 94912 images, time remaining=7.7 hours
1484: loss=7.855, avg loss=7.774, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 94976 images, time remaining=7.7 hours
1485: loss=8.712, avg loss=7.868, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 95040 images, time remaining=7.7 hours
1486: loss=9.073, avg loss=7.988, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.1 seconds, 95104 images, time remaining=7.7 hours
1487: loss=7.517, avg loss=7.941, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 95168 images, time remaining=7.7 hours
1488: loss=6.828, avg loss=7.830, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 95232 images, time remaining=7.7 hours
1489: loss=7.882, avg loss=7.835, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 95296 images, time remaining=7.7 hours
1490: loss=7.807, avg loss=7.832, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 95360 images, time remaining=7.7 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b521400000
1491: loss=6.865, avg loss=7.736, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 95424 images, time remaining=7.7 hours
1492: loss=7.976, avg loss=7.760, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 95488 images, time remaining=7.7 hours
1493: loss=7.515, avg loss=7.735, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 95552 images, time remaining=7.7 hours
1494: loss=6.732, avg loss=7.635, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 95616 images, time remaining=7.7 hours
1495: loss=7.084, avg loss=7.580, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 95680 images, time remaining=7.7 hours
1496: loss=6.756, avg loss=7.497, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 95744 images, time remaining=7.7 hours
1497: loss=7.822, avg loss=7.530, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 95808 images, time remaining=7.7 hours
1498: loss=6.821, avg loss=7.459, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 95872 images, time remaining=7.7 hours
1499: loss=7.176, avg loss=7.431, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 95936 images, time remaining=7.7 hours
1500: loss=6.925, avg loss=7.380, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 96000 images, time remaining=7.7 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b511000000
1501: loss=8.265, avg loss=7.469, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=2.0 seconds, 96064 images, time remaining=7.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1502: loss=6.631, avg loss=7.385, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.4 seconds, train=2.1 seconds, 96128 images, time remaining=7.7 hours
1503: loss=6.669, avg loss=7.313, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 96192 images, time remaining=7.7 hours
1504: loss=7.638, avg loss=7.346, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=2.2 seconds, 96256 images, time remaining=7.6 hours
1505: loss=7.573, avg loss=7.368, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 96320 images, time remaining=7.6 hours
1506: loss=6.030, avg loss=7.235, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 96384 images, time remaining=7.6 hours
1507: loss=7.177, avg loss=7.229, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 96448 images, time remaining=7.6 hours
1508: loss=6.068, avg loss=7.113, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 96512 images, time remaining=7.6 hours
1509: loss=7.130, avg loss=7.114, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 96576 images, time remaining=7.6 hours
1510: loss=5.821, avg loss=6.985, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 96640 images, time remaining=7.6 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1511: loss=9.567, avg loss=7.243, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=4.3 seconds, 96704 images, time remaining=7.6 hours
1512: loss=8.795, avg loss=7.398, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 96768 images, time remaining=7.6 hours
1513: loss=6.644, avg loss=7.323, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.9 seconds, train=4.2 seconds, 96832 images, time remaining=7.6 hours
1514: loss=8.914, avg loss=7.482, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.6 seconds, train=4.4 seconds, 96896 images, time remaining=7.6 hours
1515: loss=8.491, avg loss=7.583, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 96960 images, time remaining=7.6 hours
1516: loss=7.316, avg loss=7.556, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=4.2 seconds, 97024 images, time remaining=7.6 hours
1517: loss=7.219, avg loss=7.523, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.9 seconds, train=4.2 seconds, 97088 images, time remaining=7.6 hours
1518: loss=8.162, avg loss=7.587, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.4 seconds, train=4.4 seconds, 97152 images, time remaining=7.6 hours
1519: loss=8.544, avg loss=7.682, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.5 seconds, train=4.2 seconds, 97216 images, time remaining=7.6 hours
1520: loss=7.325, avg loss=7.647, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.2 seconds, train=4.2 seconds, 97280 images, time remaining=7.6 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1521: loss=9.879, avg loss=7.870, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 97344 images, time remaining=7.6 hours
1522: loss=8.855, avg loss=7.968, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 97408 images, time remaining=7.6 hours
1523: loss=8.764, avg loss=8.048, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 97472 images, time remaining=7.6 hours
1524: loss=7.816, avg loss=8.025, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 97536 images, time remaining=7.6 hours
1525: loss=9.220, avg loss=8.144, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 97600 images, time remaining=7.6 hours
1526: loss=8.202, avg loss=8.150, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 97664 images, time remaining=7.6 hours
1527: loss=9.030, avg loss=8.238, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=5.6 seconds, 97728 images, time remaining=7.6 hours
1528: loss=9.215, avg loss=8.336, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 97792 images, time remaining=7.6 hours
1529: loss=7.160, avg loss=8.218, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 97856 images, time remaining=7.6 hours
1530: loss=8.266, avg loss=8.223, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=5.6 seconds, 97920 images, time remaining=7.6 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1531: loss=8.873, avg loss=8.288, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 97984 images, time remaining=7.6 hours
1532: loss=9.560, avg loss=8.415, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 98048 images, time remaining=7.6 hours
1533: loss=8.058, avg loss=8.379, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=5.7 seconds, 98112 images, time remaining=7.6 hours
1534: loss=8.375, avg loss=8.379, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.4 seconds, train=5.8 seconds, 98176 images, time remaining=7.6 hours
1535: loss=8.706, avg loss=8.412, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.2 seconds, train=5.8 seconds, 98240 images, time remaining=7.6 hours
1536: loss=6.864, avg loss=8.257, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 98304 images, time remaining=7.6 hours
1537: loss=9.073, avg loss=8.338, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 98368 images, time remaining=7.6 hours
1538: loss=7.905, avg loss=8.295, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=5.7 seconds, 98432 images, time remaining=7.6 hours
1539: loss=7.269, avg loss=8.192, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.5 seconds, train=5.8 seconds, 98496 images, time remaining=7.6 hours
1540: loss=9.113, avg loss=8.284, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=5.9 seconds, 98560 images, time remaining=7.6 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1541: loss=8.640, avg loss=8.320, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=4.7 seconds, 98624 images, time remaining=7.6 hours
1542: loss=8.447, avg loss=8.333, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.4 seconds, train=4.6 seconds, 98688 images, time remaining=7.6 hours
1543: loss=6.586, avg loss=8.158, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 98752 images, time remaining=7.6 hours
1544: loss=7.657, avg loss=8.108, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=3.6 seconds, train=4.7 seconds, 98816 images, time remaining=7.6 hours
1545: loss=7.621, avg loss=8.059, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 98880 images, time remaining=7.6 hours
1546: loss=6.747, avg loss=7.928, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=4.7 seconds, 98944 images, time remaining=7.6 hours
1547: loss=8.554, avg loss=7.991, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=4.7 seconds, 99008 images, time remaining=7.6 hours
1548: loss=7.254, avg loss=7.917, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=4.6 seconds, 99072 images, time remaining=7.6 hours
1549: loss=7.388, avg loss=7.864, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.2 seconds, train=4.7 seconds, 99136 images, time remaining=7.6 hours
1550: loss=7.896, avg loss=7.867, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.4 seconds, train=4.7 seconds, 99200 images, time remaining=7.6 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b6a0600000
1551: loss=11.136, avg loss=8.194, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 99264 images, time remaining=7.6 hours
1552: loss=8.007, avg loss=8.175, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 99328 images, time remaining=7.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1553: loss=7.136, avg loss=8.071, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.2 seconds, train=1.9 seconds, 99392 images, time remaining=7.6 hours
1554: loss=7.941, avg loss=8.058, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 99456 images, time remaining=7.6 hours
1555: loss=7.261, avg loss=7.979, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 99520 images, time remaining=7.6 hours
1556: loss=7.437, avg loss=7.925, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=1.8 seconds, 99584 images, time remaining=7.6 hours
1557: loss=7.884, avg loss=7.920, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=1.8 seconds, 99648 images, time remaining=7.6 hours
1558: loss=8.464, avg loss=7.975, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 99712 images, time remaining=7.6 hours
1559: loss=8.080, avg loss=7.985, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 99776 images, time remaining=7.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1560: loss=7.157, avg loss=7.902, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=1.9 seconds, 99840 images, time remaining=7.6 hours
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1561: loss=9.694, avg loss=8.082, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.2 seconds, train=4.0 seconds, 99904 images, time remaining=7.6 hours
1562: loss=9.294, avg loss=8.203, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 99968 images, time remaining=7.6 hours
1563: loss=7.016, avg loss=8.084, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=4.0 seconds, 100032 images, time remaining=7.6 hours
1564: loss=8.362, avg loss=8.112, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 100096 images, time remaining=7.6 hours
1565: loss=7.669, avg loss=8.068, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 100160 images, time remaining=7.6 hours
1566: loss=6.957, avg loss=7.957, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 100224 images, time remaining=7.6 hours
1567: loss=8.553, avg loss=8.016, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 100288 images, time remaining=7.6 hours
1568: loss=8.030, avg loss=8.018, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=4.0 seconds, 100352 images, time remaining=7.6 hours
1569: loss=7.569, avg loss=7.973, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 100416 images, time remaining=7.6 hours
1570: loss=8.271, avg loss=8.003, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 100480 images, time remaining=7.6 hours
Resizing, random_coef=1.40, batch=4, 1088x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1571: loss=8.682, avg loss=8.071, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=4.3 seconds, 100544 images, time remaining=7.6 hours
1572: loss=7.983, avg loss=8.062, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 100608 images, time remaining=7.6 hours
1573: loss=6.749, avg loss=7.930, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.4 seconds, train=4.2 seconds, 100672 images, time remaining=7.6 hours
1574: loss=7.107, avg loss=7.848, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.6 seconds, train=4.3 seconds, 100736 images, time remaining=7.6 hours
1575: loss=7.771, avg loss=7.840, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 100800 images, time remaining=7.6 hours
1576: loss=7.931, avg loss=7.849, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 100864 images, time remaining=7.6 hours
1577: loss=7.506, avg loss=7.815, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 100928 images, time remaining=7.6 hours
1578: loss=7.193, avg loss=7.753, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 100992 images, time remaining=7.6 hours
1579: loss=7.705, avg loss=7.748, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.3 seconds, 101056 images, time remaining=7.6 hours
1580: loss=6.553, avg loss=7.629, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=4.2 seconds, 101120 images, time remaining=7.6 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b4b4000000
1581: loss=7.886, avg loss=7.654, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 101184 images, time remaining=7.6 hours
1582: loss=8.641, avg loss=7.753, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 101248 images, time remaining=7.6 hours
1583: loss=8.239, avg loss=7.802, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 101312 images, time remaining=7.6 hours
1584: loss=7.366, avg loss=7.758, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 101376 images, time remaining=7.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1585: loss=7.435, avg loss=7.726, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=3.2 seconds, train=2.1 seconds, 101440 images, time remaining=7.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1586: loss=7.545, avg loss=7.708, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=3.1 seconds, train=2.2 seconds, 101504 images, time remaining=7.6 hours
1587: loss=7.196, avg loss=7.657, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 101568 images, time remaining=7.6 hours
1588: loss=6.961, avg loss=7.587, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 101632 images, time remaining=7.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1589: loss=6.783, avg loss=7.506, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.3 seconds, train=2.0 seconds, 101696 images, time remaining=7.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1590: loss=7.822, avg loss=7.538, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=3.2 seconds, train=2.3 seconds, 101760 images, time remaining=7.6 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1591: loss=12.669, avg loss=8.051, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 101824 images, time remaining=7.6 hours
1592: loss=9.570, avg loss=8.203, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=5.5 seconds, 101888 images, time remaining=7.6 hours
1593: loss=9.764, avg loss=8.359, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=5.6 seconds, 101952 images, time remaining=7.6 hours
1594: loss=7.403, avg loss=8.264, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 102016 images, time remaining=7.6 hours
1595: loss=7.883, avg loss=8.226, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 102080 images, time remaining=7.6 hours
1596: loss=9.147, avg loss=8.318, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 102144 images, time remaining=7.6 hours
1597: loss=8.971, avg loss=8.383, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=5.5 seconds, 102208 images, time remaining=7.6 hours
1598: loss=9.112, avg loss=8.456, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 102272 images, time remaining=7.6 hours
1599: loss=8.958, avg loss=8.506, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.4 seconds, train=5.4 seconds, 102336 images, time remaining=7.6 hours
1600: loss=9.236, avg loss=8.579, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 102400 images, time remaining=7.6 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
1601: loss=6.954, avg loss=8.417, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 102464 images, time remaining=7.6 hours
1602: loss=7.240, avg loss=8.299, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 102528 images, time remaining=7.6 hours
1603: loss=8.926, avg loss=8.362, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 102592 images, time remaining=7.6 hours
1604: loss=7.939, avg loss=8.319, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 102656 images, time remaining=7.6 hours
1605: loss=8.193, avg loss=8.307, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 102720 images, time remaining=7.6 hours
1606: loss=7.530, avg loss=8.229, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 102784 images, time remaining=7.5 hours
1607: loss=8.233, avg loss=8.229, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 102848 images, time remaining=7.5 hours
1608: loss=8.107, avg loss=8.217, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 102912 images, time remaining=7.5 hours
1609: loss=8.021, avg loss=8.198, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=2.7 seconds, 102976 images, time remaining=7.5 hours
1610: loss=8.238, avg loss=8.202, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 103040 images, time remaining=7.5 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1611: loss=8.867, avg loss=8.268, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 103104 images, time remaining=7.5 hours
1612: loss=8.491, avg loss=8.290, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 103168 images, time remaining=7.5 hours
1613: loss=8.346, avg loss=8.296, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 103232 images, time remaining=7.5 hours
1614: loss=8.820, avg loss=8.348, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 103296 images, time remaining=7.5 hours
1615: loss=7.481, avg loss=8.262, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 103360 images, time remaining=7.5 hours
1616: loss=7.034, avg loss=8.139, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 103424 images, time remaining=7.5 hours
1617: loss=9.296, avg loss=8.255, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=5.4 seconds, 103488 images, time remaining=7.5 hours
1618: loss=7.415, avg loss=8.171, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 103552 images, time remaining=7.5 hours
1619: loss=8.027, avg loss=8.156, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=5.2 seconds, 103616 images, time remaining=7.5 hours
1620: loss=8.804, avg loss=8.221, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 103680 images, time remaining=7.5 hours
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1621: loss=7.306, avg loss=8.130, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 103744 images, time remaining=7.5 hours
1622: loss=7.958, avg loss=8.112, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 103808 images, time remaining=7.5 hours
1623: loss=8.190, avg loss=8.120, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 103872 images, time remaining=7.5 hours
1624: loss=7.209, avg loss=8.029, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 103936 images, time remaining=7.5 hours
1625: loss=7.516, avg loss=7.978, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 104000 images, time remaining=7.5 hours
1626: loss=6.695, avg loss=7.849, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 104064 images, time remaining=7.5 hours
1627: loss=8.361, avg loss=7.901, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 104128 images, time remaining=7.5 hours
1628: loss=7.068, avg loss=7.817, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 104192 images, time remaining=7.5 hours
1629: loss=7.975, avg loss=7.833, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=4.0 seconds, 104256 images, time remaining=7.5 hours
1630: loss=6.752, avg loss=7.725, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=4.0 seconds, 104320 images, time remaining=7.5 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1631: loss=7.173, avg loss=7.670, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 104384 images, time remaining=7.5 hours
1632: loss=8.077, avg loss=7.710, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=3.8 seconds, 104448 images, time remaining=7.5 hours
1633: loss=7.062, avg loss=7.646, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=3.9 seconds, 104512 images, time remaining=7.5 hours
1634: loss=7.283, avg loss=7.609, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 104576 images, time remaining=7.5 hours
1635: loss=6.571, avg loss=7.505, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=3.9 seconds, 104640 images, time remaining=7.5 hours
1636: loss=5.922, avg loss=7.347, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 104704 images, time remaining=7.5 hours
1637: loss=5.847, avg loss=7.197, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=3.8 seconds, 104768 images, time remaining=7.5 hours
1638: loss=6.256, avg loss=7.103, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 104832 images, time remaining=7.5 hours
1639: loss=7.347, avg loss=7.127, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 104896 images, time remaining=7.5 hours
1640: loss=6.410, avg loss=7.056, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 104960 images, time remaining=7.5 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1641: loss=7.408, avg loss=7.091, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 105024 images, time remaining=7.5 hours
1642: loss=8.041, avg loss=7.186, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 105088 images, time remaining=7.5 hours
1643: loss=7.038, avg loss=7.171, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.2 seconds, 105152 images, time remaining=7.5 hours
1644: loss=6.226, avg loss=7.077, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 105216 images, time remaining=7.5 hours
1645: loss=6.011, avg loss=6.970, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 105280 images, time remaining=7.5 hours
1646: loss=7.703, avg loss=7.043, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 105344 images, time remaining=7.5 hours
1647: loss=6.579, avg loss=6.997, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=4.2 seconds, 105408 images, time remaining=7.5 hours
1648: loss=5.398, avg loss=6.837, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=4.2 seconds, 105472 images, time remaining=7.5 hours
1649: loss=5.862, avg loss=6.739, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 105536 images, time remaining=7.5 hours
1650: loss=6.212, avg loss=6.687, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.2 seconds, train=4.1 seconds, 105600 images, time remaining=7.5 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b344000000
1651: loss=7.544, avg loss=6.772, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 105664 images, time remaining=7.5 hours
1652: loss=7.244, avg loss=6.820, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 105728 images, time remaining=7.5 hours
1653: loss=6.867, avg loss=6.824, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 105792 images, time remaining=7.5 hours
1654: loss=6.539, avg loss=6.796, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 105856 images, time remaining=7.5 hours
1655: loss=7.321, avg loss=6.848, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 105920 images, time remaining=7.5 hours
1656: loss=7.998, avg loss=6.963, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 105984 images, time remaining=7.5 hours
1657: loss=6.441, avg loss=6.911, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 106048 images, time remaining=7.5 hours
1658: loss=6.132, avg loss=6.833, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 106112 images, time remaining=7.5 hours
1659: loss=5.911, avg loss=6.741, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 106176 images, time remaining=7.5 hours
1660: loss=5.680, avg loss=6.635, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 106240 images, time remaining=7.5 hours
Resizing, random_coef=1.40, batch=4, 1184x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1661: loss=8.990, avg loss=6.870, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=4.6 seconds, 106304 images, time remaining=7.5 hours
1662: loss=7.966, avg loss=6.980, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 106368 images, time remaining=7.5 hours
1663: loss=9.100, avg loss=7.192, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.6 seconds, 106432 images, time remaining=7.5 hours
1664: loss=7.983, avg loss=7.271, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.5 seconds, 106496 images, time remaining=7.5 hours
1665: loss=7.335, avg loss=7.277, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.5 seconds, 106560 images, time remaining=7.5 hours
1666: loss=8.537, avg loss=7.403, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 106624 images, time remaining=7.5 hours
1667: loss=7.031, avg loss=7.366, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.5 seconds, 106688 images, time remaining=7.5 hours
1668: loss=8.087, avg loss=7.438, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 106752 images, time remaining=7.5 hours
1669: loss=7.927, avg loss=7.487, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.3 seconds, train=4.5 seconds, 106816 images, time remaining=7.5 hours
1670: loss=7.675, avg loss=7.506, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=3.1 seconds, train=4.6 seconds, 106880 images, time remaining=7.5 hours
Resizing, random_coef=1.40, batch=4, 1088x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1671: loss=7.824, avg loss=7.538, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=4.3 seconds, 106944 images, time remaining=7.5 hours
1672: loss=6.286, avg loss=7.412, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.2 seconds, 107008 images, time remaining=7.5 hours
1673: loss=6.920, avg loss=7.363, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.2 seconds, 107072 images, time remaining=7.5 hours
1674: loss=6.519, avg loss=7.279, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 107136 images, time remaining=7.5 hours
1675: loss=7.009, avg loss=7.252, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 107200 images, time remaining=7.5 hours
1676: loss=7.489, avg loss=7.276, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 107264 images, time remaining=7.5 hours
1677: loss=6.275, avg loss=7.176, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.2 seconds, 107328 images, time remaining=7.5 hours
1678: loss=6.637, avg loss=7.122, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 107392 images, time remaining=7.5 hours
1679: loss=8.640, avg loss=7.273, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 107456 images, time remaining=7.5 hours
1680: loss=6.733, avg loss=7.219, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.2 seconds, 107520 images, time remaining=7.5 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b599000000
1681: loss=6.665, avg loss=7.164, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 107584 images, time remaining=7.5 hours
1682: loss=6.141, avg loss=7.062, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=2.3 seconds, 107648 images, time remaining=7.5 hours
1683: loss=6.003, avg loss=6.956, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 107712 images, time remaining=7.5 hours
1684: loss=7.692, avg loss=7.029, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 107776 images, time remaining=7.5 hours
1685: loss=7.014, avg loss=7.028, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 107840 images, time remaining=7.4 hours
1686: loss=6.154, avg loss=6.941, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 107904 images, time remaining=7.4 hours
1687: loss=6.413, avg loss=6.888, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 107968 images, time remaining=7.4 hours
1688: loss=5.378, avg loss=6.737, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 108032 images, time remaining=7.4 hours
1689: loss=6.586, avg loss=6.722, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 108096 images, time remaining=7.4 hours
1690: loss=6.442, avg loss=6.694, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 108160 images, time remaining=7.4 hours
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1691: loss=8.937, avg loss=6.918, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=6.1 seconds, 108224 images, time remaining=7.4 hours
1692: loss=7.338, avg loss=6.960, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=6.1 seconds, 108288 images, time remaining=7.4 hours
1693: loss=7.498, avg loss=7.014, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=6.2 seconds, 108352 images, time remaining=7.4 hours
1694: loss=8.215, avg loss=7.134, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.2 seconds, train=6.1 seconds, 108416 images, time remaining=7.4 hours
1695: loss=7.396, avg loss=7.160, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.2 seconds, train=6.0 seconds, 108480 images, time remaining=7.4 hours
1696: loss=8.427, avg loss=7.287, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.2 seconds, train=6.0 seconds, 108544 images, time remaining=7.4 hours
1697: loss=8.898, avg loss=7.448, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 108608 images, time remaining=7.4 hours
1698: loss=8.145, avg loss=7.518, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=6.0 seconds, 108672 images, time remaining=7.4 hours
1699: loss=6.545, avg loss=7.420, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 108736 images, time remaining=7.4 hours
1700: loss=7.479, avg loss=7.426, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.2 seconds, train=6.0 seconds, 108800 images, time remaining=7.4 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1701: loss=6.970, avg loss=7.381, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 108864 images, time remaining=7.4 hours
1702: loss=6.733, avg loss=7.316, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 108928 images, time remaining=7.4 hours
1703: loss=9.187, avg loss=7.503, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 108992 images, time remaining=7.4 hours
1704: loss=6.858, avg loss=7.439, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 109056 images, time remaining=7.4 hours
1705: loss=6.931, avg loss=7.388, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 109120 images, time remaining=7.4 hours
1706: loss=6.722, avg loss=7.321, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 109184 images, time remaining=7.4 hours
1707: loss=7.560, avg loss=7.345, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 109248 images, time remaining=7.4 hours
1708: loss=7.079, avg loss=7.318, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 109312 images, time remaining=7.4 hours
1709: loss=7.522, avg loss=7.339, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 109376 images, time remaining=7.4 hours
1710: loss=6.484, avg loss=7.253, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 109440 images, time remaining=7.4 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1711: loss=6.691, avg loss=7.197, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 109504 images, time remaining=7.4 hours
1712: loss=7.496, avg loss=7.227, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=4.8 seconds, 109568 images, time remaining=7.4 hours
1713: loss=6.975, avg loss=7.202, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 109632 images, time remaining=7.4 hours
1714: loss=5.667, avg loss=7.048, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 109696 images, time remaining=7.4 hours
1715: loss=6.446, avg loss=6.988, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 109760 images, time remaining=7.4 hours
1716: loss=6.663, avg loss=6.956, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 109824 images, time remaining=7.4 hours
1717: loss=6.470, avg loss=6.907, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.6 seconds, 109888 images, time remaining=7.4 hours
1718: loss=6.973, avg loss=6.914, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 109952 images, time remaining=7.4 hours
1719: loss=6.507, avg loss=6.873, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 110016 images, time remaining=7.4 hours
1720: loss=6.113, avg loss=6.797, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 110080 images, time remaining=7.4 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b5c7400000
1721: loss=8.125, avg loss=6.930, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 110144 images, time remaining=7.4 hours
1722: loss=7.629, avg loss=7.000, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.0 seconds, train=2.0 seconds, 110208 images, time remaining=7.4 hours
1723: loss=7.277, avg loss=7.027, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 110272 images, time remaining=7.4 hours
1724: loss=7.682, avg loss=7.093, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 110336 images, time remaining=7.4 hours
1725: loss=8.238, avg loss=7.207, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 110400 images, time remaining=7.4 hours
1726: loss=6.980, avg loss=7.185, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 110464 images, time remaining=7.4 hours
1727: loss=7.625, avg loss=7.229, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 110528 images, time remaining=7.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1728: loss=7.591, avg loss=7.265, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=1.9 seconds, 110592 images, time remaining=7.4 hours
1729: loss=6.955, avg loss=7.234, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 110656 images, time remaining=7.4 hours
1730: loss=5.840, avg loss=7.095, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 110720 images, time remaining=7.4 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1731: loss=9.279, avg loss=7.313, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=4.4 seconds, 110784 images, time remaining=7.4 hours
1732: loss=8.570, avg loss=7.439, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 110848 images, time remaining=7.4 hours
1733: loss=7.504, avg loss=7.445, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 110912 images, time remaining=7.4 hours
1734: loss=7.673, avg loss=7.468, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 110976 images, time remaining=7.4 hours
1735: loss=7.083, avg loss=7.429, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=4.4 seconds, 111040 images, time remaining=7.4 hours
1736: loss=7.365, avg loss=7.423, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 111104 images, time remaining=7.4 hours
1737: loss=7.591, avg loss=7.440, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 111168 images, time remaining=7.4 hours
1738: loss=7.975, avg loss=7.493, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.3 seconds, 111232 images, time remaining=7.4 hours
1739: loss=6.992, avg loss=7.443, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 111296 images, time remaining=7.4 hours
1740: loss=6.385, avg loss=7.337, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 111360 images, time remaining=7.4 hours
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14b574c00000
1741: loss=7.478, avg loss=7.351, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 111424 images, time remaining=7.4 hours
1742: loss=7.228, avg loss=7.339, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 111488 images, time remaining=7.4 hours
1743: loss=7.817, avg loss=7.387, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 111552 images, time remaining=7.4 hours
1744: loss=7.005, avg loss=7.349, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 111616 images, time remaining=7.4 hours
1745: loss=7.175, avg loss=7.331, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 111680 images, time remaining=7.4 hours
1746: loss=6.995, avg loss=7.298, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 111744 images, time remaining=7.4 hours
1747: loss=6.076, avg loss=7.176, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 111808 images, time remaining=7.4 hours
1748: loss=7.335, avg loss=7.191, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 111872 images, time remaining=7.4 hours
1749: loss=6.436, avg loss=7.116, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=2.3 seconds, 111936 images, time remaining=7.4 hours
1750: loss=5.972, avg loss=7.002, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 112000 images, time remaining=7.4 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1751: loss=8.975, avg loss=7.199, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 112064 images, time remaining=7.4 hours
1752: loss=6.719, avg loss=7.151, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=4.4 seconds, 112128 images, time remaining=7.4 hours
1753: loss=6.895, avg loss=7.125, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 112192 images, time remaining=7.4 hours
1754: loss=7.182, avg loss=7.131, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 112256 images, time remaining=7.4 hours
1755: loss=7.033, avg loss=7.121, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 112320 images, time remaining=7.4 hours
1756: loss=7.753, avg loss=7.184, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.3 seconds, train=4.4 seconds, 112384 images, time remaining=7.4 hours
1757: loss=8.044, avg loss=7.270, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 112448 images, time remaining=7.4 hours
1758: loss=7.112, avg loss=7.254, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 112512 images, time remaining=7.4 hours
1759: loss=6.111, avg loss=7.140, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=4.3 seconds, 112576 images, time remaining=7.4 hours
1760: loss=7.369, avg loss=7.163, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 112640 images, time remaining=7.4 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1761: loss=6.613, avg loss=7.108, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 112704 images, time remaining=7.4 hours
1762: loss=7.511, avg loss=7.148, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=5.4 seconds, 112768 images, time remaining=7.4 hours
1763: loss=7.662, avg loss=7.200, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 112832 images, time remaining=7.4 hours
1764: loss=6.965, avg loss=7.176, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 112896 images, time remaining=7.4 hours
1765: loss=6.271, avg loss=7.086, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 112960 images, time remaining=7.4 hours
1766: loss=8.398, avg loss=7.217, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.1 seconds, train=5.4 seconds, 113024 images, time remaining=7.4 hours
1767: loss=6.923, avg loss=7.188, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 113088 images, time remaining=7.4 hours
1768: loss=8.355, avg loss=7.304, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 113152 images, time remaining=7.4 hours
1769: loss=6.819, avg loss=7.256, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=3.0 seconds, train=5.4 seconds, 113216 images, time remaining=7.4 hours
1770: loss=8.405, avg loss=7.371, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 113280 images, time remaining=7.4 hours
Resizing, random_coef=1.40, batch=4, 896x672
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
1771: loss=8.349, avg loss=7.469, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 113344 images, time remaining=7.4 hours
1772: loss=6.647, avg loss=7.386, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 113408 images, time remaining=7.4 hours
1773: loss=7.319, avg loss=7.380, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 113472 images, time remaining=7.3 hours
1774: loss=6.904, avg loss=7.332, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 113536 images, time remaining=7.3 hours
1775: loss=6.878, avg loss=7.287, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 113600 images, time remaining=7.3 hours
1776: loss=6.917, avg loss=7.250, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=2.6 seconds, 113664 images, time remaining=7.3 hours
1777: loss=7.212, avg loss=7.246, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 113728 images, time remaining=7.3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1778: loss=7.067, avg loss=7.228, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.5 seconds, train=2.5 seconds, 113792 images, time remaining=7.3 hours
1779: loss=7.028, avg loss=7.208, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 113856 images, time remaining=7.3 hours
1780: loss=5.996, avg loss=7.087, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 113920 images, time remaining=7.3 hours
Resizing, random_coef=1.40, batch=4, 1152x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1781: loss=7.160, avg loss=7.094, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=4.1 seconds, train=4.3 seconds, 113984 images, time remaining=7.3 hours
1782: loss=7.157, avg loss=7.100, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=4.3 seconds, 114048 images, time remaining=7.3 hours
1783: loss=6.276, avg loss=7.018, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.5 seconds, 114112 images, time remaining=7.3 hours
1784: loss=6.638, avg loss=6.980, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.5 seconds, 114176 images, time remaining=7.3 hours
1785: loss=7.874, avg loss=7.069, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=4.4 seconds, 114240 images, time remaining=7.3 hours
1786: loss=8.458, avg loss=7.208, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 114304 images, time remaining=7.3 hours
1787: loss=8.608, avg loss=7.348, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=4.5 seconds, 114368 images, time remaining=7.3 hours
1788: loss=7.587, avg loss=7.372, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 114432 images, time remaining=7.3 hours
1789: loss=7.590, avg loss=7.394, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.5 seconds, 114496 images, time remaining=7.3 hours
1790: loss=6.059, avg loss=7.260, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=4.5 seconds, 114560 images, time remaining=7.3 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
1791: loss=7.871, avg loss=7.321, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 114624 images, time remaining=7.3 hours
1792: loss=5.944, avg loss=7.184, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 114688 images, time remaining=7.3 hours
1793: loss=6.750, avg loss=7.140, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 114752 images, time remaining=7.3 hours
1794: loss=6.281, avg loss=7.054, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.8 seconds, train=2.9 seconds, 114816 images, time remaining=7.3 hours
1795: loss=5.841, avg loss=6.933, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 114880 images, time remaining=7.3 hours
1796: loss=6.769, avg loss=6.917, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 114944 images, time remaining=7.3 hours
1797: loss=7.804, avg loss=7.005, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 115008 images, time remaining=7.3 hours
1798: loss=8.176, avg loss=7.122, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 115072 images, time remaining=7.3 hours
1799: loss=7.050, avg loss=7.115, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 115136 images, time remaining=7.3 hours
1800: loss=6.117, avg loss=7.015, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 115200 images, time remaining=7.3 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1801: loss=6.796, avg loss=6.993, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=2.0 seconds, train=5.4 seconds, 115264 images, time remaining=7.3 hours
1802: loss=6.790, avg loss=6.973, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 115328 images, time remaining=7.3 hours
1803: loss=7.907, avg loss=7.067, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 115392 images, time remaining=7.3 hours
1804: loss=6.484, avg loss=7.008, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 115456 images, time remaining=7.3 hours
1805: loss=6.509, avg loss=6.958, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 115520 images, time remaining=7.3 hours
1806: loss=6.989, avg loss=6.961, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 115584 images, time remaining=7.3 hours
1807: loss=7.051, avg loss=6.970, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 115648 images, time remaining=7.3 hours
1808: loss=7.937, avg loss=7.067, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 115712 images, time remaining=7.3 hours
1809: loss=6.311, avg loss=6.991, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 115776 images, time remaining=7.3 hours
1810: loss=8.004, avg loss=7.093, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 115840 images, time remaining=7.3 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
1811: loss=6.526, avg loss=7.036, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 115904 images, time remaining=7.3 hours
1812: loss=6.848, avg loss=7.017, last=61.12%, best=61.12%, next=1812, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 115968 images, time remaining=7.3 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=184259, unique_truth_count=57264
rank=0 of ranks=184259rank=100 of ranks=184259rank=200 of ranks=184259rank=300 of ranks=184259rank=400 of ranks=184259rank=500 of ranks=184259rank=600 of ranks=184259rank=700 of ranks=184259rank=800 of ranks=184259rank=900 of ranks=184259rank=1000 of ranks=184259rank=1100 of ranks=184259rank=1200 of ranks=184259rank=1300 of ranks=184259rank=1400 of ranks=184259rank=1500 of ranks=184259rank=1600 of ranks=184259rank=1700 of ranks=184259rank=1800 of ranks=184259rank=1900 of ranks=184259rank=2000 of ranks=184259rank=2100 of ranks=184259rank=2200 of ranks=184259rank=2300 of ranks=184259rank=2400 of ranks=184259rank=2500 of ranks=184259rank=2600 of ranks=184259rank=2700 of ranks=184259rank=2800 of ranks=184259rank=2900 of ranks=184259rank=3000 of ranks=184259rank=3100 of ranks=184259rank=3200 of ranks=184259rank=3300 of ranks=184259rank=3400 of ranks=184259rank=3500 of ranks=184259rank=3600 of ranks=184259rank=3700 of ranks=184259rank=3800 of ranks=184259rank=3900 of ranks=184259rank=4000 of ranks=184259rank=4100 of ranks=184259rank=4200 of ranks=184259rank=4300 of ranks=184259rank=4400 of ranks=184259rank=4500 of ranks=184259rank=4600 of ranks=184259rank=4700 of ranks=184259rank=4800 of ranks=184259rank=4900 of ranks=184259rank=5000 of ranks=184259rank=5100 of ranks=184259rank=5200 of ranks=184259rank=5300 of ranks=184259rank=5400 of ranks=184259rank=5500 of ranks=184259rank=5600 of ranks=184259rank=5700 of ranks=184259rank=5800 of ranks=184259rank=5900 of ranks=184259rank=6000 of ranks=184259rank=6100 of ranks=184259rank=6200 of ranks=184259rank=6300 of ranks=184259rank=6400 of ranks=184259rank=6500 of ranks=184259rank=6600 of ranks=184259rank=6700 of ranks=184259rank=6800 of ranks=184259rank=6900 of ranks=184259rank=7000 of ranks=184259rank=7100 of ranks=184259rank=7200 of ranks=184259rank=7300 of ranks=184259rank=7400 of ranks=184259rank=7500 of ranks=184259rank=7600 of ranks=184259rank=7700 of ranks=184259rank=7800 of ranks=184259rank=7900 of ranks=184259rank=8000 of ranks=184259rank=8100 of ranks=184259rank=8200 of ranks=184259rank=8300 of ranks=184259rank=8400 of ranks=184259rank=8500 of ranks=184259rank=8600 of ranks=184259rank=8700 of ranks=184259rank=8800 of ranks=184259rank=8900 of ranks=184259rank=9000 of ranks=184259rank=9100 of ranks=184259rank=9200 of ranks=184259rank=9300 of ranks=184259rank=9400 of ranks=184259rank=9500 of ranks=184259rank=9600 of ranks=184259rank=9700 of ranks=184259rank=9800 of ranks=184259rank=9900 of ranks=184259rank=10000 of ranks=184259rank=10100 of ranks=184259rank=10200 of ranks=184259rank=10300 of ranks=184259rank=10400 of ranks=184259rank=10500 of ranks=184259rank=10600 of ranks=184259rank=10700 of ranks=184259rank=10800 of ranks=184259rank=10900 of ranks=184259rank=11000 of ranks=184259rank=11100 of ranks=184259rank=11200 of ranks=184259rank=11300 of ranks=184259rank=11400 of ranks=184259rank=11500 of ranks=184259rank=11600 of ranks=184259rank=11700 of ranks=184259rank=11800 of ranks=184259rank=11900 of ranks=184259rank=12000 of ranks=184259rank=12100 of ranks=184259rank=12200 of ranks=184259rank=12300 of ranks=184259rank=12400 of ranks=184259rank=12500 of ranks=184259rank=12600 of ranks=184259rank=12700 of ranks=184259rank=12800 of ranks=184259rank=12900 of ranks=184259rank=13000 of ranks=184259rank=13100 of ranks=184259rank=13200 of ranks=184259rank=13300 of ranks=184259rank=13400 of ranks=184259rank=13500 of ranks=184259rank=13600 of ranks=184259rank=13700 of ranks=184259rank=13800 of ranks=184259rank=13900 of ranks=184259rank=14000 of ranks=184259rank=14100 of ranks=184259rank=14200 of ranks=184259rank=14300 of ranks=184259rank=14400 of ranks=184259rank=14500 of ranks=184259rank=14600 of ranks=184259rank=14700 of ranks=184259rank=14800 of ranks=184259rank=14900 of ranks=184259rank=15000 of ranks=184259rank=15100 of ranks=184259rank=15200 of ranks=184259rank=15300 of ranks=184259rank=15400 of ranks=184259rank=15500 of ranks=184259rank=15600 of ranks=184259rank=15700 of ranks=184259rank=15800 of ranks=184259rank=15900 of ranks=184259rank=16000 of ranks=184259rank=16100 of ranks=184259rank=16200 of ranks=184259rank=16300 of ranks=184259rank=16400 of ranks=184259rank=16500 of ranks=184259rank=16600 of ranks=184259rank=16700 of ranks=184259rank=16800 of ranks=184259rank=16900 of ranks=184259rank=17000 of ranks=184259rank=17100 of ranks=184259rank=17200 of ranks=184259rank=17300 of ranks=184259rank=17400 of ranks=184259rank=17500 of ranks=184259rank=17600 of ranks=184259rank=17700 of ranks=184259rank=17800 of ranks=184259rank=17900 of ranks=184259rank=18000 of ranks=184259rank=18100 of ranks=184259rank=18200 of ranks=184259rank=18300 of ranks=184259rank=18400 of ranks=184259rank=18500 of ranks=184259rank=18600 of ranks=184259rank=18700 of ranks=184259rank=18800 of ranks=184259rank=18900 of ranks=184259rank=19000 of ranks=184259rank=19100 of ranks=184259rank=19200 of ranks=184259rank=19300 of ranks=184259rank=19400 of ranks=184259rank=19500 of ranks=184259rank=19600 of ranks=184259rank=19700 of ranks=184259rank=19800 of ranks=184259rank=19900 of ranks=184259rank=20000 of ranks=184259rank=20100 of ranks=184259rank=20200 of ranks=184259rank=20300 of ranks=184259rank=20400 of ranks=184259rank=20500 of ranks=184259rank=20600 of ranks=184259rank=20700 of ranks=184259rank=20800 of ranks=184259rank=20900 of ranks=184259rank=21000 of ranks=184259rank=21100 of ranks=184259rank=21200 of ranks=184259rank=21300 of ranks=184259rank=21400 of ranks=184259rank=21500 of ranks=184259rank=21600 of ranks=184259rank=21700 of ranks=184259rank=21800 of ranks=184259rank=21900 of ranks=184259rank=22000 of ranks=184259rank=22100 of ranks=184259rank=22200 of ranks=184259rank=22300 of ranks=184259rank=22400 of ranks=184259rank=22500 of ranks=184259rank=22600 of ranks=184259rank=22700 of ranks=184259rank=22800 of ranks=184259rank=22900 of ranks=184259rank=23000 of ranks=184259rank=23100 of ranks=184259rank=23200 of ranks=184259rank=23300 of ranks=184259rank=23400 of ranks=184259rank=23500 of ranks=184259rank=23600 of ranks=184259rank=23700 of ranks=184259rank=23800 of ranks=184259rank=23900 of ranks=184259rank=24000 of ranks=184259rank=24100 of ranks=184259rank=24200 of ranks=184259rank=24300 of ranks=184259rank=24400 of ranks=184259rank=24500 of ranks=184259rank=24600 of ranks=184259rank=24700 of ranks=184259rank=24800 of ranks=184259rank=24900 of ranks=184259rank=25000 of ranks=184259rank=25100 of ranks=184259rank=25200 of ranks=184259rank=25300 of ranks=184259rank=25400 of ranks=184259rank=25500 of ranks=184259rank=25600 of ranks=184259rank=25700 of ranks=184259rank=25800 of ranks=184259rank=25900 of ranks=184259rank=26000 of ranks=184259rank=26100 of ranks=184259rank=26200 of ranks=184259rank=26300 of ranks=184259rank=26400 of ranks=184259rank=26500 of ranks=184259rank=26600 of ranks=184259rank=26700 of ranks=184259rank=26800 of ranks=184259rank=26900 of ranks=184259rank=27000 of ranks=184259rank=27100 of ranks=184259rank=27200 of ranks=184259rank=27300 of ranks=184259rank=27400 of ranks=184259rank=27500 of ranks=184259rank=27600 of ranks=184259rank=27700 of ranks=184259rank=27800 of ranks=184259rank=27900 of ranks=184259rank=28000 of ranks=184259rank=28100 of ranks=184259rank=28200 of ranks=184259rank=28300 of ranks=184259rank=28400 of ranks=184259rank=28500 of ranks=184259rank=28600 of ranks=184259rank=28700 of ranks=184259rank=28800 of ranks=184259rank=28900 of ranks=184259rank=29000 of ranks=184259rank=29100 of ranks=184259rank=29200 of ranks=184259rank=29300 of ranks=184259rank=29400 of ranks=184259rank=29500 of ranks=184259rank=29600 of ranks=184259rank=29700 of ranks=184259rank=29800 of ranks=184259rank=29900 of ranks=184259rank=30000 of ranks=184259rank=30100 of ranks=184259rank=30200 of ranks=184259rank=30300 of ranks=184259rank=30400 of ranks=184259rank=30500 of ranks=184259rank=30600 of ranks=184259rank=30700 of ranks=184259rank=30800 of ranks=184259rank=30900 of ranks=184259rank=31000 of ranks=184259rank=31100 of ranks=184259rank=31200 of ranks=184259rank=31300 of ranks=184259rank=31400 of ranks=184259rank=31500 of ranks=184259rank=31600 of ranks=184259rank=31700 of ranks=184259rank=31800 of ranks=184259rank=31900 of ranks=184259rank=32000 of ranks=184259rank=32100 of ranks=184259rank=32200 of ranks=184259rank=32300 of ranks=184259rank=32400 of ranks=184259rank=32500 of ranks=184259rank=32600 of ranks=184259rank=32700 of ranks=184259rank=32800 of ranks=184259rank=32900 of ranks=184259rank=33000 of ranks=184259rank=33100 of ranks=184259rank=33200 of ranks=184259rank=33300 of ranks=184259rank=33400 of ranks=184259rank=33500 of ranks=184259rank=33600 of ranks=184259rank=33700 of ranks=184259rank=33800 of ranks=184259rank=33900 of ranks=184259rank=34000 of ranks=184259rank=34100 of ranks=184259rank=34200 of ranks=184259rank=34300 of ranks=184259rank=34400 of ranks=184259rank=34500 of ranks=184259rank=34600 of ranks=184259rank=34700 of ranks=184259rank=34800 of ranks=184259rank=34900 of ranks=184259rank=35000 of ranks=184259rank=35100 of ranks=184259rank=35200 of ranks=184259rank=35300 of ranks=184259rank=35400 of ranks=184259rank=35500 of ranks=184259rank=35600 of ranks=184259rank=35700 of ranks=184259rank=35800 of ranks=184259rank=35900 of ranks=184259rank=36000 of ranks=184259rank=36100 of ranks=184259rank=36200 of ranks=184259rank=36300 of ranks=184259rank=36400 of ranks=184259rank=36500 of ranks=184259rank=36600 of ranks=184259rank=36700 of ranks=184259rank=36800 of ranks=184259rank=36900 of ranks=184259rank=37000 of ranks=184259rank=37100 of ranks=184259rank=37200 of ranks=184259rank=37300 of ranks=184259rank=37400 of ranks=184259rank=37500 of ranks=184259rank=37600 of ranks=184259rank=37700 of ranks=184259rank=37800 of ranks=184259rank=37900 of ranks=184259rank=38000 of ranks=184259rank=38100 of ranks=184259rank=38200 of ranks=184259rank=38300 of ranks=184259rank=38400 of ranks=184259rank=38500 of ranks=184259rank=38600 of ranks=184259rank=38700 of ranks=184259rank=38800 of ranks=184259rank=38900 of ranks=184259rank=39000 of ranks=184259rank=39100 of ranks=184259rank=39200 of ranks=184259rank=39300 of ranks=184259rank=39400 of ranks=184259rank=39500 of ranks=184259rank=39600 of ranks=184259rank=39700 of ranks=184259rank=39800 of ranks=184259rank=39900 of ranks=184259rank=40000 of ranks=184259rank=40100 of ranks=184259rank=40200 of ranks=184259rank=40300 of ranks=184259rank=40400 of ranks=184259rank=40500 of ranks=184259rank=40600 of ranks=184259rank=40700 of ranks=184259rank=40800 of ranks=184259rank=40900 of ranks=184259rank=41000 of ranks=184259rank=41100 of ranks=184259rank=41200 of ranks=184259rank=41300 of ranks=184259rank=41400 of ranks=184259rank=41500 of ranks=184259rank=41600 of ranks=184259rank=41700 of ranks=184259rank=41800 of ranks=184259rank=41900 of ranks=184259rank=42000 of ranks=184259rank=42100 of ranks=184259rank=42200 of ranks=184259rank=42300 of ranks=184259rank=42400 of ranks=184259rank=42500 of ranks=184259rank=42600 of ranks=184259rank=42700 of ranks=184259rank=42800 of ranks=184259rank=42900 of ranks=184259rank=43000 of ranks=184259rank=43100 of ranks=184259rank=43200 of ranks=184259rank=43300 of ranks=184259rank=43400 of ranks=184259rank=43500 of ranks=184259rank=43600 of ranks=184259rank=43700 of ranks=184259rank=43800 of ranks=184259rank=43900 of ranks=184259rank=44000 of ranks=184259rank=44100 of ranks=184259rank=44200 of ranks=184259rank=44300 of ranks=184259rank=44400 of ranks=184259rank=44500 of ranks=184259rank=44600 of ranks=184259rank=44700 of ranks=184259rank=44800 of ranks=184259rank=44900 of ranks=184259rank=45000 of ranks=184259rank=45100 of ranks=184259rank=45200 of ranks=184259rank=45300 of ranks=184259rank=45400 of ranks=184259rank=45500 of ranks=184259rank=45600 of ranks=184259rank=45700 of ranks=184259rank=45800 of ranks=184259rank=45900 of ranks=184259rank=46000 of ranks=184259rank=46100 of ranks=184259rank=46200 of ranks=184259rank=46300 of ranks=184259rank=46400 of ranks=184259rank=46500 of ranks=184259rank=46600 of ranks=184259rank=46700 of ranks=184259rank=46800 of ranks=184259rank=46900 of ranks=184259rank=47000 of ranks=184259rank=47100 of ranks=184259rank=47200 of ranks=184259rank=47300 of ranks=184259rank=47400 of ranks=184259rank=47500 of ranks=184259rank=47600 of ranks=184259rank=47700 of ranks=184259rank=47800 of ranks=184259rank=47900 of ranks=184259rank=48000 of ranks=184259rank=48100 of ranks=184259rank=48200 of ranks=184259rank=48300 of ranks=184259rank=48400 of ranks=184259rank=48500 of ranks=184259rank=48600 of ranks=184259rank=48700 of ranks=184259rank=48800 of ranks=184259rank=48900 of ranks=184259rank=49000 of ranks=184259rank=49100 of ranks=184259rank=49200 of ranks=184259rank=49300 of ranks=184259rank=49400 of ranks=184259rank=49500 of ranks=184259rank=49600 of ranks=184259rank=49700 of ranks=184259rank=49800 of ranks=184259rank=49900 of ranks=184259rank=50000 of ranks=184259rank=50100 of ranks=184259rank=50200 of ranks=184259rank=50300 of ranks=184259rank=50400 of ranks=184259rank=50500 of ranks=184259rank=50600 of ranks=184259rank=50700 of ranks=184259rank=50800 of ranks=184259rank=50900 of ranks=184259rank=51000 of ranks=184259rank=51100 of ranks=184259rank=51200 of ranks=184259rank=51300 of ranks=184259rank=51400 of ranks=184259rank=51500 of ranks=184259rank=51600 of ranks=184259rank=51700 of ranks=184259rank=51800 of ranks=184259rank=51900 of ranks=184259rank=52000 of ranks=184259rank=52100 of ranks=184259rank=52200 of ranks=184259rank=52300 of ranks=184259rank=52400 of ranks=184259rank=52500 of ranks=184259rank=52600 of ranks=184259rank=52700 of ranks=184259rank=52800 of ranks=184259rank=52900 of ranks=184259rank=53000 of ranks=184259rank=53100 of ranks=184259rank=53200 of ranks=184259rank=53300 of ranks=184259rank=53400 of ranks=184259rank=53500 of ranks=184259rank=53600 of ranks=184259rank=53700 of ranks=184259rank=53800 of ranks=184259rank=53900 of ranks=184259rank=54000 of ranks=184259rank=54100 of ranks=184259rank=54200 of ranks=184259rank=54300 of ranks=184259rank=54400 of ranks=184259rank=54500 of ranks=184259rank=54600 of ranks=184259rank=54700 of ranks=184259rank=54800 of ranks=184259rank=54900 of ranks=184259rank=55000 of ranks=184259rank=55100 of ranks=184259rank=55200 of ranks=184259rank=55300 of ranks=184259rank=55400 of ranks=184259rank=55500 of ranks=184259rank=55600 of ranks=184259rank=55700 of ranks=184259rank=55800 of ranks=184259rank=55900 of ranks=184259rank=56000 of ranks=184259rank=56100 of ranks=184259rank=56200 of ranks=184259rank=56300 of ranks=184259rank=56400 of ranks=184259rank=56500 of ranks=184259rank=56600 of ranks=184259rank=56700 of ranks=184259rank=56800 of ranks=184259rank=56900 of ranks=184259rank=57000 of ranks=184259rank=57100 of ranks=184259rank=57200 of ranks=184259rank=57300 of ranks=184259rank=57400 of ranks=184259rank=57500 of ranks=184259rank=57600 of ranks=184259rank=57700 of ranks=184259rank=57800 of ranks=184259rank=57900 of ranks=184259rank=58000 of ranks=184259rank=58100 of ranks=184259rank=58200 of ranks=184259rank=58300 of ranks=184259rank=58400 of ranks=184259rank=58500 of ranks=184259rank=58600 of ranks=184259rank=58700 of ranks=184259rank=58800 of ranks=184259rank=58900 of ranks=184259rank=59000 of ranks=184259rank=59100 of ranks=184259rank=59200 of ranks=184259rank=59300 of ranks=184259rank=59400 of ranks=184259rank=59500 of ranks=184259rank=59600 of ranks=184259rank=59700 of ranks=184259rank=59800 of ranks=184259rank=59900 of ranks=184259rank=60000 of ranks=184259rank=60100 of ranks=184259rank=60200 of ranks=184259rank=60300 of ranks=184259rank=60400 of ranks=184259rank=60500 of ranks=184259rank=60600 of ranks=184259rank=60700 of ranks=184259rank=60800 of ranks=184259rank=60900 of ranks=184259rank=61000 of ranks=184259rank=61100 of ranks=184259rank=61200 of ranks=184259rank=61300 of ranks=184259rank=61400 of ranks=184259rank=61500 of ranks=184259rank=61600 of ranks=184259rank=61700 of ranks=184259rank=61800 of ranks=184259rank=61900 of ranks=184259rank=62000 of ranks=184259rank=62100 of ranks=184259rank=62200 of ranks=184259rank=62300 of ranks=184259rank=62400 of ranks=184259rank=62500 of ranks=184259rank=62600 of ranks=184259rank=62700 of ranks=184259rank=62800 of ranks=184259rank=62900 of ranks=184259rank=63000 of ranks=184259rank=63100 of ranks=184259rank=63200 of ranks=184259rank=63300 of ranks=184259rank=63400 of ranks=184259rank=63500 of ranks=184259rank=63600 of ranks=184259rank=63700 of ranks=184259rank=63800 of ranks=184259rank=63900 of ranks=184259rank=64000 of ranks=184259rank=64100 of ranks=184259rank=64200 of ranks=184259rank=64300 of ranks=184259rank=64400 of ranks=184259rank=64500 of ranks=184259rank=64600 of ranks=184259rank=64700 of ranks=184259rank=64800 of ranks=184259rank=64900 of ranks=184259rank=65000 of ranks=184259rank=65100 of ranks=184259rank=65200 of ranks=184259rank=65300 of ranks=184259rank=65400 of ranks=184259rank=65500 of ranks=184259rank=65600 of ranks=184259rank=65700 of ranks=184259rank=65800 of ranks=184259rank=65900 of ranks=184259rank=66000 of ranks=184259rank=66100 of ranks=184259rank=66200 of ranks=184259rank=66300 of ranks=184259rank=66400 of ranks=184259rank=66500 of ranks=184259rank=66600 of ranks=184259rank=66700 of ranks=184259rank=66800 of ranks=184259rank=66900 of ranks=184259rank=67000 of ranks=184259rank=67100 of ranks=184259rank=67200 of ranks=184259rank=67300 of ranks=184259rank=67400 of ranks=184259rank=67500 of ranks=184259rank=67600 of ranks=184259rank=67700 of ranks=184259rank=67800 of ranks=184259rank=67900 of ranks=184259rank=68000 of ranks=184259rank=68100 of ranks=184259rank=68200 of ranks=184259rank=68300 of ranks=184259rank=68400 of ranks=184259rank=68500 of ranks=184259rank=68600 of ranks=184259rank=68700 of ranks=184259rank=68800 of ranks=184259rank=68900 of ranks=184259rank=69000 of ranks=184259rank=69100 of ranks=184259rank=69200 of ranks=184259rank=69300 of ranks=184259rank=69400 of ranks=184259rank=69500 of ranks=184259rank=69600 of ranks=184259rank=69700 of ranks=184259rank=69800 of ranks=184259rank=69900 of ranks=184259rank=70000 of ranks=184259rank=70100 of ranks=184259rank=70200 of ranks=184259rank=70300 of ranks=184259rank=70400 of ranks=184259rank=70500 of ranks=184259rank=70600 of ranks=184259rank=70700 of ranks=184259rank=70800 of ranks=184259rank=70900 of ranks=184259rank=71000 of ranks=184259rank=71100 of ranks=184259rank=71200 of ranks=184259rank=71300 of ranks=184259rank=71400 of ranks=184259rank=71500 of ranks=184259rank=71600 of ranks=184259rank=71700 of ranks=184259rank=71800 of ranks=184259rank=71900 of ranks=184259rank=72000 of ranks=184259rank=72100 of ranks=184259rank=72200 of ranks=184259rank=72300 of ranks=184259rank=72400 of ranks=184259rank=72500 of ranks=184259rank=72600 of ranks=184259rank=72700 of ranks=184259rank=72800 of ranks=184259rank=72900 of ranks=184259rank=73000 of ranks=184259rank=73100 of ranks=184259rank=73200 of ranks=184259rank=73300 of ranks=184259rank=73400 of ranks=184259rank=73500 of ranks=184259rank=73600 of ranks=184259rank=73700 of ranks=184259rank=73800 of ranks=184259rank=73900 of ranks=184259rank=74000 of ranks=184259rank=74100 of ranks=184259rank=74200 of ranks=184259rank=74300 of ranks=184259rank=74400 of ranks=184259rank=74500 of ranks=184259rank=74600 of ranks=184259rank=74700 of ranks=184259rank=74800 of ranks=184259rank=74900 of ranks=184259rank=75000 of ranks=184259rank=75100 of ranks=184259rank=75200 of ranks=184259rank=75300 of ranks=184259rank=75400 of ranks=184259rank=75500 of ranks=184259rank=75600 of ranks=184259rank=75700 of ranks=184259rank=75800 of ranks=184259rank=75900 of ranks=184259rank=76000 of ranks=184259rank=76100 of ranks=184259rank=76200 of ranks=184259rank=76300 of ranks=184259rank=76400 of ranks=184259rank=76500 of ranks=184259rank=76600 of ranks=184259rank=76700 of ranks=184259rank=76800 of ranks=184259rank=76900 of ranks=184259rank=77000 of ranks=184259rank=77100 of ranks=184259rank=77200 of ranks=184259rank=77300 of ranks=184259rank=77400 of ranks=184259rank=77500 of ranks=184259rank=77600 of ranks=184259rank=77700 of ranks=184259rank=77800 of ranks=184259rank=77900 of ranks=184259rank=78000 of ranks=184259rank=78100 of ranks=184259rank=78200 of ranks=184259rank=78300 of ranks=184259rank=78400 of ranks=184259rank=78500 of ranks=184259rank=78600 of ranks=184259rank=78700 of ranks=184259rank=78800 of ranks=184259rank=78900 of ranks=184259rank=79000 of ranks=184259rank=79100 of ranks=184259rank=79200 of ranks=184259rank=79300 of ranks=184259rank=79400 of ranks=184259rank=79500 of ranks=184259rank=79600 of ranks=184259rank=79700 of ranks=184259rank=79800 of ranks=184259rank=79900 of ranks=184259rank=80000 of ranks=184259rank=80100 of ranks=184259rank=80200 of ranks=184259rank=80300 of ranks=184259rank=80400 of ranks=184259rank=80500 of ranks=184259rank=80600 of ranks=184259rank=80700 of ranks=184259rank=80800 of ranks=184259rank=80900 of ranks=184259rank=81000 of ranks=184259rank=81100 of ranks=184259rank=81200 of ranks=184259rank=81300 of ranks=184259rank=81400 of ranks=184259rank=81500 of ranks=184259rank=81600 of ranks=184259rank=81700 of ranks=184259rank=81800 of ranks=184259rank=81900 of ranks=184259rank=82000 of ranks=184259rank=82100 of ranks=184259rank=82200 of ranks=184259rank=82300 of ranks=184259rank=82400 of ranks=184259rank=82500 of ranks=184259rank=82600 of ranks=184259rank=82700 of ranks=184259rank=82800 of ranks=184259rank=82900 of ranks=184259rank=83000 of ranks=184259rank=83100 of ranks=184259rank=83200 of ranks=184259rank=83300 of ranks=184259rank=83400 of ranks=184259rank=83500 of ranks=184259rank=83600 of ranks=184259rank=83700 of ranks=184259rank=83800 of ranks=184259rank=83900 of ranks=184259rank=84000 of ranks=184259rank=84100 of ranks=184259rank=84200 of ranks=184259rank=84300 of ranks=184259rank=84400 of ranks=184259rank=84500 of ranks=184259rank=84600 of ranks=184259rank=84700 of ranks=184259rank=84800 of ranks=184259rank=84900 of ranks=184259rank=85000 of ranks=184259rank=85100 of ranks=184259rank=85200 of ranks=184259rank=85300 of ranks=184259rank=85400 of ranks=184259rank=85500 of ranks=184259rank=85600 of ranks=184259rank=85700 of ranks=184259rank=85800 of ranks=184259rank=85900 of ranks=184259rank=86000 of ranks=184259rank=86100 of ranks=184259rank=86200 of ranks=184259rank=86300 of ranks=184259rank=86400 of ranks=184259rank=86500 of ranks=184259rank=86600 of ranks=184259rank=86700 of ranks=184259rank=86800 of ranks=184259rank=86900 of ranks=184259rank=87000 of ranks=184259rank=87100 of ranks=184259rank=87200 of ranks=184259rank=87300 of ranks=184259rank=87400 of ranks=184259rank=87500 of ranks=184259rank=87600 of ranks=184259rank=87700 of ranks=184259rank=87800 of ranks=184259rank=87900 of ranks=184259rank=88000 of ranks=184259rank=88100 of ranks=184259rank=88200 of ranks=184259rank=88300 of ranks=184259rank=88400 of ranks=184259rank=88500 of ranks=184259rank=88600 of ranks=184259rank=88700 of ranks=184259rank=88800 of ranks=184259rank=88900 of ranks=184259rank=89000 of ranks=184259rank=89100 of ranks=184259rank=89200 of ranks=184259rank=89300 of ranks=184259rank=89400 of ranks=184259rank=89500 of ranks=184259rank=89600 of ranks=184259rank=89700 of ranks=184259rank=89800 of ranks=184259rank=89900 of ranks=184259rank=90000 of ranks=184259rank=90100 of ranks=184259rank=90200 of ranks=184259rank=90300 of ranks=184259rank=90400 of ranks=184259rank=90500 of ranks=184259rank=90600 of ranks=184259rank=90700 of ranks=184259rank=90800 of ranks=184259rank=90900 of ranks=184259rank=91000 of ranks=184259rank=91100 of ranks=184259rank=91200 of ranks=184259rank=91300 of ranks=184259rank=91400 of ranks=184259rank=91500 of ranks=184259rank=91600 of ranks=184259rank=91700 of ranks=184259rank=91800 of ranks=184259rank=91900 of ranks=184259rank=92000 of ranks=184259rank=92100 of ranks=184259rank=92200 of ranks=184259rank=92300 of ranks=184259rank=92400 of ranks=184259rank=92500 of ranks=184259rank=92600 of ranks=184259rank=92700 of ranks=184259rank=92800 of ranks=184259rank=92900 of ranks=184259rank=93000 of ranks=184259rank=93100 of ranks=184259rank=93200 of ranks=184259rank=93300 of ranks=184259rank=93400 of ranks=184259rank=93500 of ranks=184259rank=93600 of ranks=184259rank=93700 of ranks=184259rank=93800 of ranks=184259rank=93900 of ranks=184259rank=94000 of ranks=184259rank=94100 of ranks=184259rank=94200 of ranks=184259rank=94300 of ranks=184259rank=94400 of ranks=184259rank=94500 of ranks=184259rank=94600 of ranks=184259rank=94700 of ranks=184259rank=94800 of ranks=184259rank=94900 of ranks=184259rank=95000 of ranks=184259rank=95100 of ranks=184259rank=95200 of ranks=184259rank=95300 of ranks=184259rank=95400 of ranks=184259rank=95500 of ranks=184259rank=95600 of ranks=184259rank=95700 of ranks=184259rank=95800 of ranks=184259rank=95900 of ranks=184259rank=96000 of ranks=184259rank=96100 of ranks=184259rank=96200 of ranks=184259rank=96300 of ranks=184259rank=96400 of ranks=184259rank=96500 of ranks=184259rank=96600 of ranks=184259rank=96700 of ranks=184259rank=96800 of ranks=184259rank=96900 of ranks=184259rank=97000 of ranks=184259rank=97100 of ranks=184259rank=97200 of ranks=184259rank=97300 of ranks=184259rank=97400 of ranks=184259rank=97500 of ranks=184259rank=97600 of ranks=184259rank=97700 of ranks=184259rank=97800 of ranks=184259rank=97900 of ranks=184259rank=98000 of ranks=184259rank=98100 of ranks=184259rank=98200 of ranks=184259rank=98300 of ranks=184259rank=98400 of ranks=184259rank=98500 of ranks=184259rank=98600 of ranks=184259rank=98700 of ranks=184259rank=98800 of ranks=184259rank=98900 of ranks=184259rank=99000 of ranks=184259rank=99100 of ranks=184259rank=99200 of ranks=184259rank=99300 of ranks=184259rank=99400 of ranks=184259rank=99500 of ranks=184259rank=99600 of ranks=184259rank=99700 of ranks=184259rank=99800 of ranks=184259rank=99900 of ranks=184259rank=100000 of ranks=184259rank=100100 of ranks=184259rank=100200 of ranks=184259rank=100300 of ranks=184259rank=100400 of ranks=184259rank=100500 of ranks=184259rank=100600 of ranks=184259rank=100700 of ranks=184259rank=100800 of ranks=184259rank=100900 of ranks=184259rank=101000 of ranks=184259rank=101100 of ranks=184259rank=101200 of ranks=184259rank=101300 of ranks=184259rank=101400 of ranks=184259rank=101500 of ranks=184259rank=101600 of ranks=184259rank=101700 of ranks=184259rank=101800 of ranks=184259rank=101900 of ranks=184259rank=102000 of ranks=184259rank=102100 of ranks=184259rank=102200 of ranks=184259rank=102300 of ranks=184259rank=102400 of ranks=184259rank=102500 of ranks=184259rank=102600 of ranks=184259rank=102700 of ranks=184259rank=102800 of ranks=184259rank=102900 of ranks=184259rank=103000 of ranks=184259rank=103100 of ranks=184259rank=103200 of ranks=184259rank=103300 of ranks=184259rank=103400 of ranks=184259rank=103500 of ranks=184259rank=103600 of ranks=184259rank=103700 of ranks=184259rank=103800 of ranks=184259rank=103900 of ranks=184259rank=104000 of ranks=184259rank=104100 of ranks=184259rank=104200 of ranks=184259rank=104300 of ranks=184259rank=104400 of ranks=184259rank=104500 of ranks=184259rank=104600 of ranks=184259rank=104700 of ranks=184259rank=104800 of ranks=184259rank=104900 of ranks=184259rank=105000 of ranks=184259rank=105100 of ranks=184259rank=105200 of ranks=184259rank=105300 of ranks=184259rank=105400 of ranks=184259rank=105500 of ranks=184259rank=105600 of ranks=184259rank=105700 of ranks=184259rank=105800 of ranks=184259rank=105900 of ranks=184259rank=106000 of ranks=184259rank=106100 of ranks=184259rank=106200 of ranks=184259rank=106300 of ranks=184259rank=106400 of ranks=184259rank=106500 of ranks=184259rank=106600 of ranks=184259rank=106700 of ranks=184259rank=106800 of ranks=184259rank=106900 of ranks=184259rank=107000 of ranks=184259rank=107100 of ranks=184259rank=107200 of ranks=184259rank=107300 of ranks=184259rank=107400 of ranks=184259rank=107500 of ranks=184259rank=107600 of ranks=184259rank=107700 of ranks=184259rank=107800 of ranks=184259rank=107900 of ranks=184259rank=108000 of ranks=184259rank=108100 of ranks=184259rank=108200 of ranks=184259rank=108300 of ranks=184259rank=108400 of ranks=184259rank=108500 of ranks=184259rank=108600 of ranks=184259rank=108700 of ranks=184259rank=108800 of ranks=184259rank=108900 of ranks=184259rank=109000 of ranks=184259rank=109100 of ranks=184259rank=109200 of ranks=184259rank=109300 of ranks=184259rank=109400 of ranks=184259rank=109500 of ranks=184259rank=109600 of ranks=184259rank=109700 of ranks=184259rank=109800 of ranks=184259rank=109900 of ranks=184259rank=110000 of ranks=184259rank=110100 of ranks=184259rank=110200 of ranks=184259rank=110300 of ranks=184259rank=110400 of ranks=184259rank=110500 of ranks=184259rank=110600 of ranks=184259rank=110700 of ranks=184259rank=110800 of ranks=184259rank=110900 of ranks=184259rank=111000 of ranks=184259rank=111100 of ranks=184259rank=111200 of ranks=184259rank=111300 of ranks=184259rank=111400 of ranks=184259rank=111500 of ranks=184259rank=111600 of ranks=184259rank=111700 of ranks=184259rank=111800 of ranks=184259rank=111900 of ranks=184259rank=112000 of ranks=184259rank=112100 of ranks=184259rank=112200 of ranks=184259rank=112300 of ranks=184259rank=112400 of ranks=184259rank=112500 of ranks=184259rank=112600 of ranks=184259rank=112700 of ranks=184259rank=112800 of ranks=184259rank=112900 of ranks=184259rank=113000 of ranks=184259rank=113100 of ranks=184259rank=113200 of ranks=184259rank=113300 of ranks=184259rank=113400 of ranks=184259rank=113500 of ranks=184259rank=113600 of ranks=184259rank=113700 of ranks=184259rank=113800 of ranks=184259rank=113900 of ranks=184259rank=114000 of ranks=184259rank=114100 of ranks=184259rank=114200 of ranks=184259rank=114300 of ranks=184259rank=114400 of ranks=184259rank=114500 of ranks=184259rank=114600 of ranks=184259rank=114700 of ranks=184259rank=114800 of ranks=184259rank=114900 of ranks=184259rank=115000 of ranks=184259rank=115100 of ranks=184259rank=115200 of ranks=184259rank=115300 of ranks=184259rank=115400 of ranks=184259rank=115500 of ranks=184259rank=115600 of ranks=184259rank=115700 of ranks=184259rank=115800 of ranks=184259rank=115900 of ranks=184259rank=116000 of ranks=184259rank=116100 of ranks=184259rank=116200 of ranks=184259rank=116300 of ranks=184259rank=116400 of ranks=184259rank=116500 of ranks=184259rank=116600 of ranks=184259rank=116700 of ranks=184259rank=116800 of ranks=184259rank=116900 of ranks=184259rank=117000 of ranks=184259rank=117100 of ranks=184259rank=117200 of ranks=184259rank=117300 of ranks=184259rank=117400 of ranks=184259rank=117500 of ranks=184259rank=117600 of ranks=184259rank=117700 of ranks=184259rank=117800 of ranks=184259rank=117900 of ranks=184259rank=118000 of ranks=184259rank=118100 of ranks=184259rank=118200 of ranks=184259rank=118300 of ranks=184259rank=118400 of ranks=184259rank=118500 of ranks=184259rank=118600 of ranks=184259rank=118700 of ranks=184259rank=118800 of ranks=184259rank=118900 of ranks=184259rank=119000 of ranks=184259rank=119100 of ranks=184259rank=119200 of ranks=184259rank=119300 of ranks=184259rank=119400 of ranks=184259rank=119500 of ranks=184259rank=119600 of ranks=184259rank=119700 of ranks=184259rank=119800 of ranks=184259rank=119900 of ranks=184259rank=120000 of ranks=184259rank=120100 of ranks=184259rank=120200 of ranks=184259rank=120300 of ranks=184259rank=120400 of ranks=184259rank=120500 of ranks=184259rank=120600 of ranks=184259rank=120700 of ranks=184259rank=120800 of ranks=184259rank=120900 of ranks=184259rank=121000 of ranks=184259rank=121100 of ranks=184259rank=121200 of ranks=184259rank=121300 of ranks=184259rank=121400 of ranks=184259rank=121500 of ranks=184259rank=121600 of ranks=184259rank=121700 of ranks=184259rank=121800 of ranks=184259rank=121900 of ranks=184259rank=122000 of ranks=184259rank=122100 of ranks=184259rank=122200 of ranks=184259rank=122300 of ranks=184259rank=122400 of ranks=184259rank=122500 of ranks=184259rank=122600 of ranks=184259rank=122700 of ranks=184259rank=122800 of ranks=184259rank=122900 of ranks=184259rank=123000 of ranks=184259rank=123100 of ranks=184259rank=123200 of ranks=184259rank=123300 of ranks=184259rank=123400 of ranks=184259rank=123500 of ranks=184259rank=123600 of ranks=184259rank=123700 of ranks=184259rank=123800 of ranks=184259rank=123900 of ranks=184259rank=124000 of ranks=184259rank=124100 of ranks=184259rank=124200 of ranks=184259rank=124300 of ranks=184259rank=124400 of ranks=184259rank=124500 of ranks=184259rank=124600 of ranks=184259rank=124700 of ranks=184259rank=124800 of ranks=184259rank=124900 of ranks=184259rank=125000 of ranks=184259rank=125100 of ranks=184259rank=125200 of ranks=184259rank=125300 of ranks=184259rank=125400 of ranks=184259rank=125500 of ranks=184259rank=125600 of ranks=184259rank=125700 of ranks=184259rank=125800 of ranks=184259rank=125900 of ranks=184259rank=126000 of ranks=184259rank=126100 of ranks=184259rank=126200 of ranks=184259rank=126300 of ranks=184259rank=126400 of ranks=184259rank=126500 of ranks=184259rank=126600 of ranks=184259rank=126700 of ranks=184259rank=126800 of ranks=184259rank=126900 of ranks=184259rank=127000 of ranks=184259rank=127100 of ranks=184259rank=127200 of ranks=184259rank=127300 of ranks=184259rank=127400 of ranks=184259rank=127500 of ranks=184259rank=127600 of ranks=184259rank=127700 of ranks=184259rank=127800 of ranks=184259rank=127900 of ranks=184259rank=128000 of ranks=184259rank=128100 of ranks=184259rank=128200 of ranks=184259rank=128300 of ranks=184259rank=128400 of ranks=184259rank=128500 of ranks=184259rank=128600 of ranks=184259rank=128700 of ranks=184259rank=128800 of ranks=184259rank=128900 of ranks=184259rank=129000 of ranks=184259rank=129100 of ranks=184259rank=129200 of ranks=184259rank=129300 of ranks=184259rank=129400 of ranks=184259rank=129500 of ranks=184259rank=129600 of ranks=184259rank=129700 of ranks=184259rank=129800 of ranks=184259rank=129900 of ranks=184259rank=130000 of ranks=184259rank=130100 of ranks=184259rank=130200 of ranks=184259rank=130300 of ranks=184259rank=130400 of ranks=184259rank=130500 of ranks=184259rank=130600 of ranks=184259rank=130700 of ranks=184259rank=130800 of ranks=184259rank=130900 of ranks=184259rank=131000 of ranks=184259rank=131100 of ranks=184259rank=131200 of ranks=184259rank=131300 of ranks=184259rank=131400 of ranks=184259rank=131500 of ranks=184259rank=131600 of ranks=184259rank=131700 of ranks=184259rank=131800 of ranks=184259rank=131900 of ranks=184259rank=132000 of ranks=184259rank=132100 of ranks=184259rank=132200 of ranks=184259rank=132300 of ranks=184259rank=132400 of ranks=184259rank=132500 of ranks=184259rank=132600 of ranks=184259rank=132700 of ranks=184259rank=132800 of ranks=184259rank=132900 of ranks=184259rank=133000 of ranks=184259rank=133100 of ranks=184259rank=133200 of ranks=184259rank=133300 of ranks=184259rank=133400 of ranks=184259rank=133500 of ranks=184259rank=133600 of ranks=184259rank=133700 of ranks=184259rank=133800 of ranks=184259rank=133900 of ranks=184259rank=134000 of ranks=184259rank=134100 of ranks=184259rank=134200 of ranks=184259rank=134300 of ranks=184259rank=134400 of ranks=184259rank=134500 of ranks=184259rank=134600 of ranks=184259rank=134700 of ranks=184259rank=134800 of ranks=184259rank=134900 of ranks=184259rank=135000 of ranks=184259rank=135100 of ranks=184259rank=135200 of ranks=184259rank=135300 of ranks=184259rank=135400 of ranks=184259rank=135500 of ranks=184259rank=135600 of ranks=184259rank=135700 of ranks=184259rank=135800 of ranks=184259rank=135900 of ranks=184259rank=136000 of ranks=184259rank=136100 of ranks=184259rank=136200 of ranks=184259rank=136300 of ranks=184259rank=136400 of ranks=184259rank=136500 of ranks=184259rank=136600 of ranks=184259rank=136700 of ranks=184259rank=136800 of ranks=184259rank=136900 of ranks=184259rank=137000 of ranks=184259rank=137100 of ranks=184259rank=137200 of ranks=184259rank=137300 of ranks=184259rank=137400 of ranks=184259rank=137500 of ranks=184259rank=137600 of ranks=184259rank=137700 of ranks=184259rank=137800 of ranks=184259rank=137900 of ranks=184259rank=138000 of ranks=184259rank=138100 of ranks=184259rank=138200 of ranks=184259rank=138300 of ranks=184259rank=138400 of ranks=184259rank=138500 of ranks=184259rank=138600 of ranks=184259rank=138700 of ranks=184259rank=138800 of ranks=184259rank=138900 of ranks=184259rank=139000 of ranks=184259rank=139100 of ranks=184259rank=139200 of ranks=184259rank=139300 of ranks=184259rank=139400 of ranks=184259rank=139500 of ranks=184259rank=139600 of ranks=184259rank=139700 of ranks=184259rank=139800 of ranks=184259rank=139900 of ranks=184259rank=140000 of ranks=184259rank=140100 of ranks=184259rank=140200 of ranks=184259rank=140300 of ranks=184259rank=140400 of ranks=184259rank=140500 of ranks=184259rank=140600 of ranks=184259rank=140700 of ranks=184259rank=140800 of ranks=184259rank=140900 of ranks=184259rank=141000 of ranks=184259rank=141100 of ranks=184259rank=141200 of ranks=184259rank=141300 of ranks=184259rank=141400 of ranks=184259rank=141500 of ranks=184259rank=141600 of ranks=184259rank=141700 of ranks=184259rank=141800 of ranks=184259rank=141900 of ranks=184259rank=142000 of ranks=184259rank=142100 of ranks=184259rank=142200 of ranks=184259rank=142300 of ranks=184259rank=142400 of ranks=184259rank=142500 of ranks=184259rank=142600 of ranks=184259rank=142700 of ranks=184259rank=142800 of ranks=184259rank=142900 of ranks=184259rank=143000 of ranks=184259rank=143100 of ranks=184259rank=143200 of ranks=184259rank=143300 of ranks=184259rank=143400 of ranks=184259rank=143500 of ranks=184259rank=143600 of ranks=184259rank=143700 of ranks=184259rank=143800 of ranks=184259rank=143900 of ranks=184259rank=144000 of ranks=184259rank=144100 of ranks=184259rank=144200 of ranks=184259rank=144300 of ranks=184259rank=144400 of ranks=184259rank=144500 of ranks=184259rank=144600 of ranks=184259rank=144700 of ranks=184259rank=144800 of ranks=184259rank=144900 of ranks=184259rank=145000 of ranks=184259rank=145100 of ranks=184259rank=145200 of ranks=184259rank=145300 of ranks=184259rank=145400 of ranks=184259rank=145500 of ranks=184259rank=145600 of ranks=184259rank=145700 of ranks=184259rank=145800 of ranks=184259rank=145900 of ranks=184259rank=146000 of ranks=184259rank=146100 of ranks=184259rank=146200 of ranks=184259rank=146300 of ranks=184259rank=146400 of ranks=184259rank=146500 of ranks=184259rank=146600 of ranks=184259rank=146700 of ranks=184259rank=146800 of ranks=184259rank=146900 of ranks=184259rank=147000 of ranks=184259rank=147100 of ranks=184259rank=147200 of ranks=184259rank=147300 of ranks=184259rank=147400 of ranks=184259rank=147500 of ranks=184259rank=147600 of ranks=184259rank=147700 of ranks=184259rank=147800 of ranks=184259rank=147900 of ranks=184259rank=148000 of ranks=184259rank=148100 of ranks=184259rank=148200 of ranks=184259rank=148300 of ranks=184259rank=148400 of ranks=184259rank=148500 of ranks=184259rank=148600 of ranks=184259rank=148700 of ranks=184259rank=148800 of ranks=184259rank=148900 of ranks=184259rank=149000 of ranks=184259rank=149100 of ranks=184259rank=149200 of ranks=184259rank=149300 of ranks=184259rank=149400 of ranks=184259rank=149500 of ranks=184259rank=149600 of ranks=184259rank=149700 of ranks=184259rank=149800 of ranks=184259rank=149900 of ranks=184259rank=150000 of ranks=184259rank=150100 of ranks=184259rank=150200 of ranks=184259rank=150300 of ranks=184259rank=150400 of ranks=184259rank=150500 of ranks=184259rank=150600 of ranks=184259rank=150700 of ranks=184259rank=150800 of ranks=184259rank=150900 of ranks=184259rank=151000 of ranks=184259rank=151100 of ranks=184259rank=151200 of ranks=184259rank=151300 of ranks=184259rank=151400 of ranks=184259rank=151500 of ranks=184259rank=151600 of ranks=184259rank=151700 of ranks=184259rank=151800 of ranks=184259rank=151900 of ranks=184259rank=152000 of ranks=184259rank=152100 of ranks=184259rank=152200 of ranks=184259rank=152300 of ranks=184259rank=152400 of ranks=184259rank=152500 of ranks=184259rank=152600 of ranks=184259rank=152700 of ranks=184259rank=152800 of ranks=184259rank=152900 of ranks=184259rank=153000 of ranks=184259rank=153100 of ranks=184259rank=153200 of ranks=184259rank=153300 of ranks=184259rank=153400 of ranks=184259rank=153500 of ranks=184259rank=153600 of ranks=184259rank=153700 of ranks=184259rank=153800 of ranks=184259rank=153900 of ranks=184259rank=154000 of ranks=184259rank=154100 of ranks=184259rank=154200 of ranks=184259rank=154300 of ranks=184259rank=154400 of ranks=184259rank=154500 of ranks=184259rank=154600 of ranks=184259rank=154700 of ranks=184259rank=154800 of ranks=184259rank=154900 of ranks=184259rank=155000 of ranks=184259rank=155100 of ranks=184259rank=155200 of ranks=184259rank=155300 of ranks=184259rank=155400 of ranks=184259rank=155500 of ranks=184259rank=155600 of ranks=184259rank=155700 of ranks=184259rank=155800 of ranks=184259rank=155900 of ranks=184259rank=156000 of ranks=184259rank=156100 of ranks=184259rank=156200 of ranks=184259rank=156300 of ranks=184259rank=156400 of ranks=184259rank=156500 of ranks=184259rank=156600 of ranks=184259rank=156700 of ranks=184259rank=156800 of ranks=184259rank=156900 of ranks=184259rank=157000 of ranks=184259rank=157100 of ranks=184259rank=157200 of ranks=184259rank=157300 of ranks=184259rank=157400 of ranks=184259rank=157500 of ranks=184259rank=157600 of ranks=184259rank=157700 of ranks=184259rank=157800 of ranks=184259rank=157900 of ranks=184259rank=158000 of ranks=184259rank=158100 of ranks=184259rank=158200 of ranks=184259rank=158300 of ranks=184259rank=158400 of ranks=184259rank=158500 of ranks=184259rank=158600 of ranks=184259rank=158700 of ranks=184259rank=158800 of ranks=184259rank=158900 of ranks=184259rank=159000 of ranks=184259rank=159100 of ranks=184259rank=159200 of ranks=184259rank=159300 of ranks=184259rank=159400 of ranks=184259rank=159500 of ranks=184259rank=159600 of ranks=184259rank=159700 of ranks=184259rank=159800 of ranks=184259rank=159900 of ranks=184259rank=160000 of ranks=184259rank=160100 of ranks=184259rank=160200 of ranks=184259rank=160300 of ranks=184259rank=160400 of ranks=184259rank=160500 of ranks=184259rank=160600 of ranks=184259rank=160700 of ranks=184259rank=160800 of ranks=184259rank=160900 of ranks=184259rank=161000 of ranks=184259rank=161100 of ranks=184259rank=161200 of ranks=184259rank=161300 of ranks=184259rank=161400 of ranks=184259rank=161500 of ranks=184259rank=161600 of ranks=184259rank=161700 of ranks=184259rank=161800 of ranks=184259rank=161900 of ranks=184259rank=162000 of ranks=184259rank=162100 of ranks=184259rank=162200 of ranks=184259rank=162300 of ranks=184259rank=162400 of ranks=184259rank=162500 of ranks=184259rank=162600 of ranks=184259rank=162700 of ranks=184259rank=162800 of ranks=184259rank=162900 of ranks=184259rank=163000 of ranks=184259rank=163100 of ranks=184259rank=163200 of ranks=184259rank=163300 of ranks=184259rank=163400 of ranks=184259rank=163500 of ranks=184259rank=163600 of ranks=184259rank=163700 of ranks=184259rank=163800 of ranks=184259rank=163900 of ranks=184259rank=164000 of ranks=184259rank=164100 of ranks=184259rank=164200 of ranks=184259rank=164300 of ranks=184259rank=164400 of ranks=184259rank=164500 of ranks=184259rank=164600 of ranks=184259rank=164700 of ranks=184259rank=164800 of ranks=184259rank=164900 of ranks=184259rank=165000 of ranks=184259rank=165100 of ranks=184259rank=165200 of ranks=184259rank=165300 of ranks=184259rank=165400 of ranks=184259rank=165500 of ranks=184259rank=165600 of ranks=184259rank=165700 of ranks=184259rank=165800 of ranks=184259rank=165900 of ranks=184259rank=166000 of ranks=184259rank=166100 of ranks=184259rank=166200 of ranks=184259rank=166300 of ranks=184259rank=166400 of ranks=184259rank=166500 of ranks=184259rank=166600 of ranks=184259rank=166700 of ranks=184259rank=166800 of ranks=184259rank=166900 of ranks=184259rank=167000 of ranks=184259rank=167100 of ranks=184259rank=167200 of ranks=184259rank=167300 of ranks=184259rank=167400 of ranks=184259rank=167500 of ranks=184259rank=167600 of ranks=184259rank=167700 of ranks=184259rank=167800 of ranks=184259rank=167900 of ranks=184259rank=168000 of ranks=184259rank=168100 of ranks=184259rank=168200 of ranks=184259rank=168300 of ranks=184259rank=168400 of ranks=184259rank=168500 of ranks=184259rank=168600 of ranks=184259rank=168700 of ranks=184259rank=168800 of ranks=184259rank=168900 of ranks=184259rank=169000 of ranks=184259rank=169100 of ranks=184259rank=169200 of ranks=184259rank=169300 of ranks=184259rank=169400 of ranks=184259rank=169500 of ranks=184259rank=169600 of ranks=184259rank=169700 of ranks=184259rank=169800 of ranks=184259rank=169900 of ranks=184259rank=170000 of ranks=184259rank=170100 of ranks=184259rank=170200 of ranks=184259rank=170300 of ranks=184259rank=170400 of ranks=184259rank=170500 of ranks=184259rank=170600 of ranks=184259rank=170700 of ranks=184259rank=170800 of ranks=184259rank=170900 of ranks=184259rank=171000 of ranks=184259rank=171100 of ranks=184259rank=171200 of ranks=184259rank=171300 of ranks=184259rank=171400 of ranks=184259rank=171500 of ranks=184259rank=171600 of ranks=184259rank=171700 of ranks=184259rank=171800 of ranks=184259rank=171900 of ranks=184259rank=172000 of ranks=184259rank=172100 of ranks=184259rank=172200 of ranks=184259rank=172300 of ranks=184259rank=172400 of ranks=184259rank=172500 of ranks=184259rank=172600 of ranks=184259rank=172700 of ranks=184259rank=172800 of ranks=184259rank=172900 of ranks=184259rank=173000 of ranks=184259rank=173100 of ranks=184259rank=173200 of ranks=184259rank=173300 of ranks=184259rank=173400 of ranks=184259rank=173500 of ranks=184259rank=173600 of ranks=184259rank=173700 of ranks=184259rank=173800 of ranks=184259rank=173900 of ranks=184259rank=174000 of ranks=184259rank=174100 of ranks=184259rank=174200 of ranks=184259rank=174300 of ranks=184259rank=174400 of ranks=184259rank=174500 of ranks=184259rank=174600 of ranks=184259rank=174700 of ranks=184259rank=174800 of ranks=184259rank=174900 of ranks=184259rank=175000 of ranks=184259rank=175100 of ranks=184259rank=175200 of ranks=184259rank=175300 of ranks=184259rank=175400 of ranks=184259rank=175500 of ranks=184259rank=175600 of ranks=184259rank=175700 of ranks=184259rank=175800 of ranks=184259rank=175900 of ranks=184259rank=176000 of ranks=184259rank=176100 of ranks=184259rank=176200 of ranks=184259rank=176300 of ranks=184259rank=176400 of ranks=184259rank=176500 of ranks=184259rank=176600 of ranks=184259rank=176700 of ranks=184259rank=176800 of ranks=184259rank=176900 of ranks=184259rank=177000 of ranks=184259rank=177100 of ranks=184259rank=177200 of ranks=184259rank=177300 of ranks=184259rank=177400 of ranks=184259rank=177500 of ranks=184259rank=177600 of ranks=184259rank=177700 of ranks=184259rank=177800 of ranks=184259rank=177900 of ranks=184259rank=178000 of ranks=184259rank=178100 of ranks=184259rank=178200 of ranks=184259rank=178300 of ranks=184259rank=178400 of ranks=184259rank=178500 of ranks=184259rank=178600 of ranks=184259rank=178700 of ranks=184259rank=178800 of ranks=184259rank=178900 of ranks=184259rank=179000 of ranks=184259rank=179100 of ranks=184259rank=179200 of ranks=184259rank=179300 of ranks=184259rank=179400 of ranks=184259rank=179500 of ranks=184259rank=179600 of ranks=184259rank=179700 of ranks=184259rank=179800 of ranks=184259rank=179900 of ranks=184259rank=180000 of ranks=184259rank=180100 of ranks=184259rank=180200 of ranks=184259rank=180300 of ranks=184259rank=180400 of ranks=184259rank=180500 of ranks=184259rank=180600 of ranks=184259rank=180700 of ranks=184259rank=180800 of ranks=184259rank=180900 of ranks=184259rank=181000 of ranks=184259rank=181100 of ranks=184259rank=181200 of ranks=184259rank=181300 of ranks=184259rank=181400 of ranks=184259rank=181500 of ranks=184259rank=181600 of ranks=184259rank=181700 of ranks=184259rank=181800 of ranks=184259rank=181900 of ranks=184259rank=182000 of ranks=184259rank=182100 of ranks=184259rank=182200 of ranks=184259rank=182300 of ranks=184259rank=182400 of ranks=184259rank=182500 of ranks=184259rank=182600 of ranks=184259rank=182700 of ranks=184259rank=182800 of ranks=184259rank=182900 of ranks=184259rank=183000 of ranks=184259rank=183100 of ranks=184259rank=183200 of ranks=184259rank=183300 of ranks=184259rank=183400 of ranks=184259rank=183500 of ranks=184259rank=183600 of ranks=184259rank=183700 of ranks=184259rank=183800 of ranks=184259rank=183900 of ranks=184259rank=184000 of ranks=184259rank=184100 of ranks=184259rank=184200 of ranks=184259

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              66.3831    412  10261     86    498           60.8538
   1 car                    93.0111  49047  65822   1269  50316           67.0155
   2 truck                  67.1616   1601  17269    224   1825           49.8933
   3 bus                    30.6709    284   5472     82    366           72.3503
   4 pedestrian             70.7314   3709  30382    550   4259           47.2477

for conf_thresh=0.25, precision=0.79, recall=0.83, F1 score=0.81
for conf_thresh=0.25, TP=47778, FP=12399, FN=9486, average IoU=65.19%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=65.59%
Total detection time: 86 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
New best mAP, saving weights!
Saving weights to /workspace/.cache/splits/combined_best.weights
1813: loss=7.269, avg loss=7.042, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 116032 images, time remaining=7.4 hours
1814: loss=6.544, avg loss=6.993, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 116096 images, time remaining=7.4 hours
1815: loss=6.205, avg loss=6.914, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 116160 images, time remaining=7.4 hours
1816: loss=6.362, avg loss=6.859, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.9 seconds, 116224 images, time remaining=7.4 hours
1817: loss=7.771, avg loss=6.950, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 116288 images, time remaining=7.4 hours
1818: loss=6.809, avg loss=6.936, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 116352 images, time remaining=7.4 hours
1819: loss=6.377, avg loss=6.880, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 116416 images, time remaining=7.4 hours
1820: loss=6.312, avg loss=6.823, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 116480 images, time remaining=7.4 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b4b4000000
1821: loss=6.240, avg loss=6.765, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 116544 images, time remaining=7.4 hours
1822: loss=6.244, avg loss=6.713, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 116608 images, time remaining=7.4 hours
1823: loss=5.696, avg loss=6.611, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 116672 images, time remaining=7.4 hours
1824: loss=5.684, avg loss=6.518, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 116736 images, time remaining=7.4 hours
1825: loss=6.240, avg loss=6.490, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=2.4 seconds, 116800 images, time remaining=7.3 hours
1826: loss=5.731, avg loss=6.415, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 116864 images, time remaining=7.3 hours
1827: loss=5.458, avg loss=6.319, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 116928 images, time remaining=7.3 hours
1828: loss=6.279, avg loss=6.315, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 116992 images, time remaining=7.3 hours
1829: loss=6.306, avg loss=6.314, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=2.4 seconds, 117056 images, time remaining=7.3 hours
1830: loss=5.890, avg loss=6.272, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 117120 images, time remaining=7.3 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b6b4000000
1831: loss=5.660, avg loss=6.210, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 117184 images, time remaining=7.3 hours
1832: loss=5.645, avg loss=6.154, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 117248 images, time remaining=7.3 hours
1833: loss=5.935, avg loss=6.132, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 117312 images, time remaining=7.3 hours
1834: loss=5.685, avg loss=6.087, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 117376 images, time remaining=7.3 hours
1835: loss=6.608, avg loss=6.139, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 117440 images, time remaining=7.3 hours
1836: loss=6.115, avg loss=6.137, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 117504 images, time remaining=7.3 hours
1837: loss=4.971, avg loss=6.020, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 117568 images, time remaining=7.3 hours
1838: loss=6.934, avg loss=6.112, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 117632 images, time remaining=7.3 hours
1839: loss=4.901, avg loss=5.991, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 117696 images, time remaining=7.3 hours
1840: loss=5.817, avg loss=5.973, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 117760 images, time remaining=7.3 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1841: loss=6.153, avg loss=5.991, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 117824 images, time remaining=7.3 hours
1842: loss=7.152, avg loss=6.107, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 117888 images, time remaining=7.3 hours
1843: loss=6.426, avg loss=6.139, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.1 seconds, train=4.0 seconds, 117952 images, time remaining=7.3 hours
1844: loss=6.841, avg loss=6.209, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=3.9 seconds, train=4.2 seconds, 118016 images, time remaining=7.3 hours
1845: loss=6.235, avg loss=6.212, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.6 seconds, train=4.1 seconds, 118080 images, time remaining=7.3 hours
1846: loss=5.498, avg loss=6.140, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=4.1 seconds, 118144 images, time remaining=7.3 hours
1847: loss=6.916, avg loss=6.218, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 118208 images, time remaining=7.3 hours
1848: loss=6.089, avg loss=6.205, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 118272 images, time remaining=7.3 hours
1849: loss=6.839, avg loss=6.269, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 118336 images, time remaining=7.3 hours
1850: loss=6.378, avg loss=6.280, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 118400 images, time remaining=7.3 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1851: loss=9.272, avg loss=6.579, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.6 seconds, train=5.9 seconds, 118464 images, time remaining=7.3 hours
1852: loss=7.007, avg loss=6.622, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.3 seconds, train=5.9 seconds, 118528 images, time remaining=7.3 hours
1853: loss=8.310, avg loss=6.790, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.1 seconds, train=6.0 seconds, 118592 images, time remaining=7.3 hours
1854: loss=7.076, avg loss=6.819, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 118656 images, time remaining=7.3 hours
1855: loss=8.678, avg loss=7.005, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 118720 images, time remaining=7.3 hours
1856: loss=7.015, avg loss=7.006, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 118784 images, time remaining=7.3 hours
1857: loss=6.799, avg loss=6.985, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 118848 images, time remaining=7.3 hours
1858: loss=5.867, avg loss=6.873, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 118912 images, time remaining=7.3 hours
1859: loss=7.324, avg loss=6.918, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.3 seconds, train=5.7 seconds, 118976 images, time remaining=7.3 hours
1860: loss=6.691, avg loss=6.896, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.5 seconds, train=5.6 seconds, 119040 images, time remaining=7.3 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b6c4c00000
1861: loss=8.040, avg loss=7.010, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 119104 images, time remaining=7.3 hours
1862: loss=8.534, avg loss=7.162, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 119168 images, time remaining=7.3 hours
1863: loss=6.875, avg loss=7.134, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 119232 images, time remaining=7.3 hours
1864: loss=6.971, avg loss=7.117, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 119296 images, time remaining=7.3 hours
1865: loss=7.182, avg loss=7.124, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 119360 images, time remaining=7.3 hours
1866: loss=6.957, avg loss=7.107, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 119424 images, time remaining=7.3 hours
1867: loss=6.877, avg loss=7.084, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 119488 images, time remaining=7.3 hours
1868: loss=6.732, avg loss=7.049, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 119552 images, time remaining=7.3 hours
1869: loss=6.899, avg loss=7.034, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 119616 images, time remaining=7.3 hours
1870: loss=6.041, avg loss=6.935, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 119680 images, time remaining=7.3 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
1871: loss=7.307, avg loss=6.972, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=2.9 seconds, 119744 images, time remaining=7.3 hours
1872: loss=5.744, avg loss=6.849, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 119808 images, time remaining=7.3 hours
1873: loss=5.966, avg loss=6.761, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 119872 images, time remaining=7.3 hours
1874: loss=6.288, avg loss=6.714, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.3 seconds, train=2.8 seconds, 119936 images, time remaining=7.3 hours
1875: loss=6.942, avg loss=6.736, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 120000 images, time remaining=7.3 hours
1876: loss=7.093, avg loss=6.772, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.3 seconds, train=2.8 seconds, 120064 images, time remaining=7.3 hours
1877: loss=7.252, avg loss=6.820, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.4 seconds, train=2.8 seconds, 120128 images, time remaining=7.3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1878: loss=6.451, avg loss=6.783, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=3.3 seconds, train=2.7 seconds, 120192 images, time remaining=7.3 hours
1879: loss=7.374, avg loss=6.842, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.9 seconds, train=2.9 seconds, 120256 images, time remaining=7.3 hours
1880: loss=6.231, avg loss=6.781, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.9 seconds, 120320 images, time remaining=7.3 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b510400000
1881: loss=7.278, avg loss=6.831, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 120384 images, time remaining=7.2 hours
1882: loss=6.477, avg loss=6.795, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 120448 images, time remaining=7.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1883: loss=7.374, avg loss=6.853, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.9 seconds, train=1.9 seconds, 120512 images, time remaining=7.2 hours
1884: loss=6.885, avg loss=6.856, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 120576 images, time remaining=7.2 hours
1885: loss=7.056, avg loss=6.876, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 120640 images, time remaining=7.2 hours
1886: loss=7.449, avg loss=6.934, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 120704 images, time remaining=7.2 hours
1887: loss=6.502, avg loss=6.890, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 120768 images, time remaining=7.2 hours
1888: loss=7.100, avg loss=6.911, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 120832 images, time remaining=7.2 hours
1889: loss=5.196, avg loss=6.740, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 120896 images, time remaining=7.2 hours
1890: loss=7.095, avg loss=6.775, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 120960 images, time remaining=7.2 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1891: loss=12.498, avg loss=7.348, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 121024 images, time remaining=7.2 hours
1892: loss=9.019, avg loss=7.515, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=3.2 seconds, train=5.5 seconds, 121088 images, time remaining=7.2 hours
1893: loss=7.495, avg loss=7.513, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.0 seconds, train=5.3 seconds, 121152 images, time remaining=7.2 hours
1894: loss=7.419, avg loss=7.503, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 121216 images, time remaining=7.2 hours
1895: loss=8.126, avg loss=7.566, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 121280 images, time remaining=7.2 hours
1896: loss=8.678, avg loss=7.677, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 121344 images, time remaining=7.2 hours
1897: loss=8.552, avg loss=7.764, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=5.4 seconds, 121408 images, time remaining=7.2 hours
1898: loss=8.136, avg loss=7.802, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 121472 images, time remaining=7.2 hours
1899: loss=7.619, avg loss=7.783, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 121536 images, time remaining=7.2 hours
1900: loss=8.129, avg loss=7.818, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.3 seconds, train=5.3 seconds, 121600 images, time remaining=7.2 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 896x672
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
1901: loss=6.934, avg loss=7.729, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.4 seconds, train=2.6 seconds, 121664 images, time remaining=7.2 hours
1902: loss=6.536, avg loss=7.610, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=2.5 seconds, 121728 images, time remaining=7.2 hours
1903: loss=6.259, avg loss=7.475, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 121792 images, time remaining=7.2 hours
1904: loss=5.509, avg loss=7.278, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 121856 images, time remaining=7.2 hours
1905: loss=7.265, avg loss=7.277, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.5 seconds, 121920 images, time remaining=7.2 hours
1906: loss=6.691, avg loss=7.218, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.5 seconds, 121984 images, time remaining=7.2 hours
1907: loss=6.520, avg loss=7.149, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 122048 images, time remaining=7.2 hours
1908: loss=7.741, avg loss=7.208, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 122112 images, time remaining=7.2 hours
1909: loss=5.747, avg loss=7.062, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 122176 images, time remaining=7.2 hours
1910: loss=6.601, avg loss=7.016, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 122240 images, time remaining=7.2 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
1911: loss=6.340, avg loss=6.948, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 122304 images, time remaining=7.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1912: loss=7.518, avg loss=7.005, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=5.0 seconds, train=2.7 seconds, 122368 images, time remaining=7.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1913: loss=6.290, avg loss=6.934, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=3.5 seconds, train=2.8 seconds, 122432 images, time remaining=7.2 hours
1914: loss=5.965, avg loss=6.837, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 122496 images, time remaining=7.2 hours
1915: loss=5.675, avg loss=6.721, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=2.9 seconds, 122560 images, time remaining=7.2 hours
1916: loss=6.052, avg loss=6.654, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 122624 images, time remaining=7.2 hours
1917: loss=6.244, avg loss=6.613, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.9 seconds, 122688 images, time remaining=7.2 hours
1918: loss=6.144, avg loss=6.566, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 122752 images, time remaining=7.2 hours
1919: loss=6.622, avg loss=6.572, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 122816 images, time remaining=7.2 hours
1920: loss=5.861, avg loss=6.500, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 122880 images, time remaining=7.2 hours
Resizing, random_coef=1.40, batch=4, 1184x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1921: loss=7.477, avg loss=6.598, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 122944 images, time remaining=7.2 hours
1922: loss=7.250, avg loss=6.663, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=4.5 seconds, 123008 images, time remaining=7.2 hours
1923: loss=7.247, avg loss=6.722, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.5 seconds, 123072 images, time remaining=7.2 hours
1924: loss=7.121, avg loss=6.761, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 123136 images, time remaining=7.2 hours
1925: loss=6.275, avg loss=6.713, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.5 seconds, 123200 images, time remaining=7.2 hours
1926: loss=6.143, avg loss=6.656, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.2 seconds, train=4.6 seconds, 123264 images, time remaining=7.2 hours
1927: loss=4.873, avg loss=6.478, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 123328 images, time remaining=7.2 hours
1928: loss=5.696, avg loss=6.399, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.5 seconds, 123392 images, time remaining=7.2 hours
1929: loss=6.674, avg loss=6.427, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 123456 images, time remaining=7.2 hours
1930: loss=7.337, avg loss=6.518, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 123520 images, time remaining=7.2 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b546a00000
1931: loss=5.932, avg loss=6.459, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 123584 images, time remaining=7.2 hours
1932: loss=5.864, avg loss=6.400, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 123648 images, time remaining=7.2 hours
1933: loss=6.128, avg loss=6.373, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 123712 images, time remaining=7.2 hours
1934: loss=6.543, avg loss=6.390, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 123776 images, time remaining=7.2 hours
1935: loss=5.413, avg loss=6.292, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 123840 images, time remaining=7.2 hours
1936: loss=5.995, avg loss=6.262, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 123904 images, time remaining=7.2 hours
1937: loss=6.801, avg loss=6.316, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 123968 images, time remaining=7.2 hours
1938: loss=6.153, avg loss=6.300, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 124032 images, time remaining=7.2 hours
1939: loss=5.648, avg loss=6.235, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 124096 images, time remaining=7.1 hours
1940: loss=5.419, avg loss=6.153, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 124160 images, time remaining=7.1 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b747a00000
1941: loss=7.902, avg loss=6.328, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 124224 images, time remaining=7.1 hours
1942: loss=7.019, avg loss=6.397, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 124288 images, time remaining=7.1 hours
1943: loss=5.863, avg loss=6.344, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 124352 images, time remaining=7.1 hours
1944: loss=6.093, avg loss=6.319, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 124416 images, time remaining=7.1 hours
1945: loss=5.433, avg loss=6.230, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 124480 images, time remaining=7.1 hours
1946: loss=6.555, avg loss=6.263, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 124544 images, time remaining=7.1 hours
1947: loss=6.981, avg loss=6.334, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 124608 images, time remaining=7.1 hours
1948: loss=6.267, avg loss=6.328, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 124672 images, time remaining=7.1 hours
1949: loss=7.722, avg loss=6.467, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 124736 images, time remaining=7.1 hours
1950: loss=5.531, avg loss=6.373, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 124800 images, time remaining=7.1 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b4df800000
1951: loss=6.023, avg loss=6.338, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 124864 images, time remaining=7.1 hours
1952: loss=5.763, avg loss=6.281, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 124928 images, time remaining=7.1 hours
1953: loss=6.120, avg loss=6.265, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 124992 images, time remaining=7.1 hours
1954: loss=6.213, avg loss=6.260, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 125056 images, time remaining=7.1 hours
1955: loss=5.416, avg loss=6.175, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 125120 images, time remaining=7.1 hours
1956: loss=6.676, avg loss=6.225, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 125184 images, time remaining=7.1 hours
1957: loss=5.951, avg loss=6.198, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 125248 images, time remaining=7.1 hours
1958: loss=5.247, avg loss=6.103, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 125312 images, time remaining=7.1 hours
1959: loss=5.875, avg loss=6.080, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 125376 images, time remaining=7.1 hours
1960: loss=5.243, avg loss=5.996, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 125440 images, time remaining=7.1 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1961: loss=7.358, avg loss=6.133, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 125504 images, time remaining=7.1 hours
1962: loss=7.216, avg loss=6.241, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=3.4 seconds, train=4.6 seconds, 125568 images, time remaining=7.1 hours
1963: loss=6.102, avg loss=6.227, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 125632 images, time remaining=7.1 hours
1964: loss=7.100, avg loss=6.314, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 125696 images, time remaining=7.1 hours
1965: loss=7.328, avg loss=6.416, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 125760 images, time remaining=7.1 hours
1966: loss=6.638, avg loss=6.438, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 125824 images, time remaining=7.1 hours
1967: loss=6.673, avg loss=6.461, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 125888 images, time remaining=7.1 hours
1968: loss=6.701, avg loss=6.485, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 125952 images, time remaining=7.1 hours
1969: loss=7.965, avg loss=6.633, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 126016 images, time remaining=7.1 hours
1970: loss=7.011, avg loss=6.671, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 126080 images, time remaining=7.1 hours
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1971: loss=7.035, avg loss=6.707, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=4.2 seconds, 126144 images, time remaining=7.1 hours
1972: loss=5.632, avg loss=6.600, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 126208 images, time remaining=7.1 hours
1973: loss=6.740, avg loss=6.614, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 126272 images, time remaining=7.1 hours
1974: loss=6.732, avg loss=6.626, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 126336 images, time remaining=7.1 hours
1975: loss=7.487, avg loss=6.712, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 126400 images, time remaining=7.1 hours
1976: loss=5.728, avg loss=6.613, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.6 seconds, train=4.0 seconds, 126464 images, time remaining=7.1 hours
1977: loss=5.931, avg loss=6.545, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 126528 images, time remaining=7.1 hours
1978: loss=6.615, avg loss=6.552, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 126592 images, time remaining=7.1 hours
1979: loss=5.904, avg loss=6.487, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.1 seconds, train=4.1 seconds, 126656 images, time remaining=7.1 hours
1980: loss=6.452, avg loss=6.484, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 126720 images, time remaining=7.1 hours
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14b731600000
1981: loss=6.421, avg loss=6.478, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 126784 images, time remaining=7.1 hours
1982: loss=6.813, avg loss=6.511, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 126848 images, time remaining=7.1 hours
1983: loss=5.346, avg loss=6.395, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 126912 images, time remaining=7.1 hours
1984: loss=6.639, avg loss=6.419, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 126976 images, time remaining=7.1 hours
1985: loss=5.873, avg loss=6.364, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 127040 images, time remaining=7.1 hours
1986: loss=5.472, avg loss=6.275, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 127104 images, time remaining=7.1 hours
1987: loss=5.887, avg loss=6.236, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 127168 images, time remaining=7.1 hours
1988: loss=6.358, avg loss=6.248, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 127232 images, time remaining=7.1 hours
1989: loss=5.021, avg loss=6.126, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 127296 images, time remaining=7.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
1990: loss=5.381, avg loss=6.051, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.3 seconds, train=2.3 seconds, 127360 images, time remaining=7.1 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
1991: loss=6.927, avg loss=6.139, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 127424 images, time remaining=7.1 hours
1992: loss=5.985, avg loss=6.123, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 127488 images, time remaining=7.1 hours
1993: loss=7.012, avg loss=6.212, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 127552 images, time remaining=7.1 hours
1994: loss=6.685, avg loss=6.260, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=3.9 seconds, 127616 images, time remaining=7.1 hours
1995: loss=5.706, avg loss=6.204, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 127680 images, time remaining=7 hours
1996: loss=5.838, avg loss=6.168, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=3.9 seconds, 127744 images, time remaining=7 hours
1997: loss=5.166, avg loss=6.067, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 127808 images, time remaining=7 hours
1998: loss=5.154, avg loss=5.976, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 127872 images, time remaining=7 hours
1999: loss=5.883, avg loss=5.967, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=3.9 seconds, 127936 images, time remaining=7 hours
2000: loss=5.851, avg loss=5.955, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 128000 images, time remaining=7 hours
Saving weights to /workspace/.cache/splits/combined_2000.weights
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2001: loss=6.340, avg loss=5.994, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 128064 images, time remaining=7 hours
2002: loss=5.941, avg loss=5.988, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 128128 images, time remaining=7 hours
2003: loss=5.804, avg loss=5.970, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=3.0 seconds, train=4.1 seconds, 128192 images, time remaining=7 hours
2004: loss=6.105, avg loss=5.983, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 128256 images, time remaining=7 hours
2005: loss=6.092, avg loss=5.994, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 128320 images, time remaining=7 hours
2006: loss=5.820, avg loss=5.977, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 128384 images, time remaining=7 hours
2007: loss=6.047, avg loss=5.984, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 128448 images, time remaining=7 hours
2008: loss=5.330, avg loss=5.919, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 128512 images, time remaining=7 hours
2009: loss=5.459, avg loss=5.873, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 128576 images, time remaining=7 hours
2010: loss=5.306, avg loss=5.816, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=4.0 seconds, 128640 images, time remaining=7 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b7b4400000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
2011: loss=6.511, avg loss=5.885, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.0 seconds, train=1.9 seconds, 128704 images, time remaining=7 hours
2012: loss=6.734, avg loss=5.970, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 128768 images, time remaining=7 hours
2013: loss=5.930, avg loss=5.966, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 128832 images, time remaining=7 hours
2014: loss=5.702, avg loss=5.940, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 128896 images, time remaining=7 hours
2015: loss=5.648, avg loss=5.911, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=1.8 seconds, 128960 images, time remaining=7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
2016: loss=5.487, avg loss=5.868, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=3.0 seconds, train=1.9 seconds, 129024 images, time remaining=7 hours
2017: loss=6.152, avg loss=5.897, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 129088 images, time remaining=7 hours
2018: loss=5.614, avg loss=5.868, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 129152 images, time remaining=7 hours
2019: loss=5.680, avg loss=5.849, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 129216 images, time remaining=7 hours
2020: loss=5.260, avg loss=5.791, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 129280 images, time remaining=7 hours
Resizing, random_coef=1.40, batch=4, 704x544
GPU #0: allocating workspace: 289.6 MiB begins at 0x14b6f5200000
2021: loss=5.354, avg loss=5.747, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 129344 images, time remaining=7 hours
2022: loss=4.884, avg loss=5.661, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 129408 images, time remaining=7 hours
2023: loss=6.083, avg loss=5.703, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 129472 images, time remaining=7 hours
2024: loss=5.159, avg loss=5.648, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 129536 images, time remaining=7 hours
2025: loss=5.407, avg loss=5.624, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.1 seconds, train=1.9 seconds, 129600 images, time remaining=7 hours
2026: loss=5.860, avg loss=5.648, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 129664 images, time remaining=7 hours
2027: loss=5.312, avg loss=5.614, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.1 seconds, train=1.9 seconds, 129728 images, time remaining=7 hours
2028: loss=5.257, avg loss=5.579, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 129792 images, time remaining=7 hours
2029: loss=4.983, avg loss=5.519, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 129856 images, time remaining=7 hours
2030: loss=4.570, avg loss=5.424, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 129920 images, time remaining=7 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2031: loss=6.910, avg loss=5.573, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.9 seconds, train=4.0 seconds, 129984 images, time remaining=7 hours
2032: loss=5.923, avg loss=5.608, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=3.8 seconds, 130048 images, time remaining=7 hours
2033: loss=6.340, avg loss=5.681, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 130112 images, time remaining=7 hours
2034: loss=6.123, avg loss=5.725, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 130176 images, time remaining=7 hours
2035: loss=6.443, avg loss=5.797, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.3 seconds, train=4.1 seconds, 130240 images, time remaining=7 hours
2036: loss=7.285, avg loss=5.946, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 130304 images, time remaining=7 hours
2037: loss=5.482, avg loss=5.899, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 130368 images, time remaining=7 hours
2038: loss=4.566, avg loss=5.766, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 130432 images, time remaining=7 hours
2039: loss=5.996, avg loss=5.789, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 130496 images, time remaining=7 hours
2040: loss=4.234, avg loss=5.633, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 130560 images, time remaining=7 hours
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14b7d0600000
2041: loss=5.932, avg loss=5.663, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 130624 images, time remaining=7 hours
2042: loss=4.954, avg loss=5.592, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 130688 images, time remaining=7 hours
2043: loss=6.328, avg loss=5.666, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 130752 images, time remaining=7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
2044: loss=4.983, avg loss=5.598, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.8 seconds, train=2.2 seconds, 130816 images, time remaining=7 hours
2045: loss=5.520, avg loss=5.590, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 130880 images, time remaining=7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
2046: loss=4.907, avg loss=5.522, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.8 seconds, train=2.2 seconds, 130944 images, time remaining=6.9 hours
2047: loss=5.991, avg loss=5.569, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.0 seconds, train=2.2 seconds, 131008 images, time remaining=6.9 hours
2048: loss=5.753, avg loss=5.587, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 131072 images, time remaining=6.9 hours
2049: loss=5.934, avg loss=5.622, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 131136 images, time remaining=6.9 hours
2050: loss=6.990, avg loss=5.759, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 131200 images, time remaining=6.9 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b7c0c00000
2051: loss=5.322, avg loss=5.715, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 131264 images, time remaining=6.9 hours
2052: loss=5.473, avg loss=5.691, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 131328 images, time remaining=6.9 hours
2053: loss=6.083, avg loss=5.730, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 131392 images, time remaining=6.9 hours
2054: loss=5.540, avg loss=5.711, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 131456 images, time remaining=6.9 hours
2055: loss=4.790, avg loss=5.619, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 131520 images, time remaining=6.9 hours
2056: loss=4.698, avg loss=5.527, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 131584 images, time remaining=6.9 hours
2057: loss=5.545, avg loss=5.528, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 131648 images, time remaining=6.9 hours
2058: loss=5.704, avg loss=5.546, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 131712 images, time remaining=6.9 hours
2059: loss=5.497, avg loss=5.541, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 131776 images, time remaining=6.9 hours
2060: loss=5.901, avg loss=5.577, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.1 seconds, train=2.1 seconds, 131840 images, time remaining=6.9 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2061: loss=11.037, avg loss=6.123, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 131904 images, time remaining=6.9 hours
2062: loss=7.624, avg loss=6.273, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.4 seconds, train=5.8 seconds, 131968 images, time remaining=6.9 hours
2063: loss=6.707, avg loss=6.317, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 132032 images, time remaining=6.9 hours
2064: loss=8.540, avg loss=6.539, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 132096 images, time remaining=6.9 hours
2065: loss=7.397, avg loss=6.625, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 132160 images, time remaining=6.9 hours
2066: loss=6.660, avg loss=6.628, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 132224 images, time remaining=6.9 hours
2067: loss=7.754, avg loss=6.741, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.3 seconds, train=5.9 seconds, 132288 images, time remaining=6.9 hours
2068: loss=6.415, avg loss=6.708, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 132352 images, time remaining=6.9 hours
2069: loss=8.570, avg loss=6.894, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 132416 images, time remaining=6.9 hours
2070: loss=8.588, avg loss=7.064, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 132480 images, time remaining=6.9 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b52f000000
2071: loss=7.757, avg loss=7.133, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 132544 images, time remaining=6.9 hours
2072: loss=7.784, avg loss=7.198, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 132608 images, time remaining=6.9 hours
2073: loss=7.278, avg loss=7.206, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 132672 images, time remaining=6.9 hours
2074: loss=5.319, avg loss=7.018, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 132736 images, time remaining=6.9 hours
2075: loss=6.013, avg loss=6.917, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 132800 images, time remaining=6.9 hours
2076: loss=6.860, avg loss=6.911, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 132864 images, time remaining=6.9 hours
2077: loss=7.517, avg loss=6.972, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 132928 images, time remaining=6.9 hours
2078: loss=6.619, avg loss=6.937, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 132992 images, time remaining=6.9 hours
2079: loss=6.011, avg loss=6.844, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 133056 images, time remaining=6.9 hours
2080: loss=6.461, avg loss=6.806, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 133120 images, time remaining=6.9 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2081: loss=10.777, avg loss=7.203, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 133184 images, time remaining=6.9 hours
2082: loss=8.549, avg loss=7.337, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 133248 images, time remaining=6.9 hours
2083: loss=7.791, avg loss=7.383, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 133312 images, time remaining=6.9 hours
2084: loss=7.525, avg loss=7.397, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 133376 images, time remaining=6.9 hours
2085: loss=9.231, avg loss=7.580, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 133440 images, time remaining=6.9 hours
2086: loss=7.246, avg loss=7.547, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.9 seconds, train=5.5 seconds, 133504 images, time remaining=6.9 hours
2087: loss=6.509, avg loss=7.443, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.9 seconds, train=5.5 seconds, 133568 images, time remaining=6.9 hours
2088: loss=7.164, avg loss=7.415, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 133632 images, time remaining=6.9 hours
2089: loss=7.765, avg loss=7.450, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=5.6 seconds, 133696 images, time remaining=6.9 hours
2090: loss=7.485, avg loss=7.454, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 133760 images, time remaining=6.9 hours
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2091: loss=7.472, avg loss=7.456, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 133824 images, time remaining=6.9 hours
2092: loss=6.399, avg loss=7.350, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 133888 images, time remaining=6.9 hours
2093: loss=7.016, avg loss=7.316, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 133952 images, time remaining=6.9 hours
2094: loss=6.203, avg loss=7.205, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=4.1 seconds, 134016 images, time remaining=6.9 hours
2095: loss=6.744, avg loss=7.159, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 134080 images, time remaining=6.9 hours
2096: loss=7.446, avg loss=7.188, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.2 seconds, train=4.1 seconds, 134144 images, time remaining=6.9 hours
2097: loss=5.234, avg loss=6.992, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 134208 images, time remaining=6.9 hours
2098: loss=5.847, avg loss=6.878, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 134272 images, time remaining=6.9 hours
2099: loss=6.429, avg loss=6.833, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=4.1 seconds, 134336 images, time remaining=6.9 hours
2100: loss=7.248, avg loss=6.874, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 134400 images, time remaining=6.9 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2101: loss=7.458, avg loss=6.933, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 134464 images, time remaining=6.9 hours
2102: loss=6.695, avg loss=6.909, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 134528 images, time remaining=6.9 hours
2103: loss=5.885, avg loss=6.807, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 134592 images, time remaining=6.9 hours
2104: loss=6.916, avg loss=6.818, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 134656 images, time remaining=6.9 hours
2105: loss=6.372, avg loss=6.773, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 134720 images, time remaining=6.9 hours
2106: loss=6.712, avg loss=6.767, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 134784 images, time remaining=6.9 hours
2107: loss=7.282, avg loss=6.818, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 134848 images, time remaining=6.9 hours
2108: loss=5.634, avg loss=6.700, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=4.6 seconds, 134912 images, time remaining=6.9 hours
2109: loss=7.118, avg loss=6.742, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 134976 images, time remaining=6.9 hours
2110: loss=6.292, avg loss=6.697, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 135040 images, time remaining=6.9 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b636a00000
2111: loss=7.986, avg loss=6.826, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 135104 images, time remaining=6.9 hours
2112: loss=6.371, avg loss=6.780, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 135168 images, time remaining=6.9 hours
2113: loss=8.462, avg loss=6.948, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.0 seconds, train=2.1 seconds, 135232 images, time remaining=6.9 hours
2114: loss=6.076, avg loss=6.861, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 135296 images, time remaining=6.9 hours
2115: loss=6.959, avg loss=6.871, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 135360 images, time remaining=6.9 hours
2116: loss=5.914, avg loss=6.775, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 135424 images, time remaining=6.9 hours
2117: loss=6.637, avg loss=6.761, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 135488 images, time remaining=6.9 hours
2118: loss=7.248, avg loss=6.810, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 135552 images, time remaining=6.9 hours
2119: loss=6.356, avg loss=6.765, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 135616 images, time remaining=6.9 hours
2120: loss=5.540, avg loss=6.642, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 135680 images, time remaining=6.9 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14c2b8000000
2121: loss=5.288, avg loss=6.507, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 135744 images, time remaining=6.8 hours
2122: loss=5.648, avg loss=6.421, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 135808 images, time remaining=6.8 hours
2123: loss=6.111, avg loss=6.390, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 135872 images, time remaining=6.8 hours
2124: loss=6.110, avg loss=6.362, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 135936 images, time remaining=6.8 hours
2125: loss=5.145, avg loss=6.240, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 136000 images, time remaining=6.8 hours
2126: loss=5.510, avg loss=6.167, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 136064 images, time remaining=6.8 hours
2127: loss=6.374, avg loss=6.188, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 136128 images, time remaining=6.8 hours
2128: loss=5.364, avg loss=6.106, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 136192 images, time remaining=6.8 hours
2129: loss=5.016, avg loss=5.997, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.9 seconds, train=2.1 seconds, 136256 images, time remaining=6.8 hours
2130: loss=6.316, avg loss=6.029, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 136320 images, time remaining=6.8 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b79cc00000
2131: loss=6.503, avg loss=6.076, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 136384 images, time remaining=6.8 hours
2132: loss=6.408, avg loss=6.109, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 136448 images, time remaining=6.8 hours
2133: loss=5.637, avg loss=6.062, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 136512 images, time remaining=6.8 hours
2134: loss=4.927, avg loss=5.948, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 136576 images, time remaining=6.8 hours
2135: loss=6.345, avg loss=5.988, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 136640 images, time remaining=6.8 hours
2136: loss=5.718, avg loss=5.961, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 136704 images, time remaining=6.8 hours
2137: loss=5.649, avg loss=5.930, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 136768 images, time remaining=6.8 hours
2138: loss=5.616, avg loss=5.899, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 136832 images, time remaining=6.8 hours
2139: loss=6.005, avg loss=5.909, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 136896 images, time remaining=6.8 hours
2140: loss=6.519, avg loss=5.970, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 136960 images, time remaining=6.8 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b714200000
2141: loss=5.931, avg loss=5.966, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 137024 images, time remaining=6.8 hours
2142: loss=6.151, avg loss=5.985, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 137088 images, time remaining=6.8 hours
2143: loss=5.360, avg loss=5.922, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 137152 images, time remaining=6.8 hours
2144: loss=6.273, avg loss=5.957, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 137216 images, time remaining=6.8 hours
2145: loss=5.272, avg loss=5.889, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 137280 images, time remaining=6.8 hours
2146: loss=5.825, avg loss=5.883, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 137344 images, time remaining=6.8 hours
2147: loss=5.222, avg loss=5.816, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 137408 images, time remaining=6.8 hours
2148: loss=5.260, avg loss=5.761, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 137472 images, time remaining=6.8 hours
2149: loss=5.517, avg loss=5.736, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 137536 images, time remaining=6.8 hours
2150: loss=4.472, avg loss=5.610, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.0 seconds, train=2.3 seconds, 137600 images, time remaining=6.8 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2151: loss=7.643, avg loss=5.813, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=3.1 seconds, train=5.5 seconds, 137664 images, time remaining=6.8 hours
2152: loss=7.497, avg loss=5.982, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 137728 images, time remaining=6.8 hours
2153: loss=7.059, avg loss=6.089, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 137792 images, time remaining=6.8 hours
2154: loss=7.236, avg loss=6.204, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 137856 images, time remaining=6.8 hours
2155: loss=6.654, avg loss=6.249, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=5.5 seconds, 137920 images, time remaining=6.8 hours
2156: loss=6.661, avg loss=6.290, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 137984 images, time remaining=6.8 hours
2157: loss=6.995, avg loss=6.361, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 138048 images, time remaining=6.8 hours
2158: loss=5.918, avg loss=6.316, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 138112 images, time remaining=6.8 hours
2159: loss=6.454, avg loss=6.330, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 138176 images, time remaining=6.8 hours
2160: loss=6.994, avg loss=6.397, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 138240 images, time remaining=6.8 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2161: loss=6.709, avg loss=6.428, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 138304 images, time remaining=6.8 hours
2162: loss=6.039, avg loss=6.389, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 138368 images, time remaining=6.8 hours
2163: loss=4.729, avg loss=6.223, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 138432 images, time remaining=6.8 hours
2164: loss=6.691, avg loss=6.270, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 138496 images, time remaining=6.8 hours
2165: loss=6.296, avg loss=6.272, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 138560 images, time remaining=6.8 hours
2166: loss=5.223, avg loss=6.167, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 138624 images, time remaining=6.8 hours
2167: loss=6.265, avg loss=6.177, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 138688 images, time remaining=6.8 hours
2168: loss=5.712, avg loss=6.131, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 138752 images, time remaining=6.8 hours
2169: loss=5.160, avg loss=6.034, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 138816 images, time remaining=6.8 hours
2170: loss=7.430, avg loss=6.173, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 138880 images, time remaining=6.8 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2171: loss=6.131, avg loss=6.169, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 138944 images, time remaining=6.8 hours
2172: loss=7.284, avg loss=6.281, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 139008 images, time remaining=6.8 hours
2173: loss=6.127, avg loss=6.265, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 139072 images, time remaining=6.8 hours
2174: loss=5.386, avg loss=6.177, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 139136 images, time remaining=6.8 hours
2175: loss=5.969, avg loss=6.156, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 139200 images, time remaining=6.8 hours
2176: loss=6.444, avg loss=6.185, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 139264 images, time remaining=6.8 hours
2177: loss=6.548, avg loss=6.221, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 139328 images, time remaining=6.8 hours
2178: loss=6.347, avg loss=6.234, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 139392 images, time remaining=6.8 hours
2179: loss=5.481, avg loss=6.159, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 139456 images, time remaining=6.8 hours
2180: loss=5.372, avg loss=6.080, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 139520 images, time remaining=6.8 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2181: loss=5.636, avg loss=6.036, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=4.0 seconds, 139584 images, time remaining=6.8 hours
2182: loss=5.906, avg loss=6.023, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 139648 images, time remaining=6.8 hours
2183: loss=6.077, avg loss=6.028, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 139712 images, time remaining=6.8 hours
2184: loss=4.852, avg loss=5.910, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 139776 images, time remaining=6.8 hours
2185: loss=5.485, avg loss=5.868, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=3.9 seconds, 139840 images, time remaining=6.8 hours
2186: loss=5.711, avg loss=5.852, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 139904 images, time remaining=6.8 hours
2187: loss=5.709, avg loss=5.838, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 139968 images, time remaining=6.8 hours
2188: loss=5.615, avg loss=5.816, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.9 seconds, train=4.0 seconds, 140032 images, time remaining=6.8 hours
2189: loss=4.862, avg loss=5.720, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=3.9 seconds, 140096 images, time remaining=6.8 hours
2190: loss=5.172, avg loss=5.665, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=4.0 seconds, 140160 images, time remaining=6.8 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b87a000000
2191: loss=6.869, avg loss=5.786, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.1 seconds, train=2.3 seconds, 140224 images, time remaining=6.8 hours
2192: loss=5.748, avg loss=5.782, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 140288 images, time remaining=6.8 hours
2193: loss=5.795, avg loss=5.783, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 140352 images, time remaining=6.8 hours
2194: loss=5.502, avg loss=5.755, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 140416 images, time remaining=6.8 hours
2195: loss=4.688, avg loss=5.649, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 140480 images, time remaining=6.7 hours
2196: loss=6.317, avg loss=5.715, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 140544 images, time remaining=6.7 hours
2197: loss=5.195, avg loss=5.663, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 140608 images, time remaining=6.7 hours
2198: loss=4.951, avg loss=5.592, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 140672 images, time remaining=6.7 hours
2199: loss=6.328, avg loss=5.666, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 140736 images, time remaining=6.7 hours
2200: loss=4.754, avg loss=5.575, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 140800 images, time remaining=6.7 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b871e00000
2201: loss=5.726, avg loss=5.590, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 140864 images, time remaining=6.7 hours
2202: loss=5.820, avg loss=5.613, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 140928 images, time remaining=6.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
2203: loss=5.278, avg loss=5.579, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=3.2 seconds, train=1.7 seconds, 140992 images, time remaining=6.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
2204: loss=5.118, avg loss=5.533, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.3 seconds, train=1.8 seconds, 141056 images, time remaining=6.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
2205: loss=5.239, avg loss=5.504, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=2.7 seconds, train=1.9 seconds, 141120 images, time remaining=6.7 hours
2206: loss=4.644, avg loss=5.418, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 141184 images, time remaining=6.7 hours
2207: loss=4.702, avg loss=5.346, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 141248 images, time remaining=6.7 hours
2208: loss=5.330, avg loss=5.345, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 141312 images, time remaining=6.7 hours
2209: loss=4.590, avg loss=5.269, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 141376 images, time remaining=6.7 hours
2210: loss=6.093, avg loss=5.352, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=1.7 seconds, 141440 images, time remaining=6.7 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14c2c6400000
2211: loss=5.546, avg loss=5.371, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 141504 images, time remaining=6.7 hours
2212: loss=5.866, avg loss=5.421, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 141568 images, time remaining=6.7 hours
2213: loss=5.591, avg loss=5.438, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 141632 images, time remaining=6.7 hours
2214: loss=5.040, avg loss=5.398, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.9 seconds, train=2.0 seconds, 141696 images, time remaining=6.7 hours
2215: loss=5.501, avg loss=5.408, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 141760 images, time remaining=6.7 hours
2216: loss=5.048, avg loss=5.372, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 141824 images, time remaining=6.7 hours
2217: loss=4.582, avg loss=5.293, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 141888 images, time remaining=6.7 hours
2218: loss=5.842, avg loss=5.348, last=65.59%, best=65.59%, next=2218, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 141952 images, time remaining=6.7 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b689e00000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=223945, unique_truth_count=57264
rank=0 of ranks=223945rank=100 of ranks=223945rank=200 of ranks=223945rank=300 of ranks=223945rank=400 of ranks=223945rank=500 of ranks=223945rank=600 of ranks=223945rank=700 of ranks=223945rank=800 of ranks=223945rank=900 of ranks=223945rank=1000 of ranks=223945rank=1100 of ranks=223945rank=1200 of ranks=223945rank=1300 of ranks=223945rank=1400 of ranks=223945rank=1500 of ranks=223945rank=1600 of ranks=223945rank=1700 of ranks=223945rank=1800 of ranks=223945rank=1900 of ranks=223945rank=2000 of ranks=223945rank=2100 of ranks=223945rank=2200 of ranks=223945rank=2300 of ranks=223945rank=2400 of ranks=223945rank=2500 of ranks=223945rank=2600 of ranks=223945rank=2700 of ranks=223945rank=2800 of ranks=223945rank=2900 of ranks=223945rank=3000 of ranks=223945rank=3100 of ranks=223945rank=3200 of ranks=223945rank=3300 of ranks=223945rank=3400 of ranks=223945rank=3500 of ranks=223945rank=3600 of ranks=223945rank=3700 of ranks=223945rank=3800 of ranks=223945rank=3900 of ranks=223945rank=4000 of ranks=223945rank=4100 of ranks=223945rank=4200 of ranks=223945rank=4300 of ranks=223945rank=4400 of ranks=223945rank=4500 of ranks=223945rank=4600 of ranks=223945rank=4700 of ranks=223945rank=4800 of ranks=223945rank=4900 of ranks=223945rank=5000 of ranks=223945rank=5100 of ranks=223945rank=5200 of ranks=223945rank=5300 of ranks=223945rank=5400 of ranks=223945rank=5500 of ranks=223945rank=5600 of ranks=223945rank=5700 of ranks=223945rank=5800 of ranks=223945rank=5900 of ranks=223945rank=6000 of ranks=223945rank=6100 of ranks=223945rank=6200 of ranks=223945rank=6300 of ranks=223945rank=6400 of ranks=223945rank=6500 of ranks=223945rank=6600 of ranks=223945rank=6700 of ranks=223945rank=6800 of ranks=223945rank=6900 of ranks=223945rank=7000 of ranks=223945rank=7100 of ranks=223945rank=7200 of ranks=223945rank=7300 of ranks=223945rank=7400 of ranks=223945rank=7500 of ranks=223945rank=7600 of ranks=223945rank=7700 of ranks=223945rank=7800 of ranks=223945rank=7900 of ranks=223945rank=8000 of ranks=223945rank=8100 of ranks=223945rank=8200 of ranks=223945rank=8300 of ranks=223945rank=8400 of ranks=223945rank=8500 of ranks=223945rank=8600 of ranks=223945rank=8700 of ranks=223945rank=8800 of ranks=223945rank=8900 of ranks=223945rank=9000 of ranks=223945rank=9100 of ranks=223945rank=9200 of ranks=223945rank=9300 of ranks=223945rank=9400 of ranks=223945rank=9500 of ranks=223945rank=9600 of ranks=223945rank=9700 of ranks=223945rank=9800 of ranks=223945rank=9900 of ranks=223945rank=10000 of ranks=223945rank=10100 of ranks=223945rank=10200 of ranks=223945rank=10300 of ranks=223945rank=10400 of ranks=223945rank=10500 of ranks=223945rank=10600 of ranks=223945rank=10700 of ranks=223945rank=10800 of ranks=223945rank=10900 of ranks=223945rank=11000 of ranks=223945rank=11100 of ranks=223945rank=11200 of ranks=223945rank=11300 of ranks=223945rank=11400 of ranks=223945rank=11500 of ranks=223945rank=11600 of ranks=223945rank=11700 of ranks=223945rank=11800 of ranks=223945rank=11900 of ranks=223945rank=12000 of ranks=223945rank=12100 of ranks=223945rank=12200 of ranks=223945rank=12300 of ranks=223945rank=12400 of ranks=223945rank=12500 of ranks=223945rank=12600 of ranks=223945rank=12700 of ranks=223945rank=12800 of ranks=223945rank=12900 of ranks=223945rank=13000 of ranks=223945rank=13100 of ranks=223945rank=13200 of ranks=223945rank=13300 of ranks=223945rank=13400 of ranks=223945rank=13500 of ranks=223945rank=13600 of ranks=223945rank=13700 of ranks=223945rank=13800 of ranks=223945rank=13900 of ranks=223945rank=14000 of ranks=223945rank=14100 of ranks=223945rank=14200 of ranks=223945rank=14300 of ranks=223945rank=14400 of ranks=223945rank=14500 of ranks=223945rank=14600 of ranks=223945rank=14700 of ranks=223945rank=14800 of ranks=223945rank=14900 of ranks=223945rank=15000 of ranks=223945rank=15100 of ranks=223945rank=15200 of ranks=223945rank=15300 of ranks=223945rank=15400 of ranks=223945rank=15500 of ranks=223945rank=15600 of ranks=223945rank=15700 of ranks=223945rank=15800 of ranks=223945rank=15900 of ranks=223945rank=16000 of ranks=223945rank=16100 of ranks=223945rank=16200 of ranks=223945rank=16300 of ranks=223945rank=16400 of ranks=223945rank=16500 of ranks=223945rank=16600 of ranks=223945rank=16700 of ranks=223945rank=16800 of ranks=223945rank=16900 of ranks=223945rank=17000 of ranks=223945rank=17100 of ranks=223945rank=17200 of ranks=223945rank=17300 of ranks=223945rank=17400 of ranks=223945rank=17500 of ranks=223945rank=17600 of ranks=223945rank=17700 of ranks=223945rank=17800 of ranks=223945rank=17900 of ranks=223945rank=18000 of ranks=223945rank=18100 of ranks=223945rank=18200 of ranks=223945rank=18300 of ranks=223945rank=18400 of ranks=223945rank=18500 of ranks=223945rank=18600 of ranks=223945rank=18700 of ranks=223945rank=18800 of ranks=223945rank=18900 of ranks=223945rank=19000 of ranks=223945rank=19100 of ranks=223945rank=19200 of ranks=223945rank=19300 of ranks=223945rank=19400 of ranks=223945rank=19500 of ranks=223945rank=19600 of ranks=223945rank=19700 of ranks=223945rank=19800 of ranks=223945rank=19900 of ranks=223945rank=20000 of ranks=223945rank=20100 of ranks=223945rank=20200 of ranks=223945rank=20300 of ranks=223945rank=20400 of ranks=223945rank=20500 of ranks=223945rank=20600 of ranks=223945rank=20700 of ranks=223945rank=20800 of ranks=223945rank=20900 of ranks=223945rank=21000 of ranks=223945rank=21100 of ranks=223945rank=21200 of ranks=223945rank=21300 of ranks=223945rank=21400 of ranks=223945rank=21500 of ranks=223945rank=21600 of ranks=223945rank=21700 of ranks=223945rank=21800 of ranks=223945rank=21900 of ranks=223945rank=22000 of ranks=223945rank=22100 of ranks=223945rank=22200 of ranks=223945rank=22300 of ranks=223945rank=22400 of ranks=223945rank=22500 of ranks=223945rank=22600 of ranks=223945rank=22700 of ranks=223945rank=22800 of ranks=223945rank=22900 of ranks=223945rank=23000 of ranks=223945rank=23100 of ranks=223945rank=23200 of ranks=223945rank=23300 of ranks=223945rank=23400 of ranks=223945rank=23500 of ranks=223945rank=23600 of ranks=223945rank=23700 of ranks=223945rank=23800 of ranks=223945rank=23900 of ranks=223945rank=24000 of ranks=223945rank=24100 of ranks=223945rank=24200 of ranks=223945rank=24300 of ranks=223945rank=24400 of ranks=223945rank=24500 of ranks=223945rank=24600 of ranks=223945rank=24700 of ranks=223945rank=24800 of ranks=223945rank=24900 of ranks=223945rank=25000 of ranks=223945rank=25100 of ranks=223945rank=25200 of ranks=223945rank=25300 of ranks=223945rank=25400 of ranks=223945rank=25500 of ranks=223945rank=25600 of ranks=223945rank=25700 of ranks=223945rank=25800 of ranks=223945rank=25900 of ranks=223945rank=26000 of ranks=223945rank=26100 of ranks=223945rank=26200 of ranks=223945rank=26300 of ranks=223945rank=26400 of ranks=223945rank=26500 of ranks=223945rank=26600 of ranks=223945rank=26700 of ranks=223945rank=26800 of ranks=223945rank=26900 of ranks=223945rank=27000 of ranks=223945rank=27100 of ranks=223945rank=27200 of ranks=223945rank=27300 of ranks=223945rank=27400 of ranks=223945rank=27500 of ranks=223945rank=27600 of ranks=223945rank=27700 of ranks=223945rank=27800 of ranks=223945rank=27900 of ranks=223945rank=28000 of ranks=223945rank=28100 of ranks=223945rank=28200 of ranks=223945rank=28300 of ranks=223945rank=28400 of ranks=223945rank=28500 of ranks=223945rank=28600 of ranks=223945rank=28700 of ranks=223945rank=28800 of ranks=223945rank=28900 of ranks=223945rank=29000 of ranks=223945rank=29100 of ranks=223945rank=29200 of ranks=223945rank=29300 of ranks=223945rank=29400 of ranks=223945rank=29500 of ranks=223945rank=29600 of ranks=223945rank=29700 of ranks=223945rank=29800 of ranks=223945rank=29900 of ranks=223945rank=30000 of ranks=223945rank=30100 of ranks=223945rank=30200 of ranks=223945rank=30300 of ranks=223945rank=30400 of ranks=223945rank=30500 of ranks=223945rank=30600 of ranks=223945rank=30700 of ranks=223945rank=30800 of ranks=223945rank=30900 of ranks=223945rank=31000 of ranks=223945rank=31100 of ranks=223945rank=31200 of ranks=223945rank=31300 of ranks=223945rank=31400 of ranks=223945rank=31500 of ranks=223945rank=31600 of ranks=223945rank=31700 of ranks=223945rank=31800 of ranks=223945rank=31900 of ranks=223945rank=32000 of ranks=223945rank=32100 of ranks=223945rank=32200 of ranks=223945rank=32300 of ranks=223945rank=32400 of ranks=223945rank=32500 of ranks=223945rank=32600 of ranks=223945rank=32700 of ranks=223945rank=32800 of ranks=223945rank=32900 of ranks=223945rank=33000 of ranks=223945rank=33100 of ranks=223945rank=33200 of ranks=223945rank=33300 of ranks=223945rank=33400 of ranks=223945rank=33500 of ranks=223945rank=33600 of ranks=223945rank=33700 of ranks=223945rank=33800 of ranks=223945rank=33900 of ranks=223945rank=34000 of ranks=223945rank=34100 of ranks=223945rank=34200 of ranks=223945rank=34300 of ranks=223945rank=34400 of ranks=223945rank=34500 of ranks=223945rank=34600 of ranks=223945rank=34700 of ranks=223945rank=34800 of ranks=223945rank=34900 of ranks=223945rank=35000 of ranks=223945rank=35100 of ranks=223945rank=35200 of ranks=223945rank=35300 of ranks=223945rank=35400 of ranks=223945rank=35500 of ranks=223945rank=35600 of ranks=223945rank=35700 of ranks=223945rank=35800 of ranks=223945rank=35900 of ranks=223945rank=36000 of ranks=223945rank=36100 of ranks=223945rank=36200 of ranks=223945rank=36300 of ranks=223945rank=36400 of ranks=223945rank=36500 of ranks=223945rank=36600 of ranks=223945rank=36700 of ranks=223945rank=36800 of ranks=223945rank=36900 of ranks=223945rank=37000 of ranks=223945rank=37100 of ranks=223945rank=37200 of ranks=223945rank=37300 of ranks=223945rank=37400 of ranks=223945rank=37500 of ranks=223945rank=37600 of ranks=223945rank=37700 of ranks=223945rank=37800 of ranks=223945rank=37900 of ranks=223945rank=38000 of ranks=223945rank=38100 of ranks=223945rank=38200 of ranks=223945rank=38300 of ranks=223945rank=38400 of ranks=223945rank=38500 of ranks=223945rank=38600 of ranks=223945rank=38700 of ranks=223945rank=38800 of ranks=223945rank=38900 of ranks=223945rank=39000 of ranks=223945rank=39100 of ranks=223945rank=39200 of ranks=223945rank=39300 of ranks=223945rank=39400 of ranks=223945rank=39500 of ranks=223945rank=39600 of ranks=223945rank=39700 of ranks=223945rank=39800 of ranks=223945rank=39900 of ranks=223945rank=40000 of ranks=223945rank=40100 of ranks=223945rank=40200 of ranks=223945rank=40300 of ranks=223945rank=40400 of ranks=223945rank=40500 of ranks=223945rank=40600 of ranks=223945rank=40700 of ranks=223945rank=40800 of ranks=223945rank=40900 of ranks=223945rank=41000 of ranks=223945rank=41100 of ranks=223945rank=41200 of ranks=223945rank=41300 of ranks=223945rank=41400 of ranks=223945rank=41500 of ranks=223945rank=41600 of ranks=223945rank=41700 of ranks=223945rank=41800 of ranks=223945rank=41900 of ranks=223945rank=42000 of ranks=223945rank=42100 of ranks=223945rank=42200 of ranks=223945rank=42300 of ranks=223945rank=42400 of ranks=223945rank=42500 of ranks=223945rank=42600 of ranks=223945rank=42700 of ranks=223945rank=42800 of ranks=223945rank=42900 of ranks=223945rank=43000 of ranks=223945rank=43100 of ranks=223945rank=43200 of ranks=223945rank=43300 of ranks=223945rank=43400 of ranks=223945rank=43500 of ranks=223945rank=43600 of ranks=223945rank=43700 of ranks=223945rank=43800 of ranks=223945rank=43900 of ranks=223945rank=44000 of ranks=223945rank=44100 of ranks=223945rank=44200 of ranks=223945rank=44300 of ranks=223945rank=44400 of ranks=223945rank=44500 of ranks=223945rank=44600 of ranks=223945rank=44700 of ranks=223945rank=44800 of ranks=223945rank=44900 of ranks=223945rank=45000 of ranks=223945rank=45100 of ranks=223945rank=45200 of ranks=223945rank=45300 of ranks=223945rank=45400 of ranks=223945rank=45500 of ranks=223945rank=45600 of ranks=223945rank=45700 of ranks=223945rank=45800 of ranks=223945rank=45900 of ranks=223945rank=46000 of ranks=223945rank=46100 of ranks=223945rank=46200 of ranks=223945rank=46300 of ranks=223945rank=46400 of ranks=223945rank=46500 of ranks=223945rank=46600 of ranks=223945rank=46700 of ranks=223945rank=46800 of ranks=223945rank=46900 of ranks=223945rank=47000 of ranks=223945rank=47100 of ranks=223945rank=47200 of ranks=223945rank=47300 of ranks=223945rank=47400 of ranks=223945rank=47500 of ranks=223945rank=47600 of ranks=223945rank=47700 of ranks=223945rank=47800 of ranks=223945rank=47900 of ranks=223945rank=48000 of ranks=223945rank=48100 of ranks=223945rank=48200 of ranks=223945rank=48300 of ranks=223945rank=48400 of ranks=223945rank=48500 of ranks=223945rank=48600 of ranks=223945rank=48700 of ranks=223945rank=48800 of ranks=223945rank=48900 of ranks=223945rank=49000 of ranks=223945rank=49100 of ranks=223945rank=49200 of ranks=223945rank=49300 of ranks=223945rank=49400 of ranks=223945rank=49500 of ranks=223945rank=49600 of ranks=223945rank=49700 of ranks=223945rank=49800 of ranks=223945rank=49900 of ranks=223945rank=50000 of ranks=223945rank=50100 of ranks=223945rank=50200 of ranks=223945rank=50300 of ranks=223945rank=50400 of ranks=223945rank=50500 of ranks=223945rank=50600 of ranks=223945rank=50700 of ranks=223945rank=50800 of ranks=223945rank=50900 of ranks=223945rank=51000 of ranks=223945rank=51100 of ranks=223945rank=51200 of ranks=223945rank=51300 of ranks=223945rank=51400 of ranks=223945rank=51500 of ranks=223945rank=51600 of ranks=223945rank=51700 of ranks=223945rank=51800 of ranks=223945rank=51900 of ranks=223945rank=52000 of ranks=223945rank=52100 of ranks=223945rank=52200 of ranks=223945rank=52300 of ranks=223945rank=52400 of ranks=223945rank=52500 of ranks=223945rank=52600 of ranks=223945rank=52700 of ranks=223945rank=52800 of ranks=223945rank=52900 of ranks=223945rank=53000 of ranks=223945rank=53100 of ranks=223945rank=53200 of ranks=223945rank=53300 of ranks=223945rank=53400 of ranks=223945rank=53500 of ranks=223945rank=53600 of ranks=223945rank=53700 of ranks=223945rank=53800 of ranks=223945rank=53900 of ranks=223945rank=54000 of ranks=223945rank=54100 of ranks=223945rank=54200 of ranks=223945rank=54300 of ranks=223945rank=54400 of ranks=223945rank=54500 of ranks=223945rank=54600 of ranks=223945rank=54700 of ranks=223945rank=54800 of ranks=223945rank=54900 of ranks=223945rank=55000 of ranks=223945rank=55100 of ranks=223945rank=55200 of ranks=223945rank=55300 of ranks=223945rank=55400 of ranks=223945rank=55500 of ranks=223945rank=55600 of ranks=223945rank=55700 of ranks=223945rank=55800 of ranks=223945rank=55900 of ranks=223945rank=56000 of ranks=223945rank=56100 of ranks=223945rank=56200 of ranks=223945rank=56300 of ranks=223945rank=56400 of ranks=223945rank=56500 of ranks=223945rank=56600 of ranks=223945rank=56700 of ranks=223945rank=56800 of ranks=223945rank=56900 of ranks=223945rank=57000 of ranks=223945rank=57100 of ranks=223945rank=57200 of ranks=223945rank=57300 of ranks=223945rank=57400 of ranks=223945rank=57500 of ranks=223945rank=57600 of ranks=223945rank=57700 of ranks=223945rank=57800 of ranks=223945rank=57900 of ranks=223945rank=58000 of ranks=223945rank=58100 of ranks=223945rank=58200 of ranks=223945rank=58300 of ranks=223945rank=58400 of ranks=223945rank=58500 of ranks=223945rank=58600 of ranks=223945rank=58700 of ranks=223945rank=58800 of ranks=223945rank=58900 of ranks=223945rank=59000 of ranks=223945rank=59100 of ranks=223945rank=59200 of ranks=223945rank=59300 of ranks=223945rank=59400 of ranks=223945rank=59500 of ranks=223945rank=59600 of ranks=223945rank=59700 of ranks=223945rank=59800 of ranks=223945rank=59900 of ranks=223945rank=60000 of ranks=223945rank=60100 of ranks=223945rank=60200 of ranks=223945rank=60300 of ranks=223945rank=60400 of ranks=223945rank=60500 of ranks=223945rank=60600 of ranks=223945rank=60700 of ranks=223945rank=60800 of ranks=223945rank=60900 of ranks=223945rank=61000 of ranks=223945rank=61100 of ranks=223945rank=61200 of ranks=223945rank=61300 of ranks=223945rank=61400 of ranks=223945rank=61500 of ranks=223945rank=61600 of ranks=223945rank=61700 of ranks=223945rank=61800 of ranks=223945rank=61900 of ranks=223945rank=62000 of ranks=223945rank=62100 of ranks=223945rank=62200 of ranks=223945rank=62300 of ranks=223945rank=62400 of ranks=223945rank=62500 of ranks=223945rank=62600 of ranks=223945rank=62700 of ranks=223945rank=62800 of ranks=223945rank=62900 of ranks=223945rank=63000 of ranks=223945rank=63100 of ranks=223945rank=63200 of ranks=223945rank=63300 of ranks=223945rank=63400 of ranks=223945rank=63500 of ranks=223945rank=63600 of ranks=223945rank=63700 of ranks=223945rank=63800 of ranks=223945rank=63900 of ranks=223945rank=64000 of ranks=223945rank=64100 of ranks=223945rank=64200 of ranks=223945rank=64300 of ranks=223945rank=64400 of ranks=223945rank=64500 of ranks=223945rank=64600 of ranks=223945rank=64700 of ranks=223945rank=64800 of ranks=223945rank=64900 of ranks=223945rank=65000 of ranks=223945rank=65100 of ranks=223945rank=65200 of ranks=223945rank=65300 of ranks=223945rank=65400 of ranks=223945rank=65500 of ranks=223945rank=65600 of ranks=223945rank=65700 of ranks=223945rank=65800 of ranks=223945rank=65900 of ranks=223945rank=66000 of ranks=223945rank=66100 of ranks=223945rank=66200 of ranks=223945rank=66300 of ranks=223945rank=66400 of ranks=223945rank=66500 of ranks=223945rank=66600 of ranks=223945rank=66700 of ranks=223945rank=66800 of ranks=223945rank=66900 of ranks=223945rank=67000 of ranks=223945rank=67100 of ranks=223945rank=67200 of ranks=223945rank=67300 of ranks=223945rank=67400 of ranks=223945rank=67500 of ranks=223945rank=67600 of ranks=223945rank=67700 of ranks=223945rank=67800 of ranks=223945rank=67900 of ranks=223945rank=68000 of ranks=223945rank=68100 of ranks=223945rank=68200 of ranks=223945rank=68300 of ranks=223945rank=68400 of ranks=223945rank=68500 of ranks=223945rank=68600 of ranks=223945rank=68700 of ranks=223945rank=68800 of ranks=223945rank=68900 of ranks=223945rank=69000 of ranks=223945rank=69100 of ranks=223945rank=69200 of ranks=223945rank=69300 of ranks=223945rank=69400 of ranks=223945rank=69500 of ranks=223945rank=69600 of ranks=223945rank=69700 of ranks=223945rank=69800 of ranks=223945rank=69900 of ranks=223945rank=70000 of ranks=223945rank=70100 of ranks=223945rank=70200 of ranks=223945rank=70300 of ranks=223945rank=70400 of ranks=223945rank=70500 of ranks=223945rank=70600 of ranks=223945rank=70700 of ranks=223945rank=70800 of ranks=223945rank=70900 of ranks=223945rank=71000 of ranks=223945rank=71100 of ranks=223945rank=71200 of ranks=223945rank=71300 of ranks=223945rank=71400 of ranks=223945rank=71500 of ranks=223945rank=71600 of ranks=223945rank=71700 of ranks=223945rank=71800 of ranks=223945rank=71900 of ranks=223945rank=72000 of ranks=223945rank=72100 of ranks=223945rank=72200 of ranks=223945rank=72300 of ranks=223945rank=72400 of ranks=223945rank=72500 of ranks=223945rank=72600 of ranks=223945rank=72700 of ranks=223945rank=72800 of ranks=223945rank=72900 of ranks=223945rank=73000 of ranks=223945rank=73100 of ranks=223945rank=73200 of ranks=223945rank=73300 of ranks=223945rank=73400 of ranks=223945rank=73500 of ranks=223945rank=73600 of ranks=223945rank=73700 of ranks=223945rank=73800 of ranks=223945rank=73900 of ranks=223945rank=74000 of ranks=223945rank=74100 of ranks=223945rank=74200 of ranks=223945rank=74300 of ranks=223945rank=74400 of ranks=223945rank=74500 of ranks=223945rank=74600 of ranks=223945rank=74700 of ranks=223945rank=74800 of ranks=223945rank=74900 of ranks=223945rank=75000 of ranks=223945rank=75100 of ranks=223945rank=75200 of ranks=223945rank=75300 of ranks=223945rank=75400 of ranks=223945rank=75500 of ranks=223945rank=75600 of ranks=223945rank=75700 of ranks=223945rank=75800 of ranks=223945rank=75900 of ranks=223945rank=76000 of ranks=223945rank=76100 of ranks=223945rank=76200 of ranks=223945rank=76300 of ranks=223945rank=76400 of ranks=223945rank=76500 of ranks=223945rank=76600 of ranks=223945rank=76700 of ranks=223945rank=76800 of ranks=223945rank=76900 of ranks=223945rank=77000 of ranks=223945rank=77100 of ranks=223945rank=77200 of ranks=223945rank=77300 of ranks=223945rank=77400 of ranks=223945rank=77500 of ranks=223945rank=77600 of ranks=223945rank=77700 of ranks=223945rank=77800 of ranks=223945rank=77900 of ranks=223945rank=78000 of ranks=223945rank=78100 of ranks=223945rank=78200 of ranks=223945rank=78300 of ranks=223945rank=78400 of ranks=223945rank=78500 of ranks=223945rank=78600 of ranks=223945rank=78700 of ranks=223945rank=78800 of ranks=223945rank=78900 of ranks=223945rank=79000 of ranks=223945rank=79100 of ranks=223945rank=79200 of ranks=223945rank=79300 of ranks=223945rank=79400 of ranks=223945rank=79500 of ranks=223945rank=79600 of ranks=223945rank=79700 of ranks=223945rank=79800 of ranks=223945rank=79900 of ranks=223945rank=80000 of ranks=223945rank=80100 of ranks=223945rank=80200 of ranks=223945rank=80300 of ranks=223945rank=80400 of ranks=223945rank=80500 of ranks=223945rank=80600 of ranks=223945rank=80700 of ranks=223945rank=80800 of ranks=223945rank=80900 of ranks=223945rank=81000 of ranks=223945rank=81100 of ranks=223945rank=81200 of ranks=223945rank=81300 of ranks=223945rank=81400 of ranks=223945rank=81500 of ranks=223945rank=81600 of ranks=223945rank=81700 of ranks=223945rank=81800 of ranks=223945rank=81900 of ranks=223945rank=82000 of ranks=223945rank=82100 of ranks=223945rank=82200 of ranks=223945rank=82300 of ranks=223945rank=82400 of ranks=223945rank=82500 of ranks=223945rank=82600 of ranks=223945rank=82700 of ranks=223945rank=82800 of ranks=223945rank=82900 of ranks=223945rank=83000 of ranks=223945rank=83100 of ranks=223945rank=83200 of ranks=223945rank=83300 of ranks=223945rank=83400 of ranks=223945rank=83500 of ranks=223945rank=83600 of ranks=223945rank=83700 of ranks=223945rank=83800 of ranks=223945rank=83900 of ranks=223945rank=84000 of ranks=223945rank=84100 of ranks=223945rank=84200 of ranks=223945rank=84300 of ranks=223945rank=84400 of ranks=223945rank=84500 of ranks=223945rank=84600 of ranks=223945rank=84700 of ranks=223945rank=84800 of ranks=223945rank=84900 of ranks=223945rank=85000 of ranks=223945rank=85100 of ranks=223945rank=85200 of ranks=223945rank=85300 of ranks=223945rank=85400 of ranks=223945rank=85500 of ranks=223945rank=85600 of ranks=223945rank=85700 of ranks=223945rank=85800 of ranks=223945rank=85900 of ranks=223945rank=86000 of ranks=223945rank=86100 of ranks=223945rank=86200 of ranks=223945rank=86300 of ranks=223945rank=86400 of ranks=223945rank=86500 of ranks=223945rank=86600 of ranks=223945rank=86700 of ranks=223945rank=86800 of ranks=223945rank=86900 of ranks=223945rank=87000 of ranks=223945rank=87100 of ranks=223945rank=87200 of ranks=223945rank=87300 of ranks=223945rank=87400 of ranks=223945rank=87500 of ranks=223945rank=87600 of ranks=223945rank=87700 of ranks=223945rank=87800 of ranks=223945rank=87900 of ranks=223945rank=88000 of ranks=223945rank=88100 of ranks=223945rank=88200 of ranks=223945rank=88300 of ranks=223945rank=88400 of ranks=223945rank=88500 of ranks=223945rank=88600 of ranks=223945rank=88700 of ranks=223945rank=88800 of ranks=223945rank=88900 of ranks=223945rank=89000 of ranks=223945rank=89100 of ranks=223945rank=89200 of ranks=223945rank=89300 of ranks=223945rank=89400 of ranks=223945rank=89500 of ranks=223945rank=89600 of ranks=223945rank=89700 of ranks=223945rank=89800 of ranks=223945rank=89900 of ranks=223945rank=90000 of ranks=223945rank=90100 of ranks=223945rank=90200 of ranks=223945rank=90300 of ranks=223945rank=90400 of ranks=223945rank=90500 of ranks=223945rank=90600 of ranks=223945rank=90700 of ranks=223945rank=90800 of ranks=223945rank=90900 of ranks=223945rank=91000 of ranks=223945rank=91100 of ranks=223945rank=91200 of ranks=223945rank=91300 of ranks=223945rank=91400 of ranks=223945rank=91500 of ranks=223945rank=91600 of ranks=223945rank=91700 of ranks=223945rank=91800 of ranks=223945rank=91900 of ranks=223945rank=92000 of ranks=223945rank=92100 of ranks=223945rank=92200 of ranks=223945rank=92300 of ranks=223945rank=92400 of ranks=223945rank=92500 of ranks=223945rank=92600 of ranks=223945rank=92700 of ranks=223945rank=92800 of ranks=223945rank=92900 of ranks=223945rank=93000 of ranks=223945rank=93100 of ranks=223945rank=93200 of ranks=223945rank=93300 of ranks=223945rank=93400 of ranks=223945rank=93500 of ranks=223945rank=93600 of ranks=223945rank=93700 of ranks=223945rank=93800 of ranks=223945rank=93900 of ranks=223945rank=94000 of ranks=223945rank=94100 of ranks=223945rank=94200 of ranks=223945rank=94300 of ranks=223945rank=94400 of ranks=223945rank=94500 of ranks=223945rank=94600 of ranks=223945rank=94700 of ranks=223945rank=94800 of ranks=223945rank=94900 of ranks=223945rank=95000 of ranks=223945rank=95100 of ranks=223945rank=95200 of ranks=223945rank=95300 of ranks=223945rank=95400 of ranks=223945rank=95500 of ranks=223945rank=95600 of ranks=223945rank=95700 of ranks=223945rank=95800 of ranks=223945rank=95900 of ranks=223945rank=96000 of ranks=223945rank=96100 of ranks=223945rank=96200 of ranks=223945rank=96300 of ranks=223945rank=96400 of ranks=223945rank=96500 of ranks=223945rank=96600 of ranks=223945rank=96700 of ranks=223945rank=96800 of ranks=223945rank=96900 of ranks=223945rank=97000 of ranks=223945rank=97100 of ranks=223945rank=97200 of ranks=223945rank=97300 of ranks=223945rank=97400 of ranks=223945rank=97500 of ranks=223945rank=97600 of ranks=223945rank=97700 of ranks=223945rank=97800 of ranks=223945rank=97900 of ranks=223945rank=98000 of ranks=223945rank=98100 of ranks=223945rank=98200 of ranks=223945rank=98300 of ranks=223945rank=98400 of ranks=223945rank=98500 of ranks=223945rank=98600 of ranks=223945rank=98700 of ranks=223945rank=98800 of ranks=223945rank=98900 of ranks=223945rank=99000 of ranks=223945rank=99100 of ranks=223945rank=99200 of ranks=223945rank=99300 of ranks=223945rank=99400 of ranks=223945rank=99500 of ranks=223945rank=99600 of ranks=223945rank=99700 of ranks=223945rank=99800 of ranks=223945rank=99900 of ranks=223945rank=100000 of ranks=223945rank=100100 of ranks=223945rank=100200 of ranks=223945rank=100300 of ranks=223945rank=100400 of ranks=223945rank=100500 of ranks=223945rank=100600 of ranks=223945rank=100700 of ranks=223945rank=100800 of ranks=223945rank=100900 of ranks=223945rank=101000 of ranks=223945rank=101100 of ranks=223945rank=101200 of ranks=223945rank=101300 of ranks=223945rank=101400 of ranks=223945rank=101500 of ranks=223945rank=101600 of ranks=223945rank=101700 of ranks=223945rank=101800 of ranks=223945rank=101900 of ranks=223945rank=102000 of ranks=223945rank=102100 of ranks=223945rank=102200 of ranks=223945rank=102300 of ranks=223945rank=102400 of ranks=223945rank=102500 of ranks=223945rank=102600 of ranks=223945rank=102700 of ranks=223945rank=102800 of ranks=223945rank=102900 of ranks=223945rank=103000 of ranks=223945rank=103100 of ranks=223945rank=103200 of ranks=223945rank=103300 of ranks=223945rank=103400 of ranks=223945rank=103500 of ranks=223945rank=103600 of ranks=223945rank=103700 of ranks=223945rank=103800 of ranks=223945rank=103900 of ranks=223945rank=104000 of ranks=223945rank=104100 of ranks=223945rank=104200 of ranks=223945rank=104300 of ranks=223945rank=104400 of ranks=223945rank=104500 of ranks=223945rank=104600 of ranks=223945rank=104700 of ranks=223945rank=104800 of ranks=223945rank=104900 of ranks=223945rank=105000 of ranks=223945rank=105100 of ranks=223945rank=105200 of ranks=223945rank=105300 of ranks=223945rank=105400 of ranks=223945rank=105500 of ranks=223945rank=105600 of ranks=223945rank=105700 of ranks=223945rank=105800 of ranks=223945rank=105900 of ranks=223945rank=106000 of ranks=223945rank=106100 of ranks=223945rank=106200 of ranks=223945rank=106300 of ranks=223945rank=106400 of ranks=223945rank=106500 of ranks=223945rank=106600 of ranks=223945rank=106700 of ranks=223945rank=106800 of ranks=223945rank=106900 of ranks=223945rank=107000 of ranks=223945rank=107100 of ranks=223945rank=107200 of ranks=223945rank=107300 of ranks=223945rank=107400 of ranks=223945rank=107500 of ranks=223945rank=107600 of ranks=223945rank=107700 of ranks=223945rank=107800 of ranks=223945rank=107900 of ranks=223945rank=108000 of ranks=223945rank=108100 of ranks=223945rank=108200 of ranks=223945rank=108300 of ranks=223945rank=108400 of ranks=223945rank=108500 of ranks=223945rank=108600 of ranks=223945rank=108700 of ranks=223945rank=108800 of ranks=223945rank=108900 of ranks=223945rank=109000 of ranks=223945rank=109100 of ranks=223945rank=109200 of ranks=223945rank=109300 of ranks=223945rank=109400 of ranks=223945rank=109500 of ranks=223945rank=109600 of ranks=223945rank=109700 of ranks=223945rank=109800 of ranks=223945rank=109900 of ranks=223945rank=110000 of ranks=223945rank=110100 of ranks=223945rank=110200 of ranks=223945rank=110300 of ranks=223945rank=110400 of ranks=223945rank=110500 of ranks=223945rank=110600 of ranks=223945rank=110700 of ranks=223945rank=110800 of ranks=223945rank=110900 of ranks=223945rank=111000 of ranks=223945rank=111100 of ranks=223945rank=111200 of ranks=223945rank=111300 of ranks=223945rank=111400 of ranks=223945rank=111500 of ranks=223945rank=111600 of ranks=223945rank=111700 of ranks=223945rank=111800 of ranks=223945rank=111900 of ranks=223945rank=112000 of ranks=223945rank=112100 of ranks=223945rank=112200 of ranks=223945rank=112300 of ranks=223945rank=112400 of ranks=223945rank=112500 of ranks=223945rank=112600 of ranks=223945rank=112700 of ranks=223945rank=112800 of ranks=223945rank=112900 of ranks=223945rank=113000 of ranks=223945rank=113100 of ranks=223945rank=113200 of ranks=223945rank=113300 of ranks=223945rank=113400 of ranks=223945rank=113500 of ranks=223945rank=113600 of ranks=223945rank=113700 of ranks=223945rank=113800 of ranks=223945rank=113900 of ranks=223945rank=114000 of ranks=223945rank=114100 of ranks=223945rank=114200 of ranks=223945rank=114300 of ranks=223945rank=114400 of ranks=223945rank=114500 of ranks=223945rank=114600 of ranks=223945rank=114700 of ranks=223945rank=114800 of ranks=223945rank=114900 of ranks=223945rank=115000 of ranks=223945rank=115100 of ranks=223945rank=115200 of ranks=223945rank=115300 of ranks=223945rank=115400 of ranks=223945rank=115500 of ranks=223945rank=115600 of ranks=223945rank=115700 of ranks=223945rank=115800 of ranks=223945rank=115900 of ranks=223945rank=116000 of ranks=223945rank=116100 of ranks=223945rank=116200 of ranks=223945rank=116300 of ranks=223945rank=116400 of ranks=223945rank=116500 of ranks=223945rank=116600 of ranks=223945rank=116700 of ranks=223945rank=116800 of ranks=223945rank=116900 of ranks=223945rank=117000 of ranks=223945rank=117100 of ranks=223945rank=117200 of ranks=223945rank=117300 of ranks=223945rank=117400 of ranks=223945rank=117500 of ranks=223945rank=117600 of ranks=223945rank=117700 of ranks=223945rank=117800 of ranks=223945rank=117900 of ranks=223945rank=118000 of ranks=223945rank=118100 of ranks=223945rank=118200 of ranks=223945rank=118300 of ranks=223945rank=118400 of ranks=223945rank=118500 of ranks=223945rank=118600 of ranks=223945rank=118700 of ranks=223945rank=118800 of ranks=223945rank=118900 of ranks=223945rank=119000 of ranks=223945rank=119100 of ranks=223945rank=119200 of ranks=223945rank=119300 of ranks=223945rank=119400 of ranks=223945rank=119500 of ranks=223945rank=119600 of ranks=223945rank=119700 of ranks=223945rank=119800 of ranks=223945rank=119900 of ranks=223945rank=120000 of ranks=223945rank=120100 of ranks=223945rank=120200 of ranks=223945rank=120300 of ranks=223945rank=120400 of ranks=223945rank=120500 of ranks=223945rank=120600 of ranks=223945rank=120700 of ranks=223945rank=120800 of ranks=223945rank=120900 of ranks=223945rank=121000 of ranks=223945rank=121100 of ranks=223945rank=121200 of ranks=223945rank=121300 of ranks=223945rank=121400 of ranks=223945rank=121500 of ranks=223945rank=121600 of ranks=223945rank=121700 of ranks=223945rank=121800 of ranks=223945rank=121900 of ranks=223945rank=122000 of ranks=223945rank=122100 of ranks=223945rank=122200 of ranks=223945rank=122300 of ranks=223945rank=122400 of ranks=223945rank=122500 of ranks=223945rank=122600 of ranks=223945rank=122700 of ranks=223945rank=122800 of ranks=223945rank=122900 of ranks=223945rank=123000 of ranks=223945rank=123100 of ranks=223945rank=123200 of ranks=223945rank=123300 of ranks=223945rank=123400 of ranks=223945rank=123500 of ranks=223945rank=123600 of ranks=223945rank=123700 of ranks=223945rank=123800 of ranks=223945rank=123900 of ranks=223945rank=124000 of ranks=223945rank=124100 of ranks=223945rank=124200 of ranks=223945rank=124300 of ranks=223945rank=124400 of ranks=223945rank=124500 of ranks=223945rank=124600 of ranks=223945rank=124700 of ranks=223945rank=124800 of ranks=223945rank=124900 of ranks=223945rank=125000 of ranks=223945rank=125100 of ranks=223945rank=125200 of ranks=223945rank=125300 of ranks=223945rank=125400 of ranks=223945rank=125500 of ranks=223945rank=125600 of ranks=223945rank=125700 of ranks=223945rank=125800 of ranks=223945rank=125900 of ranks=223945rank=126000 of ranks=223945rank=126100 of ranks=223945rank=126200 of ranks=223945rank=126300 of ranks=223945rank=126400 of ranks=223945rank=126500 of ranks=223945rank=126600 of ranks=223945rank=126700 of ranks=223945rank=126800 of ranks=223945rank=126900 of ranks=223945rank=127000 of ranks=223945rank=127100 of ranks=223945rank=127200 of ranks=223945rank=127300 of ranks=223945rank=127400 of ranks=223945rank=127500 of ranks=223945rank=127600 of ranks=223945rank=127700 of ranks=223945rank=127800 of ranks=223945rank=127900 of ranks=223945rank=128000 of ranks=223945rank=128100 of ranks=223945rank=128200 of ranks=223945rank=128300 of ranks=223945rank=128400 of ranks=223945rank=128500 of ranks=223945rank=128600 of ranks=223945rank=128700 of ranks=223945rank=128800 of ranks=223945rank=128900 of ranks=223945rank=129000 of ranks=223945rank=129100 of ranks=223945rank=129200 of ranks=223945rank=129300 of ranks=223945rank=129400 of ranks=223945rank=129500 of ranks=223945rank=129600 of ranks=223945rank=129700 of ranks=223945rank=129800 of ranks=223945rank=129900 of ranks=223945rank=130000 of ranks=223945rank=130100 of ranks=223945rank=130200 of ranks=223945rank=130300 of ranks=223945rank=130400 of ranks=223945rank=130500 of ranks=223945rank=130600 of ranks=223945rank=130700 of ranks=223945rank=130800 of ranks=223945rank=130900 of ranks=223945rank=131000 of ranks=223945rank=131100 of ranks=223945rank=131200 of ranks=223945rank=131300 of ranks=223945rank=131400 of ranks=223945rank=131500 of ranks=223945rank=131600 of ranks=223945rank=131700 of ranks=223945rank=131800 of ranks=223945rank=131900 of ranks=223945rank=132000 of ranks=223945rank=132100 of ranks=223945rank=132200 of ranks=223945rank=132300 of ranks=223945rank=132400 of ranks=223945rank=132500 of ranks=223945rank=132600 of ranks=223945rank=132700 of ranks=223945rank=132800 of ranks=223945rank=132900 of ranks=223945rank=133000 of ranks=223945rank=133100 of ranks=223945rank=133200 of ranks=223945rank=133300 of ranks=223945rank=133400 of ranks=223945rank=133500 of ranks=223945rank=133600 of ranks=223945rank=133700 of ranks=223945rank=133800 of ranks=223945rank=133900 of ranks=223945rank=134000 of ranks=223945rank=134100 of ranks=223945rank=134200 of ranks=223945rank=134300 of ranks=223945rank=134400 of ranks=223945rank=134500 of ranks=223945rank=134600 of ranks=223945rank=134700 of ranks=223945rank=134800 of ranks=223945rank=134900 of ranks=223945rank=135000 of ranks=223945rank=135100 of ranks=223945rank=135200 of ranks=223945rank=135300 of ranks=223945rank=135400 of ranks=223945rank=135500 of ranks=223945rank=135600 of ranks=223945rank=135700 of ranks=223945rank=135800 of ranks=223945rank=135900 of ranks=223945rank=136000 of ranks=223945rank=136100 of ranks=223945rank=136200 of ranks=223945rank=136300 of ranks=223945rank=136400 of ranks=223945rank=136500 of ranks=223945rank=136600 of ranks=223945rank=136700 of ranks=223945rank=136800 of ranks=223945rank=136900 of ranks=223945rank=137000 of ranks=223945rank=137100 of ranks=223945rank=137200 of ranks=223945rank=137300 of ranks=223945rank=137400 of ranks=223945rank=137500 of ranks=223945rank=137600 of ranks=223945rank=137700 of ranks=223945rank=137800 of ranks=223945rank=137900 of ranks=223945rank=138000 of ranks=223945rank=138100 of ranks=223945rank=138200 of ranks=223945rank=138300 of ranks=223945rank=138400 of ranks=223945rank=138500 of ranks=223945rank=138600 of ranks=223945rank=138700 of ranks=223945rank=138800 of ranks=223945rank=138900 of ranks=223945rank=139000 of ranks=223945rank=139100 of ranks=223945rank=139200 of ranks=223945rank=139300 of ranks=223945rank=139400 of ranks=223945rank=139500 of ranks=223945rank=139600 of ranks=223945rank=139700 of ranks=223945rank=139800 of ranks=223945rank=139900 of ranks=223945rank=140000 of ranks=223945rank=140100 of ranks=223945rank=140200 of ranks=223945rank=140300 of ranks=223945rank=140400 of ranks=223945rank=140500 of ranks=223945rank=140600 of ranks=223945rank=140700 of ranks=223945rank=140800 of ranks=223945rank=140900 of ranks=223945rank=141000 of ranks=223945rank=141100 of ranks=223945rank=141200 of ranks=223945rank=141300 of ranks=223945rank=141400 of ranks=223945rank=141500 of ranks=223945rank=141600 of ranks=223945rank=141700 of ranks=223945rank=141800 of ranks=223945rank=141900 of ranks=223945rank=142000 of ranks=223945rank=142100 of ranks=223945rank=142200 of ranks=223945rank=142300 of ranks=223945rank=142400 of ranks=223945rank=142500 of ranks=223945rank=142600 of ranks=223945rank=142700 of ranks=223945rank=142800 of ranks=223945rank=142900 of ranks=223945rank=143000 of ranks=223945rank=143100 of ranks=223945rank=143200 of ranks=223945rank=143300 of ranks=223945rank=143400 of ranks=223945rank=143500 of ranks=223945rank=143600 of ranks=223945rank=143700 of ranks=223945rank=143800 of ranks=223945rank=143900 of ranks=223945rank=144000 of ranks=223945rank=144100 of ranks=223945rank=144200 of ranks=223945rank=144300 of ranks=223945rank=144400 of ranks=223945rank=144500 of ranks=223945rank=144600 of ranks=223945rank=144700 of ranks=223945rank=144800 of ranks=223945rank=144900 of ranks=223945rank=145000 of ranks=223945rank=145100 of ranks=223945rank=145200 of ranks=223945rank=145300 of ranks=223945rank=145400 of ranks=223945rank=145500 of ranks=223945rank=145600 of ranks=223945rank=145700 of ranks=223945rank=145800 of ranks=223945rank=145900 of ranks=223945rank=146000 of ranks=223945rank=146100 of ranks=223945rank=146200 of ranks=223945rank=146300 of ranks=223945rank=146400 of ranks=223945rank=146500 of ranks=223945rank=146600 of ranks=223945rank=146700 of ranks=223945rank=146800 of ranks=223945rank=146900 of ranks=223945rank=147000 of ranks=223945rank=147100 of ranks=223945rank=147200 of ranks=223945rank=147300 of ranks=223945rank=147400 of ranks=223945rank=147500 of ranks=223945rank=147600 of ranks=223945rank=147700 of ranks=223945rank=147800 of ranks=223945rank=147900 of ranks=223945rank=148000 of ranks=223945rank=148100 of ranks=223945rank=148200 of ranks=223945rank=148300 of ranks=223945rank=148400 of ranks=223945rank=148500 of ranks=223945rank=148600 of ranks=223945rank=148700 of ranks=223945rank=148800 of ranks=223945rank=148900 of ranks=223945rank=149000 of ranks=223945rank=149100 of ranks=223945rank=149200 of ranks=223945rank=149300 of ranks=223945rank=149400 of ranks=223945rank=149500 of ranks=223945rank=149600 of ranks=223945rank=149700 of ranks=223945rank=149800 of ranks=223945rank=149900 of ranks=223945rank=150000 of ranks=223945rank=150100 of ranks=223945rank=150200 of ranks=223945rank=150300 of ranks=223945rank=150400 of ranks=223945rank=150500 of ranks=223945rank=150600 of ranks=223945rank=150700 of ranks=223945rank=150800 of ranks=223945rank=150900 of ranks=223945rank=151000 of ranks=223945rank=151100 of ranks=223945rank=151200 of ranks=223945rank=151300 of ranks=223945rank=151400 of ranks=223945rank=151500 of ranks=223945rank=151600 of ranks=223945rank=151700 of ranks=223945rank=151800 of ranks=223945rank=151900 of ranks=223945rank=152000 of ranks=223945rank=152100 of ranks=223945rank=152200 of ranks=223945rank=152300 of ranks=223945rank=152400 of ranks=223945rank=152500 of ranks=223945rank=152600 of ranks=223945rank=152700 of ranks=223945rank=152800 of ranks=223945rank=152900 of ranks=223945rank=153000 of ranks=223945rank=153100 of ranks=223945rank=153200 of ranks=223945rank=153300 of ranks=223945rank=153400 of ranks=223945rank=153500 of ranks=223945rank=153600 of ranks=223945rank=153700 of ranks=223945rank=153800 of ranks=223945rank=153900 of ranks=223945rank=154000 of ranks=223945rank=154100 of ranks=223945rank=154200 of ranks=223945rank=154300 of ranks=223945rank=154400 of ranks=223945rank=154500 of ranks=223945rank=154600 of ranks=223945rank=154700 of ranks=223945rank=154800 of ranks=223945rank=154900 of ranks=223945rank=155000 of ranks=223945rank=155100 of ranks=223945rank=155200 of ranks=223945rank=155300 of ranks=223945rank=155400 of ranks=223945rank=155500 of ranks=223945rank=155600 of ranks=223945rank=155700 of ranks=223945rank=155800 of ranks=223945rank=155900 of ranks=223945rank=156000 of ranks=223945rank=156100 of ranks=223945rank=156200 of ranks=223945rank=156300 of ranks=223945rank=156400 of ranks=223945rank=156500 of ranks=223945rank=156600 of ranks=223945rank=156700 of ranks=223945rank=156800 of ranks=223945rank=156900 of ranks=223945rank=157000 of ranks=223945rank=157100 of ranks=223945rank=157200 of ranks=223945rank=157300 of ranks=223945rank=157400 of ranks=223945rank=157500 of ranks=223945rank=157600 of ranks=223945rank=157700 of ranks=223945rank=157800 of ranks=223945rank=157900 of ranks=223945rank=158000 of ranks=223945rank=158100 of ranks=223945rank=158200 of ranks=223945rank=158300 of ranks=223945rank=158400 of ranks=223945rank=158500 of ranks=223945rank=158600 of ranks=223945rank=158700 of ranks=223945rank=158800 of ranks=223945rank=158900 of ranks=223945rank=159000 of ranks=223945rank=159100 of ranks=223945rank=159200 of ranks=223945rank=159300 of ranks=223945rank=159400 of ranks=223945rank=159500 of ranks=223945rank=159600 of ranks=223945rank=159700 of ranks=223945rank=159800 of ranks=223945rank=159900 of ranks=223945rank=160000 of ranks=223945rank=160100 of ranks=223945rank=160200 of ranks=223945rank=160300 of ranks=223945rank=160400 of ranks=223945rank=160500 of ranks=223945rank=160600 of ranks=223945rank=160700 of ranks=223945rank=160800 of ranks=223945rank=160900 of ranks=223945rank=161000 of ranks=223945rank=161100 of ranks=223945rank=161200 of ranks=223945rank=161300 of ranks=223945rank=161400 of ranks=223945rank=161500 of ranks=223945rank=161600 of ranks=223945rank=161700 of ranks=223945rank=161800 of ranks=223945rank=161900 of ranks=223945rank=162000 of ranks=223945rank=162100 of ranks=223945rank=162200 of ranks=223945rank=162300 of ranks=223945rank=162400 of ranks=223945rank=162500 of ranks=223945rank=162600 of ranks=223945rank=162700 of ranks=223945rank=162800 of ranks=223945rank=162900 of ranks=223945rank=163000 of ranks=223945rank=163100 of ranks=223945rank=163200 of ranks=223945rank=163300 of ranks=223945rank=163400 of ranks=223945rank=163500 of ranks=223945rank=163600 of ranks=223945rank=163700 of ranks=223945rank=163800 of ranks=223945rank=163900 of ranks=223945rank=164000 of ranks=223945rank=164100 of ranks=223945rank=164200 of ranks=223945rank=164300 of ranks=223945rank=164400 of ranks=223945rank=164500 of ranks=223945rank=164600 of ranks=223945rank=164700 of ranks=223945rank=164800 of ranks=223945rank=164900 of ranks=223945rank=165000 of ranks=223945rank=165100 of ranks=223945rank=165200 of ranks=223945rank=165300 of ranks=223945rank=165400 of ranks=223945rank=165500 of ranks=223945rank=165600 of ranks=223945rank=165700 of ranks=223945rank=165800 of ranks=223945rank=165900 of ranks=223945rank=166000 of ranks=223945rank=166100 of ranks=223945rank=166200 of ranks=223945rank=166300 of ranks=223945rank=166400 of ranks=223945rank=166500 of ranks=223945rank=166600 of ranks=223945rank=166700 of ranks=223945rank=166800 of ranks=223945rank=166900 of ranks=223945rank=167000 of ranks=223945rank=167100 of ranks=223945rank=167200 of ranks=223945rank=167300 of ranks=223945rank=167400 of ranks=223945rank=167500 of ranks=223945rank=167600 of ranks=223945rank=167700 of ranks=223945rank=167800 of ranks=223945rank=167900 of ranks=223945rank=168000 of ranks=223945rank=168100 of ranks=223945rank=168200 of ranks=223945rank=168300 of ranks=223945rank=168400 of ranks=223945rank=168500 of ranks=223945rank=168600 of ranks=223945rank=168700 of ranks=223945rank=168800 of ranks=223945rank=168900 of ranks=223945rank=169000 of ranks=223945rank=169100 of ranks=223945rank=169200 of ranks=223945rank=169300 of ranks=223945rank=169400 of ranks=223945rank=169500 of ranks=223945rank=169600 of ranks=223945rank=169700 of ranks=223945rank=169800 of ranks=223945rank=169900 of ranks=223945rank=170000 of ranks=223945rank=170100 of ranks=223945rank=170200 of ranks=223945rank=170300 of ranks=223945rank=170400 of ranks=223945rank=170500 of ranks=223945rank=170600 of ranks=223945rank=170700 of ranks=223945rank=170800 of ranks=223945rank=170900 of ranks=223945rank=171000 of ranks=223945rank=171100 of ranks=223945rank=171200 of ranks=223945rank=171300 of ranks=223945rank=171400 of ranks=223945rank=171500 of ranks=223945rank=171600 of ranks=223945rank=171700 of ranks=223945rank=171800 of ranks=223945rank=171900 of ranks=223945rank=172000 of ranks=223945rank=172100 of ranks=223945rank=172200 of ranks=223945rank=172300 of ranks=223945rank=172400 of ranks=223945rank=172500 of ranks=223945rank=172600 of ranks=223945rank=172700 of ranks=223945rank=172800 of ranks=223945rank=172900 of ranks=223945rank=173000 of ranks=223945rank=173100 of ranks=223945rank=173200 of ranks=223945rank=173300 of ranks=223945rank=173400 of ranks=223945rank=173500 of ranks=223945rank=173600 of ranks=223945rank=173700 of ranks=223945rank=173800 of ranks=223945rank=173900 of ranks=223945rank=174000 of ranks=223945rank=174100 of ranks=223945rank=174200 of ranks=223945rank=174300 of ranks=223945rank=174400 of ranks=223945rank=174500 of ranks=223945rank=174600 of ranks=223945rank=174700 of ranks=223945rank=174800 of ranks=223945rank=174900 of ranks=223945rank=175000 of ranks=223945rank=175100 of ranks=223945rank=175200 of ranks=223945rank=175300 of ranks=223945rank=175400 of ranks=223945rank=175500 of ranks=223945rank=175600 of ranks=223945rank=175700 of ranks=223945rank=175800 of ranks=223945rank=175900 of ranks=223945rank=176000 of ranks=223945rank=176100 of ranks=223945rank=176200 of ranks=223945rank=176300 of ranks=223945rank=176400 of ranks=223945rank=176500 of ranks=223945rank=176600 of ranks=223945rank=176700 of ranks=223945rank=176800 of ranks=223945rank=176900 of ranks=223945rank=177000 of ranks=223945rank=177100 of ranks=223945rank=177200 of ranks=223945rank=177300 of ranks=223945rank=177400 of ranks=223945rank=177500 of ranks=223945rank=177600 of ranks=223945rank=177700 of ranks=223945rank=177800 of ranks=223945rank=177900 of ranks=223945rank=178000 of ranks=223945rank=178100 of ranks=223945rank=178200 of ranks=223945rank=178300 of ranks=223945rank=178400 of ranks=223945rank=178500 of ranks=223945rank=178600 of ranks=223945rank=178700 of ranks=223945rank=178800 of ranks=223945rank=178900 of ranks=223945rank=179000 of ranks=223945rank=179100 of ranks=223945rank=179200 of ranks=223945rank=179300 of ranks=223945rank=179400 of ranks=223945rank=179500 of ranks=223945rank=179600 of ranks=223945rank=179700 of ranks=223945rank=179800 of ranks=223945rank=179900 of ranks=223945rank=180000 of ranks=223945rank=180100 of ranks=223945rank=180200 of ranks=223945rank=180300 of ranks=223945rank=180400 of ranks=223945rank=180500 of ranks=223945rank=180600 of ranks=223945rank=180700 of ranks=223945rank=180800 of ranks=223945rank=180900 of ranks=223945rank=181000 of ranks=223945rank=181100 of ranks=223945rank=181200 of ranks=223945rank=181300 of ranks=223945rank=181400 of ranks=223945rank=181500 of ranks=223945rank=181600 of ranks=223945rank=181700 of ranks=223945rank=181800 of ranks=223945rank=181900 of ranks=223945rank=182000 of ranks=223945rank=182100 of ranks=223945rank=182200 of ranks=223945rank=182300 of ranks=223945rank=182400 of ranks=223945rank=182500 of ranks=223945rank=182600 of ranks=223945rank=182700 of ranks=223945rank=182800 of ranks=223945rank=182900 of ranks=223945rank=183000 of ranks=223945rank=183100 of ranks=223945rank=183200 of ranks=223945rank=183300 of ranks=223945rank=183400 of ranks=223945rank=183500 of ranks=223945rank=183600 of ranks=223945rank=183700 of ranks=223945rank=183800 of ranks=223945rank=183900 of ranks=223945rank=184000 of ranks=223945rank=184100 of ranks=223945rank=184200 of ranks=223945rank=184300 of ranks=223945rank=184400 of ranks=223945rank=184500 of ranks=223945rank=184600 of ranks=223945rank=184700 of ranks=223945rank=184800 of ranks=223945rank=184900 of ranks=223945rank=185000 of ranks=223945rank=185100 of ranks=223945rank=185200 of ranks=223945rank=185300 of ranks=223945rank=185400 of ranks=223945rank=185500 of ranks=223945rank=185600 of ranks=223945rank=185700 of ranks=223945rank=185800 of ranks=223945rank=185900 of ranks=223945rank=186000 of ranks=223945rank=186100 of ranks=223945rank=186200 of ranks=223945rank=186300 of ranks=223945rank=186400 of ranks=223945rank=186500 of ranks=223945rank=186600 of ranks=223945rank=186700 of ranks=223945rank=186800 of ranks=223945rank=186900 of ranks=223945rank=187000 of ranks=223945rank=187100 of ranks=223945rank=187200 of ranks=223945rank=187300 of ranks=223945rank=187400 of ranks=223945rank=187500 of ranks=223945rank=187600 of ranks=223945rank=187700 of ranks=223945rank=187800 of ranks=223945rank=187900 of ranks=223945rank=188000 of ranks=223945rank=188100 of ranks=223945rank=188200 of ranks=223945rank=188300 of ranks=223945rank=188400 of ranks=223945rank=188500 of ranks=223945rank=188600 of ranks=223945rank=188700 of ranks=223945rank=188800 of ranks=223945rank=188900 of ranks=223945rank=189000 of ranks=223945rank=189100 of ranks=223945rank=189200 of ranks=223945rank=189300 of ranks=223945rank=189400 of ranks=223945rank=189500 of ranks=223945rank=189600 of ranks=223945rank=189700 of ranks=223945rank=189800 of ranks=223945rank=189900 of ranks=223945rank=190000 of ranks=223945rank=190100 of ranks=223945rank=190200 of ranks=223945rank=190300 of ranks=223945rank=190400 of ranks=223945rank=190500 of ranks=223945rank=190600 of ranks=223945rank=190700 of ranks=223945rank=190800 of ranks=223945rank=190900 of ranks=223945rank=191000 of ranks=223945rank=191100 of ranks=223945rank=191200 of ranks=223945rank=191300 of ranks=223945rank=191400 of ranks=223945rank=191500 of ranks=223945rank=191600 of ranks=223945rank=191700 of ranks=223945rank=191800 of ranks=223945rank=191900 of ranks=223945rank=192000 of ranks=223945rank=192100 of ranks=223945rank=192200 of ranks=223945rank=192300 of ranks=223945rank=192400 of ranks=223945rank=192500 of ranks=223945rank=192600 of ranks=223945rank=192700 of ranks=223945rank=192800 of ranks=223945rank=192900 of ranks=223945rank=193000 of ranks=223945rank=193100 of ranks=223945rank=193200 of ranks=223945rank=193300 of ranks=223945rank=193400 of ranks=223945rank=193500 of ranks=223945rank=193600 of ranks=223945rank=193700 of ranks=223945rank=193800 of ranks=223945rank=193900 of ranks=223945rank=194000 of ranks=223945rank=194100 of ranks=223945rank=194200 of ranks=223945rank=194300 of ranks=223945rank=194400 of ranks=223945rank=194500 of ranks=223945rank=194600 of ranks=223945rank=194700 of ranks=223945rank=194800 of ranks=223945rank=194900 of ranks=223945rank=195000 of ranks=223945rank=195100 of ranks=223945rank=195200 of ranks=223945rank=195300 of ranks=223945rank=195400 of ranks=223945rank=195500 of ranks=223945rank=195600 of ranks=223945rank=195700 of ranks=223945rank=195800 of ranks=223945rank=195900 of ranks=223945rank=196000 of ranks=223945rank=196100 of ranks=223945rank=196200 of ranks=223945rank=196300 of ranks=223945rank=196400 of ranks=223945rank=196500 of ranks=223945rank=196600 of ranks=223945rank=196700 of ranks=223945rank=196800 of ranks=223945rank=196900 of ranks=223945rank=197000 of ranks=223945rank=197100 of ranks=223945rank=197200 of ranks=223945rank=197300 of ranks=223945rank=197400 of ranks=223945rank=197500 of ranks=223945rank=197600 of ranks=223945rank=197700 of ranks=223945rank=197800 of ranks=223945rank=197900 of ranks=223945rank=198000 of ranks=223945rank=198100 of ranks=223945rank=198200 of ranks=223945rank=198300 of ranks=223945rank=198400 of ranks=223945rank=198500 of ranks=223945rank=198600 of ranks=223945rank=198700 of ranks=223945rank=198800 of ranks=223945rank=198900 of ranks=223945rank=199000 of ranks=223945rank=199100 of ranks=223945rank=199200 of ranks=223945rank=199300 of ranks=223945rank=199400 of ranks=223945rank=199500 of ranks=223945rank=199600 of ranks=223945rank=199700 of ranks=223945rank=199800 of ranks=223945rank=199900 of ranks=223945rank=200000 of ranks=223945rank=200100 of ranks=223945rank=200200 of ranks=223945rank=200300 of ranks=223945rank=200400 of ranks=223945rank=200500 of ranks=223945rank=200600 of ranks=223945rank=200700 of ranks=223945rank=200800 of ranks=223945rank=200900 of ranks=223945rank=201000 of ranks=223945rank=201100 of ranks=223945rank=201200 of ranks=223945rank=201300 of ranks=223945rank=201400 of ranks=223945rank=201500 of ranks=223945rank=201600 of ranks=223945rank=201700 of ranks=223945rank=201800 of ranks=223945rank=201900 of ranks=223945rank=202000 of ranks=223945rank=202100 of ranks=223945rank=202200 of ranks=223945rank=202300 of ranks=223945rank=202400 of ranks=223945rank=202500 of ranks=223945rank=202600 of ranks=223945rank=202700 of ranks=223945rank=202800 of ranks=223945rank=202900 of ranks=223945rank=203000 of ranks=223945rank=203100 of ranks=223945rank=203200 of ranks=223945rank=203300 of ranks=223945rank=203400 of ranks=223945rank=203500 of ranks=223945rank=203600 of ranks=223945rank=203700 of ranks=223945rank=203800 of ranks=223945rank=203900 of ranks=223945rank=204000 of ranks=223945rank=204100 of ranks=223945rank=204200 of ranks=223945rank=204300 of ranks=223945rank=204400 of ranks=223945rank=204500 of ranks=223945rank=204600 of ranks=223945rank=204700 of ranks=223945rank=204800 of ranks=223945rank=204900 of ranks=223945rank=205000 of ranks=223945rank=205100 of ranks=223945rank=205200 of ranks=223945rank=205300 of ranks=223945rank=205400 of ranks=223945rank=205500 of ranks=223945rank=205600 of ranks=223945rank=205700 of ranks=223945rank=205800 of ranks=223945rank=205900 of ranks=223945rank=206000 of ranks=223945rank=206100 of ranks=223945rank=206200 of ranks=223945rank=206300 of ranks=223945rank=206400 of ranks=223945rank=206500 of ranks=223945rank=206600 of ranks=223945rank=206700 of ranks=223945rank=206800 of ranks=223945rank=206900 of ranks=223945rank=207000 of ranks=223945rank=207100 of ranks=223945rank=207200 of ranks=223945rank=207300 of ranks=223945rank=207400 of ranks=223945rank=207500 of ranks=223945rank=207600 of ranks=223945rank=207700 of ranks=223945rank=207800 of ranks=223945rank=207900 of ranks=223945rank=208000 of ranks=223945rank=208100 of ranks=223945rank=208200 of ranks=223945rank=208300 of ranks=223945rank=208400 of ranks=223945rank=208500 of ranks=223945rank=208600 of ranks=223945rank=208700 of ranks=223945rank=208800 of ranks=223945rank=208900 of ranks=223945rank=209000 of ranks=223945rank=209100 of ranks=223945rank=209200 of ranks=223945rank=209300 of ranks=223945rank=209400 of ranks=223945rank=209500 of ranks=223945rank=209600 of ranks=223945rank=209700 of ranks=223945rank=209800 of ranks=223945rank=209900 of ranks=223945rank=210000 of ranks=223945rank=210100 of ranks=223945rank=210200 of ranks=223945rank=210300 of ranks=223945rank=210400 of ranks=223945rank=210500 of ranks=223945rank=210600 of ranks=223945rank=210700 of ranks=223945rank=210800 of ranks=223945rank=210900 of ranks=223945rank=211000 of ranks=223945rank=211100 of ranks=223945rank=211200 of ranks=223945rank=211300 of ranks=223945rank=211400 of ranks=223945rank=211500 of ranks=223945rank=211600 of ranks=223945rank=211700 of ranks=223945rank=211800 of ranks=223945rank=211900 of ranks=223945rank=212000 of ranks=223945rank=212100 of ranks=223945rank=212200 of ranks=223945rank=212300 of ranks=223945rank=212400 of ranks=223945rank=212500 of ranks=223945rank=212600 of ranks=223945rank=212700 of ranks=223945rank=212800 of ranks=223945rank=212900 of ranks=223945rank=213000 of ranks=223945rank=213100 of ranks=223945rank=213200 of ranks=223945rank=213300 of ranks=223945rank=213400 of ranks=223945rank=213500 of ranks=223945rank=213600 of ranks=223945rank=213700 of ranks=223945rank=213800 of ranks=223945rank=213900 of ranks=223945rank=214000 of ranks=223945rank=214100 of ranks=223945rank=214200 of ranks=223945rank=214300 of ranks=223945rank=214400 of ranks=223945rank=214500 of ranks=223945rank=214600 of ranks=223945rank=214700 of ranks=223945rank=214800 of ranks=223945rank=214900 of ranks=223945rank=215000 of ranks=223945rank=215100 of ranks=223945rank=215200 of ranks=223945rank=215300 of ranks=223945rank=215400 of ranks=223945rank=215500 of ranks=223945rank=215600 of ranks=223945rank=215700 of ranks=223945rank=215800 of ranks=223945rank=215900 of ranks=223945rank=216000 of ranks=223945rank=216100 of ranks=223945rank=216200 of ranks=223945rank=216300 of ranks=223945rank=216400 of ranks=223945rank=216500 of ranks=223945rank=216600 of ranks=223945rank=216700 of ranks=223945rank=216800 of ranks=223945rank=216900 of ranks=223945rank=217000 of ranks=223945rank=217100 of ranks=223945rank=217200 of ranks=223945rank=217300 of ranks=223945rank=217400 of ranks=223945rank=217500 of ranks=223945rank=217600 of ranks=223945rank=217700 of ranks=223945rank=217800 of ranks=223945rank=217900 of ranks=223945rank=218000 of ranks=223945rank=218100 of ranks=223945rank=218200 of ranks=223945rank=218300 of ranks=223945rank=218400 of ranks=223945rank=218500 of ranks=223945rank=218600 of ranks=223945rank=218700 of ranks=223945rank=218800 of ranks=223945rank=218900 of ranks=223945rank=219000 of ranks=223945rank=219100 of ranks=223945rank=219200 of ranks=223945rank=219300 of ranks=223945rank=219400 of ranks=223945rank=219500 of ranks=223945rank=219600 of ranks=223945rank=219700 of ranks=223945rank=219800 of ranks=223945rank=219900 of ranks=223945rank=220000 of ranks=223945rank=220100 of ranks=223945rank=220200 of ranks=223945rank=220300 of ranks=223945rank=220400 of ranks=223945rank=220500 of ranks=223945rank=220600 of ranks=223945rank=220700 of ranks=223945rank=220800 of ranks=223945rank=220900 of ranks=223945rank=221000 of ranks=223945rank=221100 of ranks=223945rank=221200 of ranks=223945rank=221300 of ranks=223945rank=221400 of ranks=223945rank=221500 of ranks=223945rank=221600 of ranks=223945rank=221700 of ranks=223945rank=221800 of ranks=223945rank=221900 of ranks=223945rank=222000 of ranks=223945rank=222100 of ranks=223945rank=222200 of ranks=223945rank=222300 of ranks=223945rank=222400 of ranks=223945rank=222500 of ranks=223945rank=222600 of ranks=223945rank=222700 of ranks=223945rank=222800 of ranks=223945rank=222900 of ranks=223945rank=223000 of ranks=223945rank=223100 of ranks=223945rank=223200 of ranks=223945rank=223300 of ranks=223945rank=223400 of ranks=223945rank=223500 of ranks=223945rank=223600 of ranks=223945rank=223700 of ranks=223945rank=223800 of ranks=223945rank=223900 of ranks=223945

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              86.2651    468  11228     30    498           71.7544
   1 car                    96.6721  49818  64503    498  50316           72.3887
   2 truck                  82.8821   1769  40750     56   1825           40.9652
   3 bus                    56.7232    354   9830     12    366           38.8220
   4 pedestrian             86.4196   4002  41223    257   4259           48.7356

for conf_thresh=0.25, precision=0.81, recall=0.92, F1 score=0.86
for conf_thresh=0.25, TP=52511, FP=12451, FN=4753, average IoU=68.99%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=81.79%
Total detection time: 126 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
New best mAP, saving weights!
Saving weights to /workspace/.cache/splits/combined_best.weights
2219: loss=5.679, avg loss=5.381, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 142016 images, time remaining=6.8 hours
2220: loss=6.229, avg loss=5.466, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 142080 images, time remaining=6.8 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2221: loss=6.107, avg loss=5.530, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 142144 images, time remaining=6.8 hours
2222: loss=6.171, avg loss=5.594, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=5.0 seconds, 142208 images, time remaining=6.8 hours
2223: loss=5.708, avg loss=5.606, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 142272 images, time remaining=6.8 hours
2224: loss=6.431, avg loss=5.688, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 142336 images, time remaining=6.8 hours
2225: loss=6.789, avg loss=5.798, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 142400 images, time remaining=6.8 hours
2226: loss=6.220, avg loss=5.840, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 142464 images, time remaining=6.8 hours
2227: loss=6.141, avg loss=5.870, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.9 seconds, train=4.9 seconds, 142528 images, time remaining=6.8 hours
2228: loss=6.446, avg loss=5.928, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=5.0 seconds, 142592 images, time remaining=6.8 hours
2229: loss=6.904, avg loss=6.026, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 142656 images, time remaining=6.8 hours
2230: loss=5.966, avg loss=6.020, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 142720 images, time remaining=6.8 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2231: loss=7.387, avg loss=6.156, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.9 seconds, train=5.6 seconds, 142784 images, time remaining=6.8 hours
2232: loss=4.863, avg loss=6.027, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 142848 images, time remaining=6.8 hours
2233: loss=5.816, avg loss=6.006, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 142912 images, time remaining=6.8 hours
2234: loss=5.654, avg loss=5.971, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 142976 images, time remaining=6.8 hours
2235: loss=5.907, avg loss=5.964, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=5.4 seconds, 143040 images, time remaining=6.8 hours
2236: loss=6.492, avg loss=6.017, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 143104 images, time remaining=6.8 hours
2237: loss=5.698, avg loss=5.985, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 143168 images, time remaining=6.8 hours
2238: loss=5.909, avg loss=5.977, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 143232 images, time remaining=6.8 hours
2239: loss=6.256, avg loss=6.005, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=5.5 seconds, 143296 images, time remaining=6.8 hours
2240: loss=5.603, avg loss=5.965, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 143360 images, time remaining=6.8 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b4f0e00000
2241: loss=5.940, avg loss=5.963, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 143424 images, time remaining=6.8 hours
2242: loss=5.959, avg loss=5.962, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 143488 images, time remaining=6.8 hours
2243: loss=6.767, avg loss=6.043, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 143552 images, time remaining=6.8 hours
2244: loss=6.213, avg loss=6.060, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 143616 images, time remaining=6.8 hours
2245: loss=6.024, avg loss=6.056, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 143680 images, time remaining=6.8 hours
2246: loss=5.605, avg loss=6.011, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 143744 images, time remaining=6.8 hours
2247: loss=5.307, avg loss=5.941, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 143808 images, time remaining=6.8 hours
2248: loss=5.477, avg loss=5.894, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 143872 images, time remaining=6.8 hours
2249: loss=5.386, avg loss=5.844, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 143936 images, time remaining=6.8 hours
2250: loss=5.119, avg loss=5.771, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 144000 images, time remaining=6.8 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2251: loss=6.346, avg loss=5.828, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 144064 images, time remaining=6.8 hours
2252: loss=5.619, avg loss=5.808, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 144128 images, time remaining=6.8 hours
2253: loss=6.971, avg loss=5.924, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.0 seconds, train=4.7 seconds, 144192 images, time remaining=6.8 hours
2254: loss=4.691, avg loss=5.801, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 144256 images, time remaining=6.8 hours
2255: loss=5.315, avg loss=5.752, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 144320 images, time remaining=6.8 hours
2256: loss=5.646, avg loss=5.741, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 144384 images, time remaining=6.8 hours
2257: loss=5.118, avg loss=5.679, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 144448 images, time remaining=6.8 hours
2258: loss=6.315, avg loss=5.743, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 144512 images, time remaining=6.7 hours
2259: loss=7.095, avg loss=5.878, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 144576 images, time remaining=6.7 hours
2260: loss=6.635, avg loss=5.954, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 144640 images, time remaining=6.7 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2261: loss=6.852, avg loss=6.043, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 144704 images, time remaining=6.7 hours
2262: loss=6.041, avg loss=6.043, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 144768 images, time remaining=6.7 hours
2263: loss=6.052, avg loss=6.044, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.7 seconds, 144832 images, time remaining=6.7 hours
2264: loss=5.242, avg loss=5.964, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 144896 images, time remaining=6.7 hours
2265: loss=5.989, avg loss=5.966, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 144960 images, time remaining=6.7 hours
2266: loss=6.856, avg loss=6.055, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.4 seconds, train=4.8 seconds, 145024 images, time remaining=6.7 hours
2267: loss=5.179, avg loss=5.968, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 145088 images, time remaining=6.7 hours
2268: loss=6.072, avg loss=5.978, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 145152 images, time remaining=6.7 hours
2269: loss=5.704, avg loss=5.951, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 145216 images, time remaining=6.7 hours
2270: loss=5.982, avg loss=5.954, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 145280 images, time remaining=6.7 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b344000000
2271: loss=8.364, avg loss=6.195, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 145344 images, time remaining=6.7 hours
2272: loss=6.091, avg loss=6.184, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 145408 images, time remaining=6.7 hours
2273: loss=5.581, avg loss=6.124, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 145472 images, time remaining=6.7 hours
2274: loss=5.907, avg loss=6.102, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 145536 images, time remaining=6.7 hours
2275: loss=5.085, avg loss=6.001, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 145600 images, time remaining=6.7 hours
2276: loss=5.587, avg loss=5.959, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 145664 images, time remaining=6.7 hours
2277: loss=6.684, avg loss=6.032, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 145728 images, time remaining=6.7 hours
2278: loss=5.921, avg loss=6.021, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 145792 images, time remaining=6.7 hours
2279: loss=4.454, avg loss=5.864, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 145856 images, time remaining=6.7 hours
2280: loss=5.542, avg loss=5.832, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 145920 images, time remaining=6.7 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2281: loss=7.902, avg loss=6.039, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.9 seconds, train=4.4 seconds, 145984 images, time remaining=6.7 hours
2282: loss=8.456, avg loss=6.281, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.5 seconds, 146048 images, time remaining=6.7 hours
2283: loss=6.926, avg loss=6.345, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.5 seconds, 146112 images, time remaining=6.7 hours
2284: loss=5.582, avg loss=6.269, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 146176 images, time remaining=6.7 hours
2285: loss=6.032, avg loss=6.245, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.5 seconds, 146240 images, time remaining=6.7 hours
2286: loss=5.812, avg loss=6.202, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 146304 images, time remaining=6.7 hours
2287: loss=6.353, avg loss=6.217, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.5 seconds, 146368 images, time remaining=6.7 hours
2288: loss=8.586, avg loss=6.454, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=4.4 seconds, 146432 images, time remaining=6.7 hours
2289: loss=5.208, avg loss=6.329, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.2 seconds, train=4.4 seconds, 146496 images, time remaining=6.7 hours
2290: loss=6.271, avg loss=6.324, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 146560 images, time remaining=6.7 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2291: loss=4.663, avg loss=6.157, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 146624 images, time remaining=6.7 hours
2292: loss=6.382, avg loss=6.180, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 146688 images, time remaining=6.7 hours
2293: loss=6.701, avg loss=6.232, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 146752 images, time remaining=6.7 hours
2294: loss=5.720, avg loss=6.181, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=5.4 seconds, 146816 images, time remaining=6.7 hours
2295: loss=6.328, avg loss=6.195, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=5.3 seconds, 146880 images, time remaining=6.7 hours
2296: loss=6.744, avg loss=6.250, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=5.3 seconds, 146944 images, time remaining=6.7 hours
2297: loss=6.750, avg loss=6.300, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 147008 images, time remaining=6.7 hours
2298: loss=5.986, avg loss=6.269, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=5.3 seconds, 147072 images, time remaining=6.7 hours
2299: loss=6.241, avg loss=6.266, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 147136 images, time remaining=6.7 hours
2300: loss=5.773, avg loss=6.217, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 147200 images, time remaining=6.7 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
2301: loss=5.750, avg loss=6.170, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 147264 images, time remaining=6.7 hours
2302: loss=4.564, avg loss=6.009, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 147328 images, time remaining=6.7 hours
2303: loss=4.836, avg loss=5.892, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.7 seconds, 147392 images, time remaining=6.7 hours
2304: loss=5.411, avg loss=5.844, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 147456 images, time remaining=6.7 hours
2305: loss=5.385, avg loss=5.798, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 147520 images, time remaining=6.7 hours
2306: loss=5.170, avg loss=5.735, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 147584 images, time remaining=6.7 hours
2307: loss=5.772, avg loss=5.739, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.7 seconds, 147648 images, time remaining=6.7 hours
2308: loss=5.436, avg loss=5.709, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 147712 images, time remaining=6.7 hours
2309: loss=5.193, avg loss=5.657, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 147776 images, time remaining=6.7 hours
2310: loss=6.021, avg loss=5.693, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 147840 images, time remaining=6.7 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
2311: loss=5.475, avg loss=5.672, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 147904 images, time remaining=6.7 hours
2312: loss=4.856, avg loss=5.590, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 147968 images, time remaining=6.7 hours
2313: loss=4.883, avg loss=5.519, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 148032 images, time remaining=6.7 hours
2314: loss=6.748, avg loss=5.642, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 148096 images, time remaining=6.7 hours
2315: loss=4.886, avg loss=5.567, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 148160 images, time remaining=6.7 hours
2316: loss=5.938, avg loss=5.604, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 148224 images, time remaining=6.7 hours
2317: loss=5.564, avg loss=5.600, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 148288 images, time remaining=6.7 hours
2318: loss=4.960, avg loss=5.536, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 148352 images, time remaining=6.7 hours
2319: loss=5.414, avg loss=5.524, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 148416 images, time remaining=6.7 hours
2320: loss=4.877, avg loss=5.459, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.1 seconds, train=2.8 seconds, 148480 images, time remaining=6.7 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b525400000
2321: loss=6.244, avg loss=5.538, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 148544 images, time remaining=6.7 hours
2322: loss=4.939, avg loss=5.478, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 148608 images, time remaining=6.7 hours
2323: loss=4.567, avg loss=5.387, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 148672 images, time remaining=6.7 hours
2324: loss=4.561, avg loss=5.304, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 148736 images, time remaining=6.7 hours
2325: loss=4.908, avg loss=5.265, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 148800 images, time remaining=6.7 hours
2326: loss=5.743, avg loss=5.312, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 148864 images, time remaining=6.7 hours
2327: loss=5.216, avg loss=5.303, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 148928 images, time remaining=6.6 hours
2328: loss=4.941, avg loss=5.267, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 148992 images, time remaining=6.6 hours
2329: loss=5.022, avg loss=5.242, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 149056 images, time remaining=6.6 hours
2330: loss=4.493, avg loss=5.167, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 149120 images, time remaining=6.6 hours
Resizing, random_coef=1.40, batch=4, 1088x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2331: loss=6.787, avg loss=5.329, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=4.3 seconds, 149184 images, time remaining=6.6 hours
2332: loss=6.730, avg loss=5.469, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 149248 images, time remaining=6.6 hours
2333: loss=6.075, avg loss=5.530, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 149312 images, time remaining=6.6 hours
2334: loss=5.159, avg loss=5.493, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 149376 images, time remaining=6.6 hours
2335: loss=5.782, avg loss=5.522, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 149440 images, time remaining=6.6 hours
2336: loss=5.298, avg loss=5.499, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 149504 images, time remaining=6.6 hours
2337: loss=5.150, avg loss=5.464, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 149568 images, time remaining=6.6 hours
2338: loss=5.429, avg loss=5.461, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.3 seconds, 149632 images, time remaining=6.6 hours
2339: loss=5.812, avg loss=5.496, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 149696 images, time remaining=6.6 hours
2340: loss=6.223, avg loss=5.569, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 149760 images, time remaining=6.6 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b69ec00000
2341: loss=7.151, avg loss=5.727, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 149824 images, time remaining=6.6 hours
2342: loss=6.417, avg loss=5.796, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.1 seconds, train=1.9 seconds, 149888 images, time remaining=6.6 hours
2343: loss=6.732, avg loss=5.890, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 149952 images, time remaining=6.6 hours
2344: loss=6.236, avg loss=5.924, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 150016 images, time remaining=6.6 hours
2345: loss=5.828, avg loss=5.915, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 150080 images, time remaining=6.6 hours
2346: loss=5.289, avg loss=5.852, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 150144 images, time remaining=6.6 hours
2347: loss=7.287, avg loss=5.996, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 150208 images, time remaining=6.6 hours
2348: loss=6.296, avg loss=6.026, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 150272 images, time remaining=6.6 hours
2349: loss=5.659, avg loss=5.989, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 150336 images, time remaining=6.6 hours
2350: loss=5.569, avg loss=5.947, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 150400 images, time remaining=6.6 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b5d0600000
2351: loss=6.294, avg loss=5.982, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 150464 images, time remaining=6.6 hours
2352: loss=4.857, avg loss=5.869, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 150528 images, time remaining=6.6 hours
2353: loss=5.697, avg loss=5.852, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 150592 images, time remaining=6.6 hours
2354: loss=4.750, avg loss=5.742, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 150656 images, time remaining=6.6 hours
2355: loss=5.070, avg loss=5.675, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 150720 images, time remaining=6.6 hours
2356: loss=5.084, avg loss=5.616, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 150784 images, time remaining=6.6 hours
2357: loss=6.376, avg loss=5.692, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 150848 images, time remaining=6.6 hours
2358: loss=5.027, avg loss=5.625, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 150912 images, time remaining=6.6 hours
2359: loss=5.330, avg loss=5.596, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 150976 images, time remaining=6.6 hours
2360: loss=5.425, avg loss=5.578, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 151040 images, time remaining=6.6 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2361: loss=5.569, avg loss=5.577, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 151104 images, time remaining=6.6 hours
2362: loss=5.982, avg loss=5.618, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 151168 images, time remaining=6.6 hours
2363: loss=6.739, avg loss=5.730, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 151232 images, time remaining=6.6 hours
2364: loss=5.719, avg loss=5.729, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=4.3 seconds, 151296 images, time remaining=6.6 hours
2365: loss=6.025, avg loss=5.759, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 151360 images, time remaining=6.6 hours
2366: loss=4.047, avg loss=5.587, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 151424 images, time remaining=6.6 hours
2367: loss=6.036, avg loss=5.632, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.5 seconds, 151488 images, time remaining=6.6 hours
2368: loss=4.519, avg loss=5.521, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 151552 images, time remaining=6.6 hours
2369: loss=6.359, avg loss=5.605, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 151616 images, time remaining=6.6 hours
2370: loss=6.442, avg loss=5.688, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 151680 images, time remaining=6.6 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b6ebc00000
2371: loss=6.612, avg loss=5.781, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.1 seconds, train=1.9 seconds, 151744 images, time remaining=6.6 hours
2372: loss=6.409, avg loss=5.844, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 151808 images, time remaining=6.6 hours
2373: loss=5.597, avg loss=5.819, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.1 seconds, train=2.0 seconds, 151872 images, time remaining=6.6 hours
2374: loss=5.169, avg loss=5.754, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 151936 images, time remaining=6.6 hours
2375: loss=5.513, avg loss=5.730, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 152000 images, time remaining=6.6 hours
2376: loss=5.479, avg loss=5.705, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 152064 images, time remaining=6.6 hours
2377: loss=6.153, avg loss=5.750, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 152128 images, time remaining=6.6 hours
2378: loss=5.105, avg loss=5.685, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 152192 images, time remaining=6.6 hours
2379: loss=5.962, avg loss=5.713, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 152256 images, time remaining=6.6 hours
2380: loss=5.277, avg loss=5.669, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 152320 images, time remaining=6.6 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2381: loss=10.139, avg loss=6.116, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.1 seconds, train=5.6 seconds, 152384 images, time remaining=6.6 hours
2382: loss=6.990, avg loss=6.204, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.4 seconds, train=5.3 seconds, 152448 images, time remaining=6.6 hours
2383: loss=6.649, avg loss=6.248, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=3.8 seconds, train=5.5 seconds, 152512 images, time remaining=6.6 hours
2384: loss=6.850, avg loss=6.308, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 152576 images, time remaining=6.6 hours
2385: loss=6.715, avg loss=6.349, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=3.8 seconds, train=5.3 seconds, 152640 images, time remaining=6.6 hours
2386: loss=6.928, avg loss=6.407, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 152704 images, time remaining=6.6 hours
2387: loss=6.286, avg loss=6.395, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.6 seconds, 152768 images, time remaining=6.6 hours
2388: loss=6.463, avg loss=6.402, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 152832 images, time remaining=6.6 hours
2389: loss=6.876, avg loss=6.449, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 152896 images, time remaining=6.6 hours
2390: loss=7.477, avg loss=6.552, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 152960 images, time remaining=6.6 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2391: loss=6.824, avg loss=6.579, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 153024 images, time remaining=6.6 hours
2392: loss=6.081, avg loss=6.529, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 153088 images, time remaining=6.6 hours
2393: loss=6.130, avg loss=6.489, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 153152 images, time remaining=6.6 hours
2394: loss=6.996, avg loss=6.540, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 153216 images, time remaining=6.6 hours
2395: loss=7.073, avg loss=6.593, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.5 seconds, train=5.7 seconds, 153280 images, time remaining=6.6 hours
2396: loss=6.443, avg loss=6.578, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 153344 images, time remaining=6.6 hours
2397: loss=6.051, avg loss=6.526, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 153408 images, time remaining=6.6 hours
2398: loss=6.807, avg loss=6.554, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 153472 images, time remaining=6.6 hours
2399: loss=5.503, avg loss=6.449, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 153536 images, time remaining=6.6 hours
2400: loss=5.757, avg loss=6.379, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 153600 images, time remaining=6.6 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2401: loss=5.849, avg loss=6.326, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 153664 images, time remaining=6.6 hours
2402: loss=5.266, avg loss=6.220, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 153728 images, time remaining=6.6 hours
2403: loss=5.973, avg loss=6.196, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 153792 images, time remaining=6.5 hours
2404: loss=5.808, avg loss=6.157, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 153856 images, time remaining=6.5 hours
2405: loss=5.645, avg loss=6.106, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 153920 images, time remaining=6.5 hours
2406: loss=5.784, avg loss=6.074, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 153984 images, time remaining=6.5 hours
2407: loss=4.884, avg loss=5.955, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 154048 images, time remaining=6.5 hours
2408: loss=5.280, avg loss=5.887, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 154112 images, time remaining=6.5 hours
2409: loss=5.809, avg loss=5.879, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 154176 images, time remaining=6.5 hours
2410: loss=4.840, avg loss=5.775, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 154240 images, time remaining=6.5 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b8b7a00000
2411: loss=4.927, avg loss=5.691, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 154304 images, time remaining=6.5 hours
2412: loss=5.817, avg loss=5.703, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 154368 images, time remaining=6.5 hours
2413: loss=5.470, avg loss=5.680, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 154432 images, time remaining=6.5 hours
2414: loss=6.630, avg loss=5.775, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 154496 images, time remaining=6.5 hours
2415: loss=5.621, avg loss=5.760, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 154560 images, time remaining=6.5 hours
2416: loss=5.298, avg loss=5.713, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 154624 images, time remaining=6.5 hours
2417: loss=5.046, avg loss=5.647, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 154688 images, time remaining=6.5 hours
2418: loss=4.650, avg loss=5.547, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 154752 images, time remaining=6.5 hours
2419: loss=6.029, avg loss=5.595, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=2.4 seconds, 154816 images, time remaining=6.5 hours
2420: loss=4.533, avg loss=5.489, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 154880 images, time remaining=6.5 hours
Resizing, random_coef=1.40, batch=4, 1184x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2421: loss=6.725, avg loss=5.613, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 154944 images, time remaining=6.5 hours
2422: loss=5.549, avg loss=5.606, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=4.6 seconds, 155008 images, time remaining=6.5 hours
2423: loss=5.836, avg loss=5.629, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.9 seconds, train=4.5 seconds, 155072 images, time remaining=6.5 hours
2424: loss=5.872, avg loss=5.653, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.5 seconds, 155136 images, time remaining=6.5 hours
2425: loss=7.585, avg loss=5.847, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.4 seconds, train=4.6 seconds, 155200 images, time remaining=6.5 hours
2426: loss=6.594, avg loss=5.921, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 155264 images, time remaining=6.5 hours
2427: loss=5.608, avg loss=5.890, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=4.4 seconds, 155328 images, time remaining=6.5 hours
2428: loss=6.202, avg loss=5.921, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.7 seconds, train=4.5 seconds, 155392 images, time remaining=6.5 hours
2429: loss=5.702, avg loss=5.899, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 155456 images, time remaining=6.5 hours
2430: loss=5.629, avg loss=5.872, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.5 seconds, 155520 images, time remaining=6.5 hours
Resizing, random_coef=1.40, batch=4, 1216x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2431: loss=6.582, avg loss=5.943, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 155584 images, time remaining=6.5 hours
2432: loss=5.908, avg loss=5.940, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.0 seconds, train=5.2 seconds, 155648 images, time remaining=6.5 hours
2433: loss=6.880, avg loss=6.034, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.9 seconds, train=5.2 seconds, 155712 images, time remaining=6.5 hours
2434: loss=6.195, avg loss=6.050, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=5.2 seconds, 155776 images, time remaining=6.5 hours
2435: loss=5.556, avg loss=6.001, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.0 seconds, train=5.1 seconds, 155840 images, time remaining=6.5 hours
2436: loss=5.120, avg loss=5.912, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=4.3 seconds, train=5.2 seconds, 155904 images, time remaining=6.5 hours
2437: loss=5.798, avg loss=5.901, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 155968 images, time remaining=6.5 hours
2438: loss=5.168, avg loss=5.828, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 156032 images, time remaining=6.5 hours
2439: loss=6.159, avg loss=5.861, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 156096 images, time remaining=6.5 hours
2440: loss=5.840, avg loss=5.859, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=5.3 seconds, 156160 images, time remaining=6.5 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b79a000000
2441: loss=7.833, avg loss=6.056, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 156224 images, time remaining=6.5 hours
2442: loss=7.861, avg loss=6.237, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.1 seconds, train=2.0 seconds, 156288 images, time remaining=6.5 hours
2443: loss=5.520, avg loss=6.165, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 156352 images, time remaining=6.5 hours
2444: loss=5.407, avg loss=6.089, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 156416 images, time remaining=6.5 hours
2445: loss=4.851, avg loss=5.965, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 156480 images, time remaining=6.5 hours
2446: loss=6.039, avg loss=5.973, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 156544 images, time remaining=6.5 hours
2447: loss=6.136, avg loss=5.989, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 156608 images, time remaining=6.5 hours
2448: loss=5.968, avg loss=5.987, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 156672 images, time remaining=6.5 hours
2449: loss=6.120, avg loss=6.000, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 156736 images, time remaining=6.5 hours
2450: loss=6.308, avg loss=6.031, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 156800 images, time remaining=6.5 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
2451: loss=7.849, avg loss=6.213, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 156864 images, time remaining=6.5 hours
2452: loss=7.772, avg loss=6.369, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 156928 images, time remaining=6.5 hours
2453: loss=5.976, avg loss=6.329, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 156992 images, time remaining=6.5 hours
2454: loss=6.486, avg loss=6.345, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.8 seconds, 157056 images, time remaining=6.5 hours
2455: loss=5.962, avg loss=6.307, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 157120 images, time remaining=6.5 hours
2456: loss=6.892, avg loss=6.365, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 157184 images, time remaining=6.5 hours
2457: loss=4.904, avg loss=6.219, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 157248 images, time remaining=6.5 hours
2458: loss=5.593, avg loss=6.157, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 157312 images, time remaining=6.5 hours
2459: loss=6.614, avg loss=6.202, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 157376 images, time remaining=6.5 hours
2460: loss=5.652, avg loss=6.147, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 157440 images, time remaining=6.5 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b778200000
2461: loss=6.842, avg loss=6.217, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 157504 images, time remaining=6.5 hours
2462: loss=6.040, avg loss=6.199, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 157568 images, time remaining=6.5 hours
2463: loss=6.687, avg loss=6.248, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 157632 images, time remaining=6.5 hours
2464: loss=6.155, avg loss=6.239, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 157696 images, time remaining=6.5 hours
2465: loss=4.438, avg loss=6.059, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 157760 images, time remaining=6.5 hours
2466: loss=4.956, avg loss=5.948, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.1 seconds, train=1.9 seconds, 157824 images, time remaining=6.4 hours
2467: loss=5.659, avg loss=5.919, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 157888 images, time remaining=6.4 hours
2468: loss=5.972, avg loss=5.925, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 157952 images, time remaining=6.4 hours
2469: loss=6.264, avg loss=5.959, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 158016 images, time remaining=6.4 hours
2470: loss=5.883, avg loss=5.951, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 158080 images, time remaining=6.4 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2471: loss=13.121, avg loss=6.668, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 158144 images, time remaining=6.4 hours
2472: loss=8.262, avg loss=6.827, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 158208 images, time remaining=6.4 hours
2473: loss=7.201, avg loss=6.865, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=5.4 seconds, 158272 images, time remaining=6.4 hours
2474: loss=7.526, avg loss=6.931, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 158336 images, time remaining=6.4 hours
2475: loss=6.473, avg loss=6.885, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=5.4 seconds, 158400 images, time remaining=6.4 hours
2476: loss=7.813, avg loss=6.978, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 158464 images, time remaining=6.4 hours
2477: loss=8.187, avg loss=7.099, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 158528 images, time remaining=6.4 hours
2478: loss=7.795, avg loss=7.168, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 158592 images, time remaining=6.4 hours
2479: loss=7.304, avg loss=7.182, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 158656 images, time remaining=6.4 hours
2480: loss=6.651, avg loss=7.129, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 158720 images, time remaining=6.4 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b59be00000
2481: loss=8.412, avg loss=7.257, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=1.8 seconds, 158784 images, time remaining=6.4 hours
2482: loss=9.013, avg loss=7.433, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 158848 images, time remaining=6.4 hours
2483: loss=7.730, avg loss=7.463, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 158912 images, time remaining=6.4 hours
2484: loss=6.215, avg loss=7.338, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 158976 images, time remaining=6.4 hours
2485: loss=7.649, avg loss=7.369, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 159040 images, time remaining=6.4 hours
2486: loss=6.310, avg loss=7.263, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 159104 images, time remaining=6.4 hours
2487: loss=7.912, avg loss=7.328, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 159168 images, time remaining=6.4 hours
2488: loss=6.720, avg loss=7.267, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 159232 images, time remaining=6.4 hours
2489: loss=5.850, avg loss=7.125, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 159296 images, time remaining=6.4 hours
2490: loss=6.796, avg loss=7.093, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 159360 images, time remaining=6.4 hours
Resizing, random_coef=1.40, batch=4, 1184x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2491: loss=14.694, avg loss=7.853, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 159424 images, time remaining=6.4 hours
2492: loss=9.686, avg loss=8.036, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=4.5 seconds, 159488 images, time remaining=6.4 hours
2493: loss=7.823, avg loss=8.015, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.0 seconds, train=4.6 seconds, 159552 images, time remaining=6.4 hours
2494: loss=6.039, avg loss=7.817, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=4.5 seconds, 159616 images, time remaining=6.4 hours
2495: loss=8.508, avg loss=7.886, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 159680 images, time remaining=6.4 hours
2496: loss=7.584, avg loss=7.856, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 159744 images, time remaining=6.4 hours
2497: loss=7.064, avg loss=7.777, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 159808 images, time remaining=6.4 hours
2498: loss=7.454, avg loss=7.745, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 159872 images, time remaining=6.4 hours
2499: loss=7.927, avg loss=7.763, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.5 seconds, 159936 images, time remaining=6.4 hours
2500: loss=8.303, avg loss=7.817, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.4 seconds, train=4.5 seconds, 160000 images, time remaining=6.4 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
2501: loss=7.148, avg loss=7.750, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 160064 images, time remaining=6.4 hours
2502: loss=7.839, avg loss=7.759, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 160128 images, time remaining=6.4 hours
2503: loss=6.554, avg loss=7.638, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 160192 images, time remaining=6.4 hours
2504: loss=7.927, avg loss=7.667, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 160256 images, time remaining=6.4 hours
2505: loss=10.198, avg loss=7.920, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.2 seconds, train=5.5 seconds, 160320 images, time remaining=6.4 hours
2506: loss=7.433, avg loss=7.871, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 160384 images, time remaining=6.4 hours
2507: loss=7.041, avg loss=7.788, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 160448 images, time remaining=6.4 hours
2508: loss=6.128, avg loss=7.622, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 160512 images, time remaining=6.4 hours
2509: loss=6.777, avg loss=7.538, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.2 seconds, train=5.4 seconds, 160576 images, time remaining=6.4 hours
2510: loss=8.075, avg loss=7.592, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.0 seconds, train=5.6 seconds, 160640 images, time remaining=6.4 hours
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2511: loss=7.646, avg loss=7.597, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.2 seconds, train=6.2 seconds, 160704 images, time remaining=6.4 hours
2512: loss=7.555, avg loss=7.593, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.1 seconds, train=6.0 seconds, 160768 images, time remaining=6.4 hours
2513: loss=6.613, avg loss=7.495, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=6.1 seconds, 160832 images, time remaining=6.4 hours
2514: loss=6.839, avg loss=7.429, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.0 seconds, train=6.0 seconds, 160896 images, time remaining=6.4 hours
2515: loss=7.005, avg loss=7.387, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.5 seconds, train=5.9 seconds, 160960 images, time remaining=6.4 hours
2516: loss=7.441, avg loss=7.392, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.5 seconds, train=6.0 seconds, 161024 images, time remaining=6.4 hours
2517: loss=7.755, avg loss=7.429, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=6.1 seconds, 161088 images, time remaining=6.4 hours
2518: loss=6.656, avg loss=7.351, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.0 seconds, train=6.1 seconds, 161152 images, time remaining=6.4 hours
2519: loss=7.450, avg loss=7.361, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.1 seconds, train=6.2 seconds, 161216 images, time remaining=6.4 hours
2520: loss=5.640, avg loss=7.189, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.1 seconds, train=5.8 seconds, 161280 images, time remaining=6.4 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b298000000
2521: loss=8.026, avg loss=7.273, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=2.6 seconds, 161344 images, time remaining=6.4 hours
2522: loss=6.019, avg loss=7.147, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.4 seconds, train=2.7 seconds, 161408 images, time remaining=6.4 hours
2523: loss=6.223, avg loss=7.055, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 161472 images, time remaining=6.4 hours
2524: loss=6.995, avg loss=7.049, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 161536 images, time remaining=6.4 hours
2525: loss=5.658, avg loss=6.910, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 161600 images, time remaining=6.4 hours
2526: loss=5.970, avg loss=6.816, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 161664 images, time remaining=6.4 hours
2527: loss=5.530, avg loss=6.687, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 161728 images, time remaining=6.4 hours
2528: loss=5.593, avg loss=6.578, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 161792 images, time remaining=6.4 hours
2529: loss=6.292, avg loss=6.549, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 161856 images, time remaining=6.4 hours
2530: loss=5.280, avg loss=6.422, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.0 seconds, train=2.7 seconds, 161920 images, time remaining=6.4 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b5b6000000
2531: loss=5.360, avg loss=6.316, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 161984 images, time remaining=6.4 hours
2532: loss=5.921, avg loss=6.277, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 162048 images, time remaining=6.4 hours
2533: loss=6.026, avg loss=6.252, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 162112 images, time remaining=6.4 hours
2534: loss=5.483, avg loss=6.175, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 162176 images, time remaining=6.4 hours
2535: loss=4.714, avg loss=6.029, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 162240 images, time remaining=6.4 hours
2536: loss=6.360, avg loss=6.062, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 162304 images, time remaining=6.4 hours
2537: loss=5.237, avg loss=5.979, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 162368 images, time remaining=6.4 hours
2538: loss=4.356, avg loss=5.817, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 162432 images, time remaining=6.4 hours
2539: loss=5.028, avg loss=5.738, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 162496 images, time remaining=6.4 hours
2540: loss=5.817, avg loss=5.746, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 162560 images, time remaining=6.4 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b592200000
2541: loss=6.857, avg loss=5.857, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 162624 images, time remaining=6.4 hours
2542: loss=5.156, avg loss=5.787, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 162688 images, time remaining=6.4 hours
2543: loss=5.538, avg loss=5.762, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 162752 images, time remaining=6.4 hours
2544: loss=4.652, avg loss=5.651, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 162816 images, time remaining=6.4 hours
2545: loss=5.035, avg loss=5.589, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=2.7 seconds, 162880 images, time remaining=6.4 hours
2546: loss=5.778, avg loss=5.608, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 162944 images, time remaining=6.4 hours
2547: loss=5.576, avg loss=5.605, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 163008 images, time remaining=6.4 hours
2548: loss=6.049, avg loss=5.650, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 163072 images, time remaining=6.3 hours
2549: loss=5.852, avg loss=5.670, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 163136 images, time remaining=6.3 hours
2550: loss=5.008, avg loss=5.604, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 163200 images, time remaining=6.3 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b4d2600000
2551: loss=6.720, avg loss=5.715, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 163264 images, time remaining=6.3 hours
2552: loss=5.241, avg loss=5.668, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 163328 images, time remaining=6.3 hours
2553: loss=4.577, avg loss=5.559, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 163392 images, time remaining=6.3 hours
2554: loss=5.080, avg loss=5.511, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 163456 images, time remaining=6.3 hours
2555: loss=5.848, avg loss=5.545, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 163520 images, time remaining=6.3 hours
2556: loss=6.114, avg loss=5.601, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 163584 images, time remaining=6.3 hours
2557: loss=5.751, avg loss=5.616, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 163648 images, time remaining=6.3 hours
2558: loss=5.097, avg loss=5.564, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 163712 images, time remaining=6.3 hours
2559: loss=5.280, avg loss=5.536, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 163776 images, time remaining=6.3 hours
2560: loss=5.554, avg loss=5.538, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 163840 images, time remaining=6.3 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b592200000
2561: loss=4.613, avg loss=5.445, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 163904 images, time remaining=6.3 hours
2562: loss=4.538, avg loss=5.355, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 163968 images, time remaining=6.3 hours
2563: loss=5.000, avg loss=5.319, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 164032 images, time remaining=6.3 hours
2564: loss=5.141, avg loss=5.301, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 164096 images, time remaining=6.3 hours
2565: loss=5.204, avg loss=5.292, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 164160 images, time remaining=6.3 hours
2566: loss=4.686, avg loss=5.231, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 164224 images, time remaining=6.3 hours
2567: loss=4.898, avg loss=5.198, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 164288 images, time remaining=6.3 hours
2568: loss=4.653, avg loss=5.143, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 164352 images, time remaining=6.3 hours
2569: loss=4.107, avg loss=5.040, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 164416 images, time remaining=6.3 hours
2570: loss=5.391, avg loss=5.075, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 164480 images, time remaining=6.3 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b566800000
2571: loss=4.763, avg loss=5.044, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 164544 images, time remaining=6.3 hours
2572: loss=5.033, avg loss=5.043, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.2 seconds, train=2.8 seconds, 164608 images, time remaining=6.3 hours
2573: loss=4.763, avg loss=5.015, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 164672 images, time remaining=6.3 hours
2574: loss=4.810, avg loss=4.994, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 164736 images, time remaining=6.3 hours
2575: loss=5.059, avg loss=5.001, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 164800 images, time remaining=6.3 hours
2576: loss=4.937, avg loss=4.994, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 164864 images, time remaining=6.3 hours
2577: loss=5.697, avg loss=5.064, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 164928 images, time remaining=6.3 hours
2578: loss=5.157, avg loss=5.074, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 164992 images, time remaining=6.3 hours
2579: loss=4.348, avg loss=5.001, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 165056 images, time remaining=6.3 hours
2580: loss=5.264, avg loss=5.027, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.0 seconds, train=2.7 seconds, 165120 images, time remaining=6.3 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2581: loss=4.286, avg loss=4.953, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 165184 images, time remaining=6.3 hours
2582: loss=5.081, avg loss=4.966, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 165248 images, time remaining=6.3 hours
2583: loss=5.278, avg loss=4.997, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=4.1 seconds, 165312 images, time remaining=6.3 hours
2584: loss=5.596, avg loss=5.057, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.2 seconds, 165376 images, time remaining=6.3 hours
2585: loss=5.072, avg loss=5.059, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=4.0 seconds, 165440 images, time remaining=6.3 hours
2586: loss=4.414, avg loss=4.994, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 165504 images, time remaining=6.3 hours
2587: loss=4.571, avg loss=4.952, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 165568 images, time remaining=6.3 hours
2588: loss=5.298, avg loss=4.986, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.2 seconds, 165632 images, time remaining=6.3 hours
2589: loss=4.539, avg loss=4.942, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 165696 images, time remaining=6.3 hours
2590: loss=4.371, avg loss=4.885, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 165760 images, time remaining=6.3 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2591: loss=5.419, avg loss=4.938, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.5 seconds, 165824 images, time remaining=6.3 hours
2592: loss=4.958, avg loss=4.940, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 165888 images, time remaining=6.3 hours
2593: loss=4.777, avg loss=4.924, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 165952 images, time remaining=6.3 hours
2594: loss=4.611, avg loss=4.893, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 166016 images, time remaining=6.3 hours
2595: loss=4.946, avg loss=4.898, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 166080 images, time remaining=6.3 hours
2596: loss=5.004, avg loss=4.908, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 166144 images, time remaining=6.3 hours
2597: loss=5.459, avg loss=4.963, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 166208 images, time remaining=6.3 hours
2598: loss=4.691, avg loss=4.936, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=4.3 seconds, 166272 images, time remaining=6.3 hours
2599: loss=4.972, avg loss=4.940, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 166336 images, time remaining=6.3 hours
2600: loss=4.972, avg loss=4.943, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.9 seconds, train=4.4 seconds, 166400 images, time remaining=6.3 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b6f6600000
2601: loss=6.279, avg loss=5.077, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 166464 images, time remaining=6.3 hours
2602: loss=4.886, avg loss=5.058, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 166528 images, time remaining=6.3 hours
2603: loss=4.585, avg loss=5.010, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 166592 images, time remaining=6.3 hours
2604: loss=4.535, avg loss=4.963, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 166656 images, time remaining=6.3 hours
2605: loss=4.539, avg loss=4.920, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 166720 images, time remaining=6.3 hours
2606: loss=4.396, avg loss=4.868, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 166784 images, time remaining=6.3 hours
2607: loss=3.909, avg loss=4.772, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 166848 images, time remaining=6.3 hours
2608: loss=4.769, avg loss=4.772, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.7 seconds, train=2.6 seconds, 166912 images, time remaining=6.2 hours
2609: loss=5.648, avg loss=4.859, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 166976 images, time remaining=6.2 hours
2610: loss=4.754, avg loss=4.849, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=2.6 seconds, 167040 images, time remaining=6.2 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2611: loss=4.350, avg loss=4.799, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.2 seconds, train=3.9 seconds, 167104 images, time remaining=6.2 hours
2612: loss=4.774, avg loss=4.796, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.9 seconds, train=3.9 seconds, 167168 images, time remaining=6.2 hours
2613: loss=5.246, avg loss=4.841, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.2 seconds, train=4.0 seconds, 167232 images, time remaining=6.2 hours
2614: loss=4.206, avg loss=4.778, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=3.9 seconds, 167296 images, time remaining=6.2 hours
2615: loss=5.507, avg loss=4.851, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=2.1 seconds, train=3.9 seconds, 167360 images, time remaining=6.2 hours
2616: loss=5.654, avg loss=4.931, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 167424 images, time remaining=6.2 hours
2617: loss=4.151, avg loss=4.853, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 167488 images, time remaining=6.2 hours
2618: loss=5.286, avg loss=4.896, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 167552 images, time remaining=6.2 hours
2619: loss=4.702, avg loss=4.877, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.3 seconds, train=3.9 seconds, 167616 images, time remaining=6.2 hours
2620: loss=5.710, avg loss=4.960, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 167680 images, time remaining=6.2 hours
Resizing, random_coef=1.40, batch=4, 1088x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2621: loss=3.805, avg loss=4.845, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.4 seconds, train=4.3 seconds, 167744 images, time remaining=6.2 hours
2622: loss=4.731, avg loss=4.833, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 167808 images, time remaining=6.2 hours
2623: loss=5.440, avg loss=4.894, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 167872 images, time remaining=6.2 hours
2624: loss=4.914, avg loss=4.896, last=81.79%, best=81.79%, next=2624, rate=0.00130000, load 64=1.9 seconds, train=4.2 seconds, 167936 images, time remaining=6.2 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b6cfa00000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=166736, unique_truth_count=57264
rank=0 of ranks=166736rank=100 of ranks=166736rank=200 of ranks=166736rank=300 of ranks=166736rank=400 of ranks=166736rank=500 of ranks=166736rank=600 of ranks=166736rank=700 of ranks=166736rank=800 of ranks=166736rank=900 of ranks=166736rank=1000 of ranks=166736rank=1100 of ranks=166736rank=1200 of ranks=166736rank=1300 of ranks=166736rank=1400 of ranks=166736rank=1500 of ranks=166736rank=1600 of ranks=166736rank=1700 of ranks=166736rank=1800 of ranks=166736rank=1900 of ranks=166736rank=2000 of ranks=166736rank=2100 of ranks=166736rank=2200 of ranks=166736rank=2300 of ranks=166736rank=2400 of ranks=166736rank=2500 of ranks=166736rank=2600 of ranks=166736rank=2700 of ranks=166736rank=2800 of ranks=166736rank=2900 of ranks=166736rank=3000 of ranks=166736rank=3100 of ranks=166736rank=3200 of ranks=166736rank=3300 of ranks=166736rank=3400 of ranks=166736rank=3500 of ranks=166736rank=3600 of ranks=166736rank=3700 of ranks=166736rank=3800 of ranks=166736rank=3900 of ranks=166736rank=4000 of ranks=166736rank=4100 of ranks=166736rank=4200 of ranks=166736rank=4300 of ranks=166736rank=4400 of ranks=166736rank=4500 of ranks=166736rank=4600 of ranks=166736rank=4700 of ranks=166736rank=4800 of ranks=166736rank=4900 of ranks=166736rank=5000 of ranks=166736rank=5100 of ranks=166736rank=5200 of ranks=166736rank=5300 of ranks=166736rank=5400 of ranks=166736rank=5500 of ranks=166736rank=5600 of ranks=166736rank=5700 of ranks=166736rank=5800 of ranks=166736rank=5900 of ranks=166736rank=6000 of ranks=166736rank=6100 of ranks=166736rank=6200 of ranks=166736rank=6300 of ranks=166736rank=6400 of ranks=166736rank=6500 of ranks=166736rank=6600 of ranks=166736rank=6700 of ranks=166736rank=6800 of ranks=166736rank=6900 of ranks=166736rank=7000 of ranks=166736rank=7100 of ranks=166736rank=7200 of ranks=166736rank=7300 of ranks=166736rank=7400 of ranks=166736rank=7500 of ranks=166736rank=7600 of ranks=166736rank=7700 of ranks=166736rank=7800 of ranks=166736rank=7900 of ranks=166736rank=8000 of ranks=166736rank=8100 of ranks=166736rank=8200 of ranks=166736rank=8300 of ranks=166736rank=8400 of ranks=166736rank=8500 of ranks=166736rank=8600 of ranks=166736rank=8700 of ranks=166736rank=8800 of ranks=166736rank=8900 of ranks=166736rank=9000 of ranks=166736rank=9100 of ranks=166736rank=9200 of ranks=166736rank=9300 of ranks=166736rank=9400 of ranks=166736rank=9500 of ranks=166736rank=9600 of ranks=166736rank=9700 of ranks=166736rank=9800 of ranks=166736rank=9900 of ranks=166736rank=10000 of ranks=166736rank=10100 of ranks=166736rank=10200 of ranks=166736rank=10300 of ranks=166736rank=10400 of ranks=166736rank=10500 of ranks=166736rank=10600 of ranks=166736rank=10700 of ranks=166736rank=10800 of ranks=166736rank=10900 of ranks=166736rank=11000 of ranks=166736rank=11100 of ranks=166736rank=11200 of ranks=166736rank=11300 of ranks=166736rank=11400 of ranks=166736rank=11500 of ranks=166736rank=11600 of ranks=166736rank=11700 of ranks=166736rank=11800 of ranks=166736rank=11900 of ranks=166736rank=12000 of ranks=166736rank=12100 of ranks=166736rank=12200 of ranks=166736rank=12300 of ranks=166736rank=12400 of ranks=166736rank=12500 of ranks=166736rank=12600 of ranks=166736rank=12700 of ranks=166736rank=12800 of ranks=166736rank=12900 of ranks=166736rank=13000 of ranks=166736rank=13100 of ranks=166736rank=13200 of ranks=166736rank=13300 of ranks=166736rank=13400 of ranks=166736rank=13500 of ranks=166736rank=13600 of ranks=166736rank=13700 of ranks=166736rank=13800 of ranks=166736rank=13900 of ranks=166736rank=14000 of ranks=166736rank=14100 of ranks=166736rank=14200 of ranks=166736rank=14300 of ranks=166736rank=14400 of ranks=166736rank=14500 of ranks=166736rank=14600 of ranks=166736rank=14700 of ranks=166736rank=14800 of ranks=166736rank=14900 of ranks=166736rank=15000 of ranks=166736rank=15100 of ranks=166736rank=15200 of ranks=166736rank=15300 of ranks=166736rank=15400 of ranks=166736rank=15500 of ranks=166736rank=15600 of ranks=166736rank=15700 of ranks=166736rank=15800 of ranks=166736rank=15900 of ranks=166736rank=16000 of ranks=166736rank=16100 of ranks=166736rank=16200 of ranks=166736rank=16300 of ranks=166736rank=16400 of ranks=166736rank=16500 of ranks=166736rank=16600 of ranks=166736rank=16700 of ranks=166736rank=16800 of ranks=166736rank=16900 of ranks=166736rank=17000 of ranks=166736rank=17100 of ranks=166736rank=17200 of ranks=166736rank=17300 of ranks=166736rank=17400 of ranks=166736rank=17500 of ranks=166736rank=17600 of ranks=166736rank=17700 of ranks=166736rank=17800 of ranks=166736rank=17900 of ranks=166736rank=18000 of ranks=166736rank=18100 of ranks=166736rank=18200 of ranks=166736rank=18300 of ranks=166736rank=18400 of ranks=166736rank=18500 of ranks=166736rank=18600 of ranks=166736rank=18700 of ranks=166736rank=18800 of ranks=166736rank=18900 of ranks=166736rank=19000 of ranks=166736rank=19100 of ranks=166736rank=19200 of ranks=166736rank=19300 of ranks=166736rank=19400 of ranks=166736rank=19500 of ranks=166736rank=19600 of ranks=166736rank=19700 of ranks=166736rank=19800 of ranks=166736rank=19900 of ranks=166736rank=20000 of ranks=166736rank=20100 of ranks=166736rank=20200 of ranks=166736rank=20300 of ranks=166736rank=20400 of ranks=166736rank=20500 of ranks=166736rank=20600 of ranks=166736rank=20700 of ranks=166736rank=20800 of ranks=166736rank=20900 of ranks=166736rank=21000 of ranks=166736rank=21100 of ranks=166736rank=21200 of ranks=166736rank=21300 of ranks=166736rank=21400 of ranks=166736rank=21500 of ranks=166736rank=21600 of ranks=166736rank=21700 of ranks=166736rank=21800 of ranks=166736rank=21900 of ranks=166736rank=22000 of ranks=166736rank=22100 of ranks=166736rank=22200 of ranks=166736rank=22300 of ranks=166736rank=22400 of ranks=166736rank=22500 of ranks=166736rank=22600 of ranks=166736rank=22700 of ranks=166736rank=22800 of ranks=166736rank=22900 of ranks=166736rank=23000 of ranks=166736rank=23100 of ranks=166736rank=23200 of ranks=166736rank=23300 of ranks=166736rank=23400 of ranks=166736rank=23500 of ranks=166736rank=23600 of ranks=166736rank=23700 of ranks=166736rank=23800 of ranks=166736rank=23900 of ranks=166736rank=24000 of ranks=166736rank=24100 of ranks=166736rank=24200 of ranks=166736rank=24300 of ranks=166736rank=24400 of ranks=166736rank=24500 of ranks=166736rank=24600 of ranks=166736rank=24700 of ranks=166736rank=24800 of ranks=166736rank=24900 of ranks=166736rank=25000 of ranks=166736rank=25100 of ranks=166736rank=25200 of ranks=166736rank=25300 of ranks=166736rank=25400 of ranks=166736rank=25500 of ranks=166736rank=25600 of ranks=166736rank=25700 of ranks=166736rank=25800 of ranks=166736rank=25900 of ranks=166736rank=26000 of ranks=166736rank=26100 of ranks=166736rank=26200 of ranks=166736rank=26300 of ranks=166736rank=26400 of ranks=166736rank=26500 of ranks=166736rank=26600 of ranks=166736rank=26700 of ranks=166736rank=26800 of ranks=166736rank=26900 of ranks=166736rank=27000 of ranks=166736rank=27100 of ranks=166736rank=27200 of ranks=166736rank=27300 of ranks=166736rank=27400 of ranks=166736rank=27500 of ranks=166736rank=27600 of ranks=166736rank=27700 of ranks=166736rank=27800 of ranks=166736rank=27900 of ranks=166736rank=28000 of ranks=166736rank=28100 of ranks=166736rank=28200 of ranks=166736rank=28300 of ranks=166736rank=28400 of ranks=166736rank=28500 of ranks=166736rank=28600 of ranks=166736rank=28700 of ranks=166736rank=28800 of ranks=166736rank=28900 of ranks=166736rank=29000 of ranks=166736rank=29100 of ranks=166736rank=29200 of ranks=166736rank=29300 of ranks=166736rank=29400 of ranks=166736rank=29500 of ranks=166736rank=29600 of ranks=166736rank=29700 of ranks=166736rank=29800 of ranks=166736rank=29900 of ranks=166736rank=30000 of ranks=166736rank=30100 of ranks=166736rank=30200 of ranks=166736rank=30300 of ranks=166736rank=30400 of ranks=166736rank=30500 of ranks=166736rank=30600 of ranks=166736rank=30700 of ranks=166736rank=30800 of ranks=166736rank=30900 of ranks=166736rank=31000 of ranks=166736rank=31100 of ranks=166736rank=31200 of ranks=166736rank=31300 of ranks=166736rank=31400 of ranks=166736rank=31500 of ranks=166736rank=31600 of ranks=166736rank=31700 of ranks=166736rank=31800 of ranks=166736rank=31900 of ranks=166736rank=32000 of ranks=166736rank=32100 of ranks=166736rank=32200 of ranks=166736rank=32300 of ranks=166736rank=32400 of ranks=166736rank=32500 of ranks=166736rank=32600 of ranks=166736rank=32700 of ranks=166736rank=32800 of ranks=166736rank=32900 of ranks=166736rank=33000 of ranks=166736rank=33100 of ranks=166736rank=33200 of ranks=166736rank=33300 of ranks=166736rank=33400 of ranks=166736rank=33500 of ranks=166736rank=33600 of ranks=166736rank=33700 of ranks=166736rank=33800 of ranks=166736rank=33900 of ranks=166736rank=34000 of ranks=166736rank=34100 of ranks=166736rank=34200 of ranks=166736rank=34300 of ranks=166736rank=34400 of ranks=166736rank=34500 of ranks=166736rank=34600 of ranks=166736rank=34700 of ranks=166736rank=34800 of ranks=166736rank=34900 of ranks=166736rank=35000 of ranks=166736rank=35100 of ranks=166736rank=35200 of ranks=166736rank=35300 of ranks=166736rank=35400 of ranks=166736rank=35500 of ranks=166736rank=35600 of ranks=166736rank=35700 of ranks=166736rank=35800 of ranks=166736rank=35900 of ranks=166736rank=36000 of ranks=166736rank=36100 of ranks=166736rank=36200 of ranks=166736rank=36300 of ranks=166736rank=36400 of ranks=166736rank=36500 of ranks=166736rank=36600 of ranks=166736rank=36700 of ranks=166736rank=36800 of ranks=166736rank=36900 of ranks=166736rank=37000 of ranks=166736rank=37100 of ranks=166736rank=37200 of ranks=166736rank=37300 of ranks=166736rank=37400 of ranks=166736rank=37500 of ranks=166736rank=37600 of ranks=166736rank=37700 of ranks=166736rank=37800 of ranks=166736rank=37900 of ranks=166736rank=38000 of ranks=166736rank=38100 of ranks=166736rank=38200 of ranks=166736rank=38300 of ranks=166736rank=38400 of ranks=166736rank=38500 of ranks=166736rank=38600 of ranks=166736rank=38700 of ranks=166736rank=38800 of ranks=166736rank=38900 of ranks=166736rank=39000 of ranks=166736rank=39100 of ranks=166736rank=39200 of ranks=166736rank=39300 of ranks=166736rank=39400 of ranks=166736rank=39500 of ranks=166736rank=39600 of ranks=166736rank=39700 of ranks=166736rank=39800 of ranks=166736rank=39900 of ranks=166736rank=40000 of ranks=166736rank=40100 of ranks=166736rank=40200 of ranks=166736rank=40300 of ranks=166736rank=40400 of ranks=166736rank=40500 of ranks=166736rank=40600 of ranks=166736rank=40700 of ranks=166736rank=40800 of ranks=166736rank=40900 of ranks=166736rank=41000 of ranks=166736rank=41100 of ranks=166736rank=41200 of ranks=166736rank=41300 of ranks=166736rank=41400 of ranks=166736rank=41500 of ranks=166736rank=41600 of ranks=166736rank=41700 of ranks=166736rank=41800 of ranks=166736rank=41900 of ranks=166736rank=42000 of ranks=166736rank=42100 of ranks=166736rank=42200 of ranks=166736rank=42300 of ranks=166736rank=42400 of ranks=166736rank=42500 of ranks=166736rank=42600 of ranks=166736rank=42700 of ranks=166736rank=42800 of ranks=166736rank=42900 of ranks=166736rank=43000 of ranks=166736rank=43100 of ranks=166736rank=43200 of ranks=166736rank=43300 of ranks=166736rank=43400 of ranks=166736rank=43500 of ranks=166736rank=43600 of ranks=166736rank=43700 of ranks=166736rank=43800 of ranks=166736rank=43900 of ranks=166736rank=44000 of ranks=166736rank=44100 of ranks=166736rank=44200 of ranks=166736rank=44300 of ranks=166736rank=44400 of ranks=166736rank=44500 of ranks=166736rank=44600 of ranks=166736rank=44700 of ranks=166736rank=44800 of ranks=166736rank=44900 of ranks=166736rank=45000 of ranks=166736rank=45100 of ranks=166736rank=45200 of ranks=166736rank=45300 of ranks=166736rank=45400 of ranks=166736rank=45500 of ranks=166736rank=45600 of ranks=166736rank=45700 of ranks=166736rank=45800 of ranks=166736rank=45900 of ranks=166736rank=46000 of ranks=166736rank=46100 of ranks=166736rank=46200 of ranks=166736rank=46300 of ranks=166736rank=46400 of ranks=166736rank=46500 of ranks=166736rank=46600 of ranks=166736rank=46700 of ranks=166736rank=46800 of ranks=166736rank=46900 of ranks=166736rank=47000 of ranks=166736rank=47100 of ranks=166736rank=47200 of ranks=166736rank=47300 of ranks=166736rank=47400 of ranks=166736rank=47500 of ranks=166736rank=47600 of ranks=166736rank=47700 of ranks=166736rank=47800 of ranks=166736rank=47900 of ranks=166736rank=48000 of ranks=166736rank=48100 of ranks=166736rank=48200 of ranks=166736rank=48300 of ranks=166736rank=48400 of ranks=166736rank=48500 of ranks=166736rank=48600 of ranks=166736rank=48700 of ranks=166736rank=48800 of ranks=166736rank=48900 of ranks=166736rank=49000 of ranks=166736rank=49100 of ranks=166736rank=49200 of ranks=166736rank=49300 of ranks=166736rank=49400 of ranks=166736rank=49500 of ranks=166736rank=49600 of ranks=166736rank=49700 of ranks=166736rank=49800 of ranks=166736rank=49900 of ranks=166736rank=50000 of ranks=166736rank=50100 of ranks=166736rank=50200 of ranks=166736rank=50300 of ranks=166736rank=50400 of ranks=166736rank=50500 of ranks=166736rank=50600 of ranks=166736rank=50700 of ranks=166736rank=50800 of ranks=166736rank=50900 of ranks=166736rank=51000 of ranks=166736rank=51100 of ranks=166736rank=51200 of ranks=166736rank=51300 of ranks=166736rank=51400 of ranks=166736rank=51500 of ranks=166736rank=51600 of ranks=166736rank=51700 of ranks=166736rank=51800 of ranks=166736rank=51900 of ranks=166736rank=52000 of ranks=166736rank=52100 of ranks=166736rank=52200 of ranks=166736rank=52300 of ranks=166736rank=52400 of ranks=166736rank=52500 of ranks=166736rank=52600 of ranks=166736rank=52700 of ranks=166736rank=52800 of ranks=166736rank=52900 of ranks=166736rank=53000 of ranks=166736rank=53100 of ranks=166736rank=53200 of ranks=166736rank=53300 of ranks=166736rank=53400 of ranks=166736rank=53500 of ranks=166736rank=53600 of ranks=166736rank=53700 of ranks=166736rank=53800 of ranks=166736rank=53900 of ranks=166736rank=54000 of ranks=166736rank=54100 of ranks=166736rank=54200 of ranks=166736rank=54300 of ranks=166736rank=54400 of ranks=166736rank=54500 of ranks=166736rank=54600 of ranks=166736rank=54700 of ranks=166736rank=54800 of ranks=166736rank=54900 of ranks=166736rank=55000 of ranks=166736rank=55100 of ranks=166736rank=55200 of ranks=166736rank=55300 of ranks=166736rank=55400 of ranks=166736rank=55500 of ranks=166736rank=55600 of ranks=166736rank=55700 of ranks=166736rank=55800 of ranks=166736rank=55900 of ranks=166736rank=56000 of ranks=166736rank=56100 of ranks=166736rank=56200 of ranks=166736rank=56300 of ranks=166736rank=56400 of ranks=166736rank=56500 of ranks=166736rank=56600 of ranks=166736rank=56700 of ranks=166736rank=56800 of ranks=166736rank=56900 of ranks=166736rank=57000 of ranks=166736rank=57100 of ranks=166736rank=57200 of ranks=166736rank=57300 of ranks=166736rank=57400 of ranks=166736rank=57500 of ranks=166736rank=57600 of ranks=166736rank=57700 of ranks=166736rank=57800 of ranks=166736rank=57900 of ranks=166736rank=58000 of ranks=166736rank=58100 of ranks=166736rank=58200 of ranks=166736rank=58300 of ranks=166736rank=58400 of ranks=166736rank=58500 of ranks=166736rank=58600 of ranks=166736rank=58700 of ranks=166736rank=58800 of ranks=166736rank=58900 of ranks=166736rank=59000 of ranks=166736rank=59100 of ranks=166736rank=59200 of ranks=166736rank=59300 of ranks=166736rank=59400 of ranks=166736rank=59500 of ranks=166736rank=59600 of ranks=166736rank=59700 of ranks=166736rank=59800 of ranks=166736rank=59900 of ranks=166736rank=60000 of ranks=166736rank=60100 of ranks=166736rank=60200 of ranks=166736rank=60300 of ranks=166736rank=60400 of ranks=166736rank=60500 of ranks=166736rank=60600 of ranks=166736rank=60700 of ranks=166736rank=60800 of ranks=166736rank=60900 of ranks=166736rank=61000 of ranks=166736rank=61100 of ranks=166736rank=61200 of ranks=166736rank=61300 of ranks=166736rank=61400 of ranks=166736rank=61500 of ranks=166736rank=61600 of ranks=166736rank=61700 of ranks=166736rank=61800 of ranks=166736rank=61900 of ranks=166736rank=62000 of ranks=166736rank=62100 of ranks=166736rank=62200 of ranks=166736rank=62300 of ranks=166736rank=62400 of ranks=166736rank=62500 of ranks=166736rank=62600 of ranks=166736rank=62700 of ranks=166736rank=62800 of ranks=166736rank=62900 of ranks=166736rank=63000 of ranks=166736rank=63100 of ranks=166736rank=63200 of ranks=166736rank=63300 of ranks=166736rank=63400 of ranks=166736rank=63500 of ranks=166736rank=63600 of ranks=166736rank=63700 of ranks=166736rank=63800 of ranks=166736rank=63900 of ranks=166736rank=64000 of ranks=166736rank=64100 of ranks=166736rank=64200 of ranks=166736rank=64300 of ranks=166736rank=64400 of ranks=166736rank=64500 of ranks=166736rank=64600 of ranks=166736rank=64700 of ranks=166736rank=64800 of ranks=166736rank=64900 of ranks=166736rank=65000 of ranks=166736rank=65100 of ranks=166736rank=65200 of ranks=166736rank=65300 of ranks=166736rank=65400 of ranks=166736rank=65500 of ranks=166736rank=65600 of ranks=166736rank=65700 of ranks=166736rank=65800 of ranks=166736rank=65900 of ranks=166736rank=66000 of ranks=166736rank=66100 of ranks=166736rank=66200 of ranks=166736rank=66300 of ranks=166736rank=66400 of ranks=166736rank=66500 of ranks=166736rank=66600 of ranks=166736rank=66700 of ranks=166736rank=66800 of ranks=166736rank=66900 of ranks=166736rank=67000 of ranks=166736rank=67100 of ranks=166736rank=67200 of ranks=166736rank=67300 of ranks=166736rank=67400 of ranks=166736rank=67500 of ranks=166736rank=67600 of ranks=166736rank=67700 of ranks=166736rank=67800 of ranks=166736rank=67900 of ranks=166736rank=68000 of ranks=166736rank=68100 of ranks=166736rank=68200 of ranks=166736rank=68300 of ranks=166736rank=68400 of ranks=166736rank=68500 of ranks=166736rank=68600 of ranks=166736rank=68700 of ranks=166736rank=68800 of ranks=166736rank=68900 of ranks=166736rank=69000 of ranks=166736rank=69100 of ranks=166736rank=69200 of ranks=166736rank=69300 of ranks=166736rank=69400 of ranks=166736rank=69500 of ranks=166736rank=69600 of ranks=166736rank=69700 of ranks=166736rank=69800 of ranks=166736rank=69900 of ranks=166736rank=70000 of ranks=166736rank=70100 of ranks=166736rank=70200 of ranks=166736rank=70300 of ranks=166736rank=70400 of ranks=166736rank=70500 of ranks=166736rank=70600 of ranks=166736rank=70700 of ranks=166736rank=70800 of ranks=166736rank=70900 of ranks=166736rank=71000 of ranks=166736rank=71100 of ranks=166736rank=71200 of ranks=166736rank=71300 of ranks=166736rank=71400 of ranks=166736rank=71500 of ranks=166736rank=71600 of ranks=166736rank=71700 of ranks=166736rank=71800 of ranks=166736rank=71900 of ranks=166736rank=72000 of ranks=166736rank=72100 of ranks=166736rank=72200 of ranks=166736rank=72300 of ranks=166736rank=72400 of ranks=166736rank=72500 of ranks=166736rank=72600 of ranks=166736rank=72700 of ranks=166736rank=72800 of ranks=166736rank=72900 of ranks=166736rank=73000 of ranks=166736rank=73100 of ranks=166736rank=73200 of ranks=166736rank=73300 of ranks=166736rank=73400 of ranks=166736rank=73500 of ranks=166736rank=73600 of ranks=166736rank=73700 of ranks=166736rank=73800 of ranks=166736rank=73900 of ranks=166736rank=74000 of ranks=166736rank=74100 of ranks=166736rank=74200 of ranks=166736rank=74300 of ranks=166736rank=74400 of ranks=166736rank=74500 of ranks=166736rank=74600 of ranks=166736rank=74700 of ranks=166736rank=74800 of ranks=166736rank=74900 of ranks=166736rank=75000 of ranks=166736rank=75100 of ranks=166736rank=75200 of ranks=166736rank=75300 of ranks=166736rank=75400 of ranks=166736rank=75500 of ranks=166736rank=75600 of ranks=166736rank=75700 of ranks=166736rank=75800 of ranks=166736rank=75900 of ranks=166736rank=76000 of ranks=166736rank=76100 of ranks=166736rank=76200 of ranks=166736rank=76300 of ranks=166736rank=76400 of ranks=166736rank=76500 of ranks=166736rank=76600 of ranks=166736rank=76700 of ranks=166736rank=76800 of ranks=166736rank=76900 of ranks=166736rank=77000 of ranks=166736rank=77100 of ranks=166736rank=77200 of ranks=166736rank=77300 of ranks=166736rank=77400 of ranks=166736rank=77500 of ranks=166736rank=77600 of ranks=166736rank=77700 of ranks=166736rank=77800 of ranks=166736rank=77900 of ranks=166736rank=78000 of ranks=166736rank=78100 of ranks=166736rank=78200 of ranks=166736rank=78300 of ranks=166736rank=78400 of ranks=166736rank=78500 of ranks=166736rank=78600 of ranks=166736rank=78700 of ranks=166736rank=78800 of ranks=166736rank=78900 of ranks=166736rank=79000 of ranks=166736rank=79100 of ranks=166736rank=79200 of ranks=166736rank=79300 of ranks=166736rank=79400 of ranks=166736rank=79500 of ranks=166736rank=79600 of ranks=166736rank=79700 of ranks=166736rank=79800 of ranks=166736rank=79900 of ranks=166736rank=80000 of ranks=166736rank=80100 of ranks=166736rank=80200 of ranks=166736rank=80300 of ranks=166736rank=80400 of ranks=166736rank=80500 of ranks=166736rank=80600 of ranks=166736rank=80700 of ranks=166736rank=80800 of ranks=166736rank=80900 of ranks=166736rank=81000 of ranks=166736rank=81100 of ranks=166736rank=81200 of ranks=166736rank=81300 of ranks=166736rank=81400 of ranks=166736rank=81500 of ranks=166736rank=81600 of ranks=166736rank=81700 of ranks=166736rank=81800 of ranks=166736rank=81900 of ranks=166736rank=82000 of ranks=166736rank=82100 of ranks=166736rank=82200 of ranks=166736rank=82300 of ranks=166736rank=82400 of ranks=166736rank=82500 of ranks=166736rank=82600 of ranks=166736rank=82700 of ranks=166736rank=82800 of ranks=166736rank=82900 of ranks=166736rank=83000 of ranks=166736rank=83100 of ranks=166736rank=83200 of ranks=166736rank=83300 of ranks=166736rank=83400 of ranks=166736rank=83500 of ranks=166736rank=83600 of ranks=166736rank=83700 of ranks=166736rank=83800 of ranks=166736rank=83900 of ranks=166736rank=84000 of ranks=166736rank=84100 of ranks=166736rank=84200 of ranks=166736rank=84300 of ranks=166736rank=84400 of ranks=166736rank=84500 of ranks=166736rank=84600 of ranks=166736rank=84700 of ranks=166736rank=84800 of ranks=166736rank=84900 of ranks=166736rank=85000 of ranks=166736rank=85100 of ranks=166736rank=85200 of ranks=166736rank=85300 of ranks=166736rank=85400 of ranks=166736rank=85500 of ranks=166736rank=85600 of ranks=166736rank=85700 of ranks=166736rank=85800 of ranks=166736rank=85900 of ranks=166736rank=86000 of ranks=166736rank=86100 of ranks=166736rank=86200 of ranks=166736rank=86300 of ranks=166736rank=86400 of ranks=166736rank=86500 of ranks=166736rank=86600 of ranks=166736rank=86700 of ranks=166736rank=86800 of ranks=166736rank=86900 of ranks=166736rank=87000 of ranks=166736rank=87100 of ranks=166736rank=87200 of ranks=166736rank=87300 of ranks=166736rank=87400 of ranks=166736rank=87500 of ranks=166736rank=87600 of ranks=166736rank=87700 of ranks=166736rank=87800 of ranks=166736rank=87900 of ranks=166736rank=88000 of ranks=166736rank=88100 of ranks=166736rank=88200 of ranks=166736rank=88300 of ranks=166736rank=88400 of ranks=166736rank=88500 of ranks=166736rank=88600 of ranks=166736rank=88700 of ranks=166736rank=88800 of ranks=166736rank=88900 of ranks=166736rank=89000 of ranks=166736rank=89100 of ranks=166736rank=89200 of ranks=166736rank=89300 of ranks=166736rank=89400 of ranks=166736rank=89500 of ranks=166736rank=89600 of ranks=166736rank=89700 of ranks=166736rank=89800 of ranks=166736rank=89900 of ranks=166736rank=90000 of ranks=166736rank=90100 of ranks=166736rank=90200 of ranks=166736rank=90300 of ranks=166736rank=90400 of ranks=166736rank=90500 of ranks=166736rank=90600 of ranks=166736rank=90700 of ranks=166736rank=90800 of ranks=166736rank=90900 of ranks=166736rank=91000 of ranks=166736rank=91100 of ranks=166736rank=91200 of ranks=166736rank=91300 of ranks=166736rank=91400 of ranks=166736rank=91500 of ranks=166736rank=91600 of ranks=166736rank=91700 of ranks=166736rank=91800 of ranks=166736rank=91900 of ranks=166736rank=92000 of ranks=166736rank=92100 of ranks=166736rank=92200 of ranks=166736rank=92300 of ranks=166736rank=92400 of ranks=166736rank=92500 of ranks=166736rank=92600 of ranks=166736rank=92700 of ranks=166736rank=92800 of ranks=166736rank=92900 of ranks=166736rank=93000 of ranks=166736rank=93100 of ranks=166736rank=93200 of ranks=166736rank=93300 of ranks=166736rank=93400 of ranks=166736rank=93500 of ranks=166736rank=93600 of ranks=166736rank=93700 of ranks=166736rank=93800 of ranks=166736rank=93900 of ranks=166736rank=94000 of ranks=166736rank=94100 of ranks=166736rank=94200 of ranks=166736rank=94300 of ranks=166736rank=94400 of ranks=166736rank=94500 of ranks=166736rank=94600 of ranks=166736rank=94700 of ranks=166736rank=94800 of ranks=166736rank=94900 of ranks=166736rank=95000 of ranks=166736rank=95100 of ranks=166736rank=95200 of ranks=166736rank=95300 of ranks=166736rank=95400 of ranks=166736rank=95500 of ranks=166736rank=95600 of ranks=166736rank=95700 of ranks=166736rank=95800 of ranks=166736rank=95900 of ranks=166736rank=96000 of ranks=166736rank=96100 of ranks=166736rank=96200 of ranks=166736rank=96300 of ranks=166736rank=96400 of ranks=166736rank=96500 of ranks=166736rank=96600 of ranks=166736rank=96700 of ranks=166736rank=96800 of ranks=166736rank=96900 of ranks=166736rank=97000 of ranks=166736rank=97100 of ranks=166736rank=97200 of ranks=166736rank=97300 of ranks=166736rank=97400 of ranks=166736rank=97500 of ranks=166736rank=97600 of ranks=166736rank=97700 of ranks=166736rank=97800 of ranks=166736rank=97900 of ranks=166736rank=98000 of ranks=166736rank=98100 of ranks=166736rank=98200 of ranks=166736rank=98300 of ranks=166736rank=98400 of ranks=166736rank=98500 of ranks=166736rank=98600 of ranks=166736rank=98700 of ranks=166736rank=98800 of ranks=166736rank=98900 of ranks=166736rank=99000 of ranks=166736rank=99100 of ranks=166736rank=99200 of ranks=166736rank=99300 of ranks=166736rank=99400 of ranks=166736rank=99500 of ranks=166736rank=99600 of ranks=166736rank=99700 of ranks=166736rank=99800 of ranks=166736rank=99900 of ranks=166736rank=100000 of ranks=166736rank=100100 of ranks=166736rank=100200 of ranks=166736rank=100300 of ranks=166736rank=100400 of ranks=166736rank=100500 of ranks=166736rank=100600 of ranks=166736rank=100700 of ranks=166736rank=100800 of ranks=166736rank=100900 of ranks=166736rank=101000 of ranks=166736rank=101100 of ranks=166736rank=101200 of ranks=166736rank=101300 of ranks=166736rank=101400 of ranks=166736rank=101500 of ranks=166736rank=101600 of ranks=166736rank=101700 of ranks=166736rank=101800 of ranks=166736rank=101900 of ranks=166736rank=102000 of ranks=166736rank=102100 of ranks=166736rank=102200 of ranks=166736rank=102300 of ranks=166736rank=102400 of ranks=166736rank=102500 of ranks=166736rank=102600 of ranks=166736rank=102700 of ranks=166736rank=102800 of ranks=166736rank=102900 of ranks=166736rank=103000 of ranks=166736rank=103100 of ranks=166736rank=103200 of ranks=166736rank=103300 of ranks=166736rank=103400 of ranks=166736rank=103500 of ranks=166736rank=103600 of ranks=166736rank=103700 of ranks=166736rank=103800 of ranks=166736rank=103900 of ranks=166736rank=104000 of ranks=166736rank=104100 of ranks=166736rank=104200 of ranks=166736rank=104300 of ranks=166736rank=104400 of ranks=166736rank=104500 of ranks=166736rank=104600 of ranks=166736rank=104700 of ranks=166736rank=104800 of ranks=166736rank=104900 of ranks=166736rank=105000 of ranks=166736rank=105100 of ranks=166736rank=105200 of ranks=166736rank=105300 of ranks=166736rank=105400 of ranks=166736rank=105500 of ranks=166736rank=105600 of ranks=166736rank=105700 of ranks=166736rank=105800 of ranks=166736rank=105900 of ranks=166736rank=106000 of ranks=166736rank=106100 of ranks=166736rank=106200 of ranks=166736rank=106300 of ranks=166736rank=106400 of ranks=166736rank=106500 of ranks=166736rank=106600 of ranks=166736rank=106700 of ranks=166736rank=106800 of ranks=166736rank=106900 of ranks=166736rank=107000 of ranks=166736rank=107100 of ranks=166736rank=107200 of ranks=166736rank=107300 of ranks=166736rank=107400 of ranks=166736rank=107500 of ranks=166736rank=107600 of ranks=166736rank=107700 of ranks=166736rank=107800 of ranks=166736rank=107900 of ranks=166736rank=108000 of ranks=166736rank=108100 of ranks=166736rank=108200 of ranks=166736rank=108300 of ranks=166736rank=108400 of ranks=166736rank=108500 of ranks=166736rank=108600 of ranks=166736rank=108700 of ranks=166736rank=108800 of ranks=166736rank=108900 of ranks=166736rank=109000 of ranks=166736rank=109100 of ranks=166736rank=109200 of ranks=166736rank=109300 of ranks=166736rank=109400 of ranks=166736rank=109500 of ranks=166736rank=109600 of ranks=166736rank=109700 of ranks=166736rank=109800 of ranks=166736rank=109900 of ranks=166736rank=110000 of ranks=166736rank=110100 of ranks=166736rank=110200 of ranks=166736rank=110300 of ranks=166736rank=110400 of ranks=166736rank=110500 of ranks=166736rank=110600 of ranks=166736rank=110700 of ranks=166736rank=110800 of ranks=166736rank=110900 of ranks=166736rank=111000 of ranks=166736rank=111100 of ranks=166736rank=111200 of ranks=166736rank=111300 of ranks=166736rank=111400 of ranks=166736rank=111500 of ranks=166736rank=111600 of ranks=166736rank=111700 of ranks=166736rank=111800 of ranks=166736rank=111900 of ranks=166736rank=112000 of ranks=166736rank=112100 of ranks=166736rank=112200 of ranks=166736rank=112300 of ranks=166736rank=112400 of ranks=166736rank=112500 of ranks=166736rank=112600 of ranks=166736rank=112700 of ranks=166736rank=112800 of ranks=166736rank=112900 of ranks=166736rank=113000 of ranks=166736rank=113100 of ranks=166736rank=113200 of ranks=166736rank=113300 of ranks=166736rank=113400 of ranks=166736rank=113500 of ranks=166736rank=113600 of ranks=166736rank=113700 of ranks=166736rank=113800 of ranks=166736rank=113900 of ranks=166736rank=114000 of ranks=166736rank=114100 of ranks=166736rank=114200 of ranks=166736rank=114300 of ranks=166736rank=114400 of ranks=166736rank=114500 of ranks=166736rank=114600 of ranks=166736rank=114700 of ranks=166736rank=114800 of ranks=166736rank=114900 of ranks=166736rank=115000 of ranks=166736rank=115100 of ranks=166736rank=115200 of ranks=166736rank=115300 of ranks=166736rank=115400 of ranks=166736rank=115500 of ranks=166736rank=115600 of ranks=166736rank=115700 of ranks=166736rank=115800 of ranks=166736rank=115900 of ranks=166736rank=116000 of ranks=166736rank=116100 of ranks=166736rank=116200 of ranks=166736rank=116300 of ranks=166736rank=116400 of ranks=166736rank=116500 of ranks=166736rank=116600 of ranks=166736rank=116700 of ranks=166736rank=116800 of ranks=166736rank=116900 of ranks=166736rank=117000 of ranks=166736rank=117100 of ranks=166736rank=117200 of ranks=166736rank=117300 of ranks=166736rank=117400 of ranks=166736rank=117500 of ranks=166736rank=117600 of ranks=166736rank=117700 of ranks=166736rank=117800 of ranks=166736rank=117900 of ranks=166736rank=118000 of ranks=166736rank=118100 of ranks=166736rank=118200 of ranks=166736rank=118300 of ranks=166736rank=118400 of ranks=166736rank=118500 of ranks=166736rank=118600 of ranks=166736rank=118700 of ranks=166736rank=118800 of ranks=166736rank=118900 of ranks=166736rank=119000 of ranks=166736rank=119100 of ranks=166736rank=119200 of ranks=166736rank=119300 of ranks=166736rank=119400 of ranks=166736rank=119500 of ranks=166736rank=119600 of ranks=166736rank=119700 of ranks=166736rank=119800 of ranks=166736rank=119900 of ranks=166736rank=120000 of ranks=166736rank=120100 of ranks=166736rank=120200 of ranks=166736rank=120300 of ranks=166736rank=120400 of ranks=166736rank=120500 of ranks=166736rank=120600 of ranks=166736rank=120700 of ranks=166736rank=120800 of ranks=166736rank=120900 of ranks=166736rank=121000 of ranks=166736rank=121100 of ranks=166736rank=121200 of ranks=166736rank=121300 of ranks=166736rank=121400 of ranks=166736rank=121500 of ranks=166736rank=121600 of ranks=166736rank=121700 of ranks=166736rank=121800 of ranks=166736rank=121900 of ranks=166736rank=122000 of ranks=166736rank=122100 of ranks=166736rank=122200 of ranks=166736rank=122300 of ranks=166736rank=122400 of ranks=166736rank=122500 of ranks=166736rank=122600 of ranks=166736rank=122700 of ranks=166736rank=122800 of ranks=166736rank=122900 of ranks=166736rank=123000 of ranks=166736rank=123100 of ranks=166736rank=123200 of ranks=166736rank=123300 of ranks=166736rank=123400 of ranks=166736rank=123500 of ranks=166736rank=123600 of ranks=166736rank=123700 of ranks=166736rank=123800 of ranks=166736rank=123900 of ranks=166736rank=124000 of ranks=166736rank=124100 of ranks=166736rank=124200 of ranks=166736rank=124300 of ranks=166736rank=124400 of ranks=166736rank=124500 of ranks=166736rank=124600 of ranks=166736rank=124700 of ranks=166736rank=124800 of ranks=166736rank=124900 of ranks=166736rank=125000 of ranks=166736rank=125100 of ranks=166736rank=125200 of ranks=166736rank=125300 of ranks=166736rank=125400 of ranks=166736rank=125500 of ranks=166736rank=125600 of ranks=166736rank=125700 of ranks=166736rank=125800 of ranks=166736rank=125900 of ranks=166736rank=126000 of ranks=166736rank=126100 of ranks=166736rank=126200 of ranks=166736rank=126300 of ranks=166736rank=126400 of ranks=166736rank=126500 of ranks=166736rank=126600 of ranks=166736rank=126700 of ranks=166736rank=126800 of ranks=166736rank=126900 of ranks=166736rank=127000 of ranks=166736rank=127100 of ranks=166736rank=127200 of ranks=166736rank=127300 of ranks=166736rank=127400 of ranks=166736rank=127500 of ranks=166736rank=127600 of ranks=166736rank=127700 of ranks=166736rank=127800 of ranks=166736rank=127900 of ranks=166736rank=128000 of ranks=166736rank=128100 of ranks=166736rank=128200 of ranks=166736rank=128300 of ranks=166736rank=128400 of ranks=166736rank=128500 of ranks=166736rank=128600 of ranks=166736rank=128700 of ranks=166736rank=128800 of ranks=166736rank=128900 of ranks=166736rank=129000 of ranks=166736rank=129100 of ranks=166736rank=129200 of ranks=166736rank=129300 of ranks=166736rank=129400 of ranks=166736rank=129500 of ranks=166736rank=129600 of ranks=166736rank=129700 of ranks=166736rank=129800 of ranks=166736rank=129900 of ranks=166736rank=130000 of ranks=166736rank=130100 of ranks=166736rank=130200 of ranks=166736rank=130300 of ranks=166736rank=130400 of ranks=166736rank=130500 of ranks=166736rank=130600 of ranks=166736rank=130700 of ranks=166736rank=130800 of ranks=166736rank=130900 of ranks=166736rank=131000 of ranks=166736rank=131100 of ranks=166736rank=131200 of ranks=166736rank=131300 of ranks=166736rank=131400 of ranks=166736rank=131500 of ranks=166736rank=131600 of ranks=166736rank=131700 of ranks=166736rank=131800 of ranks=166736rank=131900 of ranks=166736rank=132000 of ranks=166736rank=132100 of ranks=166736rank=132200 of ranks=166736rank=132300 of ranks=166736rank=132400 of ranks=166736rank=132500 of ranks=166736rank=132600 of ranks=166736rank=132700 of ranks=166736rank=132800 of ranks=166736rank=132900 of ranks=166736rank=133000 of ranks=166736rank=133100 of ranks=166736rank=133200 of ranks=166736rank=133300 of ranks=166736rank=133400 of ranks=166736rank=133500 of ranks=166736rank=133600 of ranks=166736rank=133700 of ranks=166736rank=133800 of ranks=166736rank=133900 of ranks=166736rank=134000 of ranks=166736rank=134100 of ranks=166736rank=134200 of ranks=166736rank=134300 of ranks=166736rank=134400 of ranks=166736rank=134500 of ranks=166736rank=134600 of ranks=166736rank=134700 of ranks=166736rank=134800 of ranks=166736rank=134900 of ranks=166736rank=135000 of ranks=166736rank=135100 of ranks=166736rank=135200 of ranks=166736rank=135300 of ranks=166736rank=135400 of ranks=166736rank=135500 of ranks=166736rank=135600 of ranks=166736rank=135700 of ranks=166736rank=135800 of ranks=166736rank=135900 of ranks=166736rank=136000 of ranks=166736rank=136100 of ranks=166736rank=136200 of ranks=166736rank=136300 of ranks=166736rank=136400 of ranks=166736rank=136500 of ranks=166736rank=136600 of ranks=166736rank=136700 of ranks=166736rank=136800 of ranks=166736rank=136900 of ranks=166736rank=137000 of ranks=166736rank=137100 of ranks=166736rank=137200 of ranks=166736rank=137300 of ranks=166736rank=137400 of ranks=166736rank=137500 of ranks=166736rank=137600 of ranks=166736rank=137700 of ranks=166736rank=137800 of ranks=166736rank=137900 of ranks=166736rank=138000 of ranks=166736rank=138100 of ranks=166736rank=138200 of ranks=166736rank=138300 of ranks=166736rank=138400 of ranks=166736rank=138500 of ranks=166736rank=138600 of ranks=166736rank=138700 of ranks=166736rank=138800 of ranks=166736rank=138900 of ranks=166736rank=139000 of ranks=166736rank=139100 of ranks=166736rank=139200 of ranks=166736rank=139300 of ranks=166736rank=139400 of ranks=166736rank=139500 of ranks=166736rank=139600 of ranks=166736rank=139700 of ranks=166736rank=139800 of ranks=166736rank=139900 of ranks=166736rank=140000 of ranks=166736rank=140100 of ranks=166736rank=140200 of ranks=166736rank=140300 of ranks=166736rank=140400 of ranks=166736rank=140500 of ranks=166736rank=140600 of ranks=166736rank=140700 of ranks=166736rank=140800 of ranks=166736rank=140900 of ranks=166736rank=141000 of ranks=166736rank=141100 of ranks=166736rank=141200 of ranks=166736rank=141300 of ranks=166736rank=141400 of ranks=166736rank=141500 of ranks=166736rank=141600 of ranks=166736rank=141700 of ranks=166736rank=141800 of ranks=166736rank=141900 of ranks=166736rank=142000 of ranks=166736rank=142100 of ranks=166736rank=142200 of ranks=166736rank=142300 of ranks=166736rank=142400 of ranks=166736rank=142500 of ranks=166736rank=142600 of ranks=166736rank=142700 of ranks=166736rank=142800 of ranks=166736rank=142900 of ranks=166736rank=143000 of ranks=166736rank=143100 of ranks=166736rank=143200 of ranks=166736rank=143300 of ranks=166736rank=143400 of ranks=166736rank=143500 of ranks=166736rank=143600 of ranks=166736rank=143700 of ranks=166736rank=143800 of ranks=166736rank=143900 of ranks=166736rank=144000 of ranks=166736rank=144100 of ranks=166736rank=144200 of ranks=166736rank=144300 of ranks=166736rank=144400 of ranks=166736rank=144500 of ranks=166736rank=144600 of ranks=166736rank=144700 of ranks=166736rank=144800 of ranks=166736rank=144900 of ranks=166736rank=145000 of ranks=166736rank=145100 of ranks=166736rank=145200 of ranks=166736rank=145300 of ranks=166736rank=145400 of ranks=166736rank=145500 of ranks=166736rank=145600 of ranks=166736rank=145700 of ranks=166736rank=145800 of ranks=166736rank=145900 of ranks=166736rank=146000 of ranks=166736rank=146100 of ranks=166736rank=146200 of ranks=166736rank=146300 of ranks=166736rank=146400 of ranks=166736rank=146500 of ranks=166736rank=146600 of ranks=166736rank=146700 of ranks=166736rank=146800 of ranks=166736rank=146900 of ranks=166736rank=147000 of ranks=166736rank=147100 of ranks=166736rank=147200 of ranks=166736rank=147300 of ranks=166736rank=147400 of ranks=166736rank=147500 of ranks=166736rank=147600 of ranks=166736rank=147700 of ranks=166736rank=147800 of ranks=166736rank=147900 of ranks=166736rank=148000 of ranks=166736rank=148100 of ranks=166736rank=148200 of ranks=166736rank=148300 of ranks=166736rank=148400 of ranks=166736rank=148500 of ranks=166736rank=148600 of ranks=166736rank=148700 of ranks=166736rank=148800 of ranks=166736rank=148900 of ranks=166736rank=149000 of ranks=166736rank=149100 of ranks=166736rank=149200 of ranks=166736rank=149300 of ranks=166736rank=149400 of ranks=166736rank=149500 of ranks=166736rank=149600 of ranks=166736rank=149700 of ranks=166736rank=149800 of ranks=166736rank=149900 of ranks=166736rank=150000 of ranks=166736rank=150100 of ranks=166736rank=150200 of ranks=166736rank=150300 of ranks=166736rank=150400 of ranks=166736rank=150500 of ranks=166736rank=150600 of ranks=166736rank=150700 of ranks=166736rank=150800 of ranks=166736rank=150900 of ranks=166736rank=151000 of ranks=166736rank=151100 of ranks=166736rank=151200 of ranks=166736rank=151300 of ranks=166736rank=151400 of ranks=166736rank=151500 of ranks=166736rank=151600 of ranks=166736rank=151700 of ranks=166736rank=151800 of ranks=166736rank=151900 of ranks=166736rank=152000 of ranks=166736rank=152100 of ranks=166736rank=152200 of ranks=166736rank=152300 of ranks=166736rank=152400 of ranks=166736rank=152500 of ranks=166736rank=152600 of ranks=166736rank=152700 of ranks=166736rank=152800 of ranks=166736rank=152900 of ranks=166736rank=153000 of ranks=166736rank=153100 of ranks=166736rank=153200 of ranks=166736rank=153300 of ranks=166736rank=153400 of ranks=166736rank=153500 of ranks=166736rank=153600 of ranks=166736rank=153700 of ranks=166736rank=153800 of ranks=166736rank=153900 of ranks=166736rank=154000 of ranks=166736rank=154100 of ranks=166736rank=154200 of ranks=166736rank=154300 of ranks=166736rank=154400 of ranks=166736rank=154500 of ranks=166736rank=154600 of ranks=166736rank=154700 of ranks=166736rank=154800 of ranks=166736rank=154900 of ranks=166736rank=155000 of ranks=166736rank=155100 of ranks=166736rank=155200 of ranks=166736rank=155300 of ranks=166736rank=155400 of ranks=166736rank=155500 of ranks=166736rank=155600 of ranks=166736rank=155700 of ranks=166736rank=155800 of ranks=166736rank=155900 of ranks=166736rank=156000 of ranks=166736rank=156100 of ranks=166736rank=156200 of ranks=166736rank=156300 of ranks=166736rank=156400 of ranks=166736rank=156500 of ranks=166736rank=156600 of ranks=166736rank=156700 of ranks=166736rank=156800 of ranks=166736rank=156900 of ranks=166736rank=157000 of ranks=166736rank=157100 of ranks=166736rank=157200 of ranks=166736rank=157300 of ranks=166736rank=157400 of ranks=166736rank=157500 of ranks=166736rank=157600 of ranks=166736rank=157700 of ranks=166736rank=157800 of ranks=166736rank=157900 of ranks=166736rank=158000 of ranks=166736rank=158100 of ranks=166736rank=158200 of ranks=166736rank=158300 of ranks=166736rank=158400 of ranks=166736rank=158500 of ranks=166736rank=158600 of ranks=166736rank=158700 of ranks=166736rank=158800 of ranks=166736rank=158900 of ranks=166736rank=159000 of ranks=166736rank=159100 of ranks=166736rank=159200 of ranks=166736rank=159300 of ranks=166736rank=159400 of ranks=166736rank=159500 of ranks=166736rank=159600 of ranks=166736rank=159700 of ranks=166736rank=159800 of ranks=166736rank=159900 of ranks=166736rank=160000 of ranks=166736rank=160100 of ranks=166736rank=160200 of ranks=166736rank=160300 of ranks=166736rank=160400 of ranks=166736rank=160500 of ranks=166736rank=160600 of ranks=166736rank=160700 of ranks=166736rank=160800 of ranks=166736rank=160900 of ranks=166736rank=161000 of ranks=166736rank=161100 of ranks=166736rank=161200 of ranks=166736rank=161300 of ranks=166736rank=161400 of ranks=166736rank=161500 of ranks=166736rank=161600 of ranks=166736rank=161700 of ranks=166736rank=161800 of ranks=166736rank=161900 of ranks=166736rank=162000 of ranks=166736rank=162100 of ranks=166736rank=162200 of ranks=166736rank=162300 of ranks=166736rank=162400 of ranks=166736rank=162500 of ranks=166736rank=162600 of ranks=166736rank=162700 of ranks=166736rank=162800 of ranks=166736rank=162900 of ranks=166736rank=163000 of ranks=166736rank=163100 of ranks=166736rank=163200 of ranks=166736rank=163300 of ranks=166736rank=163400 of ranks=166736rank=163500 of ranks=166736rank=163600 of ranks=166736rank=163700 of ranks=166736rank=163800 of ranks=166736rank=163900 of ranks=166736rank=164000 of ranks=166736rank=164100 of ranks=166736rank=164200 of ranks=166736rank=164300 of ranks=166736rank=164400 of ranks=166736rank=164500 of ranks=166736rank=164600 of ranks=166736rank=164700 of ranks=166736rank=164800 of ranks=166736rank=164900 of ranks=166736rank=165000 of ranks=166736rank=165100 of ranks=166736rank=165200 of ranks=166736rank=165300 of ranks=166736rank=165400 of ranks=166736rank=165500 of ranks=166736rank=165600 of ranks=166736rank=165700 of ranks=166736rank=165800 of ranks=166736rank=165900 of ranks=166736rank=166000 of ranks=166736rank=166100 of ranks=166736rank=166200 of ranks=166736rank=166300 of ranks=166736rank=166400 of ranks=166736rank=166500 of ranks=166736rank=166600 of ranks=166736rank=166700 of ranks=166736

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              85.7032    470   8995     28    498           69.0604
   1 car                    97.1943  49859  51752    457  50316           73.4517
   2 truck                  86.6552   1781  18271     44   1825           46.4114
   3 bus                    68.8066    358   9018      8    366           36.5468
   4 pedestrian             89.5123   4028  22204    231   4259           62.3637

for conf_thresh=0.25, precision=0.83, recall=0.92, F1 score=0.87
for conf_thresh=0.25, TP=52911, FP=10935, FN=4353, average IoU=71.34%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=85.57%
Total detection time: 154 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
New best mAP, saving weights!
Saving weights to /workspace/.cache/splits/combined_best.weights
2625: loss=4.354, avg loss=4.842, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.9 seconds, train=3.0 seconds, 168000 images, time remaining=6.3 hours
2626: loss=4.785, avg loss=4.836, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.5 seconds, train=2.9 seconds, 168064 images, time remaining=6.3 hours
2627: loss=5.592, avg loss=4.912, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 168128 images, time remaining=6.3 hours
2628: loss=4.059, avg loss=4.826, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=2.8 seconds, 168192 images, time remaining=6.3 hours
2629: loss=4.237, avg loss=4.767, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=3.0 seconds, 168256 images, time remaining=6.3 hours
2630: loss=4.504, avg loss=4.741, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 168320 images, time remaining=6.3 hours
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2631: loss=7.392, avg loss=5.006, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=6.2 seconds, 168384 images, time remaining=6.3 hours
2632: loss=6.849, avg loss=5.191, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.1 seconds, train=6.0 seconds, 168448 images, time remaining=6.3 hours
2633: loss=5.640, avg loss=5.235, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=6.1 seconds, 168512 images, time remaining=6.3 hours
2634: loss=6.008, avg loss=5.313, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.1 seconds, train=6.0 seconds, 168576 images, time remaining=6.3 hours
2635: loss=5.617, avg loss=5.343, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=6.1 seconds, 168640 images, time remaining=6.3 hours
2636: loss=6.037, avg loss=5.412, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=6.1 seconds, 168704 images, time remaining=6.3 hours
2637: loss=6.052, avg loss=5.476, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 168768 images, time remaining=6.3 hours
2638: loss=6.262, avg loss=5.555, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.0 seconds, train=6.1 seconds, 168832 images, time remaining=6.3 hours
2639: loss=6.389, avg loss=5.638, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 168896 images, time remaining=6.3 hours
2640: loss=6.297, avg loss=5.704, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 168960 images, time remaining=6.3 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b81d000000
2641: loss=5.795, avg loss=5.713, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 169024 images, time remaining=6.3 hours
2642: loss=6.358, avg loss=5.778, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 169088 images, time remaining=6.3 hours
2643: loss=4.995, avg loss=5.699, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 169152 images, time remaining=6.3 hours
2644: loss=5.046, avg loss=5.634, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 169216 images, time remaining=6.3 hours
2645: loss=5.362, avg loss=5.607, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 169280 images, time remaining=6.3 hours
2646: loss=5.402, avg loss=5.586, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 169344 images, time remaining=6.3 hours
2647: loss=5.375, avg loss=5.565, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 169408 images, time remaining=6.3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
2648: loss=5.034, avg loss=5.512, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=3.0 seconds, train=2.3 seconds, 169472 images, time remaining=6.3 hours
2649: loss=4.987, avg loss=5.460, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 169536 images, time remaining=6.3 hours
2650: loss=5.145, avg loss=5.428, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 169600 images, time remaining=6.3 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2651: loss=7.379, avg loss=5.623, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=5.0 seconds, 169664 images, time remaining=6.3 hours
2652: loss=7.802, avg loss=5.841, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 169728 images, time remaining=6.3 hours
2653: loss=5.276, avg loss=5.785, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 169792 images, time remaining=6.3 hours
2654: loss=5.577, avg loss=5.764, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 169856 images, time remaining=6.3 hours
2655: loss=5.114, avg loss=5.699, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 169920 images, time remaining=6.3 hours
2656: loss=6.814, avg loss=5.810, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 169984 images, time remaining=6.3 hours
2657: loss=6.388, avg loss=5.868, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 170048 images, time remaining=6.3 hours
2658: loss=5.116, avg loss=5.793, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 170112 images, time remaining=6.3 hours
2659: loss=5.081, avg loss=5.722, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 170176 images, time remaining=6.3 hours
2660: loss=5.283, avg loss=5.678, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 170240 images, time remaining=6.3 hours
Resizing, random_coef=1.40, batch=4, 832x672
GPU #0: allocating workspace: 418.6 MiB begins at 0x14b83c800000
2661: loss=6.341, avg loss=5.744, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 170304 images, time remaining=6.3 hours
2662: loss=7.279, avg loss=5.898, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 170368 images, time remaining=6.3 hours
2663: loss=6.614, avg loss=5.969, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 170432 images, time remaining=6.3 hours
2664: loss=4.940, avg loss=5.866, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 170496 images, time remaining=6.3 hours
2665: loss=5.454, avg loss=5.825, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 170560 images, time remaining=6.3 hours
2666: loss=5.063, avg loss=5.749, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 170624 images, time remaining=6.3 hours
2667: loss=4.851, avg loss=5.659, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 170688 images, time remaining=6.3 hours
2668: loss=5.306, avg loss=5.624, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 170752 images, time remaining=6.3 hours
2669: loss=6.082, avg loss=5.670, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 170816 images, time remaining=6.3 hours
2670: loss=5.646, avg loss=5.667, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 170880 images, time remaining=6.3 hours
Resizing, random_coef=1.40, batch=4, 1344x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2671: loss=11.787, avg loss=6.279, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=6.2 seconds, 170944 images, time remaining=6.3 hours
2672: loss=7.866, avg loss=6.438, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.2 seconds, train=6.0 seconds, 171008 images, time remaining=6.3 hours
2673: loss=6.937, avg loss=6.488, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 171072 images, time remaining=6.3 hours
2674: loss=6.510, avg loss=6.490, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.3 seconds, train=5.9 seconds, 171136 images, time remaining=6.3 hours
2675: loss=6.979, avg loss=6.539, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=6.1 seconds, 171200 images, time remaining=6.3 hours
2676: loss=6.935, avg loss=6.579, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.0 seconds, train=5.9 seconds, 171264 images, time remaining=6.3 hours
2677: loss=6.838, avg loss=6.605, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 171328 images, time remaining=6.3 hours
2678: loss=8.254, avg loss=6.769, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 171392 images, time remaining=6.3 hours
2679: loss=7.168, avg loss=6.809, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 171456 images, time remaining=6.3 hours
2680: loss=8.911, avg loss=7.020, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 171520 images, time remaining=6.3 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2681: loss=5.692, avg loss=6.887, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 171584 images, time remaining=6.3 hours
2682: loss=7.084, avg loss=6.907, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 171648 images, time remaining=6.3 hours
2683: loss=5.320, avg loss=6.748, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 171712 images, time remaining=6.3 hours
2684: loss=7.022, avg loss=6.775, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 171776 images, time remaining=6.3 hours
2685: loss=5.801, avg loss=6.678, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 171840 images, time remaining=6.3 hours
2686: loss=5.211, avg loss=6.531, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 171904 images, time remaining=6.3 hours
2687: loss=5.172, avg loss=6.395, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 171968 images, time remaining=6.3 hours
2688: loss=5.669, avg loss=6.323, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 172032 images, time remaining=6.3 hours
2689: loss=5.575, avg loss=6.248, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 172096 images, time remaining=6.3 hours
2690: loss=5.804, avg loss=6.203, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 172160 images, time remaining=6.3 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2691: loss=4.622, avg loss=6.045, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 172224 images, time remaining=6.3 hours
2692: loss=6.070, avg loss=6.048, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.1 seconds, train=4.7 seconds, 172288 images, time remaining=6.3 hours
2693: loss=5.605, avg loss=6.004, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 172352 images, time remaining=6.3 hours
2694: loss=5.368, avg loss=5.940, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 172416 images, time remaining=6.3 hours
2695: loss=4.696, avg loss=5.816, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 172480 images, time remaining=6.3 hours
2696: loss=5.711, avg loss=5.805, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 172544 images, time remaining=6.2 hours
2697: loss=6.798, avg loss=5.904, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 172608 images, time remaining=6.2 hours
2698: loss=4.894, avg loss=5.803, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 172672 images, time remaining=6.2 hours
2699: loss=5.313, avg loss=5.754, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 172736 images, time remaining=6.2 hours
2700: loss=6.372, avg loss=5.816, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 172800 images, time remaining=6.2 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2701: loss=4.739, avg loss=5.708, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 172864 images, time remaining=6.2 hours
2702: loss=5.089, avg loss=5.646, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.2 seconds, train=5.2 seconds, 172928 images, time remaining=6.2 hours
2703: loss=5.272, avg loss=5.609, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=5.2 seconds, 172992 images, time remaining=6.2 hours
2704: loss=4.553, avg loss=5.504, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 173056 images, time remaining=6.2 hours
2705: loss=5.427, avg loss=5.496, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 173120 images, time remaining=6.2 hours
2706: loss=5.515, avg loss=5.498, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 173184 images, time remaining=6.2 hours
2707: loss=4.484, avg loss=5.396, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 173248 images, time remaining=6.2 hours
2708: loss=5.585, avg loss=5.415, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.1 seconds, train=5.3 seconds, 173312 images, time remaining=6.2 hours
2709: loss=4.191, avg loss=5.293, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 173376 images, time remaining=6.2 hours
2710: loss=6.150, avg loss=5.379, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=5.5 seconds, 173440 images, time remaining=6.2 hours
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2711: loss=5.729, avg loss=5.414, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.7 seconds, 173504 images, time remaining=6.2 hours
2712: loss=5.704, avg loss=5.443, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 173568 images, time remaining=6.2 hours
2713: loss=5.198, avg loss=5.418, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 173632 images, time remaining=6.2 hours
2714: loss=5.326, avg loss=5.409, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.6 seconds, 173696 images, time remaining=6.2 hours
2715: loss=4.814, avg loss=5.350, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.6 seconds, 173760 images, time remaining=6.2 hours
2716: loss=6.013, avg loss=5.416, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 173824 images, time remaining=6.2 hours
2717: loss=5.586, avg loss=5.433, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.0 seconds, train=5.6 seconds, 173888 images, time remaining=6.2 hours
2718: loss=5.961, avg loss=5.486, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.6 seconds, 173952 images, time remaining=6.2 hours
2719: loss=5.064, avg loss=5.443, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.4 seconds, train=5.7 seconds, 174016 images, time remaining=6.2 hours
2720: loss=5.439, avg loss=5.443, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 174080 images, time remaining=6.2 hours
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2721: loss=4.940, avg loss=5.393, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=4.1 seconds, 174144 images, time remaining=6.2 hours
2722: loss=4.585, avg loss=5.312, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 174208 images, time remaining=6.2 hours
2723: loss=5.065, avg loss=5.287, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.1 seconds, 174272 images, time remaining=6.2 hours
2724: loss=5.242, avg loss=5.283, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=3.9 seconds, 174336 images, time remaining=6.2 hours
2725: loss=5.834, avg loss=5.338, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=4.0 seconds, 174400 images, time remaining=6.2 hours
2726: loss=6.030, avg loss=5.407, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 174464 images, time remaining=6.2 hours
2727: loss=5.802, avg loss=5.447, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 174528 images, time remaining=6.2 hours
2728: loss=4.243, avg loss=5.326, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 174592 images, time remaining=6.2 hours
2729: loss=4.532, avg loss=5.247, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 174656 images, time remaining=6.2 hours
2730: loss=4.467, avg loss=5.169, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 174720 images, time remaining=6.2 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2731: loss=4.806, avg loss=5.133, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 174784 images, time remaining=6.2 hours
2732: loss=6.007, avg loss=5.220, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 174848 images, time remaining=6.2 hours
2733: loss=4.886, avg loss=5.187, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 174912 images, time remaining=6.2 hours
2734: loss=5.307, avg loss=5.199, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 174976 images, time remaining=6.2 hours
2735: loss=5.324, avg loss=5.211, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 175040 images, time remaining=6.2 hours
2736: loss=4.948, avg loss=5.185, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 175104 images, time remaining=6.2 hours
2737: loss=5.686, avg loss=5.235, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 175168 images, time remaining=6.2 hours
2738: loss=4.850, avg loss=5.196, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 175232 images, time remaining=6.2 hours
2739: loss=5.577, avg loss=5.235, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 175296 images, time remaining=6.2 hours
2740: loss=4.659, avg loss=5.177, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 175360 images, time remaining=6.2 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b298000000
2741: loss=5.241, avg loss=5.183, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.2 seconds, train=2.7 seconds, 175424 images, time remaining=6.2 hours
2742: loss=5.590, avg loss=5.224, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 175488 images, time remaining=6.2 hours
2743: loss=5.238, avg loss=5.225, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=2.6 seconds, 175552 images, time remaining=6.2 hours
2744: loss=4.602, avg loss=5.163, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=2.6 seconds, 175616 images, time remaining=6.2 hours
2745: loss=5.301, avg loss=5.177, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.5 seconds, 175680 images, time remaining=6.2 hours
2746: loss=4.756, avg loss=5.135, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=2.7 seconds, 175744 images, time remaining=6.2 hours
2747: loss=4.544, avg loss=5.076, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 175808 images, time remaining=6.2 hours
2748: loss=4.899, avg loss=5.058, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 175872 images, time remaining=6.2 hours
2749: loss=5.144, avg loss=5.067, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=2.6 seconds, 175936 images, time remaining=6.2 hours
2750: loss=4.647, avg loss=5.025, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 176000 images, time remaining=6.2 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b5adc00000
2751: loss=5.184, avg loss=5.041, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=3.0 seconds, 176064 images, time remaining=6.2 hours
2752: loss=5.167, avg loss=5.053, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 176128 images, time remaining=6.2 hours
2753: loss=4.310, avg loss=4.979, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 176192 images, time remaining=6.2 hours
2754: loss=4.624, avg loss=4.943, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 176256 images, time remaining=6.2 hours
2755: loss=4.416, avg loss=4.891, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=2.8 seconds, 176320 images, time remaining=6.2 hours
2756: loss=4.446, avg loss=4.846, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 176384 images, time remaining=6.2 hours
2757: loss=5.063, avg loss=4.868, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 176448 images, time remaining=6.2 hours
2758: loss=4.993, avg loss=4.880, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 176512 images, time remaining=6.2 hours
2759: loss=4.510, avg loss=4.843, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 176576 images, time remaining=6.2 hours
2760: loss=4.170, avg loss=4.776, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 176640 images, time remaining=6.2 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2761: loss=4.916, avg loss=4.790, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.0 seconds, 176704 images, time remaining=6.2 hours
2762: loss=4.973, avg loss=4.808, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 176768 images, time remaining=6.2 hours
2763: loss=5.284, avg loss=4.856, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 176832 images, time remaining=6.2 hours
2764: loss=4.798, avg loss=4.850, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 176896 images, time remaining=6.2 hours
2765: loss=5.051, avg loss=4.870, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 176960 images, time remaining=6.2 hours
2766: loss=4.716, avg loss=4.855, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 177024 images, time remaining=6.2 hours
2767: loss=4.165, avg loss=4.786, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 177088 images, time remaining=6.2 hours
2768: loss=4.630, avg loss=4.770, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=5.0 seconds, 177152 images, time remaining=6.2 hours
2769: loss=5.392, avg loss=4.832, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 177216 images, time remaining=6.2 hours
2770: loss=4.520, avg loss=4.801, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=5.0 seconds, 177280 images, time remaining=6.2 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2771: loss=5.030, avg loss=4.824, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=3.9 seconds, 177344 images, time remaining=6.2 hours
2772: loss=4.917, avg loss=4.833, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 177408 images, time remaining=6.2 hours
2773: loss=4.398, avg loss=4.790, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 177472 images, time remaining=6.2 hours
2774: loss=3.998, avg loss=4.711, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 177536 images, time remaining=6.2 hours
2775: loss=4.495, avg loss=4.689, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 177600 images, time remaining=6.2 hours
2776: loss=4.821, avg loss=4.702, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 177664 images, time remaining=6.2 hours
2777: loss=5.158, avg loss=4.748, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 177728 images, time remaining=6.2 hours
2778: loss=3.672, avg loss=4.640, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 177792 images, time remaining=6.2 hours
2779: loss=4.358, avg loss=4.612, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 177856 images, time remaining=6.2 hours
2780: loss=4.660, avg loss=4.617, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=3.9 seconds, 177920 images, time remaining=6.2 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2781: loss=5.107, avg loss=4.666, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 177984 images, time remaining=6.2 hours
2782: loss=4.802, avg loss=4.679, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 178048 images, time remaining=6.2 hours
2783: loss=5.240, avg loss=4.736, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 178112 images, time remaining=6.2 hours
2784: loss=4.369, avg loss=4.699, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 178176 images, time remaining=6.2 hours
2785: loss=3.725, avg loss=4.601, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 178240 images, time remaining=6.2 hours
2786: loss=4.878, avg loss=4.629, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 178304 images, time remaining=6.2 hours
2787: loss=4.057, avg loss=4.572, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.1 seconds, train=4.6 seconds, 178368 images, time remaining=6.2 hours
2788: loss=4.924, avg loss=4.607, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=4.6 seconds, 178432 images, time remaining=6.2 hours
2789: loss=4.970, avg loss=4.643, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.0 seconds, train=4.7 seconds, 178496 images, time remaining=6.2 hours
2790: loss=4.115, avg loss=4.591, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.0 seconds, train=4.7 seconds, 178560 images, time remaining=6.2 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b500c00000
2791: loss=6.764, avg loss=4.808, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 178624 images, time remaining=6.2 hours
2792: loss=5.451, avg loss=4.872, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 178688 images, time remaining=6.2 hours
2793: loss=4.684, avg loss=4.853, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 178752 images, time remaining=6.2 hours
2794: loss=5.163, avg loss=4.884, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 178816 images, time remaining=6.1 hours
2795: loss=5.089, avg loss=4.905, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 178880 images, time remaining=6.1 hours
2796: loss=4.851, avg loss=4.899, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 178944 images, time remaining=6.1 hours
2797: loss=4.500, avg loss=4.859, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 179008 images, time remaining=6.1 hours
2798: loss=4.741, avg loss=4.848, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 179072 images, time remaining=6.1 hours
2799: loss=4.631, avg loss=4.826, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 179136 images, time remaining=6.1 hours
2800: loss=5.571, avg loss=4.900, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 179200 images, time remaining=6.1 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2801: loss=6.465, avg loss=5.057, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 179264 images, time remaining=6.1 hours
2802: loss=5.257, avg loss=5.077, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 179328 images, time remaining=6.1 hours
2803: loss=4.437, avg loss=5.013, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 179392 images, time remaining=6.1 hours
2804: loss=5.096, avg loss=5.021, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 179456 images, time remaining=6.1 hours
2805: loss=5.488, avg loss=5.068, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 179520 images, time remaining=6.1 hours
2806: loss=6.671, avg loss=5.228, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 179584 images, time remaining=6.1 hours
2807: loss=4.668, avg loss=5.172, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.8 seconds, train=3.9 seconds, 179648 images, time remaining=6.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
2808: loss=4.710, avg loss=5.126, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=4.0 seconds, train=3.9 seconds, 179712 images, time remaining=6.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
2809: loss=4.403, avg loss=5.054, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=4.3 seconds, train=3.9 seconds, 179776 images, time remaining=6.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
2810: loss=5.104, avg loss=5.059, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=7.6 seconds, train=3.9 seconds, 179840 images, time remaining=6.1 hours
Resizing, random_coef=1.40, batch=4, 1344x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2811: loss=7.376, avg loss=5.290, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.3 seconds, train=5.9 seconds, 179904 images, time remaining=6.1 hours
2812: loss=7.008, avg loss=5.462, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=3.4 seconds, train=5.9 seconds, 179968 images, time remaining=6.1 hours
2813: loss=6.066, avg loss=5.523, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.9 seconds, train=5.8 seconds, 180032 images, time remaining=6.1 hours
2814: loss=6.406, avg loss=5.611, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.5 seconds, train=5.9 seconds, 180096 images, time remaining=6.1 hours
2815: loss=6.367, avg loss=5.686, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 180160 images, time remaining=6.1 hours
2816: loss=5.833, avg loss=5.701, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=6.1 seconds, 180224 images, time remaining=6.1 hours
2817: loss=5.416, avg loss=5.673, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 180288 images, time remaining=6.1 hours
2818: loss=4.341, avg loss=5.539, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 180352 images, time remaining=6.1 hours
2819: loss=5.353, avg loss=5.521, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=6.0 seconds, 180416 images, time remaining=6.1 hours
2820: loss=5.464, avg loss=5.515, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 180480 images, time remaining=6.1 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b6ae800000
2821: loss=8.235, avg loss=5.787, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 180544 images, time remaining=6.1 hours
2822: loss=6.122, avg loss=5.821, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 180608 images, time remaining=6.1 hours
2823: loss=6.275, avg loss=5.866, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 180672 images, time remaining=6.1 hours
2824: loss=5.104, avg loss=5.790, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 180736 images, time remaining=6.1 hours
2825: loss=4.530, avg loss=5.664, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 180800 images, time remaining=6.1 hours
2826: loss=5.626, avg loss=5.660, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 180864 images, time remaining=6.1 hours
2827: loss=6.059, avg loss=5.700, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 180928 images, time remaining=6.1 hours
2828: loss=5.992, avg loss=5.729, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 180992 images, time remaining=6.1 hours
2829: loss=6.164, avg loss=5.773, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 181056 images, time remaining=6.1 hours
2830: loss=5.405, avg loss=5.736, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 181120 images, time remaining=6.1 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2831: loss=8.695, avg loss=6.032, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=4.4 seconds, 181184 images, time remaining=6.1 hours
2832: loss=6.319, avg loss=6.061, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.4 seconds, 181248 images, time remaining=6.1 hours
2833: loss=4.970, avg loss=5.952, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 181312 images, time remaining=6.1 hours
2834: loss=5.478, avg loss=5.904, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 181376 images, time remaining=6.1 hours
2835: loss=5.046, avg loss=5.818, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 181440 images, time remaining=6.1 hours
2836: loss=5.754, avg loss=5.812, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 181504 images, time remaining=6.1 hours
2837: loss=6.973, avg loss=5.928, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=4.3 seconds, 181568 images, time remaining=6.1 hours
2838: loss=7.241, avg loss=6.059, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.5 seconds, 181632 images, time remaining=6.1 hours
2839: loss=5.748, avg loss=6.028, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 181696 images, time remaining=6.1 hours
2840: loss=4.762, avg loss=5.902, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.4 seconds, 181760 images, time remaining=6.1 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2841: loss=6.190, avg loss=5.930, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 181824 images, time remaining=6.1 hours
2842: loss=5.406, avg loss=5.878, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 181888 images, time remaining=6.1 hours
2843: loss=5.199, avg loss=5.810, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 181952 images, time remaining=6.1 hours
2844: loss=6.822, avg loss=5.911, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 182016 images, time remaining=6.1 hours
2845: loss=6.292, avg loss=5.949, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 182080 images, time remaining=6.1 hours
2846: loss=5.476, avg loss=5.902, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 182144 images, time remaining=6.1 hours
2847: loss=5.358, avg loss=5.848, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 182208 images, time remaining=6.1 hours
2848: loss=5.355, avg loss=5.798, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 182272 images, time remaining=6.1 hours
2849: loss=6.405, avg loss=5.859, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 182336 images, time remaining=6.1 hours
2850: loss=5.893, avg loss=5.862, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 182400 images, time remaining=6.1 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2851: loss=4.925, avg loss=5.769, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 182464 images, time remaining=6.1 hours
2852: loss=4.539, avg loss=5.646, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 182528 images, time remaining=6.1 hours
2853: loss=4.831, avg loss=5.564, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 182592 images, time remaining=6.1 hours
2854: loss=4.255, avg loss=5.433, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 182656 images, time remaining=6.1 hours
2855: loss=5.526, avg loss=5.443, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 182720 images, time remaining=6.1 hours
2856: loss=5.154, avg loss=5.414, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 182784 images, time remaining=6.1 hours
2857: loss=4.360, avg loss=5.308, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 182848 images, time remaining=6.1 hours
2858: loss=4.681, avg loss=5.246, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 182912 images, time remaining=6.1 hours
2859: loss=5.378, avg loss=5.259, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 182976 images, time remaining=6.1 hours
2860: loss=5.744, avg loss=5.307, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 183040 images, time remaining=6.1 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2861: loss=5.289, avg loss=5.305, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=5.4 seconds, 183104 images, time remaining=6.1 hours
2862: loss=4.763, avg loss=5.251, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 183168 images, time remaining=6.1 hours
2863: loss=5.203, avg loss=5.246, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 183232 images, time remaining=6.1 hours
2864: loss=5.536, avg loss=5.275, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.6 seconds, train=5.4 seconds, 183296 images, time remaining=6.1 hours
2865: loss=5.058, avg loss=5.254, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 183360 images, time remaining=6.1 hours
2866: loss=5.837, avg loss=5.312, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.1 seconds, train=5.4 seconds, 183424 images, time remaining=6.1 hours
2867: loss=5.682, avg loss=5.349, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=5.6 seconds, 183488 images, time remaining=6.1 hours
2868: loss=6.061, avg loss=5.420, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=5.5 seconds, 183552 images, time remaining=6.1 hours
2869: loss=4.667, avg loss=5.345, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.2 seconds, train=5.4 seconds, 183616 images, time remaining=6.1 hours
2870: loss=4.953, avg loss=5.306, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 183680 images, time remaining=6.1 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2871: loss=5.355, avg loss=5.311, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 183744 images, time remaining=6.1 hours
2872: loss=5.030, avg loss=5.282, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=5.5 seconds, 183808 images, time remaining=6.1 hours
2873: loss=4.527, avg loss=5.207, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 183872 images, time remaining=6.1 hours
2874: loss=4.943, avg loss=5.181, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 183936 images, time remaining=6.1 hours
2875: loss=6.741, avg loss=5.337, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 184000 images, time remaining=6.1 hours
2876: loss=4.889, avg loss=5.292, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 184064 images, time remaining=6.1 hours
2877: loss=4.542, avg loss=5.217, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 184128 images, time remaining=6.1 hours
2878: loss=4.524, avg loss=5.148, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 184192 images, time remaining=6.1 hours
2879: loss=4.923, avg loss=5.125, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.0 seconds, train=5.4 seconds, 184256 images, time remaining=6.1 hours
2880: loss=5.394, avg loss=5.152, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 184320 images, time remaining=6.1 hours
Resizing, random_coef=1.40, batch=4, 1216x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2881: loss=4.726, avg loss=5.109, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 184384 images, time remaining=6.1 hours
2882: loss=4.688, avg loss=5.067, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 184448 images, time remaining=6.1 hours
2883: loss=5.565, avg loss=5.117, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 184512 images, time remaining=6.1 hours
2884: loss=5.084, avg loss=5.114, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=5.2 seconds, 184576 images, time remaining=6.1 hours
2885: loss=5.021, avg loss=5.104, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 184640 images, time remaining=6.1 hours
2886: loss=5.106, avg loss=5.105, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 184704 images, time remaining=6.1 hours
2887: loss=5.522, avg loss=5.146, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 184768 images, time remaining=6.1 hours
2888: loss=3.700, avg loss=5.002, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=5.2 seconds, 184832 images, time remaining=6.1 hours
2889: loss=3.516, avg loss=4.853, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.1 seconds, 184896 images, time remaining=6.1 hours
2890: loss=5.087, avg loss=4.877, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 184960 images, time remaining=6.1 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2891: loss=4.808, avg loss=4.870, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.0 seconds, train=5.3 seconds, 185024 images, time remaining=6.1 hours
2892: loss=5.193, avg loss=4.902, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.0 seconds, train=5.3 seconds, 185088 images, time remaining=6.1 hours
2893: loss=4.410, avg loss=4.853, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 185152 images, time remaining=6.1 hours
2894: loss=4.765, avg loss=4.844, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=3.1 seconds, train=5.4 seconds, 185216 images, time remaining=6.1 hours
2895: loss=5.053, avg loss=4.865, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 185280 images, time remaining=6.1 hours
2896: loss=5.434, avg loss=4.922, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 185344 images, time remaining=6.1 hours
2897: loss=4.411, avg loss=4.871, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.4 seconds, train=5.4 seconds, 185408 images, time remaining=6.1 hours
2898: loss=4.761, avg loss=4.860, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 185472 images, time remaining=6.1 hours
2899: loss=4.581, avg loss=4.832, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 185536 images, time remaining=6.1 hours
2900: loss=5.820, avg loss=4.931, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 185600 images, time remaining=6.1 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b2a0000000
2901: loss=6.180, avg loss=5.056, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 185664 images, time remaining=6.1 hours
2902: loss=6.299, avg loss=5.180, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 185728 images, time remaining=6.1 hours
2903: loss=7.074, avg loss=5.369, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 185792 images, time remaining=6.1 hours
2904: loss=5.043, avg loss=5.337, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 185856 images, time remaining=6 hours
2905: loss=5.857, avg loss=5.389, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 185920 images, time remaining=6 hours
2906: loss=4.932, avg loss=5.343, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 185984 images, time remaining=6 hours
2907: loss=5.577, avg loss=5.366, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 186048 images, time remaining=6 hours
2908: loss=5.919, avg loss=5.422, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 186112 images, time remaining=6 hours
2909: loss=6.018, avg loss=5.481, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 186176 images, time remaining=6 hours
2910: loss=5.030, avg loss=5.436, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 186240 images, time remaining=6 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b76a400000
2911: loss=6.227, avg loss=5.515, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 186304 images, time remaining=6 hours
2912: loss=5.191, avg loss=5.483, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 186368 images, time remaining=6 hours
2913: loss=4.777, avg loss=5.412, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 186432 images, time remaining=6 hours
2914: loss=6.016, avg loss=5.473, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 186496 images, time remaining=6 hours
2915: loss=5.648, avg loss=5.490, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 186560 images, time remaining=6 hours
2916: loss=4.703, avg loss=5.411, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 186624 images, time remaining=6 hours
2917: loss=4.603, avg loss=5.331, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 186688 images, time remaining=6 hours
2918: loss=4.879, avg loss=5.285, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 186752 images, time remaining=6 hours
2919: loss=5.159, avg loss=5.273, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 186816 images, time remaining=6 hours
2920: loss=5.341, avg loss=5.280, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 186880 images, time remaining=6 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b76a400000
2921: loss=5.126, avg loss=5.264, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 186944 images, time remaining=6 hours
2922: loss=5.341, avg loss=5.272, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 187008 images, time remaining=6 hours
2923: loss=5.101, avg loss=5.255, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 187072 images, time remaining=6 hours
2924: loss=4.631, avg loss=5.192, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 187136 images, time remaining=6 hours
2925: loss=4.667, avg loss=5.140, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 187200 images, time remaining=6 hours
2926: loss=3.703, avg loss=4.996, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 187264 images, time remaining=6 hours
2927: loss=4.300, avg loss=4.927, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 187328 images, time remaining=6 hours
2928: loss=4.850, avg loss=4.919, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 187392 images, time remaining=6 hours
2929: loss=3.881, avg loss=4.815, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=1.8 seconds, 187456 images, time remaining=6 hours
2930: loss=3.867, avg loss=4.720, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 187520 images, time remaining=6 hours
Resizing, random_coef=1.40, batch=4, 992x768
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2931: loss=4.873, avg loss=4.736, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 187584 images, time remaining=6 hours
2932: loss=5.462, avg loss=4.808, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=3.8 seconds, 187648 images, time remaining=6 hours
2933: loss=4.948, avg loss=4.822, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=3.8 seconds, 187712 images, time remaining=6 hours
2934: loss=4.746, avg loss=4.815, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=3.9 seconds, 187776 images, time remaining=6 hours
2935: loss=6.184, avg loss=4.952, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=3.8 seconds, 187840 images, time remaining=6 hours
2936: loss=4.338, avg loss=4.890, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=3.7 seconds, 187904 images, time remaining=6 hours
2937: loss=4.250, avg loss=4.826, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 187968 images, time remaining=6 hours
2938: loss=4.908, avg loss=4.834, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=3.9 seconds, 188032 images, time remaining=6 hours
2939: loss=4.482, avg loss=4.799, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=3.8 seconds, 188096 images, time remaining=6 hours
2940: loss=4.650, avg loss=4.784, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 188160 images, time remaining=6 hours
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
2941: loss=4.820, avg loss=4.788, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 188224 images, time remaining=6 hours
2942: loss=5.094, avg loss=4.818, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 188288 images, time remaining=6 hours
2943: loss=4.255, avg loss=4.762, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 188352 images, time remaining=6 hours
2944: loss=3.919, avg loss=4.678, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 188416 images, time remaining=6 hours
2945: loss=3.770, avg loss=4.587, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 188480 images, time remaining=6 hours
2946: loss=4.514, avg loss=4.580, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 188544 images, time remaining=6 hours
2947: loss=4.850, avg loss=4.607, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 188608 images, time remaining=6 hours
2948: loss=4.479, avg loss=4.594, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 188672 images, time remaining=6 hours
2949: loss=4.599, avg loss=4.595, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 188736 images, time remaining=6 hours
2950: loss=4.671, avg loss=4.602, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 188800 images, time remaining=6 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b675200000
2951: loss=3.899, avg loss=4.532, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.8 seconds, 188864 images, time remaining=6 hours
2952: loss=3.937, avg loss=4.472, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 188928 images, time remaining=6 hours
2953: loss=4.663, avg loss=4.492, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 188992 images, time remaining=6 hours
2954: loss=4.245, avg loss=4.467, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 189056 images, time remaining=6 hours
2955: loss=4.197, avg loss=4.440, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 189120 images, time remaining=6 hours
2956: loss=4.810, avg loss=4.477, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 189184 images, time remaining=6 hours
2957: loss=5.116, avg loss=4.541, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 189248 images, time remaining=6 hours
2958: loss=4.664, avg loss=4.553, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 189312 images, time remaining=6 hours
2959: loss=4.745, avg loss=4.572, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.1 seconds, train=2.9 seconds, 189376 images, time remaining=6 hours
2960: loss=3.407, avg loss=4.456, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 189440 images, time remaining=6 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b5f1400000
2961: loss=4.715, avg loss=4.482, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 189504 images, time remaining=5.9 hours
2962: loss=4.028, avg loss=4.436, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 189568 images, time remaining=5.9 hours
2963: loss=4.372, avg loss=4.430, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 189632 images, time remaining=5.9 hours
2964: loss=4.341, avg loss=4.421, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 189696 images, time remaining=5.9 hours
2965: loss=3.704, avg loss=4.349, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 189760 images, time remaining=5.9 hours
2966: loss=4.410, avg loss=4.355, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 189824 images, time remaining=5.9 hours
2967: loss=4.244, avg loss=4.344, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 189888 images, time remaining=5.9 hours
2968: loss=4.408, avg loss=4.351, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 189952 images, time remaining=5.9 hours
2969: loss=4.019, avg loss=4.317, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 190016 images, time remaining=5.9 hours
2970: loss=4.606, avg loss=4.346, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 190080 images, time remaining=5.9 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b8abc00000
2971: loss=4.565, avg loss=4.368, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 190144 images, time remaining=5.9 hours
2972: loss=3.659, avg loss=4.297, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 190208 images, time remaining=5.9 hours
2973: loss=3.877, avg loss=4.255, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 190272 images, time remaining=5.9 hours
2974: loss=4.310, avg loss=4.261, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 190336 images, time remaining=5.9 hours
2975: loss=4.020, avg loss=4.237, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 190400 images, time remaining=5.9 hours
2976: loss=5.223, avg loss=4.335, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 190464 images, time remaining=5.9 hours
2977: loss=4.061, avg loss=4.308, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 190528 images, time remaining=5.9 hours
2978: loss=4.078, avg loss=4.285, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 190592 images, time remaining=5.9 hours
2979: loss=4.254, avg loss=4.282, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 190656 images, time remaining=5.9 hours
2980: loss=4.589, avg loss=4.312, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 190720 images, time remaining=5.9 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b607000000
2981: loss=3.998, avg loss=4.281, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 190784 images, time remaining=5.9 hours
2982: loss=4.322, avg loss=4.285, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 190848 images, time remaining=5.9 hours
2983: loss=4.265, avg loss=4.283, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 190912 images, time remaining=5.9 hours
2984: loss=4.142, avg loss=4.269, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 190976 images, time remaining=5.9 hours
2985: loss=3.913, avg loss=4.233, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 191040 images, time remaining=5.9 hours
2986: loss=5.101, avg loss=4.320, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 191104 images, time remaining=5.9 hours
2987: loss=4.029, avg loss=4.291, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 191168 images, time remaining=5.9 hours
2988: loss=4.380, avg loss=4.300, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 191232 images, time remaining=5.9 hours
2989: loss=4.032, avg loss=4.273, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 191296 images, time remaining=5.9 hours
2990: loss=3.605, avg loss=4.206, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 191360 images, time remaining=5.9 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b5fc200000
2991: loss=4.651, avg loss=4.251, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 191424 images, time remaining=5.9 hours
2992: loss=4.240, avg loss=4.250, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 191488 images, time remaining=5.9 hours
2993: loss=4.709, avg loss=4.296, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 191552 images, time remaining=5.9 hours
2994: loss=3.736, avg loss=4.240, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 191616 images, time remaining=5.9 hours
2995: loss=4.362, avg loss=4.252, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 191680 images, time remaining=5.9 hours
2996: loss=4.440, avg loss=4.271, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 191744 images, time remaining=5.9 hours
2997: loss=4.497, avg loss=4.293, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 191808 images, time remaining=5.9 hours
2998: loss=3.933, avg loss=4.257, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 191872 images, time remaining=5.9 hours
2999: loss=3.929, avg loss=4.225, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 191936 images, time remaining=5.9 hours
3000: loss=3.792, avg loss=4.181, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.1 seconds, train=2.3 seconds, 192000 images, time remaining=5.9 hours
Saving weights to /workspace/.cache/splits/combined_3000.weights
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1344x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3001: loss=9.302, avg loss=4.693, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 192064 images, time remaining=5.9 hours
3002: loss=7.439, avg loss=4.968, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=6.1 seconds, 192128 images, time remaining=5.9 hours
3003: loss=5.781, avg loss=5.049, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 192192 images, time remaining=5.9 hours
3004: loss=6.011, avg loss=5.145, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.0 seconds, train=5.9 seconds, 192256 images, time remaining=5.9 hours
3005: loss=5.473, avg loss=5.178, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 192320 images, time remaining=5.9 hours
3006: loss=6.936, avg loss=5.354, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 192384 images, time remaining=5.9 hours
3007: loss=6.053, avg loss=5.424, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 192448 images, time remaining=5.9 hours
3008: loss=6.219, avg loss=5.503, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=2.4 seconds, train=6.0 seconds, 192512 images, time remaining=5.9 hours
3009: loss=5.759, avg loss=5.529, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 192576 images, time remaining=5.9 hours
3010: loss=5.703, avg loss=5.546, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 192640 images, time remaining=5.9 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b298000000
3011: loss=6.221, avg loss=5.614, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 192704 images, time remaining=5.9 hours
3012: loss=5.922, avg loss=5.645, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 192768 images, time remaining=5.9 hours
3013: loss=5.344, avg loss=5.615, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 192832 images, time remaining=5.9 hours
3014: loss=6.036, avg loss=5.657, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 192896 images, time remaining=5.9 hours
3015: loss=4.339, avg loss=5.525, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 192960 images, time remaining=5.9 hours
3016: loss=5.539, avg loss=5.526, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 193024 images, time remaining=5.9 hours
3017: loss=5.302, avg loss=5.504, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 193088 images, time remaining=5.9 hours
3018: loss=5.344, avg loss=5.488, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 193152 images, time remaining=5.9 hours
3019: loss=5.004, avg loss=5.440, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 193216 images, time remaining=5.9 hours
3020: loss=5.062, avg loss=5.402, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 193280 images, time remaining=5.9 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3021: loss=9.595, avg loss=5.821, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.5 seconds, train=5.6 seconds, 193344 images, time remaining=5.9 hours
3022: loss=6.773, avg loss=5.916, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 193408 images, time remaining=5.9 hours
3023: loss=6.368, avg loss=5.961, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 193472 images, time remaining=5.9 hours
3024: loss=5.887, avg loss=5.954, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 193536 images, time remaining=5.9 hours
3025: loss=6.304, avg loss=5.989, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 193600 images, time remaining=5.9 hours
3026: loss=7.267, avg loss=6.117, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.6 seconds, 193664 images, time remaining=5.9 hours
3027: loss=6.033, avg loss=6.108, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.9 seconds, train=5.6 seconds, 193728 images, time remaining=5.9 hours
3028: loss=6.265, avg loss=6.124, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 193792 images, time remaining=5.9 hours
3029: loss=7.440, avg loss=6.256, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 193856 images, time remaining=5.9 hours
3030: loss=5.628, avg loss=6.193, last=85.57%, best=85.57%, next=3030, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 193920 images, time remaining=5.9 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b298000000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=151010, unique_truth_count=57264
rank=0 of ranks=151010rank=100 of ranks=151010rank=200 of ranks=151010rank=300 of ranks=151010rank=400 of ranks=151010rank=500 of ranks=151010rank=600 of ranks=151010rank=700 of ranks=151010rank=800 of ranks=151010rank=900 of ranks=151010rank=1000 of ranks=151010rank=1100 of ranks=151010rank=1200 of ranks=151010rank=1300 of ranks=151010rank=1400 of ranks=151010rank=1500 of ranks=151010rank=1600 of ranks=151010rank=1700 of ranks=151010rank=1800 of ranks=151010rank=1900 of ranks=151010rank=2000 of ranks=151010rank=2100 of ranks=151010rank=2200 of ranks=151010rank=2300 of ranks=151010rank=2400 of ranks=151010rank=2500 of ranks=151010rank=2600 of ranks=151010rank=2700 of ranks=151010rank=2800 of ranks=151010rank=2900 of ranks=151010rank=3000 of ranks=151010rank=3100 of ranks=151010rank=3200 of ranks=151010rank=3300 of ranks=151010rank=3400 of ranks=151010rank=3500 of ranks=151010rank=3600 of ranks=151010rank=3700 of ranks=151010rank=3800 of ranks=151010rank=3900 of ranks=151010rank=4000 of ranks=151010rank=4100 of ranks=151010rank=4200 of ranks=151010rank=4300 of ranks=151010rank=4400 of ranks=151010rank=4500 of ranks=151010rank=4600 of ranks=151010rank=4700 of ranks=151010rank=4800 of ranks=151010rank=4900 of ranks=151010rank=5000 of ranks=151010rank=5100 of ranks=151010rank=5200 of ranks=151010rank=5300 of ranks=151010rank=5400 of ranks=151010rank=5500 of ranks=151010rank=5600 of ranks=151010rank=5700 of ranks=151010rank=5800 of ranks=151010rank=5900 of ranks=151010rank=6000 of ranks=151010rank=6100 of ranks=151010rank=6200 of ranks=151010rank=6300 of ranks=151010rank=6400 of ranks=151010rank=6500 of ranks=151010rank=6600 of ranks=151010rank=6700 of ranks=151010rank=6800 of ranks=151010rank=6900 of ranks=151010rank=7000 of ranks=151010rank=7100 of ranks=151010rank=7200 of ranks=151010rank=7300 of ranks=151010rank=7400 of ranks=151010rank=7500 of ranks=151010rank=7600 of ranks=151010rank=7700 of ranks=151010rank=7800 of ranks=151010rank=7900 of ranks=151010rank=8000 of ranks=151010rank=8100 of ranks=151010rank=8200 of ranks=151010rank=8300 of ranks=151010rank=8400 of ranks=151010rank=8500 of ranks=151010rank=8600 of ranks=151010rank=8700 of ranks=151010rank=8800 of ranks=151010rank=8900 of ranks=151010rank=9000 of ranks=151010rank=9100 of ranks=151010rank=9200 of ranks=151010rank=9300 of ranks=151010rank=9400 of ranks=151010rank=9500 of ranks=151010rank=9600 of ranks=151010rank=9700 of ranks=151010rank=9800 of ranks=151010rank=9900 of ranks=151010rank=10000 of ranks=151010rank=10100 of ranks=151010rank=10200 of ranks=151010rank=10300 of ranks=151010rank=10400 of ranks=151010rank=10500 of ranks=151010rank=10600 of ranks=151010rank=10700 of ranks=151010rank=10800 of ranks=151010rank=10900 of ranks=151010rank=11000 of ranks=151010rank=11100 of ranks=151010rank=11200 of ranks=151010rank=11300 of ranks=151010rank=11400 of ranks=151010rank=11500 of ranks=151010rank=11600 of ranks=151010rank=11700 of ranks=151010rank=11800 of ranks=151010rank=11900 of ranks=151010rank=12000 of ranks=151010rank=12100 of ranks=151010rank=12200 of ranks=151010rank=12300 of ranks=151010rank=12400 of ranks=151010rank=12500 of ranks=151010rank=12600 of ranks=151010rank=12700 of ranks=151010rank=12800 of ranks=151010rank=12900 of ranks=151010rank=13000 of ranks=151010rank=13100 of ranks=151010rank=13200 of ranks=151010rank=13300 of ranks=151010rank=13400 of ranks=151010rank=13500 of ranks=151010rank=13600 of ranks=151010rank=13700 of ranks=151010rank=13800 of ranks=151010rank=13900 of ranks=151010rank=14000 of ranks=151010rank=14100 of ranks=151010rank=14200 of ranks=151010rank=14300 of ranks=151010rank=14400 of ranks=151010rank=14500 of ranks=151010rank=14600 of ranks=151010rank=14700 of ranks=151010rank=14800 of ranks=151010rank=14900 of ranks=151010rank=15000 of ranks=151010rank=15100 of ranks=151010rank=15200 of ranks=151010rank=15300 of ranks=151010rank=15400 of ranks=151010rank=15500 of ranks=151010rank=15600 of ranks=151010rank=15700 of ranks=151010rank=15800 of ranks=151010rank=15900 of ranks=151010rank=16000 of ranks=151010rank=16100 of ranks=151010rank=16200 of ranks=151010rank=16300 of ranks=151010rank=16400 of ranks=151010rank=16500 of ranks=151010rank=16600 of ranks=151010rank=16700 of ranks=151010rank=16800 of ranks=151010rank=16900 of ranks=151010rank=17000 of ranks=151010rank=17100 of ranks=151010rank=17200 of ranks=151010rank=17300 of ranks=151010rank=17400 of ranks=151010rank=17500 of ranks=151010rank=17600 of ranks=151010rank=17700 of ranks=151010rank=17800 of ranks=151010rank=17900 of ranks=151010rank=18000 of ranks=151010rank=18100 of ranks=151010rank=18200 of ranks=151010rank=18300 of ranks=151010rank=18400 of ranks=151010rank=18500 of ranks=151010rank=18600 of ranks=151010rank=18700 of ranks=151010rank=18800 of ranks=151010rank=18900 of ranks=151010rank=19000 of ranks=151010rank=19100 of ranks=151010rank=19200 of ranks=151010rank=19300 of ranks=151010rank=19400 of ranks=151010rank=19500 of ranks=151010rank=19600 of ranks=151010rank=19700 of ranks=151010rank=19800 of ranks=151010rank=19900 of ranks=151010rank=20000 of ranks=151010rank=20100 of ranks=151010rank=20200 of ranks=151010rank=20300 of ranks=151010rank=20400 of ranks=151010rank=20500 of ranks=151010rank=20600 of ranks=151010rank=20700 of ranks=151010rank=20800 of ranks=151010rank=20900 of ranks=151010rank=21000 of ranks=151010rank=21100 of ranks=151010rank=21200 of ranks=151010rank=21300 of ranks=151010rank=21400 of ranks=151010rank=21500 of ranks=151010rank=21600 of ranks=151010rank=21700 of ranks=151010rank=21800 of ranks=151010rank=21900 of ranks=151010rank=22000 of ranks=151010rank=22100 of ranks=151010rank=22200 of ranks=151010rank=22300 of ranks=151010rank=22400 of ranks=151010rank=22500 of ranks=151010rank=22600 of ranks=151010rank=22700 of ranks=151010rank=22800 of ranks=151010rank=22900 of ranks=151010rank=23000 of ranks=151010rank=23100 of ranks=151010rank=23200 of ranks=151010rank=23300 of ranks=151010rank=23400 of ranks=151010rank=23500 of ranks=151010rank=23600 of ranks=151010rank=23700 of ranks=151010rank=23800 of ranks=151010rank=23900 of ranks=151010rank=24000 of ranks=151010rank=24100 of ranks=151010rank=24200 of ranks=151010rank=24300 of ranks=151010rank=24400 of ranks=151010rank=24500 of ranks=151010rank=24600 of ranks=151010rank=24700 of ranks=151010rank=24800 of ranks=151010rank=24900 of ranks=151010rank=25000 of ranks=151010rank=25100 of ranks=151010rank=25200 of ranks=151010rank=25300 of ranks=151010rank=25400 of ranks=151010rank=25500 of ranks=151010rank=25600 of ranks=151010rank=25700 of ranks=151010rank=25800 of ranks=151010rank=25900 of ranks=151010rank=26000 of ranks=151010rank=26100 of ranks=151010rank=26200 of ranks=151010rank=26300 of ranks=151010rank=26400 of ranks=151010rank=26500 of ranks=151010rank=26600 of ranks=151010rank=26700 of ranks=151010rank=26800 of ranks=151010rank=26900 of ranks=151010rank=27000 of ranks=151010rank=27100 of ranks=151010rank=27200 of ranks=151010rank=27300 of ranks=151010rank=27400 of ranks=151010rank=27500 of ranks=151010rank=27600 of ranks=151010rank=27700 of ranks=151010rank=27800 of ranks=151010rank=27900 of ranks=151010rank=28000 of ranks=151010rank=28100 of ranks=151010rank=28200 of ranks=151010rank=28300 of ranks=151010rank=28400 of ranks=151010rank=28500 of ranks=151010rank=28600 of ranks=151010rank=28700 of ranks=151010rank=28800 of ranks=151010rank=28900 of ranks=151010rank=29000 of ranks=151010rank=29100 of ranks=151010rank=29200 of ranks=151010rank=29300 of ranks=151010rank=29400 of ranks=151010rank=29500 of ranks=151010rank=29600 of ranks=151010rank=29700 of ranks=151010rank=29800 of ranks=151010rank=29900 of ranks=151010rank=30000 of ranks=151010rank=30100 of ranks=151010rank=30200 of ranks=151010rank=30300 of ranks=151010rank=30400 of ranks=151010rank=30500 of ranks=151010rank=30600 of ranks=151010rank=30700 of ranks=151010rank=30800 of ranks=151010rank=30900 of ranks=151010rank=31000 of ranks=151010rank=31100 of ranks=151010rank=31200 of ranks=151010rank=31300 of ranks=151010rank=31400 of ranks=151010rank=31500 of ranks=151010rank=31600 of ranks=151010rank=31700 of ranks=151010rank=31800 of ranks=151010rank=31900 of ranks=151010rank=32000 of ranks=151010rank=32100 of ranks=151010rank=32200 of ranks=151010rank=32300 of ranks=151010rank=32400 of ranks=151010rank=32500 of ranks=151010rank=32600 of ranks=151010rank=32700 of ranks=151010rank=32800 of ranks=151010rank=32900 of ranks=151010rank=33000 of ranks=151010rank=33100 of ranks=151010rank=33200 of ranks=151010rank=33300 of ranks=151010rank=33400 of ranks=151010rank=33500 of ranks=151010rank=33600 of ranks=151010rank=33700 of ranks=151010rank=33800 of ranks=151010rank=33900 of ranks=151010rank=34000 of ranks=151010rank=34100 of ranks=151010rank=34200 of ranks=151010rank=34300 of ranks=151010rank=34400 of ranks=151010rank=34500 of ranks=151010rank=34600 of ranks=151010rank=34700 of ranks=151010rank=34800 of ranks=151010rank=34900 of ranks=151010rank=35000 of ranks=151010rank=35100 of ranks=151010rank=35200 of ranks=151010rank=35300 of ranks=151010rank=35400 of ranks=151010rank=35500 of ranks=151010rank=35600 of ranks=151010rank=35700 of ranks=151010rank=35800 of ranks=151010rank=35900 of ranks=151010rank=36000 of ranks=151010rank=36100 of ranks=151010rank=36200 of ranks=151010rank=36300 of ranks=151010rank=36400 of ranks=151010rank=36500 of ranks=151010rank=36600 of ranks=151010rank=36700 of ranks=151010rank=36800 of ranks=151010rank=36900 of ranks=151010rank=37000 of ranks=151010rank=37100 of ranks=151010rank=37200 of ranks=151010rank=37300 of ranks=151010rank=37400 of ranks=151010rank=37500 of ranks=151010rank=37600 of ranks=151010rank=37700 of ranks=151010rank=37800 of ranks=151010rank=37900 of ranks=151010rank=38000 of ranks=151010rank=38100 of ranks=151010rank=38200 of ranks=151010rank=38300 of ranks=151010rank=38400 of ranks=151010rank=38500 of ranks=151010rank=38600 of ranks=151010rank=38700 of ranks=151010rank=38800 of ranks=151010rank=38900 of ranks=151010rank=39000 of ranks=151010rank=39100 of ranks=151010rank=39200 of ranks=151010rank=39300 of ranks=151010rank=39400 of ranks=151010rank=39500 of ranks=151010rank=39600 of ranks=151010rank=39700 of ranks=151010rank=39800 of ranks=151010rank=39900 of ranks=151010rank=40000 of ranks=151010rank=40100 of ranks=151010rank=40200 of ranks=151010rank=40300 of ranks=151010rank=40400 of ranks=151010rank=40500 of ranks=151010rank=40600 of ranks=151010rank=40700 of ranks=151010rank=40800 of ranks=151010rank=40900 of ranks=151010rank=41000 of ranks=151010rank=41100 of ranks=151010rank=41200 of ranks=151010rank=41300 of ranks=151010rank=41400 of ranks=151010rank=41500 of ranks=151010rank=41600 of ranks=151010rank=41700 of ranks=151010rank=41800 of ranks=151010rank=41900 of ranks=151010rank=42000 of ranks=151010rank=42100 of ranks=151010rank=42200 of ranks=151010rank=42300 of ranks=151010rank=42400 of ranks=151010rank=42500 of ranks=151010rank=42600 of ranks=151010rank=42700 of ranks=151010rank=42800 of ranks=151010rank=42900 of ranks=151010rank=43000 of ranks=151010rank=43100 of ranks=151010rank=43200 of ranks=151010rank=43300 of ranks=151010rank=43400 of ranks=151010rank=43500 of ranks=151010rank=43600 of ranks=151010rank=43700 of ranks=151010rank=43800 of ranks=151010rank=43900 of ranks=151010rank=44000 of ranks=151010rank=44100 of ranks=151010rank=44200 of ranks=151010rank=44300 of ranks=151010rank=44400 of ranks=151010rank=44500 of ranks=151010rank=44600 of ranks=151010rank=44700 of ranks=151010rank=44800 of ranks=151010rank=44900 of ranks=151010rank=45000 of ranks=151010rank=45100 of ranks=151010rank=45200 of ranks=151010rank=45300 of ranks=151010rank=45400 of ranks=151010rank=45500 of ranks=151010rank=45600 of ranks=151010rank=45700 of ranks=151010rank=45800 of ranks=151010rank=45900 of ranks=151010rank=46000 of ranks=151010rank=46100 of ranks=151010rank=46200 of ranks=151010rank=46300 of ranks=151010rank=46400 of ranks=151010rank=46500 of ranks=151010rank=46600 of ranks=151010rank=46700 of ranks=151010rank=46800 of ranks=151010rank=46900 of ranks=151010rank=47000 of ranks=151010rank=47100 of ranks=151010rank=47200 of ranks=151010rank=47300 of ranks=151010rank=47400 of ranks=151010rank=47500 of ranks=151010rank=47600 of ranks=151010rank=47700 of ranks=151010rank=47800 of ranks=151010rank=47900 of ranks=151010rank=48000 of ranks=151010rank=48100 of ranks=151010rank=48200 of ranks=151010rank=48300 of ranks=151010rank=48400 of ranks=151010rank=48500 of ranks=151010rank=48600 of ranks=151010rank=48700 of ranks=151010rank=48800 of ranks=151010rank=48900 of ranks=151010rank=49000 of ranks=151010rank=49100 of ranks=151010rank=49200 of ranks=151010rank=49300 of ranks=151010rank=49400 of ranks=151010rank=49500 of ranks=151010rank=49600 of ranks=151010rank=49700 of ranks=151010rank=49800 of ranks=151010rank=49900 of ranks=151010rank=50000 of ranks=151010rank=50100 of ranks=151010rank=50200 of ranks=151010rank=50300 of ranks=151010rank=50400 of ranks=151010rank=50500 of ranks=151010rank=50600 of ranks=151010rank=50700 of ranks=151010rank=50800 of ranks=151010rank=50900 of ranks=151010rank=51000 of ranks=151010rank=51100 of ranks=151010rank=51200 of ranks=151010rank=51300 of ranks=151010rank=51400 of ranks=151010rank=51500 of ranks=151010rank=51600 of ranks=151010rank=51700 of ranks=151010rank=51800 of ranks=151010rank=51900 of ranks=151010rank=52000 of ranks=151010rank=52100 of ranks=151010rank=52200 of ranks=151010rank=52300 of ranks=151010rank=52400 of ranks=151010rank=52500 of ranks=151010rank=52600 of ranks=151010rank=52700 of ranks=151010rank=52800 of ranks=151010rank=52900 of ranks=151010rank=53000 of ranks=151010rank=53100 of ranks=151010rank=53200 of ranks=151010rank=53300 of ranks=151010rank=53400 of ranks=151010rank=53500 of ranks=151010rank=53600 of ranks=151010rank=53700 of ranks=151010rank=53800 of ranks=151010rank=53900 of ranks=151010rank=54000 of ranks=151010rank=54100 of ranks=151010rank=54200 of ranks=151010rank=54300 of ranks=151010rank=54400 of ranks=151010rank=54500 of ranks=151010rank=54600 of ranks=151010rank=54700 of ranks=151010rank=54800 of ranks=151010rank=54900 of ranks=151010rank=55000 of ranks=151010rank=55100 of ranks=151010rank=55200 of ranks=151010rank=55300 of ranks=151010rank=55400 of ranks=151010rank=55500 of ranks=151010rank=55600 of ranks=151010rank=55700 of ranks=151010rank=55800 of ranks=151010rank=55900 of ranks=151010rank=56000 of ranks=151010rank=56100 of ranks=151010rank=56200 of ranks=151010rank=56300 of ranks=151010rank=56400 of ranks=151010rank=56500 of ranks=151010rank=56600 of ranks=151010rank=56700 of ranks=151010rank=56800 of ranks=151010rank=56900 of ranks=151010rank=57000 of ranks=151010rank=57100 of ranks=151010rank=57200 of ranks=151010rank=57300 of ranks=151010rank=57400 of ranks=151010rank=57500 of ranks=151010rank=57600 of ranks=151010rank=57700 of ranks=151010rank=57800 of ranks=151010rank=57900 of ranks=151010rank=58000 of ranks=151010rank=58100 of ranks=151010rank=58200 of ranks=151010rank=58300 of ranks=151010rank=58400 of ranks=151010rank=58500 of ranks=151010rank=58600 of ranks=151010rank=58700 of ranks=151010rank=58800 of ranks=151010rank=58900 of ranks=151010rank=59000 of ranks=151010rank=59100 of ranks=151010rank=59200 of ranks=151010rank=59300 of ranks=151010rank=59400 of ranks=151010rank=59500 of ranks=151010rank=59600 of ranks=151010rank=59700 of ranks=151010rank=59800 of ranks=151010rank=59900 of ranks=151010rank=60000 of ranks=151010rank=60100 of ranks=151010rank=60200 of ranks=151010rank=60300 of ranks=151010rank=60400 of ranks=151010rank=60500 of ranks=151010rank=60600 of ranks=151010rank=60700 of ranks=151010rank=60800 of ranks=151010rank=60900 of ranks=151010rank=61000 of ranks=151010rank=61100 of ranks=151010rank=61200 of ranks=151010rank=61300 of ranks=151010rank=61400 of ranks=151010rank=61500 of ranks=151010rank=61600 of ranks=151010rank=61700 of ranks=151010rank=61800 of ranks=151010rank=61900 of ranks=151010rank=62000 of ranks=151010rank=62100 of ranks=151010rank=62200 of ranks=151010rank=62300 of ranks=151010rank=62400 of ranks=151010rank=62500 of ranks=151010rank=62600 of ranks=151010rank=62700 of ranks=151010rank=62800 of ranks=151010rank=62900 of ranks=151010rank=63000 of ranks=151010rank=63100 of ranks=151010rank=63200 of ranks=151010rank=63300 of ranks=151010rank=63400 of ranks=151010rank=63500 of ranks=151010rank=63600 of ranks=151010rank=63700 of ranks=151010rank=63800 of ranks=151010rank=63900 of ranks=151010rank=64000 of ranks=151010rank=64100 of ranks=151010rank=64200 of ranks=151010rank=64300 of ranks=151010rank=64400 of ranks=151010rank=64500 of ranks=151010rank=64600 of ranks=151010rank=64700 of ranks=151010rank=64800 of ranks=151010rank=64900 of ranks=151010rank=65000 of ranks=151010rank=65100 of ranks=151010rank=65200 of ranks=151010rank=65300 of ranks=151010rank=65400 of ranks=151010rank=65500 of ranks=151010rank=65600 of ranks=151010rank=65700 of ranks=151010rank=65800 of ranks=151010rank=65900 of ranks=151010rank=66000 of ranks=151010rank=66100 of ranks=151010rank=66200 of ranks=151010rank=66300 of ranks=151010rank=66400 of ranks=151010rank=66500 of ranks=151010rank=66600 of ranks=151010rank=66700 of ranks=151010rank=66800 of ranks=151010rank=66900 of ranks=151010rank=67000 of ranks=151010rank=67100 of ranks=151010rank=67200 of ranks=151010rank=67300 of ranks=151010rank=67400 of ranks=151010rank=67500 of ranks=151010rank=67600 of ranks=151010rank=67700 of ranks=151010rank=67800 of ranks=151010rank=67900 of ranks=151010rank=68000 of ranks=151010rank=68100 of ranks=151010rank=68200 of ranks=151010rank=68300 of ranks=151010rank=68400 of ranks=151010rank=68500 of ranks=151010rank=68600 of ranks=151010rank=68700 of ranks=151010rank=68800 of ranks=151010rank=68900 of ranks=151010rank=69000 of ranks=151010rank=69100 of ranks=151010rank=69200 of ranks=151010rank=69300 of ranks=151010rank=69400 of ranks=151010rank=69500 of ranks=151010rank=69600 of ranks=151010rank=69700 of ranks=151010rank=69800 of ranks=151010rank=69900 of ranks=151010rank=70000 of ranks=151010rank=70100 of ranks=151010rank=70200 of ranks=151010rank=70300 of ranks=151010rank=70400 of ranks=151010rank=70500 of ranks=151010rank=70600 of ranks=151010rank=70700 of ranks=151010rank=70800 of ranks=151010rank=70900 of ranks=151010rank=71000 of ranks=151010rank=71100 of ranks=151010rank=71200 of ranks=151010rank=71300 of ranks=151010rank=71400 of ranks=151010rank=71500 of ranks=151010rank=71600 of ranks=151010rank=71700 of ranks=151010rank=71800 of ranks=151010rank=71900 of ranks=151010rank=72000 of ranks=151010rank=72100 of ranks=151010rank=72200 of ranks=151010rank=72300 of ranks=151010rank=72400 of ranks=151010rank=72500 of ranks=151010rank=72600 of ranks=151010rank=72700 of ranks=151010rank=72800 of ranks=151010rank=72900 of ranks=151010rank=73000 of ranks=151010rank=73100 of ranks=151010rank=73200 of ranks=151010rank=73300 of ranks=151010rank=73400 of ranks=151010rank=73500 of ranks=151010rank=73600 of ranks=151010rank=73700 of ranks=151010rank=73800 of ranks=151010rank=73900 of ranks=151010rank=74000 of ranks=151010rank=74100 of ranks=151010rank=74200 of ranks=151010rank=74300 of ranks=151010rank=74400 of ranks=151010rank=74500 of ranks=151010rank=74600 of ranks=151010rank=74700 of ranks=151010rank=74800 of ranks=151010rank=74900 of ranks=151010rank=75000 of ranks=151010rank=75100 of ranks=151010rank=75200 of ranks=151010rank=75300 of ranks=151010rank=75400 of ranks=151010rank=75500 of ranks=151010rank=75600 of ranks=151010rank=75700 of ranks=151010rank=75800 of ranks=151010rank=75900 of ranks=151010rank=76000 of ranks=151010rank=76100 of ranks=151010rank=76200 of ranks=151010rank=76300 of ranks=151010rank=76400 of ranks=151010rank=76500 of ranks=151010rank=76600 of ranks=151010rank=76700 of ranks=151010rank=76800 of ranks=151010rank=76900 of ranks=151010rank=77000 of ranks=151010rank=77100 of ranks=151010rank=77200 of ranks=151010rank=77300 of ranks=151010rank=77400 of ranks=151010rank=77500 of ranks=151010rank=77600 of ranks=151010rank=77700 of ranks=151010rank=77800 of ranks=151010rank=77900 of ranks=151010rank=78000 of ranks=151010rank=78100 of ranks=151010rank=78200 of ranks=151010rank=78300 of ranks=151010rank=78400 of ranks=151010rank=78500 of ranks=151010rank=78600 of ranks=151010rank=78700 of ranks=151010rank=78800 of ranks=151010rank=78900 of ranks=151010rank=79000 of ranks=151010rank=79100 of ranks=151010rank=79200 of ranks=151010rank=79300 of ranks=151010rank=79400 of ranks=151010rank=79500 of ranks=151010rank=79600 of ranks=151010rank=79700 of ranks=151010rank=79800 of ranks=151010rank=79900 of ranks=151010rank=80000 of ranks=151010rank=80100 of ranks=151010rank=80200 of ranks=151010rank=80300 of ranks=151010rank=80400 of ranks=151010rank=80500 of ranks=151010rank=80600 of ranks=151010rank=80700 of ranks=151010rank=80800 of ranks=151010rank=80900 of ranks=151010rank=81000 of ranks=151010rank=81100 of ranks=151010rank=81200 of ranks=151010rank=81300 of ranks=151010rank=81400 of ranks=151010rank=81500 of ranks=151010rank=81600 of ranks=151010rank=81700 of ranks=151010rank=81800 of ranks=151010rank=81900 of ranks=151010rank=82000 of ranks=151010rank=82100 of ranks=151010rank=82200 of ranks=151010rank=82300 of ranks=151010rank=82400 of ranks=151010rank=82500 of ranks=151010rank=82600 of ranks=151010rank=82700 of ranks=151010rank=82800 of ranks=151010rank=82900 of ranks=151010rank=83000 of ranks=151010rank=83100 of ranks=151010rank=83200 of ranks=151010rank=83300 of ranks=151010rank=83400 of ranks=151010rank=83500 of ranks=151010rank=83600 of ranks=151010rank=83700 of ranks=151010rank=83800 of ranks=151010rank=83900 of ranks=151010rank=84000 of ranks=151010rank=84100 of ranks=151010rank=84200 of ranks=151010rank=84300 of ranks=151010rank=84400 of ranks=151010rank=84500 of ranks=151010rank=84600 of ranks=151010rank=84700 of ranks=151010rank=84800 of ranks=151010rank=84900 of ranks=151010rank=85000 of ranks=151010rank=85100 of ranks=151010rank=85200 of ranks=151010rank=85300 of ranks=151010rank=85400 of ranks=151010rank=85500 of ranks=151010rank=85600 of ranks=151010rank=85700 of ranks=151010rank=85800 of ranks=151010rank=85900 of ranks=151010rank=86000 of ranks=151010rank=86100 of ranks=151010rank=86200 of ranks=151010rank=86300 of ranks=151010rank=86400 of ranks=151010rank=86500 of ranks=151010rank=86600 of ranks=151010rank=86700 of ranks=151010rank=86800 of ranks=151010rank=86900 of ranks=151010rank=87000 of ranks=151010rank=87100 of ranks=151010rank=87200 of ranks=151010rank=87300 of ranks=151010rank=87400 of ranks=151010rank=87500 of ranks=151010rank=87600 of ranks=151010rank=87700 of ranks=151010rank=87800 of ranks=151010rank=87900 of ranks=151010rank=88000 of ranks=151010rank=88100 of ranks=151010rank=88200 of ranks=151010rank=88300 of ranks=151010rank=88400 of ranks=151010rank=88500 of ranks=151010rank=88600 of ranks=151010rank=88700 of ranks=151010rank=88800 of ranks=151010rank=88900 of ranks=151010rank=89000 of ranks=151010rank=89100 of ranks=151010rank=89200 of ranks=151010rank=89300 of ranks=151010rank=89400 of ranks=151010rank=89500 of ranks=151010rank=89600 of ranks=151010rank=89700 of ranks=151010rank=89800 of ranks=151010rank=89900 of ranks=151010rank=90000 of ranks=151010rank=90100 of ranks=151010rank=90200 of ranks=151010rank=90300 of ranks=151010rank=90400 of ranks=151010rank=90500 of ranks=151010rank=90600 of ranks=151010rank=90700 of ranks=151010rank=90800 of ranks=151010rank=90900 of ranks=151010rank=91000 of ranks=151010rank=91100 of ranks=151010rank=91200 of ranks=151010rank=91300 of ranks=151010rank=91400 of ranks=151010rank=91500 of ranks=151010rank=91600 of ranks=151010rank=91700 of ranks=151010rank=91800 of ranks=151010rank=91900 of ranks=151010rank=92000 of ranks=151010rank=92100 of ranks=151010rank=92200 of ranks=151010rank=92300 of ranks=151010rank=92400 of ranks=151010rank=92500 of ranks=151010rank=92600 of ranks=151010rank=92700 of ranks=151010rank=92800 of ranks=151010rank=92900 of ranks=151010rank=93000 of ranks=151010rank=93100 of ranks=151010rank=93200 of ranks=151010rank=93300 of ranks=151010rank=93400 of ranks=151010rank=93500 of ranks=151010rank=93600 of ranks=151010rank=93700 of ranks=151010rank=93800 of ranks=151010rank=93900 of ranks=151010rank=94000 of ranks=151010rank=94100 of ranks=151010rank=94200 of ranks=151010rank=94300 of ranks=151010rank=94400 of ranks=151010rank=94500 of ranks=151010rank=94600 of ranks=151010rank=94700 of ranks=151010rank=94800 of ranks=151010rank=94900 of ranks=151010rank=95000 of ranks=151010rank=95100 of ranks=151010rank=95200 of ranks=151010rank=95300 of ranks=151010rank=95400 of ranks=151010rank=95500 of ranks=151010rank=95600 of ranks=151010rank=95700 of ranks=151010rank=95800 of ranks=151010rank=95900 of ranks=151010rank=96000 of ranks=151010rank=96100 of ranks=151010rank=96200 of ranks=151010rank=96300 of ranks=151010rank=96400 of ranks=151010rank=96500 of ranks=151010rank=96600 of ranks=151010rank=96700 of ranks=151010rank=96800 of ranks=151010rank=96900 of ranks=151010rank=97000 of ranks=151010rank=97100 of ranks=151010rank=97200 of ranks=151010rank=97300 of ranks=151010rank=97400 of ranks=151010rank=97500 of ranks=151010rank=97600 of ranks=151010rank=97700 of ranks=151010rank=97800 of ranks=151010rank=97900 of ranks=151010rank=98000 of ranks=151010rank=98100 of ranks=151010rank=98200 of ranks=151010rank=98300 of ranks=151010rank=98400 of ranks=151010rank=98500 of ranks=151010rank=98600 of ranks=151010rank=98700 of ranks=151010rank=98800 of ranks=151010rank=98900 of ranks=151010rank=99000 of ranks=151010rank=99100 of ranks=151010rank=99200 of ranks=151010rank=99300 of ranks=151010rank=99400 of ranks=151010rank=99500 of ranks=151010rank=99600 of ranks=151010rank=99700 of ranks=151010rank=99800 of ranks=151010rank=99900 of ranks=151010rank=100000 of ranks=151010rank=100100 of ranks=151010rank=100200 of ranks=151010rank=100300 of ranks=151010rank=100400 of ranks=151010rank=100500 of ranks=151010rank=100600 of ranks=151010rank=100700 of ranks=151010rank=100800 of ranks=151010rank=100900 of ranks=151010rank=101000 of ranks=151010rank=101100 of ranks=151010rank=101200 of ranks=151010rank=101300 of ranks=151010rank=101400 of ranks=151010rank=101500 of ranks=151010rank=101600 of ranks=151010rank=101700 of ranks=151010rank=101800 of ranks=151010rank=101900 of ranks=151010rank=102000 of ranks=151010rank=102100 of ranks=151010rank=102200 of ranks=151010rank=102300 of ranks=151010rank=102400 of ranks=151010rank=102500 of ranks=151010rank=102600 of ranks=151010rank=102700 of ranks=151010rank=102800 of ranks=151010rank=102900 of ranks=151010rank=103000 of ranks=151010rank=103100 of ranks=151010rank=103200 of ranks=151010rank=103300 of ranks=151010rank=103400 of ranks=151010rank=103500 of ranks=151010rank=103600 of ranks=151010rank=103700 of ranks=151010rank=103800 of ranks=151010rank=103900 of ranks=151010rank=104000 of ranks=151010rank=104100 of ranks=151010rank=104200 of ranks=151010rank=104300 of ranks=151010rank=104400 of ranks=151010rank=104500 of ranks=151010rank=104600 of ranks=151010rank=104700 of ranks=151010rank=104800 of ranks=151010rank=104900 of ranks=151010rank=105000 of ranks=151010rank=105100 of ranks=151010rank=105200 of ranks=151010rank=105300 of ranks=151010rank=105400 of ranks=151010rank=105500 of ranks=151010rank=105600 of ranks=151010rank=105700 of ranks=151010rank=105800 of ranks=151010rank=105900 of ranks=151010rank=106000 of ranks=151010rank=106100 of ranks=151010rank=106200 of ranks=151010rank=106300 of ranks=151010rank=106400 of ranks=151010rank=106500 of ranks=151010rank=106600 of ranks=151010rank=106700 of ranks=151010rank=106800 of ranks=151010rank=106900 of ranks=151010rank=107000 of ranks=151010rank=107100 of ranks=151010rank=107200 of ranks=151010rank=107300 of ranks=151010rank=107400 of ranks=151010rank=107500 of ranks=151010rank=107600 of ranks=151010rank=107700 of ranks=151010rank=107800 of ranks=151010rank=107900 of ranks=151010rank=108000 of ranks=151010rank=108100 of ranks=151010rank=108200 of ranks=151010rank=108300 of ranks=151010rank=108400 of ranks=151010rank=108500 of ranks=151010rank=108600 of ranks=151010rank=108700 of ranks=151010rank=108800 of ranks=151010rank=108900 of ranks=151010rank=109000 of ranks=151010rank=109100 of ranks=151010rank=109200 of ranks=151010rank=109300 of ranks=151010rank=109400 of ranks=151010rank=109500 of ranks=151010rank=109600 of ranks=151010rank=109700 of ranks=151010rank=109800 of ranks=151010rank=109900 of ranks=151010rank=110000 of ranks=151010rank=110100 of ranks=151010rank=110200 of ranks=151010rank=110300 of ranks=151010rank=110400 of ranks=151010rank=110500 of ranks=151010rank=110600 of ranks=151010rank=110700 of ranks=151010rank=110800 of ranks=151010rank=110900 of ranks=151010rank=111000 of ranks=151010rank=111100 of ranks=151010rank=111200 of ranks=151010rank=111300 of ranks=151010rank=111400 of ranks=151010rank=111500 of ranks=151010rank=111600 of ranks=151010rank=111700 of ranks=151010rank=111800 of ranks=151010rank=111900 of ranks=151010rank=112000 of ranks=151010rank=112100 of ranks=151010rank=112200 of ranks=151010rank=112300 of ranks=151010rank=112400 of ranks=151010rank=112500 of ranks=151010rank=112600 of ranks=151010rank=112700 of ranks=151010rank=112800 of ranks=151010rank=112900 of ranks=151010rank=113000 of ranks=151010rank=113100 of ranks=151010rank=113200 of ranks=151010rank=113300 of ranks=151010rank=113400 of ranks=151010rank=113500 of ranks=151010rank=113600 of ranks=151010rank=113700 of ranks=151010rank=113800 of ranks=151010rank=113900 of ranks=151010rank=114000 of ranks=151010rank=114100 of ranks=151010rank=114200 of ranks=151010rank=114300 of ranks=151010rank=114400 of ranks=151010rank=114500 of ranks=151010rank=114600 of ranks=151010rank=114700 of ranks=151010rank=114800 of ranks=151010rank=114900 of ranks=151010rank=115000 of ranks=151010rank=115100 of ranks=151010rank=115200 of ranks=151010rank=115300 of ranks=151010rank=115400 of ranks=151010rank=115500 of ranks=151010rank=115600 of ranks=151010rank=115700 of ranks=151010rank=115800 of ranks=151010rank=115900 of ranks=151010rank=116000 of ranks=151010rank=116100 of ranks=151010rank=116200 of ranks=151010rank=116300 of ranks=151010rank=116400 of ranks=151010rank=116500 of ranks=151010rank=116600 of ranks=151010rank=116700 of ranks=151010rank=116800 of ranks=151010rank=116900 of ranks=151010rank=117000 of ranks=151010rank=117100 of ranks=151010rank=117200 of ranks=151010rank=117300 of ranks=151010rank=117400 of ranks=151010rank=117500 of ranks=151010rank=117600 of ranks=151010rank=117700 of ranks=151010rank=117800 of ranks=151010rank=117900 of ranks=151010rank=118000 of ranks=151010rank=118100 of ranks=151010rank=118200 of ranks=151010rank=118300 of ranks=151010rank=118400 of ranks=151010rank=118500 of ranks=151010rank=118600 of ranks=151010rank=118700 of ranks=151010rank=118800 of ranks=151010rank=118900 of ranks=151010rank=119000 of ranks=151010rank=119100 of ranks=151010rank=119200 of ranks=151010rank=119300 of ranks=151010rank=119400 of ranks=151010rank=119500 of ranks=151010rank=119600 of ranks=151010rank=119700 of ranks=151010rank=119800 of ranks=151010rank=119900 of ranks=151010rank=120000 of ranks=151010rank=120100 of ranks=151010rank=120200 of ranks=151010rank=120300 of ranks=151010rank=120400 of ranks=151010rank=120500 of ranks=151010rank=120600 of ranks=151010rank=120700 of ranks=151010rank=120800 of ranks=151010rank=120900 of ranks=151010rank=121000 of ranks=151010rank=121100 of ranks=151010rank=121200 of ranks=151010rank=121300 of ranks=151010rank=121400 of ranks=151010rank=121500 of ranks=151010rank=121600 of ranks=151010rank=121700 of ranks=151010rank=121800 of ranks=151010rank=121900 of ranks=151010rank=122000 of ranks=151010rank=122100 of ranks=151010rank=122200 of ranks=151010rank=122300 of ranks=151010rank=122400 of ranks=151010rank=122500 of ranks=151010rank=122600 of ranks=151010rank=122700 of ranks=151010rank=122800 of ranks=151010rank=122900 of ranks=151010rank=123000 of ranks=151010rank=123100 of ranks=151010rank=123200 of ranks=151010rank=123300 of ranks=151010rank=123400 of ranks=151010rank=123500 of ranks=151010rank=123600 of ranks=151010rank=123700 of ranks=151010rank=123800 of ranks=151010rank=123900 of ranks=151010rank=124000 of ranks=151010rank=124100 of ranks=151010rank=124200 of ranks=151010rank=124300 of ranks=151010rank=124400 of ranks=151010rank=124500 of ranks=151010rank=124600 of ranks=151010rank=124700 of ranks=151010rank=124800 of ranks=151010rank=124900 of ranks=151010rank=125000 of ranks=151010rank=125100 of ranks=151010rank=125200 of ranks=151010rank=125300 of ranks=151010rank=125400 of ranks=151010rank=125500 of ranks=151010rank=125600 of ranks=151010rank=125700 of ranks=151010rank=125800 of ranks=151010rank=125900 of ranks=151010rank=126000 of ranks=151010rank=126100 of ranks=151010rank=126200 of ranks=151010rank=126300 of ranks=151010rank=126400 of ranks=151010rank=126500 of ranks=151010rank=126600 of ranks=151010rank=126700 of ranks=151010rank=126800 of ranks=151010rank=126900 of ranks=151010rank=127000 of ranks=151010rank=127100 of ranks=151010rank=127200 of ranks=151010rank=127300 of ranks=151010rank=127400 of ranks=151010rank=127500 of ranks=151010rank=127600 of ranks=151010rank=127700 of ranks=151010rank=127800 of ranks=151010rank=127900 of ranks=151010rank=128000 of ranks=151010rank=128100 of ranks=151010rank=128200 of ranks=151010rank=128300 of ranks=151010rank=128400 of ranks=151010rank=128500 of ranks=151010rank=128600 of ranks=151010rank=128700 of ranks=151010rank=128800 of ranks=151010rank=128900 of ranks=151010rank=129000 of ranks=151010rank=129100 of ranks=151010rank=129200 of ranks=151010rank=129300 of ranks=151010rank=129400 of ranks=151010rank=129500 of ranks=151010rank=129600 of ranks=151010rank=129700 of ranks=151010rank=129800 of ranks=151010rank=129900 of ranks=151010rank=130000 of ranks=151010rank=130100 of ranks=151010rank=130200 of ranks=151010rank=130300 of ranks=151010rank=130400 of ranks=151010rank=130500 of ranks=151010rank=130600 of ranks=151010rank=130700 of ranks=151010rank=130800 of ranks=151010rank=130900 of ranks=151010rank=131000 of ranks=151010rank=131100 of ranks=151010rank=131200 of ranks=151010rank=131300 of ranks=151010rank=131400 of ranks=151010rank=131500 of ranks=151010rank=131600 of ranks=151010rank=131700 of ranks=151010rank=131800 of ranks=151010rank=131900 of ranks=151010rank=132000 of ranks=151010rank=132100 of ranks=151010rank=132200 of ranks=151010rank=132300 of ranks=151010rank=132400 of ranks=151010rank=132500 of ranks=151010rank=132600 of ranks=151010rank=132700 of ranks=151010rank=132800 of ranks=151010rank=132900 of ranks=151010rank=133000 of ranks=151010rank=133100 of ranks=151010rank=133200 of ranks=151010rank=133300 of ranks=151010rank=133400 of ranks=151010rank=133500 of ranks=151010rank=133600 of ranks=151010rank=133700 of ranks=151010rank=133800 of ranks=151010rank=133900 of ranks=151010rank=134000 of ranks=151010rank=134100 of ranks=151010rank=134200 of ranks=151010rank=134300 of ranks=151010rank=134400 of ranks=151010rank=134500 of ranks=151010rank=134600 of ranks=151010rank=134700 of ranks=151010rank=134800 of ranks=151010rank=134900 of ranks=151010rank=135000 of ranks=151010rank=135100 of ranks=151010rank=135200 of ranks=151010rank=135300 of ranks=151010rank=135400 of ranks=151010rank=135500 of ranks=151010rank=135600 of ranks=151010rank=135700 of ranks=151010rank=135800 of ranks=151010rank=135900 of ranks=151010rank=136000 of ranks=151010rank=136100 of ranks=151010rank=136200 of ranks=151010rank=136300 of ranks=151010rank=136400 of ranks=151010rank=136500 of ranks=151010rank=136600 of ranks=151010rank=136700 of ranks=151010rank=136800 of ranks=151010rank=136900 of ranks=151010rank=137000 of ranks=151010rank=137100 of ranks=151010rank=137200 of ranks=151010rank=137300 of ranks=151010rank=137400 of ranks=151010rank=137500 of ranks=151010rank=137600 of ranks=151010rank=137700 of ranks=151010rank=137800 of ranks=151010rank=137900 of ranks=151010rank=138000 of ranks=151010rank=138100 of ranks=151010rank=138200 of ranks=151010rank=138300 of ranks=151010rank=138400 of ranks=151010rank=138500 of ranks=151010rank=138600 of ranks=151010rank=138700 of ranks=151010rank=138800 of ranks=151010rank=138900 of ranks=151010rank=139000 of ranks=151010rank=139100 of ranks=151010rank=139200 of ranks=151010rank=139300 of ranks=151010rank=139400 of ranks=151010rank=139500 of ranks=151010rank=139600 of ranks=151010rank=139700 of ranks=151010rank=139800 of ranks=151010rank=139900 of ranks=151010rank=140000 of ranks=151010rank=140100 of ranks=151010rank=140200 of ranks=151010rank=140300 of ranks=151010rank=140400 of ranks=151010rank=140500 of ranks=151010rank=140600 of ranks=151010rank=140700 of ranks=151010rank=140800 of ranks=151010rank=140900 of ranks=151010rank=141000 of ranks=151010rank=141100 of ranks=151010rank=141200 of ranks=151010rank=141300 of ranks=151010rank=141400 of ranks=151010rank=141500 of ranks=151010rank=141600 of ranks=151010rank=141700 of ranks=151010rank=141800 of ranks=151010rank=141900 of ranks=151010rank=142000 of ranks=151010rank=142100 of ranks=151010rank=142200 of ranks=151010rank=142300 of ranks=151010rank=142400 of ranks=151010rank=142500 of ranks=151010rank=142600 of ranks=151010rank=142700 of ranks=151010rank=142800 of ranks=151010rank=142900 of ranks=151010rank=143000 of ranks=151010rank=143100 of ranks=151010rank=143200 of ranks=151010rank=143300 of ranks=151010rank=143400 of ranks=151010rank=143500 of ranks=151010rank=143600 of ranks=151010rank=143700 of ranks=151010rank=143800 of ranks=151010rank=143900 of ranks=151010rank=144000 of ranks=151010rank=144100 of ranks=151010rank=144200 of ranks=151010rank=144300 of ranks=151010rank=144400 of ranks=151010rank=144500 of ranks=151010rank=144600 of ranks=151010rank=144700 of ranks=151010rank=144800 of ranks=151010rank=144900 of ranks=151010rank=145000 of ranks=151010rank=145100 of ranks=151010rank=145200 of ranks=151010rank=145300 of ranks=151010rank=145400 of ranks=151010rank=145500 of ranks=151010rank=145600 of ranks=151010rank=145700 of ranks=151010rank=145800 of ranks=151010rank=145900 of ranks=151010rank=146000 of ranks=151010rank=146100 of ranks=151010rank=146200 of ranks=151010rank=146300 of ranks=151010rank=146400 of ranks=151010rank=146500 of ranks=151010rank=146600 of ranks=151010rank=146700 of ranks=151010rank=146800 of ranks=151010rank=146900 of ranks=151010rank=147000 of ranks=151010rank=147100 of ranks=151010rank=147200 of ranks=151010rank=147300 of ranks=151010rank=147400 of ranks=151010rank=147500 of ranks=151010rank=147600 of ranks=151010rank=147700 of ranks=151010rank=147800 of ranks=151010rank=147900 of ranks=151010rank=148000 of ranks=151010rank=148100 of ranks=151010rank=148200 of ranks=151010rank=148300 of ranks=151010rank=148400 of ranks=151010rank=148500 of ranks=151010rank=148600 of ranks=151010rank=148700 of ranks=151010rank=148800 of ranks=151010rank=148900 of ranks=151010rank=149000 of ranks=151010rank=149100 of ranks=151010rank=149200 of ranks=151010rank=149300 of ranks=151010rank=149400 of ranks=151010rank=149500 of ranks=151010rank=149600 of ranks=151010rank=149700 of ranks=151010rank=149800 of ranks=151010rank=149900 of ranks=151010rank=150000 of ranks=151010rank=150100 of ranks=151010rank=150200 of ranks=151010rank=150300 of ranks=151010rank=150400 of ranks=151010rank=150500 of ranks=151010rank=150600 of ranks=151010rank=150700 of ranks=151010rank=150800 of ranks=151010rank=150900 of ranks=151010rank=151000 of ranks=151010

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              82.7299    462  18388     36    498           56.7967
   1 car                    95.9551  49567  33974    749  50316           76.8207
   2 truck                  83.8038   1756  18996     69   1825           60.7184
   3 bus                    63.9948    360   6787      6    366           56.7305
   4 pedestrian             86.2359   3908  16812    351   4259           69.3522

for conf_thresh=0.25, precision=0.88, recall=0.88, F1 score=0.88
for conf_thresh=0.25, TP=50639, FP=6945, FN=6625, average IoU=75.59%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=82.54%
Total detection time: 111 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3031: loss=5.707, avg loss=6.144, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 193984 images, time remaining=5.9 hours
3032: loss=5.041, avg loss=6.034, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 194048 images, time remaining=5.9 hours
3033: loss=6.894, avg loss=6.120, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 194112 images, time remaining=5.9 hours
3034: loss=5.925, avg loss=6.100, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 194176 images, time remaining=5.9 hours
3035: loss=6.676, avg loss=6.158, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 194240 images, time remaining=5.9 hours
3036: loss=7.960, avg loss=6.338, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 194304 images, time remaining=5.9 hours
3037: loss=6.654, avg loss=6.370, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 194368 images, time remaining=5.9 hours
3038: loss=6.854, avg loss=6.418, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 194432 images, time remaining=5.9 hours
3039: loss=5.261, avg loss=6.302, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 194496 images, time remaining=5.9 hours
3040: loss=5.976, avg loss=6.270, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.1 seconds, train=5.7 seconds, 194560 images, time remaining=5.9 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b5dc200000
3041: loss=6.654, avg loss=6.308, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 194624 images, time remaining=5.9 hours
3042: loss=6.354, avg loss=6.313, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 194688 images, time remaining=5.9 hours
3043: loss=4.972, avg loss=6.179, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 194752 images, time remaining=5.9 hours
3044: loss=4.923, avg loss=6.053, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 194816 images, time remaining=5.9 hours
3045: loss=4.672, avg loss=5.915, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 194880 images, time remaining=5.9 hours
3046: loss=5.712, avg loss=5.895, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 194944 images, time remaining=5.9 hours
3047: loss=5.565, avg loss=5.862, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 195008 images, time remaining=5.9 hours
3048: loss=5.906, avg loss=5.866, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 195072 images, time remaining=5.9 hours
3049: loss=4.744, avg loss=5.754, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 195136 images, time remaining=5.9 hours
3050: loss=5.774, avg loss=5.756, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 195200 images, time remaining=5.9 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3051: loss=8.942, avg loss=6.075, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 195264 images, time remaining=5.9 hours
3052: loss=6.842, avg loss=6.151, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 195328 images, time remaining=5.9 hours
3053: loss=6.286, avg loss=6.165, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=5.0 seconds, 195392 images, time remaining=5.9 hours
3054: loss=5.520, avg loss=6.100, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 195456 images, time remaining=5.9 hours
3055: loss=5.656, avg loss=6.056, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=4.9 seconds, 195520 images, time remaining=5.9 hours
3056: loss=6.484, avg loss=6.099, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 195584 images, time remaining=5.9 hours
3057: loss=6.113, avg loss=6.100, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 195648 images, time remaining=5.9 hours
3058: loss=6.189, avg loss=6.109, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 195712 images, time remaining=5.9 hours
3059: loss=5.958, avg loss=6.094, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 195776 images, time remaining=5.9 hours
3060: loss=4.972, avg loss=5.982, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 195840 images, time remaining=5.9 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b5c5e00000
3061: loss=6.398, avg loss=6.023, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.1 seconds, train=1.9 seconds, 195904 images, time remaining=5.9 hours
3062: loss=6.640, avg loss=6.085, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.1 seconds, train=1.9 seconds, 195968 images, time remaining=5.9 hours
3063: loss=7.016, avg loss=6.178, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 196032 images, time remaining=5.9 hours
3064: loss=6.689, avg loss=6.229, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=2.0 seconds, 196096 images, time remaining=5.9 hours
3065: loss=6.136, avg loss=6.220, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 196160 images, time remaining=5.9 hours
3066: loss=5.278, avg loss=6.126, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 196224 images, time remaining=5.9 hours
3067: loss=5.836, avg loss=6.097, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 196288 images, time remaining=5.9 hours
3068: loss=4.930, avg loss=5.980, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 196352 images, time remaining=5.9 hours
3069: loss=5.738, avg loss=5.956, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 196416 images, time remaining=5.9 hours
3070: loss=6.517, avg loss=6.012, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 196480 images, time remaining=5.8 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3071: loss=10.783, avg loss=6.489, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.4 seconds, train=4.8 seconds, 196544 images, time remaining=5.9 hours
3072: loss=9.496, avg loss=6.790, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 196608 images, time remaining=5.8 hours
3073: loss=6.642, avg loss=6.775, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=4.8 seconds, 196672 images, time remaining=5.8 hours
3074: loss=5.482, avg loss=6.646, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 196736 images, time remaining=5.8 hours
3075: loss=5.573, avg loss=6.538, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 196800 images, time remaining=5.8 hours
3076: loss=5.634, avg loss=6.448, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=4.7 seconds, 196864 images, time remaining=5.8 hours
3077: loss=7.791, avg loss=6.582, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 196928 images, time remaining=5.8 hours
3078: loss=6.349, avg loss=6.559, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=4.8 seconds, 196992 images, time remaining=5.8 hours
3079: loss=8.387, avg loss=6.742, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 197056 images, time remaining=5.8 hours
3080: loss=5.891, avg loss=6.657, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 197120 images, time remaining=5.8 hours
Resizing, random_coef=1.40, batch=4, 1216x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3081: loss=7.315, avg loss=6.722, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 197184 images, time remaining=5.8 hours
3082: loss=6.905, avg loss=6.741, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 197248 images, time remaining=5.8 hours
3083: loss=7.034, avg loss=6.770, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 197312 images, time remaining=5.8 hours
3084: loss=6.108, avg loss=6.704, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=5.3 seconds, 197376 images, time remaining=5.8 hours
3085: loss=5.499, avg loss=6.583, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=5.2 seconds, 197440 images, time remaining=5.8 hours
3086: loss=5.111, avg loss=6.436, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 197504 images, time remaining=5.8 hours
3087: loss=5.755, avg loss=6.368, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.2 seconds, 197568 images, time remaining=5.8 hours
3088: loss=6.360, avg loss=6.367, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.1 seconds, 197632 images, time remaining=5.8 hours
3089: loss=6.057, avg loss=6.336, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=5.1 seconds, 197696 images, time remaining=5.8 hours
3090: loss=6.027, avg loss=6.305, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.4 seconds, train=5.1 seconds, 197760 images, time remaining=5.8 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b507e00000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3091: loss=8.571, avg loss=6.532, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=1.8 seconds, 197824 images, time remaining=5.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3092: loss=8.042, avg loss=6.683, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.8 seconds, train=2.0 seconds, 197888 images, time remaining=5.8 hours
3093: loss=7.843, avg loss=6.799, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 197952 images, time remaining=5.8 hours
3094: loss=5.257, avg loss=6.645, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=1.7 seconds, 198016 images, time remaining=5.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3095: loss=4.783, avg loss=6.459, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=1.9 seconds, 198080 images, time remaining=5.8 hours
3096: loss=6.173, avg loss=6.430, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 198144 images, time remaining=5.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3097: loss=5.154, avg loss=6.302, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=3.4 seconds, train=1.8 seconds, 198208 images, time remaining=5.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3098: loss=5.828, avg loss=6.255, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=1.9 seconds, 198272 images, time remaining=5.8 hours
3099: loss=5.562, avg loss=6.186, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 198336 images, time remaining=5.8 hours
3100: loss=5.909, avg loss=6.158, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 198400 images, time remaining=5.8 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b59fe00000
3101: loss=6.395, avg loss=6.182, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 198464 images, time remaining=5.8 hours
3102: loss=6.049, avg loss=6.168, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 198528 images, time remaining=5.8 hours
3103: loss=5.646, avg loss=6.116, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 198592 images, time remaining=5.8 hours
3104: loss=4.881, avg loss=5.993, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 198656 images, time remaining=5.8 hours
3105: loss=5.379, avg loss=5.931, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=2.7 seconds, 198720 images, time remaining=5.8 hours
3106: loss=5.401, avg loss=5.878, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 198784 images, time remaining=5.8 hours
3107: loss=6.019, avg loss=5.892, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.8 seconds, 198848 images, time remaining=5.8 hours
3108: loss=6.359, avg loss=5.939, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 198912 images, time remaining=5.8 hours
3109: loss=5.556, avg loss=5.901, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 198976 images, time remaining=5.8 hours
3110: loss=4.982, avg loss=5.809, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 199040 images, time remaining=5.8 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b578600000
3111: loss=6.288, avg loss=5.857, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 199104 images, time remaining=5.8 hours
3112: loss=5.394, avg loss=5.811, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 199168 images, time remaining=5.8 hours
3113: loss=5.007, avg loss=5.730, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 199232 images, time remaining=5.8 hours
3114: loss=5.428, avg loss=5.700, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 199296 images, time remaining=5.8 hours
3115: loss=5.083, avg loss=5.638, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 199360 images, time remaining=5.8 hours
3116: loss=5.265, avg loss=5.601, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=2.1 seconds, 199424 images, time remaining=5.8 hours
3117: loss=6.006, avg loss=5.641, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 199488 images, time remaining=5.8 hours
3118: loss=5.467, avg loss=5.624, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 199552 images, time remaining=5.8 hours
3119: loss=6.167, avg loss=5.678, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 199616 images, time remaining=5.8 hours
3120: loss=4.807, avg loss=5.591, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.1 seconds, train=2.0 seconds, 199680 images, time remaining=5.8 hours
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3121: loss=10.840, avg loss=6.116, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=5.6 seconds, 199744 images, time remaining=5.8 hours
3122: loss=9.903, avg loss=6.495, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=5.5 seconds, 199808 images, time remaining=5.8 hours
3123: loss=6.891, avg loss=6.534, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 199872 images, time remaining=5.8 hours
3124: loss=6.251, avg loss=6.506, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 199936 images, time remaining=5.8 hours
3125: loss=6.641, avg loss=6.519, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 200000 images, time remaining=5.8 hours
3126: loss=6.650, avg loss=6.533, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 200064 images, time remaining=5.8 hours
3127: loss=7.696, avg loss=6.649, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.1 seconds, train=5.7 seconds, 200128 images, time remaining=5.8 hours
3128: loss=5.132, avg loss=6.497, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=5.6 seconds, 200192 images, time remaining=5.8 hours
3129: loss=6.463, avg loss=6.494, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 200256 images, time remaining=5.8 hours
3130: loss=5.977, avg loss=6.442, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=5.5 seconds, 200320 images, time remaining=5.8 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3131: loss=6.462, avg loss=6.444, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 200384 images, time remaining=5.8 hours
3132: loss=6.030, avg loss=6.403, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 200448 images, time remaining=5.8 hours
3133: loss=7.279, avg loss=6.490, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 200512 images, time remaining=5.8 hours
3134: loss=6.256, avg loss=6.467, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 200576 images, time remaining=5.8 hours
3135: loss=5.807, avg loss=6.401, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 200640 images, time remaining=5.8 hours
3136: loss=6.220, avg loss=6.383, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 200704 images, time remaining=5.8 hours
3137: loss=6.636, avg loss=6.408, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 200768 images, time remaining=5.8 hours
3138: loss=5.605, avg loss=6.328, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 200832 images, time remaining=5.8 hours
3139: loss=4.748, avg loss=6.170, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 200896 images, time remaining=5.8 hours
3140: loss=6.271, avg loss=6.180, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 200960 images, time remaining=5.8 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b298000000
3141: loss=6.537, avg loss=6.216, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 201024 images, time remaining=5.8 hours
3142: loss=5.665, avg loss=6.160, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 201088 images, time remaining=5.8 hours
3143: loss=6.975, avg loss=6.242, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 201152 images, time remaining=5.8 hours
3144: loss=4.229, avg loss=6.041, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 201216 images, time remaining=5.8 hours
3145: loss=5.163, avg loss=5.953, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 201280 images, time remaining=5.8 hours
3146: loss=4.640, avg loss=5.822, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 201344 images, time remaining=5.8 hours
3147: loss=3.731, avg loss=5.613, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.7 seconds, 201408 images, time remaining=5.8 hours
3148: loss=5.282, avg loss=5.580, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 201472 images, time remaining=5.8 hours
3149: loss=4.415, avg loss=5.463, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=2.6 seconds, 201536 images, time remaining=5.8 hours
3150: loss=5.239, avg loss=5.441, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 201600 images, time remaining=5.7 hours
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3151: loss=10.882, avg loss=5.985, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=6.1 seconds, 201664 images, time remaining=5.8 hours
3152: loss=7.488, avg loss=6.135, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 201728 images, time remaining=5.8 hours
3153: loss=7.477, avg loss=6.269, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=6.0 seconds, 201792 images, time remaining=5.8 hours
3154: loss=5.161, avg loss=6.158, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 201856 images, time remaining=5.8 hours
3155: loss=6.876, avg loss=6.230, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 201920 images, time remaining=5.8 hours
3156: loss=6.949, avg loss=6.302, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 201984 images, time remaining=5.7 hours
3157: loss=6.848, avg loss=6.357, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 202048 images, time remaining=5.7 hours
3158: loss=6.611, avg loss=6.382, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 202112 images, time remaining=5.7 hours
3159: loss=7.078, avg loss=6.452, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 202176 images, time remaining=5.7 hours
3160: loss=6.253, avg loss=6.432, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=6.1 seconds, 202240 images, time remaining=5.7 hours
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14c7b6000000
3161: loss=7.591, avg loss=6.548, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 202304 images, time remaining=5.7 hours
3162: loss=6.688, avg loss=6.562, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 202368 images, time remaining=5.7 hours
3163: loss=6.596, avg loss=6.565, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 202432 images, time remaining=5.7 hours
3164: loss=6.841, avg loss=6.593, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 202496 images, time remaining=5.7 hours
3165: loss=6.461, avg loss=6.580, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 202560 images, time remaining=5.7 hours
3166: loss=5.318, avg loss=6.453, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 202624 images, time remaining=5.7 hours
3167: loss=5.806, avg loss=6.389, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 202688 images, time remaining=5.7 hours
3168: loss=5.680, avg loss=6.318, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 202752 images, time remaining=5.7 hours
3169: loss=5.596, avg loss=6.246, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 202816 images, time remaining=5.7 hours
3170: loss=6.401, avg loss=6.261, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 202880 images, time remaining=5.7 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3171: loss=12.715, avg loss=6.907, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 202944 images, time remaining=5.7 hours
3172: loss=9.606, avg loss=7.177, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 203008 images, time remaining=5.7 hours
3173: loss=7.883, avg loss=7.247, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 203072 images, time remaining=5.7 hours
3174: loss=6.165, avg loss=7.139, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 203136 images, time remaining=5.7 hours
3175: loss=6.372, avg loss=7.062, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 203200 images, time remaining=5.7 hours
3176: loss=7.445, avg loss=7.101, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=5.3 seconds, 203264 images, time remaining=5.7 hours
3177: loss=7.651, avg loss=7.156, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=5.3 seconds, 203328 images, time remaining=5.7 hours
3178: loss=7.372, avg loss=7.177, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 203392 images, time remaining=5.7 hours
3179: loss=6.060, avg loss=7.065, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 203456 images, time remaining=5.7 hours
3180: loss=6.073, avg loss=6.966, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 203520 images, time remaining=5.7 hours
Resizing, random_coef=1.40, batch=4, 1088x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3181: loss=8.057, avg loss=7.075, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=4.3 seconds, 203584 images, time remaining=5.7 hours
3182: loss=5.291, avg loss=6.897, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.3 seconds, train=4.3 seconds, 203648 images, time remaining=5.7 hours
3183: loss=5.523, avg loss=6.759, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 203712 images, time remaining=5.7 hours
3184: loss=7.157, avg loss=6.799, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 203776 images, time remaining=5.7 hours
3185: loss=5.953, avg loss=6.715, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=4.4 seconds, 203840 images, time remaining=5.7 hours
3186: loss=5.920, avg loss=6.635, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 203904 images, time remaining=5.7 hours
3187: loss=6.611, avg loss=6.633, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.6 seconds, train=4.3 seconds, 203968 images, time remaining=5.7 hours
3188: loss=5.968, avg loss=6.566, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=4.3 seconds, 204032 images, time remaining=5.7 hours
3189: loss=6.715, avg loss=6.581, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 204096 images, time remaining=5.7 hours
3190: loss=5.739, avg loss=6.497, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.2 seconds, 204160 images, time remaining=5.7 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b298000000
3191: loss=4.651, avg loss=6.312, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 204224 images, time remaining=5.7 hours
3192: loss=5.335, avg loss=6.215, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.8 seconds, 204288 images, time remaining=5.7 hours
3193: loss=4.493, avg loss=6.042, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 204352 images, time remaining=5.7 hours
3194: loss=5.373, avg loss=5.975, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=2.7 seconds, 204416 images, time remaining=5.7 hours
3195: loss=6.133, avg loss=5.991, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 204480 images, time remaining=5.7 hours
3196: loss=4.311, avg loss=5.823, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 204544 images, time remaining=5.7 hours
3197: loss=5.264, avg loss=5.767, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 204608 images, time remaining=5.7 hours
3198: loss=4.198, avg loss=5.610, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 204672 images, time remaining=5.7 hours
3199: loss=4.580, avg loss=5.507, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 204736 images, time remaining=5.7 hours
3200: loss=3.978, avg loss=5.354, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 204800 images, time remaining=5.7 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3201: loss=6.043, avg loss=5.423, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 204864 images, time remaining=5.7 hours
3202: loss=5.461, avg loss=5.427, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=3.6 seconds, train=5.5 seconds, 204928 images, time remaining=5.7 hours
3203: loss=6.643, avg loss=5.549, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 204992 images, time remaining=5.7 hours
3204: loss=4.815, avg loss=5.475, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 205056 images, time remaining=5.7 hours
3205: loss=5.279, avg loss=5.456, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 205120 images, time remaining=5.7 hours
3206: loss=4.407, avg loss=5.351, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 205184 images, time remaining=5.7 hours
3207: loss=4.814, avg loss=5.297, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 205248 images, time remaining=5.7 hours
3208: loss=5.951, avg loss=5.363, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 205312 images, time remaining=5.7 hours
3209: loss=6.382, avg loss=5.465, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 205376 images, time remaining=5.7 hours
3210: loss=5.889, avg loss=5.507, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 205440 images, time remaining=5.7 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b298000000
3211: loss=6.232, avg loss=5.580, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.2 seconds, train=2.8 seconds, 205504 images, time remaining=5.7 hours
3212: loss=5.477, avg loss=5.569, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 205568 images, time remaining=5.7 hours
3213: loss=4.339, avg loss=5.446, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 205632 images, time remaining=5.7 hours
3214: loss=3.886, avg loss=5.290, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 205696 images, time remaining=5.7 hours
3215: loss=4.087, avg loss=5.170, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 205760 images, time remaining=5.7 hours
3216: loss=5.807, avg loss=5.234, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=2.9 seconds, 205824 images, time remaining=5.7 hours
3217: loss=4.379, avg loss=5.148, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 205888 images, time remaining=5.7 hours
3218: loss=4.539, avg loss=5.087, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 205952 images, time remaining=5.7 hours
3219: loss=5.109, avg loss=5.089, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 206016 images, time remaining=5.7 hours
3220: loss=4.558, avg loss=5.036, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 206080 images, time remaining=5.7 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b298000000
3221: loss=4.633, avg loss=4.996, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 206144 images, time remaining=5.7 hours
3222: loss=4.558, avg loss=4.952, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=2.9 seconds, 206208 images, time remaining=5.7 hours
3223: loss=4.289, avg loss=4.886, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 206272 images, time remaining=5.7 hours
3224: loss=4.490, avg loss=4.846, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 206336 images, time remaining=5.7 hours
3225: loss=4.565, avg loss=4.818, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 206400 images, time remaining=5.7 hours
3226: loss=4.979, avg loss=4.834, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 206464 images, time remaining=5.7 hours
3227: loss=4.339, avg loss=4.785, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=2.8 seconds, 206528 images, time remaining=5.7 hours
3228: loss=4.490, avg loss=4.755, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 206592 images, time remaining=5.7 hours
3229: loss=4.958, avg loss=4.775, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 206656 images, time remaining=5.7 hours
3230: loss=3.476, avg loss=4.645, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 206720 images, time remaining=5.7 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3231: loss=5.241, avg loss=4.705, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 206784 images, time remaining=5.7 hours
3232: loss=6.119, avg loss=4.846, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.1 seconds, train=5.9 seconds, 206848 images, time remaining=5.7 hours
3233: loss=4.598, avg loss=4.822, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.1 seconds, train=5.7 seconds, 206912 images, time remaining=5.7 hours
3234: loss=4.858, avg loss=4.825, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 206976 images, time remaining=5.7 hours
3235: loss=5.177, avg loss=4.860, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.1 seconds, train=5.7 seconds, 207040 images, time remaining=5.7 hours
3236: loss=5.623, avg loss=4.937, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 207104 images, time remaining=5.7 hours
3237: loss=5.771, avg loss=5.020, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 207168 images, time remaining=5.7 hours
3238: loss=4.754, avg loss=4.993, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.2 seconds, train=5.6 seconds, 207232 images, time remaining=5.7 hours
3239: loss=5.241, avg loss=5.018, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.2 seconds, train=5.8 seconds, 207296 images, time remaining=5.7 hours
3240: loss=4.951, avg loss=5.011, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=5.7 seconds, 207360 images, time remaining=5.7 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3241: loss=5.719, avg loss=5.082, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 207424 images, time remaining=5.7 hours
3242: loss=4.604, avg loss=5.034, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 207488 images, time remaining=5.7 hours
3243: loss=4.785, avg loss=5.009, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 207552 images, time remaining=5.6 hours
3244: loss=5.334, avg loss=5.042, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 207616 images, time remaining=5.6 hours
3245: loss=4.107, avg loss=4.948, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 207680 images, time remaining=5.6 hours
3246: loss=5.645, avg loss=5.018, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=3.7 seconds, train=5.3 seconds, 207744 images, time remaining=5.6 hours
3247: loss=4.609, avg loss=4.977, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 207808 images, time remaining=5.6 hours
3248: loss=5.034, avg loss=4.983, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=5.1 seconds, 207872 images, time remaining=5.6 hours
3249: loss=4.309, avg loss=4.915, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=4.1 seconds, train=5.4 seconds, 207936 images, time remaining=5.6 hours
3250: loss=4.544, avg loss=4.878, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 208000 images, time remaining=5.6 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3251: loss=4.281, avg loss=4.819, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.1 seconds, train=5.4 seconds, 208064 images, time remaining=5.6 hours
3252: loss=4.636, avg loss=4.800, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=3.5 seconds, train=5.3 seconds, 208128 images, time remaining=5.6 hours
3253: loss=4.629, avg loss=4.783, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.9 seconds, train=5.4 seconds, 208192 images, time remaining=5.6 hours
3254: loss=3.806, avg loss=4.685, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.4 seconds, train=5.3 seconds, 208256 images, time remaining=5.6 hours
3255: loss=4.160, avg loss=4.633, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=4.8 seconds, train=5.4 seconds, 208320 images, time remaining=5.6 hours
3256: loss=4.630, avg loss=4.633, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 208384 images, time remaining=5.6 hours
3257: loss=4.299, avg loss=4.599, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 208448 images, time remaining=5.6 hours
3258: loss=4.020, avg loss=4.541, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=3.0 seconds, train=5.4 seconds, 208512 images, time remaining=5.6 hours
3259: loss=4.216, avg loss=4.509, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 208576 images, time remaining=5.6 hours
3260: loss=4.367, avg loss=4.495, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 208640 images, time remaining=5.6 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b5e6e00000
3261: loss=6.006, avg loss=4.646, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 208704 images, time remaining=5.6 hours
3262: loss=5.745, avg loss=4.756, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 208768 images, time remaining=5.6 hours
3263: loss=5.554, avg loss=4.835, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 208832 images, time remaining=5.6 hours
3264: loss=4.521, avg loss=4.804, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 208896 images, time remaining=5.6 hours
3265: loss=4.606, avg loss=4.784, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 208960 images, time remaining=5.6 hours
3266: loss=4.534, avg loss=4.759, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 209024 images, time remaining=5.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3267: loss=4.990, avg loss=4.782, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.7 seconds, train=2.2 seconds, 209088 images, time remaining=5.6 hours
3268: loss=4.975, avg loss=4.802, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 209152 images, time remaining=5.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3269: loss=5.394, avg loss=4.861, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=3.4 seconds, train=2.2 seconds, 209216 images, time remaining=5.6 hours
3270: loss=4.423, avg loss=4.817, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 209280 images, time remaining=5.6 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3271: loss=7.579, avg loss=5.093, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.0 seconds, 209344 images, time remaining=5.6 hours
3272: loss=5.518, avg loss=5.136, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=4.8 seconds, 209408 images, time remaining=5.6 hours
3273: loss=5.401, avg loss=5.162, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.7 seconds, train=4.8 seconds, 209472 images, time remaining=5.6 hours
3274: loss=4.405, avg loss=5.086, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=3.1 seconds, train=4.9 seconds, 209536 images, time remaining=5.6 hours
3275: loss=5.677, avg loss=5.146, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 209600 images, time remaining=5.6 hours
3276: loss=3.976, avg loss=5.029, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 209664 images, time remaining=5.6 hours
3277: loss=5.665, avg loss=5.092, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=3.0 seconds, train=4.8 seconds, 209728 images, time remaining=5.6 hours
3278: loss=5.099, avg loss=5.093, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 209792 images, time remaining=5.6 hours
3279: loss=4.496, avg loss=5.033, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 209856 images, time remaining=5.6 hours
3280: loss=6.119, avg loss=5.142, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.4 seconds, train=4.7 seconds, 209920 images, time remaining=5.6 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af86000000
3281: loss=4.902, avg loss=5.118, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 209984 images, time remaining=5.6 hours
3282: loss=5.035, avg loss=5.110, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 210048 images, time remaining=5.6 hours
3283: loss=5.395, avg loss=5.138, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.2 seconds, train=4.7 seconds, 210112 images, time remaining=5.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3284: loss=4.310, avg loss=5.055, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=6.4 seconds, train=4.8 seconds, 210176 images, time remaining=5.6 hours
3285: loss=5.102, avg loss=5.060, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 210240 images, time remaining=5.6 hours
3286: loss=4.925, avg loss=5.046, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=4.4 seconds, train=4.8 seconds, 210304 images, time remaining=5.6 hours
3287: loss=3.802, avg loss=4.922, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=4.8 seconds, 210368 images, time remaining=5.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3288: loss=5.141, avg loss=4.944, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=5.3 seconds, train=4.7 seconds, 210432 images, time remaining=5.6 hours
3289: loss=4.878, avg loss=4.937, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.5 seconds, train=4.9 seconds, 210496 images, time remaining=5.6 hours
3290: loss=5.256, avg loss=4.969, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 210560 images, time remaining=5.6 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b559600000
3291: loss=5.323, avg loss=5.005, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=2.0 seconds, 210624 images, time remaining=5.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3292: loss=4.982, avg loss=5.002, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.1 seconds, train=1.9 seconds, 210688 images, time remaining=5.6 hours
3293: loss=4.102, avg loss=4.912, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=2.0 seconds, 210752 images, time remaining=5.6 hours
3294: loss=4.689, avg loss=4.890, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 210816 images, time remaining=5.6 hours
3295: loss=4.752, avg loss=4.876, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 210880 images, time remaining=5.6 hours
3296: loss=4.467, avg loss=4.835, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 210944 images, time remaining=5.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3297: loss=4.204, avg loss=4.772, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.3 seconds, train=2.0 seconds, 211008 images, time remaining=5.6 hours
3298: loss=5.410, avg loss=4.836, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 211072 images, time remaining=5.6 hours
3299: loss=5.079, avg loss=4.860, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=2.1 seconds, 211136 images, time remaining=5.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3300: loss=4.241, avg loss=4.798, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.2 seconds, train=2.1 seconds, 211200 images, time remaining=5.6 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14c2b6000000
3301: loss=4.862, avg loss=4.805, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 211264 images, time remaining=5.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3302: loss=4.676, avg loss=4.792, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=9.4 seconds, train=2.2 seconds, 211328 images, time remaining=5.6 hours
3303: loss=4.357, avg loss=4.748, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 211392 images, time remaining=5.6 hours
3304: loss=4.250, avg loss=4.698, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 211456 images, time remaining=5.6 hours
3305: loss=4.171, avg loss=4.646, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 211520 images, time remaining=5.6 hours
3306: loss=4.779, avg loss=4.659, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 211584 images, time remaining=5.6 hours
3307: loss=4.423, avg loss=4.635, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 211648 images, time remaining=5.6 hours
3308: loss=4.153, avg loss=4.587, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 211712 images, time remaining=5.6 hours
3309: loss=4.124, avg loss=4.541, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 211776 images, time remaining=5.6 hours
3310: loss=4.132, avg loss=4.500, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 211840 images, time remaining=5.6 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b803400000
3311: loss=5.068, avg loss=4.557, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 211904 images, time remaining=5.6 hours
3312: loss=3.648, avg loss=4.466, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 211968 images, time remaining=5.6 hours
3313: loss=5.480, avg loss=4.567, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 212032 images, time remaining=5.6 hours
3314: loss=3.593, avg loss=4.470, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.1 seconds, train=2.2 seconds, 212096 images, time remaining=5.6 hours
3315: loss=3.964, avg loss=4.419, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 212160 images, time remaining=5.6 hours
3316: loss=4.307, avg loss=4.408, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 212224 images, time remaining=5.6 hours
3317: loss=3.681, avg loss=4.335, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 212288 images, time remaining=5.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3318: loss=4.129, avg loss=4.315, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.1 seconds, train=2.0 seconds, 212352 images, time remaining=5.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3319: loss=4.699, avg loss=4.353, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=3.1 seconds, train=2.3 seconds, 212416 images, time remaining=5.6 hours
3320: loss=4.325, avg loss=4.350, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=2.2 seconds, 212480 images, time remaining=5.5 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b803400000
3321: loss=3.464, avg loss=4.262, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 212544 images, time remaining=5.5 hours
3322: loss=3.657, avg loss=4.201, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 212608 images, time remaining=5.5 hours
3323: loss=5.070, avg loss=4.288, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=2.2 seconds, 212672 images, time remaining=5.5 hours
3324: loss=3.618, avg loss=4.221, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=2.2 seconds, 212736 images, time remaining=5.5 hours
3325: loss=4.439, avg loss=4.243, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 212800 images, time remaining=5.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3326: loss=4.313, avg loss=4.250, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=4.4 seconds, train=2.1 seconds, 212864 images, time remaining=5.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3327: loss=4.859, avg loss=4.311, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.8 seconds, train=2.2 seconds, 212928 images, time remaining=5.5 hours
3328: loss=4.340, avg loss=4.314, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 212992 images, time remaining=5.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3329: loss=5.281, avg loss=4.411, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.4 seconds, train=2.2 seconds, 213056 images, time remaining=5.5 hours
3330: loss=4.430, avg loss=4.413, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 213120 images, time remaining=5.5 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af9e000000
3331: loss=8.084, avg loss=4.780, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 213184 images, time remaining=5.5 hours
3332: loss=7.454, avg loss=5.047, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.6 seconds, train=5.7 seconds, 213248 images, time remaining=5.5 hours
3333: loss=7.417, avg loss=5.284, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 213312 images, time remaining=5.5 hours
3334: loss=5.495, avg loss=5.305, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.4 seconds, train=5.3 seconds, 213376 images, time remaining=5.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3335: loss=6.817, avg loss=5.456, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=6.0 seconds, train=5.5 seconds, 213440 images, time remaining=5.5 hours
3336: loss=6.855, avg loss=5.596, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.7 seconds, train=5.7 seconds, 213504 images, time remaining=5.5 hours
3337: loss=7.419, avg loss=5.778, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=5.7 seconds, 213568 images, time remaining=5.5 hours
3338: loss=5.506, avg loss=5.751, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 213632 images, time remaining=5.5 hours
3339: loss=6.551, avg loss=5.831, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 213696 images, time remaining=5.5 hours
3340: loss=5.887, avg loss=5.837, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 213760 images, time remaining=5.5 hours
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af9e000000
3341: loss=4.778, avg loss=5.731, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 213824 images, time remaining=5.5 hours
3342: loss=5.981, avg loss=5.756, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 213888 images, time remaining=5.5 hours
3343: loss=5.938, avg loss=5.774, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=4.1 seconds, 213952 images, time remaining=5.5 hours
3344: loss=4.849, avg loss=5.682, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 214016 images, time remaining=5.5 hours
3345: loss=4.281, avg loss=5.542, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 214080 images, time remaining=5.5 hours
3346: loss=5.912, avg loss=5.579, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=3.5 seconds, train=3.9 seconds, 214144 images, time remaining=5.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3347: loss=5.906, avg loss=5.611, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=4.9 seconds, train=3.9 seconds, 214208 images, time remaining=5.5 hours
3348: loss=4.447, avg loss=5.495, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=3.9 seconds, 214272 images, time remaining=5.5 hours
3349: loss=5.349, avg loss=5.480, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 214336 images, time remaining=5.5 hours
3350: loss=4.958, avg loss=5.428, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 214400 images, time remaining=5.5 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af9e000000
3351: loss=5.595, avg loss=5.445, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.6 seconds, train=4.9 seconds, 214464 images, time remaining=5.5 hours
3352: loss=5.859, avg loss=5.486, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 214528 images, time remaining=5.5 hours
3353: loss=6.243, avg loss=5.562, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.3 seconds, train=4.9 seconds, 214592 images, time remaining=5.5 hours
3354: loss=5.290, avg loss=5.535, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=4.9 seconds, 214656 images, time remaining=5.5 hours
3355: loss=5.658, avg loss=5.547, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 214720 images, time remaining=5.5 hours
3356: loss=5.037, avg loss=5.496, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 214784 images, time remaining=5.5 hours
3357: loss=5.886, avg loss=5.535, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 214848 images, time remaining=5.5 hours
3358: loss=5.683, avg loss=5.550, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 214912 images, time remaining=5.5 hours
3359: loss=5.124, avg loss=5.507, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 214976 images, time remaining=5.5 hours
3360: loss=4.802, avg loss=5.437, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 215040 images, time remaining=5.5 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af9e000000
3361: loss=5.144, avg loss=5.407, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=4.7 seconds, 215104 images, time remaining=5.5 hours
3362: loss=5.548, avg loss=5.421, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.3 seconds, train=4.7 seconds, 215168 images, time remaining=5.5 hours
3363: loss=4.696, avg loss=5.349, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 215232 images, time remaining=5.5 hours
3364: loss=4.938, avg loss=5.308, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 215296 images, time remaining=5.5 hours
3365: loss=5.697, avg loss=5.347, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 215360 images, time remaining=5.5 hours
3366: loss=5.318, avg loss=5.344, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=4.6 seconds, 215424 images, time remaining=5.5 hours
3367: loss=5.490, avg loss=5.358, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 215488 images, time remaining=5.5 hours
3368: loss=5.193, avg loss=5.342, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 215552 images, time remaining=5.5 hours
3369: loss=4.874, avg loss=5.295, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=4.6 seconds, 215616 images, time remaining=5.5 hours
3370: loss=3.973, avg loss=5.163, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 215680 images, time remaining=5.5 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2b0000000
3371: loss=4.516, avg loss=5.098, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 215744 images, time remaining=5.5 hours
3372: loss=4.662, avg loss=5.055, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 215808 images, time remaining=5.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3373: loss=4.535, avg loss=5.003, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=3.0 seconds, train=2.5 seconds, 215872 images, time remaining=5.5 hours
3374: loss=4.753, avg loss=4.978, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 215936 images, time remaining=5.5 hours
3375: loss=4.573, avg loss=4.937, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 216000 images, time remaining=5.5 hours
3376: loss=5.103, avg loss=4.954, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=2.6 seconds, 216064 images, time remaining=5.5 hours
3377: loss=4.796, avg loss=4.938, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 216128 images, time remaining=5.5 hours
3378: loss=4.183, avg loss=4.863, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 216192 images, time remaining=5.5 hours
3379: loss=5.436, avg loss=4.920, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 216256 images, time remaining=5.5 hours
3380: loss=4.468, avg loss=4.875, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 216320 images, time remaining=5.5 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af9e000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3381: loss=6.371, avg loss=5.024, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=10.4 seconds, train=4.6 seconds, 216384 images, time remaining=5.5 hours
3382: loss=5.673, avg loss=5.089, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.8 seconds, train=4.7 seconds, 216448 images, time remaining=5.5 hours
3383: loss=5.412, avg loss=5.121, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 216512 images, time remaining=5.5 hours
3384: loss=4.751, avg loss=5.084, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 216576 images, time remaining=5.5 hours
3385: loss=5.740, avg loss=5.150, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 216640 images, time remaining=5.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3386: loss=5.523, avg loss=5.187, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=7.7 seconds, train=4.6 seconds, 216704 images, time remaining=5.5 hours
3387: loss=6.144, avg loss=5.283, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 216768 images, time remaining=5.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3388: loss=5.994, avg loss=5.354, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=6.0 seconds, train=4.5 seconds, 216832 images, time remaining=5.5 hours
3389: loss=4.656, avg loss=5.284, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=4.0 seconds, train=4.7 seconds, 216896 images, time remaining=5.5 hours
3390: loss=5.204, avg loss=5.276, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=4.6 seconds, 216960 images, time remaining=5.5 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b4e6a00000
3391: loss=7.454, avg loss=5.494, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 217024 images, time remaining=5.5 hours
3392: loss=5.927, avg loss=5.537, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 217088 images, time remaining=5.5 hours
3393: loss=5.054, avg loss=5.489, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 217152 images, time remaining=5.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3394: loss=5.174, avg loss=5.457, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.1 seconds, train=2.0 seconds, 217216 images, time remaining=5.5 hours
3395: loss=4.210, avg loss=5.333, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 217280 images, time remaining=5.5 hours
3396: loss=3.978, avg loss=5.197, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 217344 images, time remaining=5.5 hours
3397: loss=4.702, avg loss=5.148, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 217408 images, time remaining=5.5 hours
3398: loss=4.186, avg loss=5.051, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 217472 images, time remaining=5.5 hours
3399: loss=6.131, avg loss=5.159, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 217536 images, time remaining=5.5 hours
3400: loss=4.614, avg loss=5.105, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 217600 images, time remaining=5.5 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af9e000000
3401: loss=11.640, avg loss=5.758, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 217664 images, time remaining=5.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3402: loss=7.819, avg loss=5.964, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=13.6 seconds, train=4.4 seconds, 217728 images, time remaining=5.5 hours
3403: loss=6.958, avg loss=6.064, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=4.6 seconds, 217792 images, time remaining=5.5 hours
3404: loss=6.392, avg loss=6.097, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=4.4 seconds, train=4.6 seconds, 217856 images, time remaining=5.5 hours
3405: loss=5.430, avg loss=6.030, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=4.6 seconds, 217920 images, time remaining=5.5 hours
3406: loss=5.990, avg loss=6.026, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=4.6 seconds, 217984 images, time remaining=5.5 hours
3407: loss=5.616, avg loss=5.985, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=3.7 seconds, train=4.7 seconds, 218048 images, time remaining=5.5 hours
3408: loss=6.129, avg loss=5.999, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.3 seconds, train=4.6 seconds, 218112 images, time remaining=5.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3409: loss=5.870, avg loss=5.986, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=11.5 seconds, train=4.6 seconds, 218176 images, time remaining=5.5 hours
3410: loss=4.864, avg loss=5.874, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=4.2 seconds, train=4.6 seconds, 218240 images, time remaining=5.5 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b579400000
3411: loss=7.794, avg loss=6.066, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=2.5 seconds, 218304 images, time remaining=5.5 hours
3412: loss=5.979, avg loss=6.057, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 218368 images, time remaining=5.5 hours
3413: loss=5.661, avg loss=6.018, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 218432 images, time remaining=5.4 hours
3414: loss=5.693, avg loss=5.985, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 218496 images, time remaining=5.4 hours
3415: loss=5.996, avg loss=5.986, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=2.4 seconds, 218560 images, time remaining=5.4 hours
3416: loss=6.625, avg loss=6.050, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 218624 images, time remaining=5.4 hours
3417: loss=5.659, avg loss=6.011, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=2.3 seconds, 218688 images, time remaining=5.4 hours
3418: loss=5.659, avg loss=5.976, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 218752 images, time remaining=5.4 hours
3419: loss=5.535, avg loss=5.932, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 218816 images, time remaining=5.4 hours
3420: loss=5.255, avg loss=5.864, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 218880 images, time remaining=5.4 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af9e000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3421: loss=9.992, avg loss=6.277, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=8.7 seconds, train=4.6 seconds, 218944 images, time remaining=5.4 hours
3422: loss=7.315, avg loss=6.381, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.4 seconds, train=4.8 seconds, 219008 images, time remaining=5.4 hours
3423: loss=6.713, avg loss=6.414, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.4 seconds, train=4.8 seconds, 219072 images, time remaining=5.4 hours
3424: loss=5.963, avg loss=6.369, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 219136 images, time remaining=5.4 hours
3425: loss=5.212, avg loss=6.253, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=4.7 seconds, 219200 images, time remaining=5.4 hours
3426: loss=6.104, avg loss=6.238, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 219264 images, time remaining=5.4 hours
3427: loss=6.459, avg loss=6.260, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.8 seconds, train=4.6 seconds, 219328 images, time remaining=5.4 hours
3428: loss=5.188, avg loss=6.153, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.7 seconds, train=4.8 seconds, 219392 images, time remaining=5.4 hours
3429: loss=7.334, avg loss=6.271, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 219456 images, time remaining=5.4 hours
3430: loss=6.604, avg loss=6.304, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=4.7 seconds, 219520 images, time remaining=5.4 hours
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af9e000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3431: loss=6.074, avg loss=6.281, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=11.9 seconds, train=4.0 seconds, 219584 images, time remaining=5.4 hours
3432: loss=5.943, avg loss=6.248, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 219648 images, time remaining=5.4 hours
3433: loss=5.511, avg loss=6.174, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.7 seconds, train=3.9 seconds, 219712 images, time remaining=5.4 hours
3434: loss=6.348, avg loss=6.191, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=2.0 seconds, train=3.8 seconds, 219776 images, time remaining=5.4 hours
3435: loss=5.214, avg loss=6.094, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=3.4 seconds, train=4.0 seconds, 219840 images, time remaining=5.4 hours
3436: loss=5.805, avg loss=6.065, last=82.54%, best=85.57%, next=3436, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 219904 images, time remaining=5.4 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2b0000000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=144106, unique_truth_count=57264
rank=0 of ranks=144106rank=100 of ranks=144106rank=200 of ranks=144106rank=300 of ranks=144106rank=400 of ranks=144106rank=500 of ranks=144106rank=600 of ranks=144106rank=700 of ranks=144106rank=800 of ranks=144106rank=900 of ranks=144106rank=1000 of ranks=144106rank=1100 of ranks=144106rank=1200 of ranks=144106rank=1300 of ranks=144106rank=1400 of ranks=144106rank=1500 of ranks=144106rank=1600 of ranks=144106rank=1700 of ranks=144106rank=1800 of ranks=144106rank=1900 of ranks=144106rank=2000 of ranks=144106rank=2100 of ranks=144106rank=2200 of ranks=144106rank=2300 of ranks=144106rank=2400 of ranks=144106rank=2500 of ranks=144106rank=2600 of ranks=144106rank=2700 of ranks=144106rank=2800 of ranks=144106rank=2900 of ranks=144106rank=3000 of ranks=144106rank=3100 of ranks=144106rank=3200 of ranks=144106rank=3300 of ranks=144106rank=3400 of ranks=144106rank=3500 of ranks=144106rank=3600 of ranks=144106rank=3700 of ranks=144106rank=3800 of ranks=144106rank=3900 of ranks=144106rank=4000 of ranks=144106rank=4100 of ranks=144106rank=4200 of ranks=144106rank=4300 of ranks=144106rank=4400 of ranks=144106rank=4500 of ranks=144106rank=4600 of ranks=144106rank=4700 of ranks=144106rank=4800 of ranks=144106rank=4900 of ranks=144106rank=5000 of ranks=144106rank=5100 of ranks=144106rank=5200 of ranks=144106rank=5300 of ranks=144106rank=5400 of ranks=144106rank=5500 of ranks=144106rank=5600 of ranks=144106rank=5700 of ranks=144106rank=5800 of ranks=144106rank=5900 of ranks=144106rank=6000 of ranks=144106rank=6100 of ranks=144106rank=6200 of ranks=144106rank=6300 of ranks=144106rank=6400 of ranks=144106rank=6500 of ranks=144106rank=6600 of ranks=144106rank=6700 of ranks=144106rank=6800 of ranks=144106rank=6900 of ranks=144106rank=7000 of ranks=144106rank=7100 of ranks=144106rank=7200 of ranks=144106rank=7300 of ranks=144106rank=7400 of ranks=144106rank=7500 of ranks=144106rank=7600 of ranks=144106rank=7700 of ranks=144106rank=7800 of ranks=144106rank=7900 of ranks=144106rank=8000 of ranks=144106rank=8100 of ranks=144106rank=8200 of ranks=144106rank=8300 of ranks=144106rank=8400 of ranks=144106rank=8500 of ranks=144106rank=8600 of ranks=144106rank=8700 of ranks=144106rank=8800 of ranks=144106rank=8900 of ranks=144106rank=9000 of ranks=144106rank=9100 of ranks=144106rank=9200 of ranks=144106rank=9300 of ranks=144106rank=9400 of ranks=144106rank=9500 of ranks=144106rank=9600 of ranks=144106rank=9700 of ranks=144106rank=9800 of ranks=144106rank=9900 of ranks=144106rank=10000 of ranks=144106rank=10100 of ranks=144106rank=10200 of ranks=144106rank=10300 of ranks=144106rank=10400 of ranks=144106rank=10500 of ranks=144106rank=10600 of ranks=144106rank=10700 of ranks=144106rank=10800 of ranks=144106rank=10900 of ranks=144106rank=11000 of ranks=144106rank=11100 of ranks=144106rank=11200 of ranks=144106rank=11300 of ranks=144106rank=11400 of ranks=144106rank=11500 of ranks=144106rank=11600 of ranks=144106rank=11700 of ranks=144106rank=11800 of ranks=144106rank=11900 of ranks=144106rank=12000 of ranks=144106rank=12100 of ranks=144106rank=12200 of ranks=144106rank=12300 of ranks=144106rank=12400 of ranks=144106rank=12500 of ranks=144106rank=12600 of ranks=144106rank=12700 of ranks=144106rank=12800 of ranks=144106rank=12900 of ranks=144106rank=13000 of ranks=144106rank=13100 of ranks=144106rank=13200 of ranks=144106rank=13300 of ranks=144106rank=13400 of ranks=144106rank=13500 of ranks=144106rank=13600 of ranks=144106rank=13700 of ranks=144106rank=13800 of ranks=144106rank=13900 of ranks=144106rank=14000 of ranks=144106rank=14100 of ranks=144106rank=14200 of ranks=144106rank=14300 of ranks=144106rank=14400 of ranks=144106rank=14500 of ranks=144106rank=14600 of ranks=144106rank=14700 of ranks=144106rank=14800 of ranks=144106rank=14900 of ranks=144106rank=15000 of ranks=144106rank=15100 of ranks=144106rank=15200 of ranks=144106rank=15300 of ranks=144106rank=15400 of ranks=144106rank=15500 of ranks=144106rank=15600 of ranks=144106rank=15700 of ranks=144106rank=15800 of ranks=144106rank=15900 of ranks=144106rank=16000 of ranks=144106rank=16100 of ranks=144106rank=16200 of ranks=144106rank=16300 of ranks=144106rank=16400 of ranks=144106rank=16500 of ranks=144106rank=16600 of ranks=144106rank=16700 of ranks=144106rank=16800 of ranks=144106rank=16900 of ranks=144106rank=17000 of ranks=144106rank=17100 of ranks=144106rank=17200 of ranks=144106rank=17300 of ranks=144106rank=17400 of ranks=144106rank=17500 of ranks=144106rank=17600 of ranks=144106rank=17700 of ranks=144106rank=17800 of ranks=144106rank=17900 of ranks=144106rank=18000 of ranks=144106rank=18100 of ranks=144106rank=18200 of ranks=144106rank=18300 of ranks=144106rank=18400 of ranks=144106rank=18500 of ranks=144106rank=18600 of ranks=144106rank=18700 of ranks=144106rank=18800 of ranks=144106rank=18900 of ranks=144106rank=19000 of ranks=144106rank=19100 of ranks=144106rank=19200 of ranks=144106rank=19300 of ranks=144106rank=19400 of ranks=144106rank=19500 of ranks=144106rank=19600 of ranks=144106rank=19700 of ranks=144106rank=19800 of ranks=144106rank=19900 of ranks=144106rank=20000 of ranks=144106rank=20100 of ranks=144106rank=20200 of ranks=144106rank=20300 of ranks=144106rank=20400 of ranks=144106rank=20500 of ranks=144106rank=20600 of ranks=144106rank=20700 of ranks=144106rank=20800 of ranks=144106rank=20900 of ranks=144106rank=21000 of ranks=144106rank=21100 of ranks=144106rank=21200 of ranks=144106rank=21300 of ranks=144106rank=21400 of ranks=144106rank=21500 of ranks=144106rank=21600 of ranks=144106rank=21700 of ranks=144106rank=21800 of ranks=144106rank=21900 of ranks=144106rank=22000 of ranks=144106rank=22100 of ranks=144106rank=22200 of ranks=144106rank=22300 of ranks=144106rank=22400 of ranks=144106rank=22500 of ranks=144106rank=22600 of ranks=144106rank=22700 of ranks=144106rank=22800 of ranks=144106rank=22900 of ranks=144106rank=23000 of ranks=144106rank=23100 of ranks=144106rank=23200 of ranks=144106rank=23300 of ranks=144106rank=23400 of ranks=144106rank=23500 of ranks=144106rank=23600 of ranks=144106rank=23700 of ranks=144106rank=23800 of ranks=144106rank=23900 of ranks=144106rank=24000 of ranks=144106rank=24100 of ranks=144106rank=24200 of ranks=144106rank=24300 of ranks=144106rank=24400 of ranks=144106rank=24500 of ranks=144106rank=24600 of ranks=144106rank=24700 of ranks=144106rank=24800 of ranks=144106rank=24900 of ranks=144106rank=25000 of ranks=144106rank=25100 of ranks=144106rank=25200 of ranks=144106rank=25300 of ranks=144106rank=25400 of ranks=144106rank=25500 of ranks=144106rank=25600 of ranks=144106rank=25700 of ranks=144106rank=25800 of ranks=144106rank=25900 of ranks=144106rank=26000 of ranks=144106rank=26100 of ranks=144106rank=26200 of ranks=144106rank=26300 of ranks=144106rank=26400 of ranks=144106rank=26500 of ranks=144106rank=26600 of ranks=144106rank=26700 of ranks=144106rank=26800 of ranks=144106rank=26900 of ranks=144106rank=27000 of ranks=144106rank=27100 of ranks=144106rank=27200 of ranks=144106rank=27300 of ranks=144106rank=27400 of ranks=144106rank=27500 of ranks=144106rank=27600 of ranks=144106rank=27700 of ranks=144106rank=27800 of ranks=144106rank=27900 of ranks=144106rank=28000 of ranks=144106rank=28100 of ranks=144106rank=28200 of ranks=144106rank=28300 of ranks=144106rank=28400 of ranks=144106rank=28500 of ranks=144106rank=28600 of ranks=144106rank=28700 of ranks=144106rank=28800 of ranks=144106rank=28900 of ranks=144106rank=29000 of ranks=144106rank=29100 of ranks=144106rank=29200 of ranks=144106rank=29300 of ranks=144106rank=29400 of ranks=144106rank=29500 of ranks=144106rank=29600 of ranks=144106rank=29700 of ranks=144106rank=29800 of ranks=144106rank=29900 of ranks=144106rank=30000 of ranks=144106rank=30100 of ranks=144106rank=30200 of ranks=144106rank=30300 of ranks=144106rank=30400 of ranks=144106rank=30500 of ranks=144106rank=30600 of ranks=144106rank=30700 of ranks=144106rank=30800 of ranks=144106rank=30900 of ranks=144106rank=31000 of ranks=144106rank=31100 of ranks=144106rank=31200 of ranks=144106rank=31300 of ranks=144106rank=31400 of ranks=144106rank=31500 of ranks=144106rank=31600 of ranks=144106rank=31700 of ranks=144106rank=31800 of ranks=144106rank=31900 of ranks=144106rank=32000 of ranks=144106rank=32100 of ranks=144106rank=32200 of ranks=144106rank=32300 of ranks=144106rank=32400 of ranks=144106rank=32500 of ranks=144106rank=32600 of ranks=144106rank=32700 of ranks=144106rank=32800 of ranks=144106rank=32900 of ranks=144106rank=33000 of ranks=144106rank=33100 of ranks=144106rank=33200 of ranks=144106rank=33300 of ranks=144106rank=33400 of ranks=144106rank=33500 of ranks=144106rank=33600 of ranks=144106rank=33700 of ranks=144106rank=33800 of ranks=144106rank=33900 of ranks=144106rank=34000 of ranks=144106rank=34100 of ranks=144106rank=34200 of ranks=144106rank=34300 of ranks=144106rank=34400 of ranks=144106rank=34500 of ranks=144106rank=34600 of ranks=144106rank=34700 of ranks=144106rank=34800 of ranks=144106rank=34900 of ranks=144106rank=35000 of ranks=144106rank=35100 of ranks=144106rank=35200 of ranks=144106rank=35300 of ranks=144106rank=35400 of ranks=144106rank=35500 of ranks=144106rank=35600 of ranks=144106rank=35700 of ranks=144106rank=35800 of ranks=144106rank=35900 of ranks=144106rank=36000 of ranks=144106rank=36100 of ranks=144106rank=36200 of ranks=144106rank=36300 of ranks=144106rank=36400 of ranks=144106rank=36500 of ranks=144106rank=36600 of ranks=144106rank=36700 of ranks=144106rank=36800 of ranks=144106rank=36900 of ranks=144106rank=37000 of ranks=144106rank=37100 of ranks=144106rank=37200 of ranks=144106rank=37300 of ranks=144106rank=37400 of ranks=144106rank=37500 of ranks=144106rank=37600 of ranks=144106rank=37700 of ranks=144106rank=37800 of ranks=144106rank=37900 of ranks=144106rank=38000 of ranks=144106rank=38100 of ranks=144106rank=38200 of ranks=144106rank=38300 of ranks=144106rank=38400 of ranks=144106rank=38500 of ranks=144106rank=38600 of ranks=144106rank=38700 of ranks=144106rank=38800 of ranks=144106rank=38900 of ranks=144106rank=39000 of ranks=144106rank=39100 of ranks=144106rank=39200 of ranks=144106rank=39300 of ranks=144106rank=39400 of ranks=144106rank=39500 of ranks=144106rank=39600 of ranks=144106rank=39700 of ranks=144106rank=39800 of ranks=144106rank=39900 of ranks=144106rank=40000 of ranks=144106rank=40100 of ranks=144106rank=40200 of ranks=144106rank=40300 of ranks=144106rank=40400 of ranks=144106rank=40500 of ranks=144106rank=40600 of ranks=144106rank=40700 of ranks=144106rank=40800 of ranks=144106rank=40900 of ranks=144106rank=41000 of ranks=144106rank=41100 of ranks=144106rank=41200 of ranks=144106rank=41300 of ranks=144106rank=41400 of ranks=144106rank=41500 of ranks=144106rank=41600 of ranks=144106rank=41700 of ranks=144106rank=41800 of ranks=144106rank=41900 of ranks=144106rank=42000 of ranks=144106rank=42100 of ranks=144106rank=42200 of ranks=144106rank=42300 of ranks=144106rank=42400 of ranks=144106rank=42500 of ranks=144106rank=42600 of ranks=144106rank=42700 of ranks=144106rank=42800 of ranks=144106rank=42900 of ranks=144106rank=43000 of ranks=144106rank=43100 of ranks=144106rank=43200 of ranks=144106rank=43300 of ranks=144106rank=43400 of ranks=144106rank=43500 of ranks=144106rank=43600 of ranks=144106rank=43700 of ranks=144106rank=43800 of ranks=144106rank=43900 of ranks=144106rank=44000 of ranks=144106rank=44100 of ranks=144106rank=44200 of ranks=144106rank=44300 of ranks=144106rank=44400 of ranks=144106rank=44500 of ranks=144106rank=44600 of ranks=144106rank=44700 of ranks=144106rank=44800 of ranks=144106rank=44900 of ranks=144106rank=45000 of ranks=144106rank=45100 of ranks=144106rank=45200 of ranks=144106rank=45300 of ranks=144106rank=45400 of ranks=144106rank=45500 of ranks=144106rank=45600 of ranks=144106rank=45700 of ranks=144106rank=45800 of ranks=144106rank=45900 of ranks=144106rank=46000 of ranks=144106rank=46100 of ranks=144106rank=46200 of ranks=144106rank=46300 of ranks=144106rank=46400 of ranks=144106rank=46500 of ranks=144106rank=46600 of ranks=144106rank=46700 of ranks=144106rank=46800 of ranks=144106rank=46900 of ranks=144106rank=47000 of ranks=144106rank=47100 of ranks=144106rank=47200 of ranks=144106rank=47300 of ranks=144106rank=47400 of ranks=144106rank=47500 of ranks=144106rank=47600 of ranks=144106rank=47700 of ranks=144106rank=47800 of ranks=144106rank=47900 of ranks=144106rank=48000 of ranks=144106rank=48100 of ranks=144106rank=48200 of ranks=144106rank=48300 of ranks=144106rank=48400 of ranks=144106rank=48500 of ranks=144106rank=48600 of ranks=144106rank=48700 of ranks=144106rank=48800 of ranks=144106rank=48900 of ranks=144106rank=49000 of ranks=144106rank=49100 of ranks=144106rank=49200 of ranks=144106rank=49300 of ranks=144106rank=49400 of ranks=144106rank=49500 of ranks=144106rank=49600 of ranks=144106rank=49700 of ranks=144106rank=49800 of ranks=144106rank=49900 of ranks=144106rank=50000 of ranks=144106rank=50100 of ranks=144106rank=50200 of ranks=144106rank=50300 of ranks=144106rank=50400 of ranks=144106rank=50500 of ranks=144106rank=50600 of ranks=144106rank=50700 of ranks=144106rank=50800 of ranks=144106rank=50900 of ranks=144106rank=51000 of ranks=144106rank=51100 of ranks=144106rank=51200 of ranks=144106rank=51300 of ranks=144106rank=51400 of ranks=144106rank=51500 of ranks=144106rank=51600 of ranks=144106rank=51700 of ranks=144106rank=51800 of ranks=144106rank=51900 of ranks=144106rank=52000 of ranks=144106rank=52100 of ranks=144106rank=52200 of ranks=144106rank=52300 of ranks=144106rank=52400 of ranks=144106rank=52500 of ranks=144106rank=52600 of ranks=144106rank=52700 of ranks=144106rank=52800 of ranks=144106rank=52900 of ranks=144106rank=53000 of ranks=144106rank=53100 of ranks=144106rank=53200 of ranks=144106rank=53300 of ranks=144106rank=53400 of ranks=144106rank=53500 of ranks=144106rank=53600 of ranks=144106rank=53700 of ranks=144106rank=53800 of ranks=144106rank=53900 of ranks=144106rank=54000 of ranks=144106rank=54100 of ranks=144106rank=54200 of ranks=144106rank=54300 of ranks=144106rank=54400 of ranks=144106rank=54500 of ranks=144106rank=54600 of ranks=144106rank=54700 of ranks=144106rank=54800 of ranks=144106rank=54900 of ranks=144106rank=55000 of ranks=144106rank=55100 of ranks=144106rank=55200 of ranks=144106rank=55300 of ranks=144106rank=55400 of ranks=144106rank=55500 of ranks=144106rank=55600 of ranks=144106rank=55700 of ranks=144106rank=55800 of ranks=144106rank=55900 of ranks=144106rank=56000 of ranks=144106rank=56100 of ranks=144106rank=56200 of ranks=144106rank=56300 of ranks=144106rank=56400 of ranks=144106rank=56500 of ranks=144106rank=56600 of ranks=144106rank=56700 of ranks=144106rank=56800 of ranks=144106rank=56900 of ranks=144106rank=57000 of ranks=144106rank=57100 of ranks=144106rank=57200 of ranks=144106rank=57300 of ranks=144106rank=57400 of ranks=144106rank=57500 of ranks=144106rank=57600 of ranks=144106rank=57700 of ranks=144106rank=57800 of ranks=144106rank=57900 of ranks=144106rank=58000 of ranks=144106rank=58100 of ranks=144106rank=58200 of ranks=144106rank=58300 of ranks=144106rank=58400 of ranks=144106rank=58500 of ranks=144106rank=58600 of ranks=144106rank=58700 of ranks=144106rank=58800 of ranks=144106rank=58900 of ranks=144106rank=59000 of ranks=144106rank=59100 of ranks=144106rank=59200 of ranks=144106rank=59300 of ranks=144106rank=59400 of ranks=144106rank=59500 of ranks=144106rank=59600 of ranks=144106rank=59700 of ranks=144106rank=59800 of ranks=144106rank=59900 of ranks=144106rank=60000 of ranks=144106rank=60100 of ranks=144106rank=60200 of ranks=144106rank=60300 of ranks=144106rank=60400 of ranks=144106rank=60500 of ranks=144106rank=60600 of ranks=144106rank=60700 of ranks=144106rank=60800 of ranks=144106rank=60900 of ranks=144106rank=61000 of ranks=144106rank=61100 of ranks=144106rank=61200 of ranks=144106rank=61300 of ranks=144106rank=61400 of ranks=144106rank=61500 of ranks=144106rank=61600 of ranks=144106rank=61700 of ranks=144106rank=61800 of ranks=144106rank=61900 of ranks=144106rank=62000 of ranks=144106rank=62100 of ranks=144106rank=62200 of ranks=144106rank=62300 of ranks=144106rank=62400 of ranks=144106rank=62500 of ranks=144106rank=62600 of ranks=144106rank=62700 of ranks=144106rank=62800 of ranks=144106rank=62900 of ranks=144106rank=63000 of ranks=144106rank=63100 of ranks=144106rank=63200 of ranks=144106rank=63300 of ranks=144106rank=63400 of ranks=144106rank=63500 of ranks=144106rank=63600 of ranks=144106rank=63700 of ranks=144106rank=63800 of ranks=144106rank=63900 of ranks=144106rank=64000 of ranks=144106rank=64100 of ranks=144106rank=64200 of ranks=144106rank=64300 of ranks=144106rank=64400 of ranks=144106rank=64500 of ranks=144106rank=64600 of ranks=144106rank=64700 of ranks=144106rank=64800 of ranks=144106rank=64900 of ranks=144106rank=65000 of ranks=144106rank=65100 of ranks=144106rank=65200 of ranks=144106rank=65300 of ranks=144106rank=65400 of ranks=144106rank=65500 of ranks=144106rank=65600 of ranks=144106rank=65700 of ranks=144106rank=65800 of ranks=144106rank=65900 of ranks=144106rank=66000 of ranks=144106rank=66100 of ranks=144106rank=66200 of ranks=144106rank=66300 of ranks=144106rank=66400 of ranks=144106rank=66500 of ranks=144106rank=66600 of ranks=144106rank=66700 of ranks=144106rank=66800 of ranks=144106rank=66900 of ranks=144106rank=67000 of ranks=144106rank=67100 of ranks=144106rank=67200 of ranks=144106rank=67300 of ranks=144106rank=67400 of ranks=144106rank=67500 of ranks=144106rank=67600 of ranks=144106rank=67700 of ranks=144106rank=67800 of ranks=144106rank=67900 of ranks=144106rank=68000 of ranks=144106rank=68100 of ranks=144106rank=68200 of ranks=144106rank=68300 of ranks=144106rank=68400 of ranks=144106rank=68500 of ranks=144106rank=68600 of ranks=144106rank=68700 of ranks=144106rank=68800 of ranks=144106rank=68900 of ranks=144106rank=69000 of ranks=144106rank=69100 of ranks=144106rank=69200 of ranks=144106rank=69300 of ranks=144106rank=69400 of ranks=144106rank=69500 of ranks=144106rank=69600 of ranks=144106rank=69700 of ranks=144106rank=69800 of ranks=144106rank=69900 of ranks=144106rank=70000 of ranks=144106rank=70100 of ranks=144106rank=70200 of ranks=144106rank=70300 of ranks=144106rank=70400 of ranks=144106rank=70500 of ranks=144106rank=70600 of ranks=144106rank=70700 of ranks=144106rank=70800 of ranks=144106rank=70900 of ranks=144106rank=71000 of ranks=144106rank=71100 of ranks=144106rank=71200 of ranks=144106rank=71300 of ranks=144106rank=71400 of ranks=144106rank=71500 of ranks=144106rank=71600 of ranks=144106rank=71700 of ranks=144106rank=71800 of ranks=144106rank=71900 of ranks=144106rank=72000 of ranks=144106rank=72100 of ranks=144106rank=72200 of ranks=144106rank=72300 of ranks=144106rank=72400 of ranks=144106rank=72500 of ranks=144106rank=72600 of ranks=144106rank=72700 of ranks=144106rank=72800 of ranks=144106rank=72900 of ranks=144106rank=73000 of ranks=144106rank=73100 of ranks=144106rank=73200 of ranks=144106rank=73300 of ranks=144106rank=73400 of ranks=144106rank=73500 of ranks=144106rank=73600 of ranks=144106rank=73700 of ranks=144106rank=73800 of ranks=144106rank=73900 of ranks=144106rank=74000 of ranks=144106rank=74100 of ranks=144106rank=74200 of ranks=144106rank=74300 of ranks=144106rank=74400 of ranks=144106rank=74500 of ranks=144106rank=74600 of ranks=144106rank=74700 of ranks=144106rank=74800 of ranks=144106rank=74900 of ranks=144106rank=75000 of ranks=144106rank=75100 of ranks=144106rank=75200 of ranks=144106rank=75300 of ranks=144106rank=75400 of ranks=144106rank=75500 of ranks=144106rank=75600 of ranks=144106rank=75700 of ranks=144106rank=75800 of ranks=144106rank=75900 of ranks=144106rank=76000 of ranks=144106rank=76100 of ranks=144106rank=76200 of ranks=144106rank=76300 of ranks=144106rank=76400 of ranks=144106rank=76500 of ranks=144106rank=76600 of ranks=144106rank=76700 of ranks=144106rank=76800 of ranks=144106rank=76900 of ranks=144106rank=77000 of ranks=144106rank=77100 of ranks=144106rank=77200 of ranks=144106rank=77300 of ranks=144106rank=77400 of ranks=144106rank=77500 of ranks=144106rank=77600 of ranks=144106rank=77700 of ranks=144106rank=77800 of ranks=144106rank=77900 of ranks=144106rank=78000 of ranks=144106rank=78100 of ranks=144106rank=78200 of ranks=144106rank=78300 of ranks=144106rank=78400 of ranks=144106rank=78500 of ranks=144106rank=78600 of ranks=144106rank=78700 of ranks=144106rank=78800 of ranks=144106rank=78900 of ranks=144106rank=79000 of ranks=144106rank=79100 of ranks=144106rank=79200 of ranks=144106rank=79300 of ranks=144106rank=79400 of ranks=144106rank=79500 of ranks=144106rank=79600 of ranks=144106rank=79700 of ranks=144106rank=79800 of ranks=144106rank=79900 of ranks=144106rank=80000 of ranks=144106rank=80100 of ranks=144106rank=80200 of ranks=144106rank=80300 of ranks=144106rank=80400 of ranks=144106rank=80500 of ranks=144106rank=80600 of ranks=144106rank=80700 of ranks=144106rank=80800 of ranks=144106rank=80900 of ranks=144106rank=81000 of ranks=144106rank=81100 of ranks=144106rank=81200 of ranks=144106rank=81300 of ranks=144106rank=81400 of ranks=144106rank=81500 of ranks=144106rank=81600 of ranks=144106rank=81700 of ranks=144106rank=81800 of ranks=144106rank=81900 of ranks=144106rank=82000 of ranks=144106rank=82100 of ranks=144106rank=82200 of ranks=144106rank=82300 of ranks=144106rank=82400 of ranks=144106rank=82500 of ranks=144106rank=82600 of ranks=144106rank=82700 of ranks=144106rank=82800 of ranks=144106rank=82900 of ranks=144106rank=83000 of ranks=144106rank=83100 of ranks=144106rank=83200 of ranks=144106rank=83300 of ranks=144106rank=83400 of ranks=144106rank=83500 of ranks=144106rank=83600 of ranks=144106rank=83700 of ranks=144106rank=83800 of ranks=144106rank=83900 of ranks=144106rank=84000 of ranks=144106rank=84100 of ranks=144106rank=84200 of ranks=144106rank=84300 of ranks=144106rank=84400 of ranks=144106rank=84500 of ranks=144106rank=84600 of ranks=144106rank=84700 of ranks=144106rank=84800 of ranks=144106rank=84900 of ranks=144106rank=85000 of ranks=144106rank=85100 of ranks=144106rank=85200 of ranks=144106rank=85300 of ranks=144106rank=85400 of ranks=144106rank=85500 of ranks=144106rank=85600 of ranks=144106rank=85700 of ranks=144106rank=85800 of ranks=144106rank=85900 of ranks=144106rank=86000 of ranks=144106rank=86100 of ranks=144106rank=86200 of ranks=144106rank=86300 of ranks=144106rank=86400 of ranks=144106rank=86500 of ranks=144106rank=86600 of ranks=144106rank=86700 of ranks=144106rank=86800 of ranks=144106rank=86900 of ranks=144106rank=87000 of ranks=144106rank=87100 of ranks=144106rank=87200 of ranks=144106rank=87300 of ranks=144106rank=87400 of ranks=144106rank=87500 of ranks=144106rank=87600 of ranks=144106rank=87700 of ranks=144106rank=87800 of ranks=144106rank=87900 of ranks=144106rank=88000 of ranks=144106rank=88100 of ranks=144106rank=88200 of ranks=144106rank=88300 of ranks=144106rank=88400 of ranks=144106rank=88500 of ranks=144106rank=88600 of ranks=144106rank=88700 of ranks=144106rank=88800 of ranks=144106rank=88900 of ranks=144106rank=89000 of ranks=144106rank=89100 of ranks=144106rank=89200 of ranks=144106rank=89300 of ranks=144106rank=89400 of ranks=144106rank=89500 of ranks=144106rank=89600 of ranks=144106rank=89700 of ranks=144106rank=89800 of ranks=144106rank=89900 of ranks=144106rank=90000 of ranks=144106rank=90100 of ranks=144106rank=90200 of ranks=144106rank=90300 of ranks=144106rank=90400 of ranks=144106rank=90500 of ranks=144106rank=90600 of ranks=144106rank=90700 of ranks=144106rank=90800 of ranks=144106rank=90900 of ranks=144106rank=91000 of ranks=144106rank=91100 of ranks=144106rank=91200 of ranks=144106rank=91300 of ranks=144106rank=91400 of ranks=144106rank=91500 of ranks=144106rank=91600 of ranks=144106rank=91700 of ranks=144106rank=91800 of ranks=144106rank=91900 of ranks=144106rank=92000 of ranks=144106rank=92100 of ranks=144106rank=92200 of ranks=144106rank=92300 of ranks=144106rank=92400 of ranks=144106rank=92500 of ranks=144106rank=92600 of ranks=144106rank=92700 of ranks=144106rank=92800 of ranks=144106rank=92900 of ranks=144106rank=93000 of ranks=144106rank=93100 of ranks=144106rank=93200 of ranks=144106rank=93300 of ranks=144106rank=93400 of ranks=144106rank=93500 of ranks=144106rank=93600 of ranks=144106rank=93700 of ranks=144106rank=93800 of ranks=144106rank=93900 of ranks=144106rank=94000 of ranks=144106rank=94100 of ranks=144106rank=94200 of ranks=144106rank=94300 of ranks=144106rank=94400 of ranks=144106rank=94500 of ranks=144106rank=94600 of ranks=144106rank=94700 of ranks=144106rank=94800 of ranks=144106rank=94900 of ranks=144106rank=95000 of ranks=144106rank=95100 of ranks=144106rank=95200 of ranks=144106rank=95300 of ranks=144106rank=95400 of ranks=144106rank=95500 of ranks=144106rank=95600 of ranks=144106rank=95700 of ranks=144106rank=95800 of ranks=144106rank=95900 of ranks=144106rank=96000 of ranks=144106rank=96100 of ranks=144106rank=96200 of ranks=144106rank=96300 of ranks=144106rank=96400 of ranks=144106rank=96500 of ranks=144106rank=96600 of ranks=144106rank=96700 of ranks=144106rank=96800 of ranks=144106rank=96900 of ranks=144106rank=97000 of ranks=144106rank=97100 of ranks=144106rank=97200 of ranks=144106rank=97300 of ranks=144106rank=97400 of ranks=144106rank=97500 of ranks=144106rank=97600 of ranks=144106rank=97700 of ranks=144106rank=97800 of ranks=144106rank=97900 of ranks=144106rank=98000 of ranks=144106rank=98100 of ranks=144106rank=98200 of ranks=144106rank=98300 of ranks=144106rank=98400 of ranks=144106rank=98500 of ranks=144106rank=98600 of ranks=144106rank=98700 of ranks=144106rank=98800 of ranks=144106rank=98900 of ranks=144106rank=99000 of ranks=144106rank=99100 of ranks=144106rank=99200 of ranks=144106rank=99300 of ranks=144106rank=99400 of ranks=144106rank=99500 of ranks=144106rank=99600 of ranks=144106rank=99700 of ranks=144106rank=99800 of ranks=144106rank=99900 of ranks=144106rank=100000 of ranks=144106rank=100100 of ranks=144106rank=100200 of ranks=144106rank=100300 of ranks=144106rank=100400 of ranks=144106rank=100500 of ranks=144106rank=100600 of ranks=144106rank=100700 of ranks=144106rank=100800 of ranks=144106rank=100900 of ranks=144106rank=101000 of ranks=144106rank=101100 of ranks=144106rank=101200 of ranks=144106rank=101300 of ranks=144106rank=101400 of ranks=144106rank=101500 of ranks=144106rank=101600 of ranks=144106rank=101700 of ranks=144106rank=101800 of ranks=144106rank=101900 of ranks=144106rank=102000 of ranks=144106rank=102100 of ranks=144106rank=102200 of ranks=144106rank=102300 of ranks=144106rank=102400 of ranks=144106rank=102500 of ranks=144106rank=102600 of ranks=144106rank=102700 of ranks=144106rank=102800 of ranks=144106rank=102900 of ranks=144106rank=103000 of ranks=144106rank=103100 of ranks=144106rank=103200 of ranks=144106rank=103300 of ranks=144106rank=103400 of ranks=144106rank=103500 of ranks=144106rank=103600 of ranks=144106rank=103700 of ranks=144106rank=103800 of ranks=144106rank=103900 of ranks=144106rank=104000 of ranks=144106rank=104100 of ranks=144106rank=104200 of ranks=144106rank=104300 of ranks=144106rank=104400 of ranks=144106rank=104500 of ranks=144106rank=104600 of ranks=144106rank=104700 of ranks=144106rank=104800 of ranks=144106rank=104900 of ranks=144106rank=105000 of ranks=144106rank=105100 of ranks=144106rank=105200 of ranks=144106rank=105300 of ranks=144106rank=105400 of ranks=144106rank=105500 of ranks=144106rank=105600 of ranks=144106rank=105700 of ranks=144106rank=105800 of ranks=144106rank=105900 of ranks=144106rank=106000 of ranks=144106rank=106100 of ranks=144106rank=106200 of ranks=144106rank=106300 of ranks=144106rank=106400 of ranks=144106rank=106500 of ranks=144106rank=106600 of ranks=144106rank=106700 of ranks=144106rank=106800 of ranks=144106rank=106900 of ranks=144106rank=107000 of ranks=144106rank=107100 of ranks=144106rank=107200 of ranks=144106rank=107300 of ranks=144106rank=107400 of ranks=144106rank=107500 of ranks=144106rank=107600 of ranks=144106rank=107700 of ranks=144106rank=107800 of ranks=144106rank=107900 of ranks=144106rank=108000 of ranks=144106rank=108100 of ranks=144106rank=108200 of ranks=144106rank=108300 of ranks=144106rank=108400 of ranks=144106rank=108500 of ranks=144106rank=108600 of ranks=144106rank=108700 of ranks=144106rank=108800 of ranks=144106rank=108900 of ranks=144106rank=109000 of ranks=144106rank=109100 of ranks=144106rank=109200 of ranks=144106rank=109300 of ranks=144106rank=109400 of ranks=144106rank=109500 of ranks=144106rank=109600 of ranks=144106rank=109700 of ranks=144106rank=109800 of ranks=144106rank=109900 of ranks=144106rank=110000 of ranks=144106rank=110100 of ranks=144106rank=110200 of ranks=144106rank=110300 of ranks=144106rank=110400 of ranks=144106rank=110500 of ranks=144106rank=110600 of ranks=144106rank=110700 of ranks=144106rank=110800 of ranks=144106rank=110900 of ranks=144106rank=111000 of ranks=144106rank=111100 of ranks=144106rank=111200 of ranks=144106rank=111300 of ranks=144106rank=111400 of ranks=144106rank=111500 of ranks=144106rank=111600 of ranks=144106rank=111700 of ranks=144106rank=111800 of ranks=144106rank=111900 of ranks=144106rank=112000 of ranks=144106rank=112100 of ranks=144106rank=112200 of ranks=144106rank=112300 of ranks=144106rank=112400 of ranks=144106rank=112500 of ranks=144106rank=112600 of ranks=144106rank=112700 of ranks=144106rank=112800 of ranks=144106rank=112900 of ranks=144106rank=113000 of ranks=144106rank=113100 of ranks=144106rank=113200 of ranks=144106rank=113300 of ranks=144106rank=113400 of ranks=144106rank=113500 of ranks=144106rank=113600 of ranks=144106rank=113700 of ranks=144106rank=113800 of ranks=144106rank=113900 of ranks=144106rank=114000 of ranks=144106rank=114100 of ranks=144106rank=114200 of ranks=144106rank=114300 of ranks=144106rank=114400 of ranks=144106rank=114500 of ranks=144106rank=114600 of ranks=144106rank=114700 of ranks=144106rank=114800 of ranks=144106rank=114900 of ranks=144106rank=115000 of ranks=144106rank=115100 of ranks=144106rank=115200 of ranks=144106rank=115300 of ranks=144106rank=115400 of ranks=144106rank=115500 of ranks=144106rank=115600 of ranks=144106rank=115700 of ranks=144106rank=115800 of ranks=144106rank=115900 of ranks=144106rank=116000 of ranks=144106rank=116100 of ranks=144106rank=116200 of ranks=144106rank=116300 of ranks=144106rank=116400 of ranks=144106rank=116500 of ranks=144106rank=116600 of ranks=144106rank=116700 of ranks=144106rank=116800 of ranks=144106rank=116900 of ranks=144106rank=117000 of ranks=144106rank=117100 of ranks=144106rank=117200 of ranks=144106rank=117300 of ranks=144106rank=117400 of ranks=144106rank=117500 of ranks=144106rank=117600 of ranks=144106rank=117700 of ranks=144106rank=117800 of ranks=144106rank=117900 of ranks=144106rank=118000 of ranks=144106rank=118100 of ranks=144106rank=118200 of ranks=144106rank=118300 of ranks=144106rank=118400 of ranks=144106rank=118500 of ranks=144106rank=118600 of ranks=144106rank=118700 of ranks=144106rank=118800 of ranks=144106rank=118900 of ranks=144106rank=119000 of ranks=144106rank=119100 of ranks=144106rank=119200 of ranks=144106rank=119300 of ranks=144106rank=119400 of ranks=144106rank=119500 of ranks=144106rank=119600 of ranks=144106rank=119700 of ranks=144106rank=119800 of ranks=144106rank=119900 of ranks=144106rank=120000 of ranks=144106rank=120100 of ranks=144106rank=120200 of ranks=144106rank=120300 of ranks=144106rank=120400 of ranks=144106rank=120500 of ranks=144106rank=120600 of ranks=144106rank=120700 of ranks=144106rank=120800 of ranks=144106rank=120900 of ranks=144106rank=121000 of ranks=144106rank=121100 of ranks=144106rank=121200 of ranks=144106rank=121300 of ranks=144106rank=121400 of ranks=144106rank=121500 of ranks=144106rank=121600 of ranks=144106rank=121700 of ranks=144106rank=121800 of ranks=144106rank=121900 of ranks=144106rank=122000 of ranks=144106rank=122100 of ranks=144106rank=122200 of ranks=144106rank=122300 of ranks=144106rank=122400 of ranks=144106rank=122500 of ranks=144106rank=122600 of ranks=144106rank=122700 of ranks=144106rank=122800 of ranks=144106rank=122900 of ranks=144106rank=123000 of ranks=144106rank=123100 of ranks=144106rank=123200 of ranks=144106rank=123300 of ranks=144106rank=123400 of ranks=144106rank=123500 of ranks=144106rank=123600 of ranks=144106rank=123700 of ranks=144106rank=123800 of ranks=144106rank=123900 of ranks=144106rank=124000 of ranks=144106rank=124100 of ranks=144106rank=124200 of ranks=144106rank=124300 of ranks=144106rank=124400 of ranks=144106rank=124500 of ranks=144106rank=124600 of ranks=144106rank=124700 of ranks=144106rank=124800 of ranks=144106rank=124900 of ranks=144106rank=125000 of ranks=144106rank=125100 of ranks=144106rank=125200 of ranks=144106rank=125300 of ranks=144106rank=125400 of ranks=144106rank=125500 of ranks=144106rank=125600 of ranks=144106rank=125700 of ranks=144106rank=125800 of ranks=144106rank=125900 of ranks=144106rank=126000 of ranks=144106rank=126100 of ranks=144106rank=126200 of ranks=144106rank=126300 of ranks=144106rank=126400 of ranks=144106rank=126500 of ranks=144106rank=126600 of ranks=144106rank=126700 of ranks=144106rank=126800 of ranks=144106rank=126900 of ranks=144106rank=127000 of ranks=144106rank=127100 of ranks=144106rank=127200 of ranks=144106rank=127300 of ranks=144106rank=127400 of ranks=144106rank=127500 of ranks=144106rank=127600 of ranks=144106rank=127700 of ranks=144106rank=127800 of ranks=144106rank=127900 of ranks=144106rank=128000 of ranks=144106rank=128100 of ranks=144106rank=128200 of ranks=144106rank=128300 of ranks=144106rank=128400 of ranks=144106rank=128500 of ranks=144106rank=128600 of ranks=144106rank=128700 of ranks=144106rank=128800 of ranks=144106rank=128900 of ranks=144106rank=129000 of ranks=144106rank=129100 of ranks=144106rank=129200 of ranks=144106rank=129300 of ranks=144106rank=129400 of ranks=144106rank=129500 of ranks=144106rank=129600 of ranks=144106rank=129700 of ranks=144106rank=129800 of ranks=144106rank=129900 of ranks=144106rank=130000 of ranks=144106rank=130100 of ranks=144106rank=130200 of ranks=144106rank=130300 of ranks=144106rank=130400 of ranks=144106rank=130500 of ranks=144106rank=130600 of ranks=144106rank=130700 of ranks=144106rank=130800 of ranks=144106rank=130900 of ranks=144106rank=131000 of ranks=144106rank=131100 of ranks=144106rank=131200 of ranks=144106rank=131300 of ranks=144106rank=131400 of ranks=144106rank=131500 of ranks=144106rank=131600 of ranks=144106rank=131700 of ranks=144106rank=131800 of ranks=144106rank=131900 of ranks=144106rank=132000 of ranks=144106rank=132100 of ranks=144106rank=132200 of ranks=144106rank=132300 of ranks=144106rank=132400 of ranks=144106rank=132500 of ranks=144106rank=132600 of ranks=144106rank=132700 of ranks=144106rank=132800 of ranks=144106rank=132900 of ranks=144106rank=133000 of ranks=144106rank=133100 of ranks=144106rank=133200 of ranks=144106rank=133300 of ranks=144106rank=133400 of ranks=144106rank=133500 of ranks=144106rank=133600 of ranks=144106rank=133700 of ranks=144106rank=133800 of ranks=144106rank=133900 of ranks=144106rank=134000 of ranks=144106rank=134100 of ranks=144106rank=134200 of ranks=144106rank=134300 of ranks=144106rank=134400 of ranks=144106rank=134500 of ranks=144106rank=134600 of ranks=144106rank=134700 of ranks=144106rank=134800 of ranks=144106rank=134900 of ranks=144106rank=135000 of ranks=144106rank=135100 of ranks=144106rank=135200 of ranks=144106rank=135300 of ranks=144106rank=135400 of ranks=144106rank=135500 of ranks=144106rank=135600 of ranks=144106rank=135700 of ranks=144106rank=135800 of ranks=144106rank=135900 of ranks=144106rank=136000 of ranks=144106rank=136100 of ranks=144106rank=136200 of ranks=144106rank=136300 of ranks=144106rank=136400 of ranks=144106rank=136500 of ranks=144106rank=136600 of ranks=144106rank=136700 of ranks=144106rank=136800 of ranks=144106rank=136900 of ranks=144106rank=137000 of ranks=144106rank=137100 of ranks=144106rank=137200 of ranks=144106rank=137300 of ranks=144106rank=137400 of ranks=144106rank=137500 of ranks=144106rank=137600 of ranks=144106rank=137700 of ranks=144106rank=137800 of ranks=144106rank=137900 of ranks=144106rank=138000 of ranks=144106rank=138100 of ranks=144106rank=138200 of ranks=144106rank=138300 of ranks=144106rank=138400 of ranks=144106rank=138500 of ranks=144106rank=138600 of ranks=144106rank=138700 of ranks=144106rank=138800 of ranks=144106rank=138900 of ranks=144106rank=139000 of ranks=144106rank=139100 of ranks=144106rank=139200 of ranks=144106rank=139300 of ranks=144106rank=139400 of ranks=144106rank=139500 of ranks=144106rank=139600 of ranks=144106rank=139700 of ranks=144106rank=139800 of ranks=144106rank=139900 of ranks=144106rank=140000 of ranks=144106rank=140100 of ranks=144106rank=140200 of ranks=144106rank=140300 of ranks=144106rank=140400 of ranks=144106rank=140500 of ranks=144106rank=140600 of ranks=144106rank=140700 of ranks=144106rank=140800 of ranks=144106rank=140900 of ranks=144106rank=141000 of ranks=144106rank=141100 of ranks=144106rank=141200 of ranks=144106rank=141300 of ranks=144106rank=141400 of ranks=144106rank=141500 of ranks=144106rank=141600 of ranks=144106rank=141700 of ranks=144106rank=141800 of ranks=144106rank=141900 of ranks=144106rank=142000 of ranks=144106rank=142100 of ranks=144106rank=142200 of ranks=144106rank=142300 of ranks=144106rank=142400 of ranks=144106rank=142500 of ranks=144106rank=142600 of ranks=144106rank=142700 of ranks=144106rank=142800 of ranks=144106rank=142900 of ranks=144106rank=143000 of ranks=144106rank=143100 of ranks=144106rank=143200 of ranks=144106rank=143300 of ranks=144106rank=143400 of ranks=144106rank=143500 of ranks=144106rank=143600 of ranks=144106rank=143700 of ranks=144106rank=143800 of ranks=144106rank=143900 of ranks=144106rank=144000 of ranks=144106rank=144100 of ranks=144106

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              86.2181    463   3649     35    498           76.9108
   1 car                    96.6773  49796  57454    520  50316           71.7200
   2 truck                  83.9323   1747  11282     78   1825           58.1470
   3 bus                    70.3279    347   4255     19    366           74.8990
   4 pedestrian             87.5942   3978  11135    281   4259           66.2702

for conf_thresh=0.25, precision=0.83, recall=0.91, F1 score=0.87
for conf_thresh=0.25, TP=52370, FP=10929, FN=4894, average IoU=71.04%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=84.95%
Total detection time: 195 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
3437: loss=4.890, avg loss=5.947, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 219968 images, time remaining=5.5 hours
3438: loss=5.329, avg loss=5.885, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.2 seconds, train=2.7 seconds, 220032 images, time remaining=5.5 hours
3439: loss=4.523, avg loss=5.749, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 220096 images, time remaining=5.5 hours
3440: loss=5.964, avg loss=5.771, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 220160 images, time remaining=5.5 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af9e000000
3441: loss=5.341, avg loss=5.728, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 220224 images, time remaining=5.5 hours
3442: loss=5.061, avg loss=5.661, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 220288 images, time remaining=5.5 hours
3443: loss=4.712, avg loss=5.566, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 220352 images, time remaining=5.5 hours
3444: loss=4.943, avg loss=5.504, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 220416 images, time remaining=5.5 hours
3445: loss=4.908, avg loss=5.444, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=4.0 seconds, 220480 images, time remaining=5.5 hours
3446: loss=5.389, avg loss=5.439, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 220544 images, time remaining=5.5 hours
3447: loss=5.510, avg loss=5.446, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=3.8 seconds, 220608 images, time remaining=5.5 hours
3448: loss=4.528, avg loss=5.354, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.6 seconds, train=3.9 seconds, 220672 images, time remaining=5.5 hours
3449: loss=4.755, avg loss=5.294, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 220736 images, time remaining=5.5 hours
3450: loss=4.807, avg loss=5.245, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 220800 images, time remaining=5.5 hours
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af9e000000
3451: loss=7.038, avg loss=5.425, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=6.1 seconds, 220864 images, time remaining=5.5 hours
3452: loss=5.471, avg loss=5.429, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 220928 images, time remaining=5.5 hours
3453: loss=5.924, avg loss=5.479, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 220992 images, time remaining=5.5 hours
3454: loss=5.830, avg loss=5.514, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=6.1 seconds, 221056 images, time remaining=5.5 hours
3455: loss=5.459, avg loss=5.508, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=6.1 seconds, 221120 images, time remaining=5.5 hours
3456: loss=6.559, avg loss=5.613, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 221184 images, time remaining=5.5 hours
3457: loss=4.802, avg loss=5.532, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 221248 images, time remaining=5.5 hours
3458: loss=5.445, avg loss=5.523, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 221312 images, time remaining=5.5 hours
3459: loss=5.713, avg loss=5.542, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=6.1 seconds, 221376 images, time remaining=5.5 hours
3460: loss=5.270, avg loss=5.515, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 221440 images, time remaining=5.5 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2b0000000
3461: loss=6.470, avg loss=5.611, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 221504 images, time remaining=5.5 hours
3462: loss=5.730, avg loss=5.623, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.9 seconds, 221568 images, time remaining=5.5 hours
3463: loss=5.878, avg loss=5.648, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.9 seconds, 221632 images, time remaining=5.5 hours
3464: loss=5.374, avg loss=5.621, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 221696 images, time remaining=5.5 hours
3465: loss=4.811, avg loss=5.540, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.9 seconds, 221760 images, time remaining=5.5 hours
3466: loss=4.510, avg loss=5.437, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 221824 images, time remaining=5.5 hours
3467: loss=4.691, avg loss=5.362, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 221888 images, time remaining=5.5 hours
3468: loss=5.242, avg loss=5.350, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 221952 images, time remaining=5.5 hours
3469: loss=4.771, avg loss=5.292, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=2.8 seconds, 222016 images, time remaining=5.5 hours
3470: loss=5.088, avg loss=5.272, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 222080 images, time remaining=5.5 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b2b8000000
3471: loss=4.347, avg loss=5.179, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 222144 images, time remaining=5.5 hours
3472: loss=4.670, avg loss=5.128, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 222208 images, time remaining=5.5 hours
3473: loss=5.401, avg loss=5.156, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 222272 images, time remaining=5.5 hours
3474: loss=4.562, avg loss=5.096, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 222336 images, time remaining=5.4 hours
3475: loss=4.354, avg loss=5.022, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 222400 images, time remaining=5.4 hours
3476: loss=5.413, avg loss=5.061, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 222464 images, time remaining=5.4 hours
3477: loss=4.710, avg loss=5.026, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 222528 images, time remaining=5.4 hours
3478: loss=4.169, avg loss=4.940, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 222592 images, time remaining=5.4 hours
3479: loss=5.441, avg loss=4.990, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 222656 images, time remaining=5.4 hours
3480: loss=4.846, avg loss=4.976, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 222720 images, time remaining=5.4 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2b0000000
3481: loss=4.989, avg loss=4.977, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.6 seconds, train=2.7 seconds, 222784 images, time remaining=5.4 hours
3482: loss=5.909, avg loss=5.070, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 222848 images, time remaining=5.4 hours
3483: loss=4.217, avg loss=4.985, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.6 seconds, 222912 images, time remaining=5.4 hours
3484: loss=4.606, avg loss=4.947, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 222976 images, time remaining=5.4 hours
3485: loss=4.092, avg loss=4.862, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 223040 images, time remaining=5.4 hours
3486: loss=4.938, avg loss=4.869, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 223104 images, time remaining=5.4 hours
3487: loss=4.386, avg loss=4.821, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 223168 images, time remaining=5.4 hours
3488: loss=3.737, avg loss=4.713, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 223232 images, time remaining=5.4 hours
3489: loss=4.669, avg loss=4.708, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=2.7 seconds, 223296 images, time remaining=5.4 hours
3490: loss=4.225, avg loss=4.660, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 223360 images, time remaining=5.4 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3491: loss=4.872, avg loss=4.681, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=4.5 seconds, 223424 images, time remaining=5.4 hours
3492: loss=5.039, avg loss=4.717, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 223488 images, time remaining=5.4 hours
3493: loss=4.128, avg loss=4.658, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 223552 images, time remaining=5.4 hours
3494: loss=4.529, avg loss=4.645, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 223616 images, time remaining=5.4 hours
3495: loss=3.692, avg loss=4.550, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 223680 images, time remaining=5.4 hours
3496: loss=5.182, avg loss=4.613, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=4.3 seconds, 223744 images, time remaining=5.4 hours
3497: loss=4.065, avg loss=4.558, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 223808 images, time remaining=5.4 hours
3498: loss=4.781, avg loss=4.580, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=4.3 seconds, 223872 images, time remaining=5.4 hours
3499: loss=3.946, avg loss=4.517, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.7 seconds, train=4.4 seconds, 223936 images, time remaining=5.4 hours
3500: loss=4.760, avg loss=4.541, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 224000 images, time remaining=5.4 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b697a00000
3501: loss=5.973, avg loss=4.685, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 224064 images, time remaining=5.4 hours
3502: loss=5.266, avg loss=4.743, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 224128 images, time remaining=5.4 hours
3503: loss=5.736, avg loss=4.842, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 224192 images, time remaining=5.4 hours
3504: loss=4.630, avg loss=4.821, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 224256 images, time remaining=5.4 hours
3505: loss=4.157, avg loss=4.754, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 224320 images, time remaining=5.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3506: loss=4.166, avg loss=4.696, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.8 seconds, train=2.2 seconds, 224384 images, time remaining=5.4 hours
3507: loss=4.494, avg loss=4.675, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 224448 images, time remaining=5.4 hours
3508: loss=4.795, avg loss=4.687, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=2.2 seconds, 224512 images, time remaining=5.4 hours
3509: loss=4.699, avg loss=4.689, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 224576 images, time remaining=5.4 hours
3510: loss=4.864, avg loss=4.706, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 224640 images, time remaining=5.4 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3511: loss=10.645, avg loss=5.300, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 224704 images, time remaining=5.4 hours
3512: loss=9.175, avg loss=5.688, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 224768 images, time remaining=5.4 hours
3513: loss=5.979, avg loss=5.717, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 224832 images, time remaining=5.4 hours
3514: loss=4.978, avg loss=5.643, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 224896 images, time remaining=5.4 hours
3515: loss=6.929, avg loss=5.771, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 224960 images, time remaining=5.4 hours
3516: loss=6.750, avg loss=5.869, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 225024 images, time remaining=5.4 hours
3517: loss=6.324, avg loss=5.915, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 225088 images, time remaining=5.4 hours
3518: loss=6.519, avg loss=5.975, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 225152 images, time remaining=5.4 hours
3519: loss=6.525, avg loss=6.030, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 225216 images, time remaining=5.4 hours
3520: loss=6.122, avg loss=6.039, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.4 seconds, train=5.8 seconds, 225280 images, time remaining=5.4 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3521: loss=7.260, avg loss=6.161, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.2 seconds, train=5.7 seconds, 225344 images, time remaining=5.4 hours
3522: loss=7.556, avg loss=6.301, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.2 seconds, train=5.7 seconds, 225408 images, time remaining=5.4 hours
3523: loss=5.898, avg loss=6.261, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 225472 images, time remaining=5.4 hours
3524: loss=5.948, avg loss=6.229, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 225536 images, time remaining=5.4 hours
3525: loss=6.159, avg loss=6.222, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 225600 images, time remaining=5.4 hours
3526: loss=5.339, avg loss=6.134, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 225664 images, time remaining=5.4 hours
3527: loss=6.246, avg loss=6.145, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 225728 images, time remaining=5.4 hours
3528: loss=5.949, avg loss=6.125, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 225792 images, time remaining=5.4 hours
3529: loss=5.479, avg loss=6.061, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 225856 images, time remaining=5.4 hours
3530: loss=7.213, avg loss=6.176, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 225920 images, time remaining=5.4 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b316000000
3531: loss=7.543, avg loss=6.313, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 225984 images, time remaining=5.4 hours
3532: loss=7.234, avg loss=6.405, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.1 seconds, train=2.3 seconds, 226048 images, time remaining=5.4 hours
3533: loss=6.690, avg loss=6.433, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 226112 images, time remaining=5.4 hours
3534: loss=5.365, avg loss=6.327, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 226176 images, time remaining=5.4 hours
3535: loss=5.654, avg loss=6.259, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 226240 images, time remaining=5.4 hours
3536: loss=5.067, avg loss=6.140, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 226304 images, time remaining=5.4 hours
3537: loss=5.194, avg loss=6.045, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 226368 images, time remaining=5.4 hours
3538: loss=6.441, avg loss=6.085, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 226432 images, time remaining=5.4 hours
3539: loss=6.078, avg loss=6.084, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 226496 images, time remaining=5.4 hours
3540: loss=5.886, avg loss=6.064, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 226560 images, time remaining=5.4 hours
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3541: loss=13.641, avg loss=6.822, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=5.6 seconds, 226624 images, time remaining=5.4 hours
3542: loss=10.870, avg loss=7.227, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 226688 images, time remaining=5.4 hours
3543: loss=7.387, avg loss=7.243, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=3.1 seconds, train=5.6 seconds, 226752 images, time remaining=5.4 hours
3544: loss=6.730, avg loss=7.192, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 226816 images, time remaining=5.4 hours
3545: loss=7.121, avg loss=7.185, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 226880 images, time remaining=5.4 hours
3546: loss=7.582, avg loss=7.224, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 226944 images, time remaining=5.4 hours
3547: loss=7.262, avg loss=7.228, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 227008 images, time remaining=5.4 hours
3548: loss=6.046, avg loss=7.110, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 227072 images, time remaining=5.4 hours
3549: loss=8.504, avg loss=7.249, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 227136 images, time remaining=5.4 hours
3550: loss=6.989, avg loss=7.223, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.3 seconds, train=5.7 seconds, 227200 images, time remaining=5.4 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b30e000000
3551: loss=7.516, avg loss=7.253, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 227264 images, time remaining=5.4 hours
3552: loss=6.484, avg loss=7.176, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.6 seconds, 227328 images, time remaining=5.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3553: loss=6.169, avg loss=7.075, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.7 seconds, train=2.6 seconds, 227392 images, time remaining=5.4 hours
3554: loss=7.161, avg loss=7.084, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 227456 images, time remaining=5.3 hours
3555: loss=7.901, avg loss=7.165, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 227520 images, time remaining=5.3 hours
3556: loss=5.829, avg loss=7.032, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.6 seconds, 227584 images, time remaining=5.3 hours
3557: loss=6.589, avg loss=6.988, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.5 seconds, train=2.7 seconds, 227648 images, time remaining=5.3 hours
3558: loss=6.169, avg loss=6.906, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 227712 images, time remaining=5.3 hours
3559: loss=4.852, avg loss=6.700, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 227776 images, time remaining=5.3 hours
3560: loss=5.085, avg loss=6.539, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 227840 images, time remaining=5.3 hours
Resizing, random_coef=1.40, batch=4, 1344x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3561: loss=9.161, avg loss=6.801, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 227904 images, time remaining=5.3 hours
3562: loss=8.880, avg loss=7.009, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 227968 images, time remaining=5.3 hours
3563: loss=7.756, avg loss=7.084, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 228032 images, time remaining=5.3 hours
3564: loss=6.860, avg loss=7.061, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 228096 images, time remaining=5.3 hours
3565: loss=7.022, avg loss=7.057, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.4 seconds, train=6.1 seconds, 228160 images, time remaining=5.3 hours
3566: loss=5.999, avg loss=6.952, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=6.0 seconds, 228224 images, time remaining=5.3 hours
3567: loss=6.279, avg loss=6.884, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 228288 images, time remaining=5.3 hours
3568: loss=5.617, avg loss=6.758, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.2 seconds, train=5.8 seconds, 228352 images, time remaining=5.3 hours
3569: loss=6.362, avg loss=6.718, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.6 seconds, train=5.9 seconds, 228416 images, time remaining=5.3 hours
3570: loss=5.684, avg loss=6.615, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=5.8 seconds, 228480 images, time remaining=5.3 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3571: loss=6.701, avg loss=6.623, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 228544 images, time remaining=5.3 hours
3572: loss=5.850, avg loss=6.546, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=4.7 seconds, 228608 images, time remaining=5.3 hours
3573: loss=6.310, avg loss=6.522, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=4.8 seconds, 228672 images, time remaining=5.3 hours
3574: loss=5.228, avg loss=6.393, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=4.7 seconds, 228736 images, time remaining=5.3 hours
3575: loss=6.221, avg loss=6.376, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=5.0 seconds, 228800 images, time remaining=5.3 hours
3576: loss=6.571, avg loss=6.395, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 228864 images, time remaining=5.3 hours
3577: loss=5.579, avg loss=6.314, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.5 seconds, 228928 images, time remaining=5.3 hours
3578: loss=5.744, avg loss=6.257, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=3.9 seconds, train=4.7 seconds, 228992 images, time remaining=5.3 hours
3579: loss=5.308, avg loss=6.162, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 229056 images, time remaining=5.3 hours
3580: loss=5.345, avg loss=6.080, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=4.6 seconds, 229120 images, time remaining=5.3 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b316000000
3581: loss=6.595, avg loss=6.132, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 229184 images, time remaining=5.3 hours
3582: loss=7.061, avg loss=6.225, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=2.2 seconds, 229248 images, time remaining=5.3 hours
3583: loss=5.809, avg loss=6.183, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 229312 images, time remaining=5.3 hours
3584: loss=5.238, avg loss=6.089, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=2.1 seconds, 229376 images, time remaining=5.3 hours
3585: loss=5.606, avg loss=6.040, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 229440 images, time remaining=5.3 hours
3586: loss=5.047, avg loss=5.941, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 229504 images, time remaining=5.3 hours
3587: loss=4.811, avg loss=5.828, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 229568 images, time remaining=5.3 hours
3588: loss=5.366, avg loss=5.782, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 229632 images, time remaining=5.3 hours
3589: loss=5.571, avg loss=5.761, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 229696 images, time remaining=5.3 hours
3590: loss=4.331, avg loss=5.618, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 229760 images, time remaining=5.3 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3591: loss=5.910, avg loss=5.647, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=4.1 seconds, 229824 images, time remaining=5.3 hours
3592: loss=5.369, avg loss=5.619, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=4.1 seconds, 229888 images, time remaining=5.3 hours
3593: loss=6.425, avg loss=5.700, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 229952 images, time remaining=5.3 hours
3594: loss=6.037, avg loss=5.733, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.2 seconds, train=4.1 seconds, 230016 images, time remaining=5.3 hours
3595: loss=5.671, avg loss=5.727, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 230080 images, time remaining=5.3 hours
3596: loss=4.257, avg loss=5.580, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 230144 images, time remaining=5.3 hours
3597: loss=4.882, avg loss=5.510, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 230208 images, time remaining=5.3 hours
3598: loss=4.556, avg loss=5.415, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.9 seconds, train=4.1 seconds, 230272 images, time remaining=5.3 hours
3599: loss=6.200, avg loss=5.493, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=4.1 seconds, 230336 images, time remaining=5.3 hours
3600: loss=5.469, avg loss=5.491, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 230400 images, time remaining=5.3 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b673400000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3601: loss=6.050, avg loss=5.547, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=3.3 seconds, train=2.3 seconds, 230464 images, time remaining=5.3 hours
3602: loss=6.131, avg loss=5.605, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 230528 images, time remaining=5.3 hours
3603: loss=5.262, avg loss=5.571, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 230592 images, time remaining=5.3 hours
3604: loss=5.455, avg loss=5.559, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 230656 images, time remaining=5.3 hours
3605: loss=4.687, avg loss=5.472, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=2.3 seconds, 230720 images, time remaining=5.3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3606: loss=4.093, avg loss=5.334, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.3 seconds, train=2.2 seconds, 230784 images, time remaining=5.3 hours
3607: loss=4.068, avg loss=5.208, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 230848 images, time remaining=5.3 hours
3608: loss=4.174, avg loss=5.104, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=2.4 seconds, 230912 images, time remaining=5.3 hours
3609: loss=4.141, avg loss=5.008, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 230976 images, time remaining=5.3 hours
3610: loss=5.730, avg loss=5.080, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 231040 images, time remaining=5.3 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b4b4000000
3611: loss=4.427, avg loss=5.015, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.9 seconds, 231104 images, time remaining=5.3 hours
3612: loss=5.725, avg loss=5.086, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=2.6 seconds, 231168 images, time remaining=5.3 hours
3613: loss=5.263, avg loss=5.104, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 231232 images, time remaining=5.3 hours
3614: loss=4.597, avg loss=5.053, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 231296 images, time remaining=5.3 hours
3615: loss=4.581, avg loss=5.006, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 231360 images, time remaining=5.3 hours
3616: loss=5.021, avg loss=5.007, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=2.7 seconds, 231424 images, time remaining=5.3 hours
3617: loss=4.259, avg loss=4.932, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 231488 images, time remaining=5.3 hours
3618: loss=5.015, avg loss=4.941, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=2.5 seconds, 231552 images, time remaining=5.3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3619: loss=3.886, avg loss=4.835, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.9 seconds, train=2.8 seconds, 231616 images, time remaining=5.3 hours
3620: loss=4.547, avg loss=4.806, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 231680 images, time remaining=5.3 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b8b3e00000
3621: loss=3.682, avg loss=4.694, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 231744 images, time remaining=5.3 hours
3622: loss=4.084, avg loss=4.633, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 231808 images, time remaining=5.3 hours
3623: loss=4.617, avg loss=4.631, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=2.3 seconds, 231872 images, time remaining=5.3 hours
3624: loss=4.570, avg loss=4.625, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 231936 images, time remaining=5.3 hours
3625: loss=3.939, avg loss=4.557, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 232000 images, time remaining=5.3 hours
3626: loss=4.033, avg loss=4.504, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 232064 images, time remaining=5.2 hours
3627: loss=4.101, avg loss=4.464, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=2.3 seconds, 232128 images, time remaining=5.2 hours
3628: loss=4.053, avg loss=4.423, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 232192 images, time remaining=5.2 hours
3629: loss=4.153, avg loss=4.396, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 232256 images, time remaining=5.2 hours
3630: loss=4.107, avg loss=4.367, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 232320 images, time remaining=5.2 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3631: loss=5.088, avg loss=4.439, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 232384 images, time remaining=5.2 hours
3632: loss=5.259, avg loss=4.521, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 232448 images, time remaining=5.2 hours
3633: loss=4.532, avg loss=4.522, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=4.4 seconds, 232512 images, time remaining=5.2 hours
3634: loss=4.621, avg loss=4.532, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 232576 images, time remaining=5.2 hours
3635: loss=4.463, avg loss=4.525, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.6 seconds, train=4.3 seconds, 232640 images, time remaining=5.2 hours
3636: loss=4.715, avg loss=4.544, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 232704 images, time remaining=5.2 hours
3637: loss=4.361, avg loss=4.526, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 232768 images, time remaining=5.2 hours
3638: loss=4.377, avg loss=4.511, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=4.3 seconds, 232832 images, time remaining=5.2 hours
3639: loss=4.562, avg loss=4.516, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=3.1 seconds, train=4.1 seconds, 232896 images, time remaining=5.2 hours
3640: loss=5.128, avg loss=4.577, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=4.4 seconds, 232960 images, time remaining=5.2 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b4ca800000
3641: loss=5.248, avg loss=4.644, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 233024 images, time remaining=5.2 hours
3642: loss=4.699, avg loss=4.650, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 233088 images, time remaining=5.2 hours
3643: loss=5.165, avg loss=4.701, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 233152 images, time remaining=5.2 hours
3644: loss=4.663, avg loss=4.697, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 233216 images, time remaining=5.2 hours
3645: loss=4.236, avg loss=4.651, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 233280 images, time remaining=5.2 hours
3646: loss=4.268, avg loss=4.613, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=2.1 seconds, 233344 images, time remaining=5.2 hours
3647: loss=3.903, avg loss=4.542, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 233408 images, time remaining=5.2 hours
3648: loss=4.137, avg loss=4.501, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 233472 images, time remaining=5.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3649: loss=4.474, avg loss=4.499, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=6.9 seconds, train=1.8 seconds, 233536 images, time remaining=5.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3650: loss=4.415, avg loss=4.490, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=4.2 seconds, train=2.1 seconds, 233600 images, time remaining=5.2 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14bf5aa00000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3651: loss=4.767, avg loss=4.518, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=3.1 seconds, train=2.0 seconds, 233664 images, time remaining=5.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3652: loss=4.611, avg loss=4.527, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=3.1 seconds, train=1.9 seconds, 233728 images, time remaining=5.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3653: loss=4.472, avg loss=4.522, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=2.0 seconds, 233792 images, time remaining=5.2 hours
3654: loss=4.476, avg loss=4.517, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 233856 images, time remaining=5.2 hours
3655: loss=4.164, avg loss=4.482, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 233920 images, time remaining=5.2 hours
3656: loss=3.977, avg loss=4.431, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 233984 images, time remaining=5.2 hours
3657: loss=4.472, avg loss=4.435, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 234048 images, time remaining=5.2 hours
3658: loss=3.959, avg loss=4.388, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 234112 images, time remaining=5.2 hours
3659: loss=3.759, avg loss=4.325, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=1.7 seconds, 234176 images, time remaining=5.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3660: loss=3.777, avg loss=4.270, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=4.0 seconds, train=2.0 seconds, 234240 images, time remaining=5.2 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3661: loss=5.377, avg loss=4.381, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 234304 images, time remaining=5.2 hours
3662: loss=5.383, avg loss=4.481, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.5 seconds, train=4.7 seconds, 234368 images, time remaining=5.2 hours
3663: loss=5.158, avg loss=4.549, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=4.6 seconds, 234432 images, time remaining=5.2 hours
3664: loss=3.997, avg loss=4.494, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 234496 images, time remaining=5.2 hours
3665: loss=4.532, avg loss=4.497, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 234560 images, time remaining=5.2 hours
3666: loss=4.785, avg loss=4.526, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=4.7 seconds, 234624 images, time remaining=5.2 hours
3667: loss=4.576, avg loss=4.531, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 234688 images, time remaining=5.2 hours
3668: loss=5.127, avg loss=4.591, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.5 seconds, 234752 images, time remaining=5.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3669: loss=4.508, avg loss=4.582, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=4.9 seconds, train=4.6 seconds, 234816 images, time remaining=5.2 hours
3670: loss=4.675, avg loss=4.592, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=4.8 seconds, 234880 images, time remaining=5.2 hours
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3671: loss=5.751, avg loss=4.708, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 234944 images, time remaining=5.2 hours
3672: loss=3.972, avg loss=4.634, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=4.1 seconds, 235008 images, time remaining=5.2 hours
3673: loss=3.622, avg loss=4.533, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 235072 images, time remaining=5.2 hours
3674: loss=4.383, avg loss=4.518, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 235136 images, time remaining=5.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3675: loss=4.464, avg loss=4.512, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=4.5 seconds, train=4.1 seconds, 235200 images, time remaining=5.2 hours
3676: loss=4.194, avg loss=4.481, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 235264 images, time remaining=5.2 hours
3677: loss=3.606, avg loss=4.393, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 235328 images, time remaining=5.2 hours
3678: loss=4.761, avg loss=4.430, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 235392 images, time remaining=5.2 hours
3679: loss=3.720, avg loss=4.359, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 235456 images, time remaining=5.2 hours
3680: loss=4.822, avg loss=4.405, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 235520 images, time remaining=5.2 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b4c4e00000
3681: loss=4.003, avg loss=4.365, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 235584 images, time remaining=5.2 hours
3682: loss=4.761, avg loss=4.405, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 235648 images, time remaining=5.2 hours
3683: loss=5.219, avg loss=4.486, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 235712 images, time remaining=5.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3684: loss=3.969, avg loss=4.434, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=6.0 seconds, train=2.1 seconds, 235776 images, time remaining=5.2 hours
3685: loss=3.194, avg loss=4.310, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=2.0 seconds, 235840 images, time remaining=5.2 hours
3686: loss=4.267, avg loss=4.306, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 235904 images, time remaining=5.2 hours
3687: loss=3.496, avg loss=4.225, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.0 seconds, 235968 images, time remaining=5.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3688: loss=3.752, avg loss=4.178, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=2.0 seconds, 236032 images, time remaining=5.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3689: loss=4.117, avg loss=4.172, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=2.0 seconds, 236096 images, time remaining=5.2 hours
3690: loss=4.407, avg loss=4.195, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 236160 images, time remaining=5.2 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b8a6a00000
3691: loss=4.753, avg loss=4.251, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.1 seconds, train=2.3 seconds, 236224 images, time remaining=5.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3692: loss=3.659, avg loss=4.192, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.5 seconds, train=2.4 seconds, 236288 images, time remaining=5.2 hours
3693: loss=3.925, avg loss=4.165, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 236352 images, time remaining=5.2 hours
3694: loss=4.041, avg loss=4.153, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 236416 images, time remaining=5.2 hours
3695: loss=4.742, avg loss=4.212, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 236480 images, time remaining=5.2 hours
3696: loss=3.652, avg loss=4.156, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 236544 images, time remaining=5.1 hours
3697: loss=3.652, avg loss=4.105, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 236608 images, time remaining=5.1 hours
3698: loss=3.814, avg loss=4.076, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 236672 images, time remaining=5.1 hours
3699: loss=4.203, avg loss=4.089, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=2.4 seconds, 236736 images, time remaining=5.1 hours
3700: loss=3.688, avg loss=4.049, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.4 seconds, 236800 images, time remaining=5.1 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3701: loss=6.653, avg loss=4.309, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=4.6 seconds, train=5.7 seconds, 236864 images, time remaining=5.1 hours
3702: loss=5.506, avg loss=4.429, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 236928 images, time remaining=5.1 hours
3703: loss=5.909, avg loss=4.577, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=3.1 seconds, train=5.6 seconds, 236992 images, time remaining=5.1 hours
3704: loss=5.180, avg loss=4.637, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.2 seconds, train=5.6 seconds, 237056 images, time remaining=5.1 hours
3705: loss=4.749, avg loss=4.648, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 237120 images, time remaining=5.1 hours
3706: loss=4.785, avg loss=4.662, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=5.6 seconds, 237184 images, time remaining=5.1 hours
3707: loss=4.476, avg loss=4.643, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=5.6 seconds, 237248 images, time remaining=5.1 hours
3708: loss=4.326, avg loss=4.612, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=5.4 seconds, 237312 images, time remaining=5.1 hours
3709: loss=4.789, avg loss=4.629, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=5.6 seconds, 237376 images, time remaining=5.1 hours
3710: loss=4.889, avg loss=4.655, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 237440 images, time remaining=5.1 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3711: loss=4.833, avg loss=4.673, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 237504 images, time remaining=5.1 hours
3712: loss=5.272, avg loss=4.733, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 237568 images, time remaining=5.1 hours
3713: loss=4.960, avg loss=4.756, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 237632 images, time remaining=5.1 hours
3714: loss=5.750, avg loss=4.855, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 237696 images, time remaining=5.1 hours
3715: loss=4.603, avg loss=4.830, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=5.2 seconds, 237760 images, time remaining=5.1 hours
3716: loss=4.934, avg loss=4.840, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=5.2 seconds, 237824 images, time remaining=5.1 hours
3717: loss=4.218, avg loss=4.778, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=5.4 seconds, 237888 images, time remaining=5.1 hours
3718: loss=5.615, avg loss=4.862, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.2 seconds, train=5.2 seconds, 237952 images, time remaining=5.1 hours
3719: loss=4.746, avg loss=4.850, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=5.2 seconds, 238016 images, time remaining=5.1 hours
3720: loss=4.924, avg loss=4.858, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.2 seconds, train=5.4 seconds, 238080 images, time remaining=5.1 hours
Resizing, random_coef=1.40, batch=4, 736x544
GPU #0: allocating workspace: 302.4 MiB begins at 0x14b888800000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3721: loss=4.714, avg loss=4.843, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=4.9 seconds, train=1.8 seconds, 238144 images, time remaining=5.1 hours
3722: loss=6.491, avg loss=5.008, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 238208 images, time remaining=5.1 hours
3723: loss=5.345, avg loss=5.042, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 238272 images, time remaining=5.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3724: loss=4.895, avg loss=5.027, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.2 seconds, train=1.8 seconds, 238336 images, time remaining=5.1 hours
3725: loss=4.878, avg loss=5.012, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=1.7 seconds, 238400 images, time remaining=5.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3726: loss=3.898, avg loss=4.901, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.5 seconds, train=1.8 seconds, 238464 images, time remaining=5.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3727: loss=4.284, avg loss=4.839, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.3 seconds, train=1.7 seconds, 238528 images, time remaining=5.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3728: loss=4.559, avg loss=4.811, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=1.8 seconds, 238592 images, time remaining=5.1 hours
3729: loss=4.886, avg loss=4.818, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=1.9 seconds, 238656 images, time remaining=5.1 hours
3730: loss=4.989, avg loss=4.835, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=1.8 seconds, 238720 images, time remaining=5.1 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3731: loss=8.968, avg loss=5.249, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 238784 images, time remaining=5.1 hours
3732: loss=8.378, avg loss=5.562, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 238848 images, time remaining=5.1 hours
3733: loss=7.480, avg loss=5.754, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=5.2 seconds, 238912 images, time remaining=5.1 hours
3734: loss=4.669, avg loss=5.645, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 238976 images, time remaining=5.1 hours
3735: loss=5.679, avg loss=5.648, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=5.2 seconds, 239040 images, time remaining=5.1 hours
3736: loss=5.690, avg loss=5.653, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=3.3 seconds, train=5.4 seconds, 239104 images, time remaining=5.1 hours
3737: loss=5.113, avg loss=5.599, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 239168 images, time remaining=5.1 hours
3738: loss=4.926, avg loss=5.531, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.1 seconds, 239232 images, time remaining=5.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3739: loss=5.707, avg loss=5.549, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=8.3 seconds, train=5.2 seconds, 239296 images, time remaining=5.1 hours
3740: loss=7.165, avg loss=5.711, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=4.6 seconds, train=5.5 seconds, 239360 images, time remaining=5.1 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3741: loss=5.477, avg loss=5.687, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=4.3 seconds, 239424 images, time remaining=5.1 hours
3742: loss=5.332, avg loss=5.652, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=4.2 seconds, 239488 images, time remaining=5.1 hours
3743: loss=6.529, avg loss=5.739, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.2 seconds, 239552 images, time remaining=5.1 hours
3744: loss=4.621, avg loss=5.628, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=4.3 seconds, 239616 images, time remaining=5.1 hours
3745: loss=5.556, avg loss=5.620, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=4.3 seconds, 239680 images, time remaining=5.1 hours
3746: loss=4.568, avg loss=5.515, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 239744 images, time remaining=5.1 hours
3747: loss=5.479, avg loss=5.511, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=4.4 seconds, 239808 images, time remaining=5.1 hours
3748: loss=5.772, avg loss=5.538, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=4.3 seconds, 239872 images, time remaining=5.1 hours
3749: loss=5.192, avg loss=5.503, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.9 seconds, train=4.3 seconds, 239936 images, time remaining=5.1 hours
3750: loss=4.715, avg loss=5.424, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 240000 images, time remaining=5.1 hours
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3751: loss=7.331, avg loss=5.615, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 240064 images, time remaining=5.1 hours
3752: loss=6.138, avg loss=5.667, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=5.2 seconds, train=5.9 seconds, 240128 images, time remaining=5.1 hours
3753: loss=5.650, avg loss=5.665, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 240192 images, time remaining=5.1 hours
3754: loss=5.763, avg loss=5.675, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=3.3 seconds, train=6.0 seconds, 240256 images, time remaining=5.1 hours
3755: loss=5.310, avg loss=5.639, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 240320 images, time remaining=5.1 hours
3756: loss=5.209, avg loss=5.596, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.2 seconds, train=6.1 seconds, 240384 images, time remaining=5.1 hours
3757: loss=5.482, avg loss=5.584, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.6 seconds, train=6.1 seconds, 240448 images, time remaining=5.1 hours
3758: loss=6.359, avg loss=5.662, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=6.0 seconds, 240512 images, time remaining=5.1 hours
3759: loss=4.589, avg loss=5.555, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.5 seconds, train=6.0 seconds, 240576 images, time remaining=5.1 hours
3760: loss=6.158, avg loss=5.615, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.3 seconds, train=5.8 seconds, 240640 images, time remaining=5.1 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b57b400000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3761: loss=5.959, avg loss=5.649, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=4.8 seconds, train=2.0 seconds, 240704 images, time remaining=5.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3762: loss=8.079, avg loss=5.892, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.3 seconds, train=2.0 seconds, 240768 images, time remaining=5.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3763: loss=6.001, avg loss=5.903, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.7 seconds, train=1.9 seconds, 240832 images, time remaining=5.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3764: loss=5.739, avg loss=5.887, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=4.2 seconds, train=2.1 seconds, 240896 images, time remaining=5.1 hours
3765: loss=5.207, avg loss=5.819, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=2.0 seconds, 240960 images, time remaining=5.1 hours
3766: loss=3.597, avg loss=5.597, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 241024 images, time remaining=5.1 hours
3767: loss=4.573, avg loss=5.494, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 241088 images, time remaining=5.1 hours
3768: loss=4.643, avg loss=5.409, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 241152 images, time remaining=5.1 hours
3769: loss=4.640, avg loss=5.332, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 241216 images, time remaining=5.1 hours
3770: loss=5.372, avg loss=5.336, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 241280 images, time remaining=5.1 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b57b400000
3771: loss=4.429, avg loss=5.245, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 241344 images, time remaining=5.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3772: loss=4.815, avg loss=5.202, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.9 seconds, train=2.0 seconds, 241408 images, time remaining=5.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3773: loss=4.849, avg loss=5.167, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.2 seconds, train=2.0 seconds, 241472 images, time remaining=5.1 hours
3774: loss=4.169, avg loss=5.067, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 241536 images, time remaining=5.1 hours
3775: loss=5.152, avg loss=5.076, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 241600 images, time remaining=5.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3776: loss=4.324, avg loss=5.001, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=5.7 seconds, train=2.0 seconds, 241664 images, time remaining=5.1 hours
3777: loss=4.894, avg loss=4.990, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 241728 images, time remaining=5.1 hours
3778: loss=4.346, avg loss=4.926, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=1.8 seconds, 241792 images, time remaining=5.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3779: loss=4.471, avg loss=4.880, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=5.2 seconds, train=2.1 seconds, 241856 images, time remaining=5.1 hours
3780: loss=4.087, avg loss=4.801, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 241920 images, time remaining=5.1 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b8a0000000
3781: loss=4.074, avg loss=4.728, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 241984 images, time remaining=5.1 hours
3782: loss=3.573, avg loss=4.613, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 242048 images, time remaining=5.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3783: loss=3.447, avg loss=4.496, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=5.7 seconds, train=2.3 seconds, 242112 images, time remaining=5.1 hours
3784: loss=3.458, avg loss=4.392, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=2.3 seconds, 242176 images, time remaining=5 hours
3785: loss=3.909, avg loss=4.344, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 242240 images, time remaining=5 hours
3786: loss=4.624, avg loss=4.372, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=2.4 seconds, 242304 images, time remaining=5 hours
3787: loss=3.507, avg loss=4.285, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 242368 images, time remaining=5 hours
3788: loss=3.622, avg loss=4.219, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.4 seconds, 242432 images, time remaining=5 hours
3789: loss=4.446, avg loss=4.242, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=2.4 seconds, 242496 images, time remaining=5 hours
3790: loss=4.427, avg loss=4.260, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 242560 images, time remaining=5 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3791: loss=4.065, avg loss=4.241, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.2 seconds, train=4.9 seconds, 242624 images, time remaining=5 hours
3792: loss=5.082, avg loss=4.325, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 242688 images, time remaining=5 hours
3793: loss=5.564, avg loss=4.449, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=4.5 seconds, 242752 images, time remaining=5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3794: loss=4.748, avg loss=4.479, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=9.5 seconds, train=4.9 seconds, 242816 images, time remaining=5 hours
3795: loss=3.973, avg loss=4.428, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.9 seconds, train=4.7 seconds, 242880 images, time remaining=5 hours
3796: loss=3.771, avg loss=4.362, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 242944 images, time remaining=5 hours
3797: loss=4.534, avg loss=4.380, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 243008 images, time remaining=5 hours
3798: loss=4.474, avg loss=4.389, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 243072 images, time remaining=5 hours
3799: loss=3.967, avg loss=4.347, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 243136 images, time remaining=5 hours
3800: loss=3.765, avg loss=4.289, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=4.8 seconds, 243200 images, time remaining=5 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b734800000
3801: loss=4.566, avg loss=4.316, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 243264 images, time remaining=5 hours
3802: loss=4.751, avg loss=4.360, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 243328 images, time remaining=5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3803: loss=3.754, avg loss=4.299, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=8.3 seconds, train=2.2 seconds, 243392 images, time remaining=5 hours
3804: loss=3.543, avg loss=4.224, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 243456 images, time remaining=5 hours
3805: loss=3.882, avg loss=4.190, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 243520 images, time remaining=5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3806: loss=3.670, avg loss=4.138, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.5 seconds, train=2.1 seconds, 243584 images, time remaining=5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3807: loss=4.849, avg loss=4.209, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=8.5 seconds, train=2.3 seconds, 243648 images, time remaining=5 hours
3808: loss=3.378, avg loss=4.126, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 243712 images, time remaining=5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3809: loss=4.150, avg loss=4.128, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.6 seconds, train=2.4 seconds, 243776 images, time remaining=5 hours
3810: loss=3.662, avg loss=4.081, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 243840 images, time remaining=5 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3811: loss=6.562, avg loss=4.330, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 243904 images, time remaining=5 hours
3812: loss=6.084, avg loss=4.505, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=5.2 seconds, 243968 images, time remaining=5 hours
3813: loss=4.903, avg loss=4.545, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=5.4 seconds, 244032 images, time remaining=5 hours
3814: loss=5.080, avg loss=4.598, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 244096 images, time remaining=5 hours
3815: loss=5.093, avg loss=4.648, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 244160 images, time remaining=5 hours
3816: loss=5.098, avg loss=4.693, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=5.3 seconds, 244224 images, time remaining=5 hours
3817: loss=4.275, avg loss=4.651, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.9 seconds, train=5.3 seconds, 244288 images, time remaining=5 hours
3818: loss=4.034, avg loss=4.589, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 244352 images, time remaining=5 hours
3819: loss=5.531, avg loss=4.683, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=3.0 seconds, train=5.5 seconds, 244416 images, time remaining=5 hours
3820: loss=4.742, avg loss=4.689, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 244480 images, time remaining=5 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b5ec000000
3821: loss=6.556, avg loss=4.876, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 244544 images, time remaining=5 hours
3822: loss=5.793, avg loss=4.968, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 244608 images, time remaining=5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3823: loss=5.448, avg loss=5.016, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=2.0 seconds, 244672 images, time remaining=5 hours
3824: loss=4.870, avg loss=5.001, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 244736 images, time remaining=5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3825: loss=3.930, avg loss=4.894, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.3 seconds, train=1.9 seconds, 244800 images, time remaining=5 hours
3826: loss=4.293, avg loss=4.834, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 244864 images, time remaining=5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3827: loss=4.257, avg loss=4.776, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=4.8 seconds, train=1.9 seconds, 244928 images, time remaining=5 hours
3828: loss=4.718, avg loss=4.770, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.0 seconds, 244992 images, time remaining=5 hours
3829: loss=4.610, avg loss=4.754, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 245056 images, time remaining=5 hours
3830: loss=3.842, avg loss=4.663, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 245120 images, time remaining=5 hours
Resizing, random_coef=1.40, batch=4, 1344x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3831: loss=10.926, avg loss=5.289, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.0 seconds, train=6.0 seconds, 245184 images, time remaining=5 hours
3832: loss=6.691, avg loss=5.430, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=5.9 seconds, 245248 images, time remaining=5 hours
3833: loss=6.308, avg loss=5.517, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 245312 images, time remaining=5 hours
3834: loss=5.463, avg loss=5.512, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.5 seconds, train=6.0 seconds, 245376 images, time remaining=5 hours
3835: loss=5.471, avg loss=5.508, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.4 seconds, train=5.9 seconds, 245440 images, time remaining=5 hours
3836: loss=5.003, avg loss=5.457, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.3 seconds, train=5.9 seconds, 245504 images, time remaining=5 hours
3837: loss=6.246, avg loss=5.536, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.5 seconds, train=6.1 seconds, 245568 images, time remaining=5 hours
3838: loss=5.309, avg loss=5.514, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=2.1 seconds, train=5.9 seconds, 245632 images, time remaining=5 hours
3839: loss=5.455, avg loss=5.508, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 245696 images, time remaining=5 hours
3840: loss=6.058, avg loss=5.563, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=4.7 seconds, train=6.0 seconds, 245760 images, time remaining=5 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b721000000
3841: loss=5.710, avg loss=5.578, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 245824 images, time remaining=5 hours
3842: loss=3.821, avg loss=5.402, last=84.95%, best=85.57%, next=3842, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 245888 images, time remaining=5 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b30e000000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=133220, unique_truth_count=57264
rank=0 of ranks=133220rank=100 of ranks=133220rank=200 of ranks=133220rank=300 of ranks=133220rank=400 of ranks=133220rank=500 of ranks=133220rank=600 of ranks=133220rank=700 of ranks=133220rank=800 of ranks=133220rank=900 of ranks=133220rank=1000 of ranks=133220rank=1100 of ranks=133220rank=1200 of ranks=133220rank=1300 of ranks=133220rank=1400 of ranks=133220rank=1500 of ranks=133220rank=1600 of ranks=133220rank=1700 of ranks=133220rank=1800 of ranks=133220rank=1900 of ranks=133220rank=2000 of ranks=133220rank=2100 of ranks=133220rank=2200 of ranks=133220rank=2300 of ranks=133220rank=2400 of ranks=133220rank=2500 of ranks=133220rank=2600 of ranks=133220rank=2700 of ranks=133220rank=2800 of ranks=133220rank=2900 of ranks=133220rank=3000 of ranks=133220rank=3100 of ranks=133220rank=3200 of ranks=133220rank=3300 of ranks=133220rank=3400 of ranks=133220rank=3500 of ranks=133220rank=3600 of ranks=133220rank=3700 of ranks=133220rank=3800 of ranks=133220rank=3900 of ranks=133220rank=4000 of ranks=133220rank=4100 of ranks=133220rank=4200 of ranks=133220rank=4300 of ranks=133220rank=4400 of ranks=133220rank=4500 of ranks=133220rank=4600 of ranks=133220rank=4700 of ranks=133220rank=4800 of ranks=133220rank=4900 of ranks=133220rank=5000 of ranks=133220rank=5100 of ranks=133220rank=5200 of ranks=133220rank=5300 of ranks=133220rank=5400 of ranks=133220rank=5500 of ranks=133220rank=5600 of ranks=133220rank=5700 of ranks=133220rank=5800 of ranks=133220rank=5900 of ranks=133220rank=6000 of ranks=133220rank=6100 of ranks=133220rank=6200 of ranks=133220rank=6300 of ranks=133220rank=6400 of ranks=133220rank=6500 of ranks=133220rank=6600 of ranks=133220rank=6700 of ranks=133220rank=6800 of ranks=133220rank=6900 of ranks=133220rank=7000 of ranks=133220rank=7100 of ranks=133220rank=7200 of ranks=133220rank=7300 of ranks=133220rank=7400 of ranks=133220rank=7500 of ranks=133220rank=7600 of ranks=133220rank=7700 of ranks=133220rank=7800 of ranks=133220rank=7900 of ranks=133220rank=8000 of ranks=133220rank=8100 of ranks=133220rank=8200 of ranks=133220rank=8300 of ranks=133220rank=8400 of ranks=133220rank=8500 of ranks=133220rank=8600 of ranks=133220rank=8700 of ranks=133220rank=8800 of ranks=133220rank=8900 of ranks=133220rank=9000 of ranks=133220rank=9100 of ranks=133220rank=9200 of ranks=133220rank=9300 of ranks=133220rank=9400 of ranks=133220rank=9500 of ranks=133220rank=9600 of ranks=133220rank=9700 of ranks=133220rank=9800 of ranks=133220rank=9900 of ranks=133220rank=10000 of ranks=133220rank=10100 of ranks=133220rank=10200 of ranks=133220rank=10300 of ranks=133220rank=10400 of ranks=133220rank=10500 of ranks=133220rank=10600 of ranks=133220rank=10700 of ranks=133220rank=10800 of ranks=133220rank=10900 of ranks=133220rank=11000 of ranks=133220rank=11100 of ranks=133220rank=11200 of ranks=133220rank=11300 of ranks=133220rank=11400 of ranks=133220rank=11500 of ranks=133220rank=11600 of ranks=133220rank=11700 of ranks=133220rank=11800 of ranks=133220rank=11900 of ranks=133220rank=12000 of ranks=133220rank=12100 of ranks=133220rank=12200 of ranks=133220rank=12300 of ranks=133220rank=12400 of ranks=133220rank=12500 of ranks=133220rank=12600 of ranks=133220rank=12700 of ranks=133220rank=12800 of ranks=133220rank=12900 of ranks=133220rank=13000 of ranks=133220rank=13100 of ranks=133220rank=13200 of ranks=133220rank=13300 of ranks=133220rank=13400 of ranks=133220rank=13500 of ranks=133220rank=13600 of ranks=133220rank=13700 of ranks=133220rank=13800 of ranks=133220rank=13900 of ranks=133220rank=14000 of ranks=133220rank=14100 of ranks=133220rank=14200 of ranks=133220rank=14300 of ranks=133220rank=14400 of ranks=133220rank=14500 of ranks=133220rank=14600 of ranks=133220rank=14700 of ranks=133220rank=14800 of ranks=133220rank=14900 of ranks=133220rank=15000 of ranks=133220rank=15100 of ranks=133220rank=15200 of ranks=133220rank=15300 of ranks=133220rank=15400 of ranks=133220rank=15500 of ranks=133220rank=15600 of ranks=133220rank=15700 of ranks=133220rank=15800 of ranks=133220rank=15900 of ranks=133220rank=16000 of ranks=133220rank=16100 of ranks=133220rank=16200 of ranks=133220rank=16300 of ranks=133220rank=16400 of ranks=133220rank=16500 of ranks=133220rank=16600 of ranks=133220rank=16700 of ranks=133220rank=16800 of ranks=133220rank=16900 of ranks=133220rank=17000 of ranks=133220rank=17100 of ranks=133220rank=17200 of ranks=133220rank=17300 of ranks=133220rank=17400 of ranks=133220rank=17500 of ranks=133220rank=17600 of ranks=133220rank=17700 of ranks=133220rank=17800 of ranks=133220rank=17900 of ranks=133220rank=18000 of ranks=133220rank=18100 of ranks=133220rank=18200 of ranks=133220rank=18300 of ranks=133220rank=18400 of ranks=133220rank=18500 of ranks=133220rank=18600 of ranks=133220rank=18700 of ranks=133220rank=18800 of ranks=133220rank=18900 of ranks=133220rank=19000 of ranks=133220rank=19100 of ranks=133220rank=19200 of ranks=133220rank=19300 of ranks=133220rank=19400 of ranks=133220rank=19500 of ranks=133220rank=19600 of ranks=133220rank=19700 of ranks=133220rank=19800 of ranks=133220rank=19900 of ranks=133220rank=20000 of ranks=133220rank=20100 of ranks=133220rank=20200 of ranks=133220rank=20300 of ranks=133220rank=20400 of ranks=133220rank=20500 of ranks=133220rank=20600 of ranks=133220rank=20700 of ranks=133220rank=20800 of ranks=133220rank=20900 of ranks=133220rank=21000 of ranks=133220rank=21100 of ranks=133220rank=21200 of ranks=133220rank=21300 of ranks=133220rank=21400 of ranks=133220rank=21500 of ranks=133220rank=21600 of ranks=133220rank=21700 of ranks=133220rank=21800 of ranks=133220rank=21900 of ranks=133220rank=22000 of ranks=133220rank=22100 of ranks=133220rank=22200 of ranks=133220rank=22300 of ranks=133220rank=22400 of ranks=133220rank=22500 of ranks=133220rank=22600 of ranks=133220rank=22700 of ranks=133220rank=22800 of ranks=133220rank=22900 of ranks=133220rank=23000 of ranks=133220rank=23100 of ranks=133220rank=23200 of ranks=133220rank=23300 of ranks=133220rank=23400 of ranks=133220rank=23500 of ranks=133220rank=23600 of ranks=133220rank=23700 of ranks=133220rank=23800 of ranks=133220rank=23900 of ranks=133220rank=24000 of ranks=133220rank=24100 of ranks=133220rank=24200 of ranks=133220rank=24300 of ranks=133220rank=24400 of ranks=133220rank=24500 of ranks=133220rank=24600 of ranks=133220rank=24700 of ranks=133220rank=24800 of ranks=133220rank=24900 of ranks=133220rank=25000 of ranks=133220rank=25100 of ranks=133220rank=25200 of ranks=133220rank=25300 of ranks=133220rank=25400 of ranks=133220rank=25500 of ranks=133220rank=25600 of ranks=133220rank=25700 of ranks=133220rank=25800 of ranks=133220rank=25900 of ranks=133220rank=26000 of ranks=133220rank=26100 of ranks=133220rank=26200 of ranks=133220rank=26300 of ranks=133220rank=26400 of ranks=133220rank=26500 of ranks=133220rank=26600 of ranks=133220rank=26700 of ranks=133220rank=26800 of ranks=133220rank=26900 of ranks=133220rank=27000 of ranks=133220rank=27100 of ranks=133220rank=27200 of ranks=133220rank=27300 of ranks=133220rank=27400 of ranks=133220rank=27500 of ranks=133220rank=27600 of ranks=133220rank=27700 of ranks=133220rank=27800 of ranks=133220rank=27900 of ranks=133220rank=28000 of ranks=133220rank=28100 of ranks=133220rank=28200 of ranks=133220rank=28300 of ranks=133220rank=28400 of ranks=133220rank=28500 of ranks=133220rank=28600 of ranks=133220rank=28700 of ranks=133220rank=28800 of ranks=133220rank=28900 of ranks=133220rank=29000 of ranks=133220rank=29100 of ranks=133220rank=29200 of ranks=133220rank=29300 of ranks=133220rank=29400 of ranks=133220rank=29500 of ranks=133220rank=29600 of ranks=133220rank=29700 of ranks=133220rank=29800 of ranks=133220rank=29900 of ranks=133220rank=30000 of ranks=133220rank=30100 of ranks=133220rank=30200 of ranks=133220rank=30300 of ranks=133220rank=30400 of ranks=133220rank=30500 of ranks=133220rank=30600 of ranks=133220rank=30700 of ranks=133220rank=30800 of ranks=133220rank=30900 of ranks=133220rank=31000 of ranks=133220rank=31100 of ranks=133220rank=31200 of ranks=133220rank=31300 of ranks=133220rank=31400 of ranks=133220rank=31500 of ranks=133220rank=31600 of ranks=133220rank=31700 of ranks=133220rank=31800 of ranks=133220rank=31900 of ranks=133220rank=32000 of ranks=133220rank=32100 of ranks=133220rank=32200 of ranks=133220rank=32300 of ranks=133220rank=32400 of ranks=133220rank=32500 of ranks=133220rank=32600 of ranks=133220rank=32700 of ranks=133220rank=32800 of ranks=133220rank=32900 of ranks=133220rank=33000 of ranks=133220rank=33100 of ranks=133220rank=33200 of ranks=133220rank=33300 of ranks=133220rank=33400 of ranks=133220rank=33500 of ranks=133220rank=33600 of ranks=133220rank=33700 of ranks=133220rank=33800 of ranks=133220rank=33900 of ranks=133220rank=34000 of ranks=133220rank=34100 of ranks=133220rank=34200 of ranks=133220rank=34300 of ranks=133220rank=34400 of ranks=133220rank=34500 of ranks=133220rank=34600 of ranks=133220rank=34700 of ranks=133220rank=34800 of ranks=133220rank=34900 of ranks=133220rank=35000 of ranks=133220rank=35100 of ranks=133220rank=35200 of ranks=133220rank=35300 of ranks=133220rank=35400 of ranks=133220rank=35500 of ranks=133220rank=35600 of ranks=133220rank=35700 of ranks=133220rank=35800 of ranks=133220rank=35900 of ranks=133220rank=36000 of ranks=133220rank=36100 of ranks=133220rank=36200 of ranks=133220rank=36300 of ranks=133220rank=36400 of ranks=133220rank=36500 of ranks=133220rank=36600 of ranks=133220rank=36700 of ranks=133220rank=36800 of ranks=133220rank=36900 of ranks=133220rank=37000 of ranks=133220rank=37100 of ranks=133220rank=37200 of ranks=133220rank=37300 of ranks=133220rank=37400 of ranks=133220rank=37500 of ranks=133220rank=37600 of ranks=133220rank=37700 of ranks=133220rank=37800 of ranks=133220rank=37900 of ranks=133220rank=38000 of ranks=133220rank=38100 of ranks=133220rank=38200 of ranks=133220rank=38300 of ranks=133220rank=38400 of ranks=133220rank=38500 of ranks=133220rank=38600 of ranks=133220rank=38700 of ranks=133220rank=38800 of ranks=133220rank=38900 of ranks=133220rank=39000 of ranks=133220rank=39100 of ranks=133220rank=39200 of ranks=133220rank=39300 of ranks=133220rank=39400 of ranks=133220rank=39500 of ranks=133220rank=39600 of ranks=133220rank=39700 of ranks=133220rank=39800 of ranks=133220rank=39900 of ranks=133220rank=40000 of ranks=133220rank=40100 of ranks=133220rank=40200 of ranks=133220rank=40300 of ranks=133220rank=40400 of ranks=133220rank=40500 of ranks=133220rank=40600 of ranks=133220rank=40700 of ranks=133220rank=40800 of ranks=133220rank=40900 of ranks=133220rank=41000 of ranks=133220rank=41100 of ranks=133220rank=41200 of ranks=133220rank=41300 of ranks=133220rank=41400 of ranks=133220rank=41500 of ranks=133220rank=41600 of ranks=133220rank=41700 of ranks=133220rank=41800 of ranks=133220rank=41900 of ranks=133220rank=42000 of ranks=133220rank=42100 of ranks=133220rank=42200 of ranks=133220rank=42300 of ranks=133220rank=42400 of ranks=133220rank=42500 of ranks=133220rank=42600 of ranks=133220rank=42700 of ranks=133220rank=42800 of ranks=133220rank=42900 of ranks=133220rank=43000 of ranks=133220rank=43100 of ranks=133220rank=43200 of ranks=133220rank=43300 of ranks=133220rank=43400 of ranks=133220rank=43500 of ranks=133220rank=43600 of ranks=133220rank=43700 of ranks=133220rank=43800 of ranks=133220rank=43900 of ranks=133220rank=44000 of ranks=133220rank=44100 of ranks=133220rank=44200 of ranks=133220rank=44300 of ranks=133220rank=44400 of ranks=133220rank=44500 of ranks=133220rank=44600 of ranks=133220rank=44700 of ranks=133220rank=44800 of ranks=133220rank=44900 of ranks=133220rank=45000 of ranks=133220rank=45100 of ranks=133220rank=45200 of ranks=133220rank=45300 of ranks=133220rank=45400 of ranks=133220rank=45500 of ranks=133220rank=45600 of ranks=133220rank=45700 of ranks=133220rank=45800 of ranks=133220rank=45900 of ranks=133220rank=46000 of ranks=133220rank=46100 of ranks=133220rank=46200 of ranks=133220rank=46300 of ranks=133220rank=46400 of ranks=133220rank=46500 of ranks=133220rank=46600 of ranks=133220rank=46700 of ranks=133220rank=46800 of ranks=133220rank=46900 of ranks=133220rank=47000 of ranks=133220rank=47100 of ranks=133220rank=47200 of ranks=133220rank=47300 of ranks=133220rank=47400 of ranks=133220rank=47500 of ranks=133220rank=47600 of ranks=133220rank=47700 of ranks=133220rank=47800 of ranks=133220rank=47900 of ranks=133220rank=48000 of ranks=133220rank=48100 of ranks=133220rank=48200 of ranks=133220rank=48300 of ranks=133220rank=48400 of ranks=133220rank=48500 of ranks=133220rank=48600 of ranks=133220rank=48700 of ranks=133220rank=48800 of ranks=133220rank=48900 of ranks=133220rank=49000 of ranks=133220rank=49100 of ranks=133220rank=49200 of ranks=133220rank=49300 of ranks=133220rank=49400 of ranks=133220rank=49500 of ranks=133220rank=49600 of ranks=133220rank=49700 of ranks=133220rank=49800 of ranks=133220rank=49900 of ranks=133220rank=50000 of ranks=133220rank=50100 of ranks=133220rank=50200 of ranks=133220rank=50300 of ranks=133220rank=50400 of ranks=133220rank=50500 of ranks=133220rank=50600 of ranks=133220rank=50700 of ranks=133220rank=50800 of ranks=133220rank=50900 of ranks=133220rank=51000 of ranks=133220rank=51100 of ranks=133220rank=51200 of ranks=133220rank=51300 of ranks=133220rank=51400 of ranks=133220rank=51500 of ranks=133220rank=51600 of ranks=133220rank=51700 of ranks=133220rank=51800 of ranks=133220rank=51900 of ranks=133220rank=52000 of ranks=133220rank=52100 of ranks=133220rank=52200 of ranks=133220rank=52300 of ranks=133220rank=52400 of ranks=133220rank=52500 of ranks=133220rank=52600 of ranks=133220rank=52700 of ranks=133220rank=52800 of ranks=133220rank=52900 of ranks=133220rank=53000 of ranks=133220rank=53100 of ranks=133220rank=53200 of ranks=133220rank=53300 of ranks=133220rank=53400 of ranks=133220rank=53500 of ranks=133220rank=53600 of ranks=133220rank=53700 of ranks=133220rank=53800 of ranks=133220rank=53900 of ranks=133220rank=54000 of ranks=133220rank=54100 of ranks=133220rank=54200 of ranks=133220rank=54300 of ranks=133220rank=54400 of ranks=133220rank=54500 of ranks=133220rank=54600 of ranks=133220rank=54700 of ranks=133220rank=54800 of ranks=133220rank=54900 of ranks=133220rank=55000 of ranks=133220rank=55100 of ranks=133220rank=55200 of ranks=133220rank=55300 of ranks=133220rank=55400 of ranks=133220rank=55500 of ranks=133220rank=55600 of ranks=133220rank=55700 of ranks=133220rank=55800 of ranks=133220rank=55900 of ranks=133220rank=56000 of ranks=133220rank=56100 of ranks=133220rank=56200 of ranks=133220rank=56300 of ranks=133220rank=56400 of ranks=133220rank=56500 of ranks=133220rank=56600 of ranks=133220rank=56700 of ranks=133220rank=56800 of ranks=133220rank=56900 of ranks=133220rank=57000 of ranks=133220rank=57100 of ranks=133220rank=57200 of ranks=133220rank=57300 of ranks=133220rank=57400 of ranks=133220rank=57500 of ranks=133220rank=57600 of ranks=133220rank=57700 of ranks=133220rank=57800 of ranks=133220rank=57900 of ranks=133220rank=58000 of ranks=133220rank=58100 of ranks=133220rank=58200 of ranks=133220rank=58300 of ranks=133220rank=58400 of ranks=133220rank=58500 of ranks=133220rank=58600 of ranks=133220rank=58700 of ranks=133220rank=58800 of ranks=133220rank=58900 of ranks=133220rank=59000 of ranks=133220rank=59100 of ranks=133220rank=59200 of ranks=133220rank=59300 of ranks=133220rank=59400 of ranks=133220rank=59500 of ranks=133220rank=59600 of ranks=133220rank=59700 of ranks=133220rank=59800 of ranks=133220rank=59900 of ranks=133220rank=60000 of ranks=133220rank=60100 of ranks=133220rank=60200 of ranks=133220rank=60300 of ranks=133220rank=60400 of ranks=133220rank=60500 of ranks=133220rank=60600 of ranks=133220rank=60700 of ranks=133220rank=60800 of ranks=133220rank=60900 of ranks=133220rank=61000 of ranks=133220rank=61100 of ranks=133220rank=61200 of ranks=133220rank=61300 of ranks=133220rank=61400 of ranks=133220rank=61500 of ranks=133220rank=61600 of ranks=133220rank=61700 of ranks=133220rank=61800 of ranks=133220rank=61900 of ranks=133220rank=62000 of ranks=133220rank=62100 of ranks=133220rank=62200 of ranks=133220rank=62300 of ranks=133220rank=62400 of ranks=133220rank=62500 of ranks=133220rank=62600 of ranks=133220rank=62700 of ranks=133220rank=62800 of ranks=133220rank=62900 of ranks=133220rank=63000 of ranks=133220rank=63100 of ranks=133220rank=63200 of ranks=133220rank=63300 of ranks=133220rank=63400 of ranks=133220rank=63500 of ranks=133220rank=63600 of ranks=133220rank=63700 of ranks=133220rank=63800 of ranks=133220rank=63900 of ranks=133220rank=64000 of ranks=133220rank=64100 of ranks=133220rank=64200 of ranks=133220rank=64300 of ranks=133220rank=64400 of ranks=133220rank=64500 of ranks=133220rank=64600 of ranks=133220rank=64700 of ranks=133220rank=64800 of ranks=133220rank=64900 of ranks=133220rank=65000 of ranks=133220rank=65100 of ranks=133220rank=65200 of ranks=133220rank=65300 of ranks=133220rank=65400 of ranks=133220rank=65500 of ranks=133220rank=65600 of ranks=133220rank=65700 of ranks=133220rank=65800 of ranks=133220rank=65900 of ranks=133220rank=66000 of ranks=133220rank=66100 of ranks=133220rank=66200 of ranks=133220rank=66300 of ranks=133220rank=66400 of ranks=133220rank=66500 of ranks=133220rank=66600 of ranks=133220rank=66700 of ranks=133220rank=66800 of ranks=133220rank=66900 of ranks=133220rank=67000 of ranks=133220rank=67100 of ranks=133220rank=67200 of ranks=133220rank=67300 of ranks=133220rank=67400 of ranks=133220rank=67500 of ranks=133220rank=67600 of ranks=133220rank=67700 of ranks=133220rank=67800 of ranks=133220rank=67900 of ranks=133220rank=68000 of ranks=133220rank=68100 of ranks=133220rank=68200 of ranks=133220rank=68300 of ranks=133220rank=68400 of ranks=133220rank=68500 of ranks=133220rank=68600 of ranks=133220rank=68700 of ranks=133220rank=68800 of ranks=133220rank=68900 of ranks=133220rank=69000 of ranks=133220rank=69100 of ranks=133220rank=69200 of ranks=133220rank=69300 of ranks=133220rank=69400 of ranks=133220rank=69500 of ranks=133220rank=69600 of ranks=133220rank=69700 of ranks=133220rank=69800 of ranks=133220rank=69900 of ranks=133220rank=70000 of ranks=133220rank=70100 of ranks=133220rank=70200 of ranks=133220rank=70300 of ranks=133220rank=70400 of ranks=133220rank=70500 of ranks=133220rank=70600 of ranks=133220rank=70700 of ranks=133220rank=70800 of ranks=133220rank=70900 of ranks=133220rank=71000 of ranks=133220rank=71100 of ranks=133220rank=71200 of ranks=133220rank=71300 of ranks=133220rank=71400 of ranks=133220rank=71500 of ranks=133220rank=71600 of ranks=133220rank=71700 of ranks=133220rank=71800 of ranks=133220rank=71900 of ranks=133220rank=72000 of ranks=133220rank=72100 of ranks=133220rank=72200 of ranks=133220rank=72300 of ranks=133220rank=72400 of ranks=133220rank=72500 of ranks=133220rank=72600 of ranks=133220rank=72700 of ranks=133220rank=72800 of ranks=133220rank=72900 of ranks=133220rank=73000 of ranks=133220rank=73100 of ranks=133220rank=73200 of ranks=133220rank=73300 of ranks=133220rank=73400 of ranks=133220rank=73500 of ranks=133220rank=73600 of ranks=133220rank=73700 of ranks=133220rank=73800 of ranks=133220rank=73900 of ranks=133220rank=74000 of ranks=133220rank=74100 of ranks=133220rank=74200 of ranks=133220rank=74300 of ranks=133220rank=74400 of ranks=133220rank=74500 of ranks=133220rank=74600 of ranks=133220rank=74700 of ranks=133220rank=74800 of ranks=133220rank=74900 of ranks=133220rank=75000 of ranks=133220rank=75100 of ranks=133220rank=75200 of ranks=133220rank=75300 of ranks=133220rank=75400 of ranks=133220rank=75500 of ranks=133220rank=75600 of ranks=133220rank=75700 of ranks=133220rank=75800 of ranks=133220rank=75900 of ranks=133220rank=76000 of ranks=133220rank=76100 of ranks=133220rank=76200 of ranks=133220rank=76300 of ranks=133220rank=76400 of ranks=133220rank=76500 of ranks=133220rank=76600 of ranks=133220rank=76700 of ranks=133220rank=76800 of ranks=133220rank=76900 of ranks=133220rank=77000 of ranks=133220rank=77100 of ranks=133220rank=77200 of ranks=133220rank=77300 of ranks=133220rank=77400 of ranks=133220rank=77500 of ranks=133220rank=77600 of ranks=133220rank=77700 of ranks=133220rank=77800 of ranks=133220rank=77900 of ranks=133220rank=78000 of ranks=133220rank=78100 of ranks=133220rank=78200 of ranks=133220rank=78300 of ranks=133220rank=78400 of ranks=133220rank=78500 of ranks=133220rank=78600 of ranks=133220rank=78700 of ranks=133220rank=78800 of ranks=133220rank=78900 of ranks=133220rank=79000 of ranks=133220rank=79100 of ranks=133220rank=79200 of ranks=133220rank=79300 of ranks=133220rank=79400 of ranks=133220rank=79500 of ranks=133220rank=79600 of ranks=133220rank=79700 of ranks=133220rank=79800 of ranks=133220rank=79900 of ranks=133220rank=80000 of ranks=133220rank=80100 of ranks=133220rank=80200 of ranks=133220rank=80300 of ranks=133220rank=80400 of ranks=133220rank=80500 of ranks=133220rank=80600 of ranks=133220rank=80700 of ranks=133220rank=80800 of ranks=133220rank=80900 of ranks=133220rank=81000 of ranks=133220rank=81100 of ranks=133220rank=81200 of ranks=133220rank=81300 of ranks=133220rank=81400 of ranks=133220rank=81500 of ranks=133220rank=81600 of ranks=133220rank=81700 of ranks=133220rank=81800 of ranks=133220rank=81900 of ranks=133220rank=82000 of ranks=133220rank=82100 of ranks=133220rank=82200 of ranks=133220rank=82300 of ranks=133220rank=82400 of ranks=133220rank=82500 of ranks=133220rank=82600 of ranks=133220rank=82700 of ranks=133220rank=82800 of ranks=133220rank=82900 of ranks=133220rank=83000 of ranks=133220rank=83100 of ranks=133220rank=83200 of ranks=133220rank=83300 of ranks=133220rank=83400 of ranks=133220rank=83500 of ranks=133220rank=83600 of ranks=133220rank=83700 of ranks=133220rank=83800 of ranks=133220rank=83900 of ranks=133220rank=84000 of ranks=133220rank=84100 of ranks=133220rank=84200 of ranks=133220rank=84300 of ranks=133220rank=84400 of ranks=133220rank=84500 of ranks=133220rank=84600 of ranks=133220rank=84700 of ranks=133220rank=84800 of ranks=133220rank=84900 of ranks=133220rank=85000 of ranks=133220rank=85100 of ranks=133220rank=85200 of ranks=133220rank=85300 of ranks=133220rank=85400 of ranks=133220rank=85500 of ranks=133220rank=85600 of ranks=133220rank=85700 of ranks=133220rank=85800 of ranks=133220rank=85900 of ranks=133220rank=86000 of ranks=133220rank=86100 of ranks=133220rank=86200 of ranks=133220rank=86300 of ranks=133220rank=86400 of ranks=133220rank=86500 of ranks=133220rank=86600 of ranks=133220rank=86700 of ranks=133220rank=86800 of ranks=133220rank=86900 of ranks=133220rank=87000 of ranks=133220rank=87100 of ranks=133220rank=87200 of ranks=133220rank=87300 of ranks=133220rank=87400 of ranks=133220rank=87500 of ranks=133220rank=87600 of ranks=133220rank=87700 of ranks=133220rank=87800 of ranks=133220rank=87900 of ranks=133220rank=88000 of ranks=133220rank=88100 of ranks=133220rank=88200 of ranks=133220rank=88300 of ranks=133220rank=88400 of ranks=133220rank=88500 of ranks=133220rank=88600 of ranks=133220rank=88700 of ranks=133220rank=88800 of ranks=133220rank=88900 of ranks=133220rank=89000 of ranks=133220rank=89100 of ranks=133220rank=89200 of ranks=133220rank=89300 of ranks=133220rank=89400 of ranks=133220rank=89500 of ranks=133220rank=89600 of ranks=133220rank=89700 of ranks=133220rank=89800 of ranks=133220rank=89900 of ranks=133220rank=90000 of ranks=133220rank=90100 of ranks=133220rank=90200 of ranks=133220rank=90300 of ranks=133220rank=90400 of ranks=133220rank=90500 of ranks=133220rank=90600 of ranks=133220rank=90700 of ranks=133220rank=90800 of ranks=133220rank=90900 of ranks=133220rank=91000 of ranks=133220rank=91100 of ranks=133220rank=91200 of ranks=133220rank=91300 of ranks=133220rank=91400 of ranks=133220rank=91500 of ranks=133220rank=91600 of ranks=133220rank=91700 of ranks=133220rank=91800 of ranks=133220rank=91900 of ranks=133220rank=92000 of ranks=133220rank=92100 of ranks=133220rank=92200 of ranks=133220rank=92300 of ranks=133220rank=92400 of ranks=133220rank=92500 of ranks=133220rank=92600 of ranks=133220rank=92700 of ranks=133220rank=92800 of ranks=133220rank=92900 of ranks=133220rank=93000 of ranks=133220rank=93100 of ranks=133220rank=93200 of ranks=133220rank=93300 of ranks=133220rank=93400 of ranks=133220rank=93500 of ranks=133220rank=93600 of ranks=133220rank=93700 of ranks=133220rank=93800 of ranks=133220rank=93900 of ranks=133220rank=94000 of ranks=133220rank=94100 of ranks=133220rank=94200 of ranks=133220rank=94300 of ranks=133220rank=94400 of ranks=133220rank=94500 of ranks=133220rank=94600 of ranks=133220rank=94700 of ranks=133220rank=94800 of ranks=133220rank=94900 of ranks=133220rank=95000 of ranks=133220rank=95100 of ranks=133220rank=95200 of ranks=133220rank=95300 of ranks=133220rank=95400 of ranks=133220rank=95500 of ranks=133220rank=95600 of ranks=133220rank=95700 of ranks=133220rank=95800 of ranks=133220rank=95900 of ranks=133220rank=96000 of ranks=133220rank=96100 of ranks=133220rank=96200 of ranks=133220rank=96300 of ranks=133220rank=96400 of ranks=133220rank=96500 of ranks=133220rank=96600 of ranks=133220rank=96700 of ranks=133220rank=96800 of ranks=133220rank=96900 of ranks=133220rank=97000 of ranks=133220rank=97100 of ranks=133220rank=97200 of ranks=133220rank=97300 of ranks=133220rank=97400 of ranks=133220rank=97500 of ranks=133220rank=97600 of ranks=133220rank=97700 of ranks=133220rank=97800 of ranks=133220rank=97900 of ranks=133220rank=98000 of ranks=133220rank=98100 of ranks=133220rank=98200 of ranks=133220rank=98300 of ranks=133220rank=98400 of ranks=133220rank=98500 of ranks=133220rank=98600 of ranks=133220rank=98700 of ranks=133220rank=98800 of ranks=133220rank=98900 of ranks=133220rank=99000 of ranks=133220rank=99100 of ranks=133220rank=99200 of ranks=133220rank=99300 of ranks=133220rank=99400 of ranks=133220rank=99500 of ranks=133220rank=99600 of ranks=133220rank=99700 of ranks=133220rank=99800 of ranks=133220rank=99900 of ranks=133220rank=100000 of ranks=133220rank=100100 of ranks=133220rank=100200 of ranks=133220rank=100300 of ranks=133220rank=100400 of ranks=133220rank=100500 of ranks=133220rank=100600 of ranks=133220rank=100700 of ranks=133220rank=100800 of ranks=133220rank=100900 of ranks=133220rank=101000 of ranks=133220rank=101100 of ranks=133220rank=101200 of ranks=133220rank=101300 of ranks=133220rank=101400 of ranks=133220rank=101500 of ranks=133220rank=101600 of ranks=133220rank=101700 of ranks=133220rank=101800 of ranks=133220rank=101900 of ranks=133220rank=102000 of ranks=133220rank=102100 of ranks=133220rank=102200 of ranks=133220rank=102300 of ranks=133220rank=102400 of ranks=133220rank=102500 of ranks=133220rank=102600 of ranks=133220rank=102700 of ranks=133220rank=102800 of ranks=133220rank=102900 of ranks=133220rank=103000 of ranks=133220rank=103100 of ranks=133220rank=103200 of ranks=133220rank=103300 of ranks=133220rank=103400 of ranks=133220rank=103500 of ranks=133220rank=103600 of ranks=133220rank=103700 of ranks=133220rank=103800 of ranks=133220rank=103900 of ranks=133220rank=104000 of ranks=133220rank=104100 of ranks=133220rank=104200 of ranks=133220rank=104300 of ranks=133220rank=104400 of ranks=133220rank=104500 of ranks=133220rank=104600 of ranks=133220rank=104700 of ranks=133220rank=104800 of ranks=133220rank=104900 of ranks=133220rank=105000 of ranks=133220rank=105100 of ranks=133220rank=105200 of ranks=133220rank=105300 of ranks=133220rank=105400 of ranks=133220rank=105500 of ranks=133220rank=105600 of ranks=133220rank=105700 of ranks=133220rank=105800 of ranks=133220rank=105900 of ranks=133220rank=106000 of ranks=133220rank=106100 of ranks=133220rank=106200 of ranks=133220rank=106300 of ranks=133220rank=106400 of ranks=133220rank=106500 of ranks=133220rank=106600 of ranks=133220rank=106700 of ranks=133220rank=106800 of ranks=133220rank=106900 of ranks=133220rank=107000 of ranks=133220rank=107100 of ranks=133220rank=107200 of ranks=133220rank=107300 of ranks=133220rank=107400 of ranks=133220rank=107500 of ranks=133220rank=107600 of ranks=133220rank=107700 of ranks=133220rank=107800 of ranks=133220rank=107900 of ranks=133220rank=108000 of ranks=133220rank=108100 of ranks=133220rank=108200 of ranks=133220rank=108300 of ranks=133220rank=108400 of ranks=133220rank=108500 of ranks=133220rank=108600 of ranks=133220rank=108700 of ranks=133220rank=108800 of ranks=133220rank=108900 of ranks=133220rank=109000 of ranks=133220rank=109100 of ranks=133220rank=109200 of ranks=133220rank=109300 of ranks=133220rank=109400 of ranks=133220rank=109500 of ranks=133220rank=109600 of ranks=133220rank=109700 of ranks=133220rank=109800 of ranks=133220rank=109900 of ranks=133220rank=110000 of ranks=133220rank=110100 of ranks=133220rank=110200 of ranks=133220rank=110300 of ranks=133220rank=110400 of ranks=133220rank=110500 of ranks=133220rank=110600 of ranks=133220rank=110700 of ranks=133220rank=110800 of ranks=133220rank=110900 of ranks=133220rank=111000 of ranks=133220rank=111100 of ranks=133220rank=111200 of ranks=133220rank=111300 of ranks=133220rank=111400 of ranks=133220rank=111500 of ranks=133220rank=111600 of ranks=133220rank=111700 of ranks=133220rank=111800 of ranks=133220rank=111900 of ranks=133220rank=112000 of ranks=133220rank=112100 of ranks=133220rank=112200 of ranks=133220rank=112300 of ranks=133220rank=112400 of ranks=133220rank=112500 of ranks=133220rank=112600 of ranks=133220rank=112700 of ranks=133220rank=112800 of ranks=133220rank=112900 of ranks=133220rank=113000 of ranks=133220rank=113100 of ranks=133220rank=113200 of ranks=133220rank=113300 of ranks=133220rank=113400 of ranks=133220rank=113500 of ranks=133220rank=113600 of ranks=133220rank=113700 of ranks=133220rank=113800 of ranks=133220rank=113900 of ranks=133220rank=114000 of ranks=133220rank=114100 of ranks=133220rank=114200 of ranks=133220rank=114300 of ranks=133220rank=114400 of ranks=133220rank=114500 of ranks=133220rank=114600 of ranks=133220rank=114700 of ranks=133220rank=114800 of ranks=133220rank=114900 of ranks=133220rank=115000 of ranks=133220rank=115100 of ranks=133220rank=115200 of ranks=133220rank=115300 of ranks=133220rank=115400 of ranks=133220rank=115500 of ranks=133220rank=115600 of ranks=133220rank=115700 of ranks=133220rank=115800 of ranks=133220rank=115900 of ranks=133220rank=116000 of ranks=133220rank=116100 of ranks=133220rank=116200 of ranks=133220rank=116300 of ranks=133220rank=116400 of ranks=133220rank=116500 of ranks=133220rank=116600 of ranks=133220rank=116700 of ranks=133220rank=116800 of ranks=133220rank=116900 of ranks=133220rank=117000 of ranks=133220rank=117100 of ranks=133220rank=117200 of ranks=133220rank=117300 of ranks=133220rank=117400 of ranks=133220rank=117500 of ranks=133220rank=117600 of ranks=133220rank=117700 of ranks=133220rank=117800 of ranks=133220rank=117900 of ranks=133220rank=118000 of ranks=133220rank=118100 of ranks=133220rank=118200 of ranks=133220rank=118300 of ranks=133220rank=118400 of ranks=133220rank=118500 of ranks=133220rank=118600 of ranks=133220rank=118700 of ranks=133220rank=118800 of ranks=133220rank=118900 of ranks=133220rank=119000 of ranks=133220rank=119100 of ranks=133220rank=119200 of ranks=133220rank=119300 of ranks=133220rank=119400 of ranks=133220rank=119500 of ranks=133220rank=119600 of ranks=133220rank=119700 of ranks=133220rank=119800 of ranks=133220rank=119900 of ranks=133220rank=120000 of ranks=133220rank=120100 of ranks=133220rank=120200 of ranks=133220rank=120300 of ranks=133220rank=120400 of ranks=133220rank=120500 of ranks=133220rank=120600 of ranks=133220rank=120700 of ranks=133220rank=120800 of ranks=133220rank=120900 of ranks=133220rank=121000 of ranks=133220rank=121100 of ranks=133220rank=121200 of ranks=133220rank=121300 of ranks=133220rank=121400 of ranks=133220rank=121500 of ranks=133220rank=121600 of ranks=133220rank=121700 of ranks=133220rank=121800 of ranks=133220rank=121900 of ranks=133220rank=122000 of ranks=133220rank=122100 of ranks=133220rank=122200 of ranks=133220rank=122300 of ranks=133220rank=122400 of ranks=133220rank=122500 of ranks=133220rank=122600 of ranks=133220rank=122700 of ranks=133220rank=122800 of ranks=133220rank=122900 of ranks=133220rank=123000 of ranks=133220rank=123100 of ranks=133220rank=123200 of ranks=133220rank=123300 of ranks=133220rank=123400 of ranks=133220rank=123500 of ranks=133220rank=123600 of ranks=133220rank=123700 of ranks=133220rank=123800 of ranks=133220rank=123900 of ranks=133220rank=124000 of ranks=133220rank=124100 of ranks=133220rank=124200 of ranks=133220rank=124300 of ranks=133220rank=124400 of ranks=133220rank=124500 of ranks=133220rank=124600 of ranks=133220rank=124700 of ranks=133220rank=124800 of ranks=133220rank=124900 of ranks=133220rank=125000 of ranks=133220rank=125100 of ranks=133220rank=125200 of ranks=133220rank=125300 of ranks=133220rank=125400 of ranks=133220rank=125500 of ranks=133220rank=125600 of ranks=133220rank=125700 of ranks=133220rank=125800 of ranks=133220rank=125900 of ranks=133220rank=126000 of ranks=133220rank=126100 of ranks=133220rank=126200 of ranks=133220rank=126300 of ranks=133220rank=126400 of ranks=133220rank=126500 of ranks=133220rank=126600 of ranks=133220rank=126700 of ranks=133220rank=126800 of ranks=133220rank=126900 of ranks=133220rank=127000 of ranks=133220rank=127100 of ranks=133220rank=127200 of ranks=133220rank=127300 of ranks=133220rank=127400 of ranks=133220rank=127500 of ranks=133220rank=127600 of ranks=133220rank=127700 of ranks=133220rank=127800 of ranks=133220rank=127900 of ranks=133220rank=128000 of ranks=133220rank=128100 of ranks=133220rank=128200 of ranks=133220rank=128300 of ranks=133220rank=128400 of ranks=133220rank=128500 of ranks=133220rank=128600 of ranks=133220rank=128700 of ranks=133220rank=128800 of ranks=133220rank=128900 of ranks=133220rank=129000 of ranks=133220rank=129100 of ranks=133220rank=129200 of ranks=133220rank=129300 of ranks=133220rank=129400 of ranks=133220rank=129500 of ranks=133220rank=129600 of ranks=133220rank=129700 of ranks=133220rank=129800 of ranks=133220rank=129900 of ranks=133220rank=130000 of ranks=133220rank=130100 of ranks=133220rank=130200 of ranks=133220rank=130300 of ranks=133220rank=130400 of ranks=133220rank=130500 of ranks=133220rank=130600 of ranks=133220rank=130700 of ranks=133220rank=130800 of ranks=133220rank=130900 of ranks=133220rank=131000 of ranks=133220rank=131100 of ranks=133220rank=131200 of ranks=133220rank=131300 of ranks=133220rank=131400 of ranks=133220rank=131500 of ranks=133220rank=131600 of ranks=133220rank=131700 of ranks=133220rank=131800 of ranks=133220rank=131900 of ranks=133220rank=132000 of ranks=133220rank=132100 of ranks=133220rank=132200 of ranks=133220rank=132300 of ranks=133220rank=132400 of ranks=133220rank=132500 of ranks=133220rank=132600 of ranks=133220rank=132700 of ranks=133220rank=132800 of ranks=133220rank=132900 of ranks=133220rank=133000 of ranks=133220rank=133100 of ranks=133220rank=133200 of ranks=133220

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              79.1858    466   6344     32    498           55.1074
   1 car                    96.9813  49660  32269    656  50316           78.6366
   2 truck                  88.2165   1783  18538     42   1825           54.4613
   3 bus                    73.8382    356   5952     10    366           55.6519
   4 pedestrian             89.5283   4030  13822    229   4259           67.0662

for conf_thresh=0.25, precision=0.90, recall=0.90, F1 score=0.90
for conf_thresh=0.25, TP=51784, FP=5793, FN=5480, average IoU=76.67%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=85.55%
Total detection time: 234 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
3843: loss=4.806, avg loss=5.342, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.9 seconds, 245952 images, time remaining=5.1 hours
3844: loss=5.381, avg loss=5.346, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 246016 images, time remaining=5.1 hours
3845: loss=4.622, avg loss=5.274, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.9 seconds, 246080 images, time remaining=5.1 hours
3846: loss=4.657, avg loss=5.212, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 246144 images, time remaining=5.1 hours
3847: loss=4.937, avg loss=5.184, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 246208 images, time remaining=5 hours
3848: loss=5.515, avg loss=5.218, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 246272 images, time remaining=5 hours
3849: loss=4.871, avg loss=5.183, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 246336 images, time remaining=5 hours
3850: loss=5.216, avg loss=5.186, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.9 seconds, 246400 images, time remaining=5 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3851: loss=6.063, avg loss=5.274, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=6.9 seconds, train=4.8 seconds, 246464 images, time remaining=5 hours
3852: loss=5.101, avg loss=5.257, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=3.7 seconds, train=4.9 seconds, 246528 images, time remaining=5 hours
3853: loss=4.326, avg loss=5.164, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 246592 images, time remaining=5 hours
3854: loss=4.587, avg loss=5.106, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 246656 images, time remaining=5 hours
3855: loss=4.197, avg loss=5.015, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=4.8 seconds, 246720 images, time remaining=5 hours
3856: loss=4.430, avg loss=4.957, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.2 seconds, train=4.9 seconds, 246784 images, time remaining=5 hours
3857: loss=5.569, avg loss=5.018, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=5.0 seconds, 246848 images, time remaining=5 hours
3858: loss=4.947, avg loss=5.011, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 246912 images, time remaining=5 hours
3859: loss=4.609, avg loss=4.970, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 246976 images, time remaining=5 hours
3860: loss=4.323, avg loss=4.906, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 247040 images, time remaining=5 hours
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3861: loss=5.080, avg loss=4.923, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=3.5 seconds, train=5.9 seconds, 247104 images, time remaining=5 hours
3862: loss=5.363, avg loss=4.967, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.7 seconds, train=6.0 seconds, 247168 images, time remaining=5 hours
3863: loss=5.454, avg loss=5.016, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=3.3 seconds, train=5.9 seconds, 247232 images, time remaining=5 hours
3864: loss=4.617, avg loss=4.976, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.5 seconds, train=6.0 seconds, 247296 images, time remaining=5 hours
3865: loss=5.563, avg loss=5.035, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 247360 images, time remaining=5 hours
3866: loss=4.602, avg loss=4.991, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=6.0 seconds, 247424 images, time remaining=5 hours
3867: loss=5.151, avg loss=5.007, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 247488 images, time remaining=5 hours
3868: loss=5.139, avg loss=5.021, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 247552 images, time remaining=5 hours
3869: loss=5.052, avg loss=5.024, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=6.1 seconds, 247616 images, time remaining=5 hours
3870: loss=4.041, avg loss=4.925, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.1 seconds, train=5.9 seconds, 247680 images, time remaining=5 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b30e000000
3871: loss=4.096, avg loss=4.843, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.7 seconds, train=2.7 seconds, 247744 images, time remaining=5 hours
3872: loss=3.509, avg loss=4.709, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.7 seconds, 247808 images, time remaining=5 hours
3873: loss=4.427, avg loss=4.681, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.1 seconds, train=2.8 seconds, 247872 images, time remaining=5 hours
3874: loss=4.663, avg loss=4.679, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 247936 images, time remaining=5 hours
3875: loss=4.500, avg loss=4.661, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 248000 images, time remaining=5 hours
3876: loss=4.103, avg loss=4.605, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 248064 images, time remaining=5 hours
3877: loss=4.785, avg loss=4.623, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=2.9 seconds, 248128 images, time remaining=5 hours
3878: loss=4.476, avg loss=4.609, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.4 seconds, train=2.8 seconds, 248192 images, time remaining=5 hours
3879: loss=3.793, avg loss=4.527, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.2 seconds, train=2.8 seconds, 248256 images, time remaining=5 hours
3880: loss=4.235, avg loss=4.498, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.5 seconds, train=2.8 seconds, 248320 images, time remaining=5 hours
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3881: loss=4.932, avg loss=4.541, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=4.0 seconds, 248384 images, time remaining=5 hours
3882: loss=3.829, avg loss=4.470, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=3.8 seconds, 248448 images, time remaining=5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3883: loss=3.903, avg loss=4.413, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=4.8 seconds, train=3.7 seconds, 248512 images, time remaining=5 hours
3884: loss=4.868, avg loss=4.459, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.5 seconds, train=4.0 seconds, 248576 images, time remaining=5 hours
3885: loss=3.687, avg loss=4.382, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.2 seconds, train=3.9 seconds, 248640 images, time remaining=5 hours
3886: loss=3.806, avg loss=4.324, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=3.8 seconds, train=4.1 seconds, 248704 images, time remaining=5 hours
3887: loss=3.994, avg loss=4.291, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 248768 images, time remaining=5 hours
3888: loss=3.728, avg loss=4.235, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 248832 images, time remaining=5 hours
3889: loss=4.055, avg loss=4.217, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 248896 images, time remaining=5 hours
3890: loss=3.713, avg loss=4.166, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.1 seconds, train=4.0 seconds, 248960 images, time remaining=5 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b673800000
3891: loss=5.007, avg loss=4.250, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.0 seconds, train=2.1 seconds, 249024 images, time remaining=5 hours
3892: loss=4.815, avg loss=4.307, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 249088 images, time remaining=5 hours
3893: loss=4.723, avg loss=4.348, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 249152 images, time remaining=5 hours
3894: loss=4.507, avg loss=4.364, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 249216 images, time remaining=5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3895: loss=4.391, avg loss=4.367, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.3 seconds, train=2.1 seconds, 249280 images, time remaining=5 hours
3896: loss=4.471, avg loss=4.377, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 249344 images, time remaining=5 hours
3897: loss=4.833, avg loss=4.423, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 249408 images, time remaining=5 hours
3898: loss=4.127, avg loss=4.393, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 249472 images, time remaining=5 hours
3899: loss=4.253, avg loss=4.379, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=2.2 seconds, 249536 images, time remaining=5 hours
3900: loss=5.097, avg loss=4.451, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 249600 images, time remaining=5 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14c25c000000
3901: loss=3.670, avg loss=4.373, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 249664 images, time remaining=5 hours
3902: loss=4.414, avg loss=4.377, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 249728 images, time remaining=5 hours
3903: loss=4.698, avg loss=4.409, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 249792 images, time remaining=5 hours
3904: loss=4.187, avg loss=4.387, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 249856 images, time remaining=5 hours
3905: loss=3.892, avg loss=4.337, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 249920 images, time remaining=5 hours
3906: loss=4.046, avg loss=4.308, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 249984 images, time remaining=5 hours
3907: loss=3.420, avg loss=4.219, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 250048 images, time remaining=5 hours
3908: loss=3.165, avg loss=4.114, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 250112 images, time remaining=5 hours
3909: loss=4.260, avg loss=4.129, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 250176 images, time remaining=5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3910: loss=3.987, avg loss=4.114, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=3.4 seconds, train=1.9 seconds, 250240 images, time remaining=5 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3911: loss=4.623, avg loss=4.165, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.7 seconds, train=5.8 seconds, 250304 images, time remaining=5 hours
3912: loss=5.259, avg loss=4.275, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 250368 images, time remaining=5 hours
3913: loss=5.544, avg loss=4.402, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 250432 images, time remaining=5 hours
3914: loss=4.888, avg loss=4.450, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.2 seconds, train=5.8 seconds, 250496 images, time remaining=5 hours
3915: loss=4.749, avg loss=4.480, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 250560 images, time remaining=5 hours
3916: loss=4.482, avg loss=4.480, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=3.1 seconds, train=5.8 seconds, 250624 images, time remaining=5 hours
3917: loss=5.212, avg loss=4.553, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.1 seconds, train=5.8 seconds, 250688 images, time remaining=5 hours
3918: loss=4.494, avg loss=4.548, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 250752 images, time remaining=5 hours
3919: loss=4.622, avg loss=4.555, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 250816 images, time remaining=5 hours
3920: loss=5.326, avg loss=4.632, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.2 seconds, train=5.9 seconds, 250880 images, time remaining=5 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b67e000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3921: loss=5.690, avg loss=4.738, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.3 seconds, train=2.1 seconds, 250944 images, time remaining=5 hours
3922: loss=5.304, avg loss=4.795, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 251008 images, time remaining=5 hours
3923: loss=3.959, avg loss=4.711, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 251072 images, time remaining=5 hours
3924: loss=4.113, avg loss=4.651, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 251136 images, time remaining=5 hours
3925: loss=4.648, avg loss=4.651, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 251200 images, time remaining=5 hours
3926: loss=4.520, avg loss=4.638, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 251264 images, time remaining=4.9 hours
3927: loss=3.368, avg loss=4.511, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 251328 images, time remaining=4.9 hours
3928: loss=3.929, avg loss=4.453, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.1 seconds, train=2.2 seconds, 251392 images, time remaining=4.9 hours
3929: loss=4.413, avg loss=4.449, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 251456 images, time remaining=4.9 hours
3930: loss=4.352, avg loss=4.439, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 251520 images, time remaining=4.9 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3931: loss=5.384, avg loss=4.533, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=4.1 seconds, 251584 images, time remaining=4.9 hours
3932: loss=5.150, avg loss=4.595, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.4 seconds, train=4.1 seconds, 251648 images, time remaining=4.9 hours
3933: loss=4.540, avg loss=4.590, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.6 seconds, train=4.1 seconds, 251712 images, time remaining=4.9 hours
3934: loss=4.628, avg loss=4.593, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.1 seconds, train=4.1 seconds, 251776 images, time remaining=4.9 hours
3935: loss=3.971, avg loss=4.531, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 251840 images, time remaining=4.9 hours
3936: loss=4.084, avg loss=4.486, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=4.1 seconds, 251904 images, time remaining=4.9 hours
3937: loss=4.124, avg loss=4.450, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 251968 images, time remaining=4.9 hours
3938: loss=4.995, avg loss=4.505, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.6 seconds, train=4.1 seconds, 252032 images, time remaining=4.9 hours
3939: loss=4.403, avg loss=4.494, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 252096 images, time remaining=4.9 hours
3940: loss=4.959, avg loss=4.541, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=4.1 seconds, 252160 images, time remaining=4.9 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b7a7800000
3941: loss=5.241, avg loss=4.611, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 252224 images, time remaining=4.9 hours
3942: loss=4.504, avg loss=4.600, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 252288 images, time remaining=4.9 hours
3943: loss=4.766, avg loss=4.617, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.1 seconds, train=2.2 seconds, 252352 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3944: loss=4.417, avg loss=4.597, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.7 seconds, train=2.4 seconds, 252416 images, time remaining=4.9 hours
3945: loss=3.357, avg loss=4.473, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.4 seconds, 252480 images, time remaining=4.9 hours
3946: loss=3.844, avg loss=4.410, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 252544 images, time remaining=4.9 hours
3947: loss=4.306, avg loss=4.400, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 252608 images, time remaining=4.9 hours
3948: loss=4.537, avg loss=4.413, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 252672 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3949: loss=4.771, avg loss=4.449, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.5 seconds, train=2.3 seconds, 252736 images, time remaining=4.9 hours
3950: loss=4.090, avg loss=4.413, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 252800 images, time remaining=4.9 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3951: loss=6.083, avg loss=4.580, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 252864 images, time remaining=4.9 hours
3952: loss=7.912, avg loss=4.913, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=5.5 seconds, 252928 images, time remaining=4.9 hours
3953: loss=5.650, avg loss=4.987, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 252992 images, time remaining=4.9 hours
3954: loss=4.372, avg loss=4.926, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 253056 images, time remaining=4.9 hours
3955: loss=4.355, avg loss=4.868, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 253120 images, time remaining=4.9 hours
3956: loss=5.252, avg loss=4.907, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 253184 images, time remaining=4.9 hours
3957: loss=4.776, avg loss=4.894, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=5.0 seconds, train=5.5 seconds, 253248 images, time remaining=4.9 hours
3958: loss=4.406, avg loss=4.845, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.6 seconds, train=5.4 seconds, 253312 images, time remaining=4.9 hours
3959: loss=6.048, avg loss=4.965, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 253376 images, time remaining=4.9 hours
3960: loss=6.373, avg loss=5.106, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.1 seconds, train=5.5 seconds, 253440 images, time remaining=4.9 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
3961: loss=5.662, avg loss=5.162, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 253504 images, time remaining=4.9 hours
3962: loss=4.856, avg loss=5.131, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=3.1 seconds, train=5.7 seconds, 253568 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3963: loss=4.740, avg loss=5.092, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=5.8 seconds, train=5.7 seconds, 253632 images, time remaining=4.9 hours
3964: loss=4.087, avg loss=4.991, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.5 seconds, train=5.8 seconds, 253696 images, time remaining=4.9 hours
3965: loss=5.063, avg loss=4.999, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 253760 images, time remaining=4.9 hours
3966: loss=4.871, avg loss=4.986, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.3 seconds, train=5.7 seconds, 253824 images, time remaining=4.9 hours
3967: loss=4.330, avg loss=4.920, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.2 seconds, train=5.9 seconds, 253888 images, time remaining=4.9 hours
3968: loss=5.355, avg loss=4.964, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.4 seconds, train=5.9 seconds, 253952 images, time remaining=4.9 hours
3969: loss=4.301, avg loss=4.898, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.4 seconds, train=5.7 seconds, 254016 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3970: loss=5.492, avg loss=4.957, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=6.1 seconds, train=5.8 seconds, 254080 images, time remaining=4.9 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b632400000
3971: loss=5.986, avg loss=5.060, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.2 seconds, train=1.7 seconds, 254144 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3972: loss=4.879, avg loss=5.042, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=6.3 seconds, train=1.8 seconds, 254208 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3973: loss=4.887, avg loss=5.026, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.3 seconds, train=1.7 seconds, 254272 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3974: loss=4.589, avg loss=4.983, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=4.9 seconds, train=1.9 seconds, 254336 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3975: loss=4.074, avg loss=4.892, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.1 seconds, train=1.8 seconds, 254400 images, time remaining=4.9 hours
3976: loss=4.473, avg loss=4.850, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 254464 images, time remaining=4.9 hours
3977: loss=3.833, avg loss=4.748, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 254528 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3978: loss=5.033, avg loss=4.777, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=1.7 seconds, 254592 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3979: loss=3.810, avg loss=4.680, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.3 seconds, train=1.8 seconds, 254656 images, time remaining=4.9 hours
3980: loss=4.097, avg loss=4.622, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=1.8 seconds, 254720 images, time remaining=4.9 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b432400000
3981: loss=4.218, avg loss=4.581, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 254784 images, time remaining=4.9 hours
3982: loss=5.019, avg loss=4.625, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 254848 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3983: loss=4.688, avg loss=4.631, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=1.8 seconds, 254912 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3984: loss=3.861, avg loss=4.554, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=5.9 seconds, train=2.1 seconds, 254976 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3985: loss=5.014, avg loss=4.600, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=3.1 seconds, train=2.2 seconds, 255040 images, time remaining=4.9 hours
3986: loss=3.917, avg loss=4.532, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 255104 images, time remaining=4.9 hours
3987: loss=4.017, avg loss=4.481, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 255168 images, time remaining=4.9 hours
3988: loss=4.092, avg loss=4.442, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 255232 images, time remaining=4.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
3989: loss=3.353, avg loss=4.333, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.5 seconds, train=2.2 seconds, 255296 images, time remaining=4.9 hours
3990: loss=3.912, avg loss=4.291, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 255360 images, time remaining=4.9 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b50cc00000
3991: loss=3.774, avg loss=4.239, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.5 seconds, 255424 images, time remaining=4.9 hours
3992: loss=4.290, avg loss=4.244, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 255488 images, time remaining=4.9 hours
3993: loss=4.152, avg loss=4.235, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 255552 images, time remaining=4.9 hours
3994: loss=3.714, avg loss=4.183, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=2.3 seconds, 255616 images, time remaining=4.9 hours
3995: loss=4.205, avg loss=4.185, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 255680 images, time remaining=4.9 hours
3996: loss=3.932, avg loss=4.160, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 255744 images, time remaining=4.9 hours
3997: loss=3.811, avg loss=4.125, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 255808 images, time remaining=4.9 hours
3998: loss=3.263, avg loss=4.039, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 255872 images, time remaining=4.9 hours
3999: loss=3.860, avg loss=4.021, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 255936 images, time remaining=4.9 hours
4000: loss=3.653, avg loss=3.984, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 256000 images, time remaining=4.8 hours
Saving weights to /workspace/.cache/splits/combined_4000.weights
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b50cc00000
4001: loss=3.303, avg loss=3.916, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 256064 images, time remaining=4.8 hours
4002: loss=3.290, avg loss=3.853, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 256128 images, time remaining=4.8 hours
4003: loss=3.480, avg loss=3.816, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 256192 images, time remaining=4.8 hours
4004: loss=4.097, avg loss=3.844, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=1.8 seconds, 256256 images, time remaining=4.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4005: loss=4.202, avg loss=3.880, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=4.9 seconds, train=1.9 seconds, 256320 images, time remaining=4.8 hours
4006: loss=3.353, avg loss=3.827, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 256384 images, time remaining=4.8 hours
4007: loss=3.626, avg loss=3.807, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 256448 images, time remaining=4.8 hours
4008: loss=3.878, avg loss=3.814, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 256512 images, time remaining=4.8 hours
4009: loss=4.157, avg loss=3.848, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 256576 images, time remaining=4.8 hours
4010: loss=3.777, avg loss=3.841, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 256640 images, time remaining=4.8 hours
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4011: loss=8.236, avg loss=4.281, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=6.2 seconds, 256704 images, time remaining=4.8 hours
4012: loss=6.634, avg loss=4.516, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.9 seconds, train=6.1 seconds, 256768 images, time remaining=4.8 hours
4013: loss=5.620, avg loss=4.626, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=6.0 seconds, train=6.0 seconds, 256832 images, time remaining=4.8 hours
4014: loss=4.385, avg loss=4.602, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.6 seconds, train=6.0 seconds, 256896 images, time remaining=4.8 hours
4015: loss=4.147, avg loss=4.557, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 256960 images, time remaining=4.8 hours
4016: loss=5.192, avg loss=4.620, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=6.0 seconds, 257024 images, time remaining=4.8 hours
4017: loss=4.480, avg loss=4.606, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=3.7 seconds, train=6.0 seconds, 257088 images, time remaining=4.8 hours
4018: loss=6.109, avg loss=4.757, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=5.9 seconds, 257152 images, time remaining=4.8 hours
4019: loss=5.116, avg loss=4.792, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=4.5 seconds, train=6.1 seconds, 257216 images, time remaining=4.8 hours
4020: loss=5.280, avg loss=4.841, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 257280 images, time remaining=4.8 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b82d000000
4021: loss=5.306, avg loss=4.888, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 257344 images, time remaining=4.8 hours
4022: loss=5.673, avg loss=4.966, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 257408 images, time remaining=4.8 hours
4023: loss=4.883, avg loss=4.958, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.0 seconds, 257472 images, time remaining=4.8 hours
4024: loss=5.724, avg loss=5.034, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 257536 images, time remaining=4.8 hours
4025: loss=4.885, avg loss=5.020, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 257600 images, time remaining=4.8 hours
4026: loss=4.231, avg loss=4.941, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 257664 images, time remaining=4.8 hours
4027: loss=5.058, avg loss=4.952, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 257728 images, time remaining=4.8 hours
4028: loss=4.464, avg loss=4.904, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 257792 images, time remaining=4.8 hours
4029: loss=4.108, avg loss=4.824, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 257856 images, time remaining=4.8 hours
4030: loss=5.142, avg loss=4.856, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=1.7 seconds, 257920 images, time remaining=4.8 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b516600000
4031: loss=5.733, avg loss=4.944, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 257984 images, time remaining=4.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4032: loss=5.681, avg loss=5.017, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=6.3 seconds, train=2.7 seconds, 258048 images, time remaining=4.8 hours
4033: loss=5.762, avg loss=5.092, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.5 seconds, train=2.8 seconds, 258112 images, time remaining=4.8 hours
4034: loss=5.238, avg loss=5.106, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 258176 images, time remaining=4.8 hours
4035: loss=4.699, avg loss=5.066, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 258240 images, time remaining=4.8 hours
4036: loss=3.757, avg loss=4.935, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 258304 images, time remaining=4.8 hours
4037: loss=3.994, avg loss=4.841, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.2 seconds, train=2.7 seconds, 258368 images, time remaining=4.8 hours
4038: loss=3.764, avg loss=4.733, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 258432 images, time remaining=4.8 hours
4039: loss=4.638, avg loss=4.723, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.4 seconds, train=2.7 seconds, 258496 images, time remaining=4.8 hours
4040: loss=3.881, avg loss=4.639, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 258560 images, time remaining=4.8 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b776800000
4041: loss=4.694, avg loss=4.645, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 258624 images, time remaining=4.8 hours
4042: loss=6.024, avg loss=4.783, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.1 seconds, 258688 images, time remaining=4.8 hours
4043: loss=5.170, avg loss=4.821, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.1 seconds, 258752 images, time remaining=4.8 hours
4044: loss=4.815, avg loss=4.821, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 258816 images, time remaining=4.8 hours
4045: loss=3.953, avg loss=4.734, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 258880 images, time remaining=4.8 hours
4046: loss=3.832, avg loss=4.644, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 258944 images, time remaining=4.8 hours
4047: loss=4.049, avg loss=4.584, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 259008 images, time remaining=4.8 hours
4048: loss=4.044, avg loss=4.530, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 259072 images, time remaining=4.8 hours
4049: loss=4.232, avg loss=4.500, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 259136 images, time remaining=4.8 hours
4050: loss=3.933, avg loss=4.444, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 259200 images, time remaining=4.8 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b776800000
4051: loss=4.239, avg loss=4.423, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 259264 images, time remaining=4.8 hours
4052: loss=4.337, avg loss=4.415, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 259328 images, time remaining=4.8 hours
4053: loss=3.632, avg loss=4.336, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 259392 images, time remaining=4.8 hours
4054: loss=4.678, avg loss=4.370, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 259456 images, time remaining=4.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4055: loss=3.608, avg loss=4.294, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=3.2 seconds, train=2.1 seconds, 259520 images, time remaining=4.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4056: loss=4.637, avg loss=4.328, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.6 seconds, train=2.1 seconds, 259584 images, time remaining=4.8 hours
4057: loss=4.555, avg loss=4.351, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 259648 images, time remaining=4.8 hours
4058: loss=4.010, avg loss=4.317, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 259712 images, time remaining=4.8 hours
4059: loss=3.906, avg loss=4.276, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 259776 images, time remaining=4.8 hours
4060: loss=4.094, avg loss=4.258, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 259840 images, time remaining=4.8 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b776800000
4061: loss=4.007, avg loss=4.233, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 259904 images, time remaining=4.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4062: loss=3.365, avg loss=4.146, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.1 seconds, train=2.1 seconds, 259968 images, time remaining=4.8 hours
4063: loss=4.388, avg loss=4.170, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 260032 images, time remaining=4.8 hours
4064: loss=3.289, avg loss=4.082, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 260096 images, time remaining=4.8 hours
4065: loss=3.804, avg loss=4.054, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 260160 images, time remaining=4.8 hours
4066: loss=3.633, avg loss=4.012, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 260224 images, time remaining=4.7 hours
4067: loss=3.362, avg loss=3.947, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 260288 images, time remaining=4.7 hours
4068: loss=4.017, avg loss=3.954, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 260352 images, time remaining=4.7 hours
4069: loss=3.395, avg loss=3.898, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 260416 images, time remaining=4.7 hours
4070: loss=4.366, avg loss=3.945, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 260480 images, time remaining=4.7 hours
Resizing, random_coef=1.40, batch=4, 1088x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4071: loss=4.818, avg loss=4.032, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 260544 images, time remaining=4.7 hours
4072: loss=4.614, avg loss=4.090, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=4.1 seconds, 260608 images, time remaining=4.7 hours
4073: loss=3.613, avg loss=4.043, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=4.1 seconds, 260672 images, time remaining=4.7 hours
4074: loss=4.669, avg loss=4.105, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 260736 images, time remaining=4.7 hours
4075: loss=4.157, avg loss=4.110, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=4.3 seconds, 260800 images, time remaining=4.7 hours
4076: loss=3.556, avg loss=4.055, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=4.2 seconds, 260864 images, time remaining=4.7 hours
4077: loss=3.758, avg loss=4.025, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=4.3 seconds, 260928 images, time remaining=4.7 hours
4078: loss=4.326, avg loss=4.055, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=4.3 seconds, 260992 images, time remaining=4.7 hours
4079: loss=3.967, avg loss=4.047, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 261056 images, time remaining=4.7 hours
4080: loss=4.169, avg loss=4.059, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=4.2 seconds, 261120 images, time remaining=4.7 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b623e00000
4081: loss=4.053, avg loss=4.058, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 261184 images, time remaining=4.7 hours
4082: loss=4.001, avg loss=4.053, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 261248 images, time remaining=4.7 hours
4083: loss=4.429, avg loss=4.090, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 261312 images, time remaining=4.7 hours
4084: loss=3.899, avg loss=4.071, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 261376 images, time remaining=4.7 hours
4085: loss=3.543, avg loss=4.018, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 261440 images, time remaining=4.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4086: loss=3.595, avg loss=3.976, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.8 seconds, train=2.6 seconds, 261504 images, time remaining=4.7 hours
4087: loss=3.649, avg loss=3.943, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 261568 images, time remaining=4.7 hours
4088: loss=3.884, avg loss=3.937, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.6 seconds, 261632 images, time remaining=4.7 hours
4089: loss=3.871, avg loss=3.931, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.6 seconds, 261696 images, time remaining=4.7 hours
4090: loss=3.945, avg loss=3.932, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 261760 images, time remaining=4.7 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b623e00000
4091: loss=3.445, avg loss=3.883, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.6 seconds, 261824 images, time remaining=4.7 hours
4092: loss=3.871, avg loss=3.882, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.6 seconds, 261888 images, time remaining=4.7 hours
4093: loss=3.957, avg loss=3.890, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 261952 images, time remaining=4.7 hours
4094: loss=3.352, avg loss=3.836, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 262016 images, time remaining=4.7 hours
4095: loss=3.362, avg loss=3.789, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 262080 images, time remaining=4.7 hours
4096: loss=3.691, avg loss=3.779, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 262144 images, time remaining=4.7 hours
4097: loss=3.368, avg loss=3.738, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.5 seconds, 262208 images, time remaining=4.7 hours
4098: loss=3.704, avg loss=3.734, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 262272 images, time remaining=4.7 hours
4099: loss=3.464, avg loss=3.707, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.6 seconds, 262336 images, time remaining=4.7 hours
4100: loss=2.875, avg loss=3.624, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.5 seconds, 262400 images, time remaining=4.7 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4101: loss=3.844, avg loss=3.646, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.1 seconds, train=4.7 seconds, 262464 images, time remaining=4.7 hours
4102: loss=4.297, avg loss=3.711, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=4.7 seconds, 262528 images, time remaining=4.7 hours
4103: loss=4.402, avg loss=3.780, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 262592 images, time remaining=4.7 hours
4104: loss=4.173, avg loss=3.819, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 262656 images, time remaining=4.7 hours
4105: loss=4.076, avg loss=3.845, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 262720 images, time remaining=4.7 hours
4106: loss=4.310, avg loss=3.892, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 262784 images, time remaining=4.7 hours
4107: loss=3.710, avg loss=3.873, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 262848 images, time remaining=4.7 hours
4108: loss=4.571, avg loss=3.943, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 262912 images, time remaining=4.7 hours
4109: loss=4.185, avg loss=3.967, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=4.6 seconds, 262976 images, time remaining=4.7 hours
4110: loss=4.317, avg loss=4.002, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=4.8 seconds, 263040 images, time remaining=4.7 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b6d0600000
4111: loss=4.184, avg loss=4.021, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 263104 images, time remaining=4.7 hours
4112: loss=4.500, avg loss=4.068, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.3 seconds, 263168 images, time remaining=4.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4113: loss=4.457, avg loss=4.107, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.8 seconds, train=2.4 seconds, 263232 images, time remaining=4.7 hours
4114: loss=3.748, avg loss=4.071, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 263296 images, time remaining=4.7 hours
4115: loss=3.377, avg loss=4.002, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 263360 images, time remaining=4.7 hours
4116: loss=3.272, avg loss=3.929, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=2.3 seconds, 263424 images, time remaining=4.7 hours
4117: loss=3.619, avg loss=3.898, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 263488 images, time remaining=4.7 hours
4118: loss=3.686, avg loss=3.877, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 263552 images, time remaining=4.7 hours
4119: loss=3.960, avg loss=3.885, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 263616 images, time remaining=4.7 hours
4120: loss=3.412, avg loss=3.838, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 263680 images, time remaining=4.7 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b30e000000
4121: loss=3.812, avg loss=3.835, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 263744 images, time remaining=4.7 hours
4122: loss=3.942, avg loss=3.846, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.7 seconds, 263808 images, time remaining=4.7 hours
4123: loss=2.756, avg loss=3.737, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 263872 images, time remaining=4.7 hours
4124: loss=3.600, avg loss=3.723, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.8 seconds, 263936 images, time remaining=4.7 hours
4125: loss=3.772, avg loss=3.728, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=2.8 seconds, 264000 images, time remaining=4.7 hours
4126: loss=3.006, avg loss=3.656, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 264064 images, time remaining=4.7 hours
4127: loss=4.298, avg loss=3.720, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 264128 images, time remaining=4.7 hours
4128: loss=3.702, avg loss=3.718, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 264192 images, time remaining=4.7 hours
4129: loss=3.471, avg loss=3.694, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 264256 images, time remaining=4.7 hours
4130: loss=3.688, avg loss=3.693, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 264320 images, time remaining=4.7 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b54dc00000
4131: loss=3.880, avg loss=3.712, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 264384 images, time remaining=4.7 hours
4132: loss=3.726, avg loss=3.713, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 264448 images, time remaining=4.7 hours
4133: loss=4.079, avg loss=3.750, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 264512 images, time remaining=4.7 hours
4134: loss=4.126, avg loss=3.787, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 264576 images, time remaining=4.7 hours
4135: loss=4.705, avg loss=3.879, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 264640 images, time remaining=4.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4136: loss=3.336, avg loss=3.825, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=6.5 seconds, train=2.4 seconds, 264704 images, time remaining=4.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4137: loss=3.571, avg loss=3.799, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.5 seconds, train=2.3 seconds, 264768 images, time remaining=4.6 hours
4138: loss=3.526, avg loss=3.772, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 264832 images, time remaining=4.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4139: loss=3.636, avg loss=3.759, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=3.5 seconds, train=2.5 seconds, 264896 images, time remaining=4.6 hours
4140: loss=4.034, avg loss=3.786, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 264960 images, time remaining=4.6 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b54dc00000
4141: loss=3.271, avg loss=3.735, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 265024 images, time remaining=4.6 hours
4142: loss=3.656, avg loss=3.727, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 265088 images, time remaining=4.6 hours
4143: loss=3.385, avg loss=3.692, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 265152 images, time remaining=4.6 hours
4144: loss=2.969, avg loss=3.620, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 265216 images, time remaining=4.6 hours
4145: loss=3.489, avg loss=3.607, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 265280 images, time remaining=4.6 hours
4146: loss=3.503, avg loss=3.597, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 265344 images, time remaining=4.6 hours
4147: loss=3.510, avg loss=3.588, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 265408 images, time remaining=4.6 hours
4148: loss=3.853, avg loss=3.615, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 265472 images, time remaining=4.6 hours
4149: loss=3.860, avg loss=3.639, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 265536 images, time remaining=4.6 hours
4150: loss=2.822, avg loss=3.557, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 265600 images, time remaining=4.6 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b611200000
4151: loss=3.027, avg loss=3.504, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 265664 images, time remaining=4.6 hours
4152: loss=3.307, avg loss=3.485, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 265728 images, time remaining=4.6 hours
4153: loss=3.708, avg loss=3.507, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 265792 images, time remaining=4.6 hours
4154: loss=3.683, avg loss=3.524, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 265856 images, time remaining=4.6 hours
4155: loss=3.462, avg loss=3.518, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 265920 images, time remaining=4.6 hours
4156: loss=3.216, avg loss=3.488, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 265984 images, time remaining=4.6 hours
4157: loss=3.253, avg loss=3.464, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 266048 images, time remaining=4.6 hours
4158: loss=3.698, avg loss=3.488, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.7 seconds, train=2.7 seconds, 266112 images, time remaining=4.6 hours
4159: loss=3.534, avg loss=3.492, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.5 seconds, train=2.7 seconds, 266176 images, time remaining=4.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4160: loss=3.514, avg loss=3.495, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=4.2 seconds, train=2.6 seconds, 266240 images, time remaining=4.6 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4161: loss=3.537, avg loss=3.499, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=4.4 seconds, 266304 images, time remaining=4.6 hours
4162: loss=4.751, avg loss=3.624, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 266368 images, time remaining=4.6 hours
4163: loss=3.461, avg loss=3.608, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 266432 images, time remaining=4.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4164: loss=3.843, avg loss=3.631, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=7.7 seconds, train=4.2 seconds, 266496 images, time remaining=4.6 hours
4165: loss=2.981, avg loss=3.566, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=4.3 seconds, 266560 images, time remaining=4.6 hours
4166: loss=3.821, avg loss=3.592, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=4.4 seconds, 266624 images, time remaining=4.6 hours
4167: loss=3.768, avg loss=3.609, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.5 seconds, train=4.3 seconds, 266688 images, time remaining=4.6 hours
4168: loss=3.539, avg loss=3.602, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.2 seconds, train=4.3 seconds, 266752 images, time remaining=4.6 hours
4169: loss=3.458, avg loss=3.588, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=4.2 seconds, 266816 images, time remaining=4.6 hours
4170: loss=3.312, avg loss=3.560, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=4.2 seconds, 266880 images, time remaining=4.6 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b76f800000
4171: loss=3.966, avg loss=3.601, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 266944 images, time remaining=4.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4172: loss=4.335, avg loss=3.674, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.3 seconds, train=2.2 seconds, 267008 images, time remaining=4.6 hours
4173: loss=3.062, avg loss=3.613, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 267072 images, time remaining=4.6 hours
4174: loss=3.882, avg loss=3.640, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 267136 images, time remaining=4.6 hours
4175: loss=3.180, avg loss=3.594, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 267200 images, time remaining=4.6 hours
4176: loss=3.762, avg loss=3.611, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 267264 images, time remaining=4.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4177: loss=2.900, avg loss=3.540, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.6 seconds, train=2.2 seconds, 267328 images, time remaining=4.6 hours
4178: loss=3.227, avg loss=3.508, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 267392 images, time remaining=4.6 hours
4179: loss=3.764, avg loss=3.534, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 267456 images, time remaining=4.6 hours
4180: loss=3.645, avg loss=3.545, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.2 seconds, train=2.3 seconds, 267520 images, time remaining=4.6 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b696a00000
4181: loss=4.973, avg loss=3.688, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 267584 images, time remaining=4.6 hours
4182: loss=4.099, avg loss=3.729, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.0 seconds, 267648 images, time remaining=4.6 hours
4183: loss=3.616, avg loss=3.718, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 267712 images, time remaining=4.6 hours
4184: loss=3.801, avg loss=3.726, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 267776 images, time remaining=4.6 hours
4185: loss=2.745, avg loss=3.628, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 267840 images, time remaining=4.6 hours
4186: loss=3.386, avg loss=3.604, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 267904 images, time remaining=4.6 hours
4187: loss=3.985, avg loss=3.642, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 267968 images, time remaining=4.6 hours
4188: loss=3.912, avg loss=3.669, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 268032 images, time remaining=4.6 hours
4189: loss=3.223, avg loss=3.624, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 268096 images, time remaining=4.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4190: loss=3.419, avg loss=3.604, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=1.9 seconds, 268160 images, time remaining=4.6 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4191: loss=3.783, avg loss=3.622, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 268224 images, time remaining=4.6 hours
4192: loss=5.101, avg loss=3.770, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=4.0 seconds, train=4.3 seconds, 268288 images, time remaining=4.6 hours
4193: loss=4.349, avg loss=3.827, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=4.1 seconds, 268352 images, time remaining=4.6 hours
4194: loss=3.840, avg loss=3.829, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=4.1 seconds, 268416 images, time remaining=4.6 hours
4195: loss=3.837, avg loss=3.830, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 268480 images, time remaining=4.6 hours
4196: loss=3.421, avg loss=3.789, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=3.9 seconds, 268544 images, time remaining=4.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4197: loss=4.112, avg loss=3.821, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=6.1 seconds, train=3.9 seconds, 268608 images, time remaining=4.6 hours
4198: loss=3.574, avg loss=3.796, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.9 seconds, train=4.0 seconds, 268672 images, time remaining=4.6 hours
4199: loss=3.958, avg loss=3.812, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.9 seconds, train=4.1 seconds, 268736 images, time remaining=4.6 hours
4200: loss=3.581, avg loss=3.789, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 268800 images, time remaining=4.6 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b62c400000
4201: loss=4.029, avg loss=3.813, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 268864 images, time remaining=4.6 hours
4202: loss=3.937, avg loss=3.826, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 268928 images, time remaining=4.6 hours
4203: loss=3.893, avg loss=3.832, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 268992 images, time remaining=4.5 hours
4204: loss=4.657, avg loss=3.915, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 269056 images, time remaining=4.5 hours
4205: loss=4.047, avg loss=3.928, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 269120 images, time remaining=4.5 hours
4206: loss=3.511, avg loss=3.886, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 269184 images, time remaining=4.5 hours
4207: loss=3.882, avg loss=3.886, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=1.9 seconds, 269248 images, time remaining=4.5 hours
4208: loss=3.066, avg loss=3.804, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.0 seconds, 269312 images, time remaining=4.5 hours
4209: loss=4.571, avg loss=3.881, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 269376 images, time remaining=4.5 hours
4210: loss=3.717, avg loss=3.864, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 269440 images, time remaining=4.5 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b4e5400000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4211: loss=3.701, avg loss=3.848, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.7 seconds, train=1.8 seconds, 269504 images, time remaining=4.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4212: loss=3.243, avg loss=3.787, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.4 seconds, train=1.9 seconds, 269568 images, time remaining=4.5 hours
4213: loss=3.997, avg loss=3.808, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 269632 images, time remaining=4.5 hours
4214: loss=3.056, avg loss=3.733, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 269696 images, time remaining=4.5 hours
4215: loss=4.631, avg loss=3.823, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 269760 images, time remaining=4.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4216: loss=3.063, avg loss=3.747, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=1.8 seconds, 269824 images, time remaining=4.5 hours
4217: loss=4.058, avg loss=3.778, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 269888 images, time remaining=4.5 hours
4218: loss=3.422, avg loss=3.743, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 269952 images, time remaining=4.5 hours
4219: loss=3.702, avg loss=3.738, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 270016 images, time remaining=4.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4220: loss=3.358, avg loss=3.700, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=1.9 seconds, 270080 images, time remaining=4.5 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b739e00000
4221: loss=4.000, avg loss=3.730, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.0 seconds, train=2.8 seconds, 270144 images, time remaining=4.5 hours
4222: loss=3.292, avg loss=3.687, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 270208 images, time remaining=4.5 hours
4223: loss=3.483, avg loss=3.666, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.8 seconds, 270272 images, time remaining=4.5 hours
4224: loss=2.997, avg loss=3.599, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.9 seconds, train=2.8 seconds, 270336 images, time remaining=4.5 hours
4225: loss=3.937, avg loss=3.633, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 270400 images, time remaining=4.5 hours
4226: loss=3.673, avg loss=3.637, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 270464 images, time remaining=4.5 hours
4227: loss=3.393, avg loss=3.613, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.7 seconds, 270528 images, time remaining=4.5 hours
4228: loss=4.196, avg loss=3.671, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 270592 images, time remaining=4.5 hours
4229: loss=3.843, avg loss=3.688, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 270656 images, time remaining=4.5 hours
4230: loss=3.177, avg loss=3.637, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 270720 images, time remaining=4.5 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b715200000
4231: loss=3.547, avg loss=3.628, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 270784 images, time remaining=4.5 hours
4232: loss=3.555, avg loss=3.621, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 270848 images, time remaining=4.5 hours
4233: loss=3.333, avg loss=3.592, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 270912 images, time remaining=4.5 hours
4234: loss=3.841, avg loss=3.617, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 270976 images, time remaining=4.5 hours
4235: loss=3.410, avg loss=3.596, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 271040 images, time remaining=4.5 hours
4236: loss=3.303, avg loss=3.567, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.2 seconds, train=2.9 seconds, 271104 images, time remaining=4.5 hours
4237: loss=3.051, avg loss=3.515, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 271168 images, time remaining=4.5 hours
4238: loss=3.437, avg loss=3.507, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 271232 images, time remaining=4.5 hours
4239: loss=3.312, avg loss=3.488, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 271296 images, time remaining=4.5 hours
4240: loss=4.296, avg loss=3.569, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.3 seconds, train=2.7 seconds, 271360 images, time remaining=4.5 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b715200000
4241: loss=3.897, avg loss=3.602, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 271424 images, time remaining=4.5 hours
4242: loss=3.627, avg loss=3.604, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 271488 images, time remaining=4.5 hours
4243: loss=3.241, avg loss=3.568, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 271552 images, time remaining=4.5 hours
4244: loss=3.979, avg loss=3.609, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.8 seconds, train=2.7 seconds, 271616 images, time remaining=4.5 hours
4245: loss=3.507, avg loss=3.599, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=2.1 seconds, train=2.9 seconds, 271680 images, time remaining=4.5 hours
4246: loss=3.544, avg loss=3.593, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 271744 images, time remaining=4.5 hours
4247: loss=3.734, avg loss=3.607, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 271808 images, time remaining=4.5 hours
4248: loss=3.364, avg loss=3.583, last=85.55%, best=85.57%, next=4248, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 271872 images, time remaining=4.5 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b715200000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=137265, unique_truth_count=57264
rank=0 of ranks=137265rank=100 of ranks=137265rank=200 of ranks=137265rank=300 of ranks=137265rank=400 of ranks=137265rank=500 of ranks=137265rank=600 of ranks=137265rank=700 of ranks=137265rank=800 of ranks=137265rank=900 of ranks=137265rank=1000 of ranks=137265rank=1100 of ranks=137265rank=1200 of ranks=137265rank=1300 of ranks=137265rank=1400 of ranks=137265rank=1500 of ranks=137265rank=1600 of ranks=137265rank=1700 of ranks=137265rank=1800 of ranks=137265rank=1900 of ranks=137265rank=2000 of ranks=137265rank=2100 of ranks=137265rank=2200 of ranks=137265rank=2300 of ranks=137265rank=2400 of ranks=137265rank=2500 of ranks=137265rank=2600 of ranks=137265rank=2700 of ranks=137265rank=2800 of ranks=137265rank=2900 of ranks=137265rank=3000 of ranks=137265rank=3100 of ranks=137265rank=3200 of ranks=137265rank=3300 of ranks=137265rank=3400 of ranks=137265rank=3500 of ranks=137265rank=3600 of ranks=137265rank=3700 of ranks=137265rank=3800 of ranks=137265rank=3900 of ranks=137265rank=4000 of ranks=137265rank=4100 of ranks=137265rank=4200 of ranks=137265rank=4300 of ranks=137265rank=4400 of ranks=137265rank=4500 of ranks=137265rank=4600 of ranks=137265rank=4700 of ranks=137265rank=4800 of ranks=137265rank=4900 of ranks=137265rank=5000 of ranks=137265rank=5100 of ranks=137265rank=5200 of ranks=137265rank=5300 of ranks=137265rank=5400 of ranks=137265rank=5500 of ranks=137265rank=5600 of ranks=137265rank=5700 of ranks=137265rank=5800 of ranks=137265rank=5900 of ranks=137265rank=6000 of ranks=137265rank=6100 of ranks=137265rank=6200 of ranks=137265rank=6300 of ranks=137265rank=6400 of ranks=137265rank=6500 of ranks=137265rank=6600 of ranks=137265rank=6700 of ranks=137265rank=6800 of ranks=137265rank=6900 of ranks=137265rank=7000 of ranks=137265rank=7100 of ranks=137265rank=7200 of ranks=137265rank=7300 of ranks=137265rank=7400 of ranks=137265rank=7500 of ranks=137265rank=7600 of ranks=137265rank=7700 of ranks=137265rank=7800 of ranks=137265rank=7900 of ranks=137265rank=8000 of ranks=137265rank=8100 of ranks=137265rank=8200 of ranks=137265rank=8300 of ranks=137265rank=8400 of ranks=137265rank=8500 of ranks=137265rank=8600 of ranks=137265rank=8700 of ranks=137265rank=8800 of ranks=137265rank=8900 of ranks=137265rank=9000 of ranks=137265rank=9100 of ranks=137265rank=9200 of ranks=137265rank=9300 of ranks=137265rank=9400 of ranks=137265rank=9500 of ranks=137265rank=9600 of ranks=137265rank=9700 of ranks=137265rank=9800 of ranks=137265rank=9900 of ranks=137265rank=10000 of ranks=137265rank=10100 of ranks=137265rank=10200 of ranks=137265rank=10300 of ranks=137265rank=10400 of ranks=137265rank=10500 of ranks=137265rank=10600 of ranks=137265rank=10700 of ranks=137265rank=10800 of ranks=137265rank=10900 of ranks=137265rank=11000 of ranks=137265rank=11100 of ranks=137265rank=11200 of ranks=137265rank=11300 of ranks=137265rank=11400 of ranks=137265rank=11500 of ranks=137265rank=11600 of ranks=137265rank=11700 of ranks=137265rank=11800 of ranks=137265rank=11900 of ranks=137265rank=12000 of ranks=137265rank=12100 of ranks=137265rank=12200 of ranks=137265rank=12300 of ranks=137265rank=12400 of ranks=137265rank=12500 of ranks=137265rank=12600 of ranks=137265rank=12700 of ranks=137265rank=12800 of ranks=137265rank=12900 of ranks=137265rank=13000 of ranks=137265rank=13100 of ranks=137265rank=13200 of ranks=137265rank=13300 of ranks=137265rank=13400 of ranks=137265rank=13500 of ranks=137265rank=13600 of ranks=137265rank=13700 of ranks=137265rank=13800 of ranks=137265rank=13900 of ranks=137265rank=14000 of ranks=137265rank=14100 of ranks=137265rank=14200 of ranks=137265rank=14300 of ranks=137265rank=14400 of ranks=137265rank=14500 of ranks=137265rank=14600 of ranks=137265rank=14700 of ranks=137265rank=14800 of ranks=137265rank=14900 of ranks=137265rank=15000 of ranks=137265rank=15100 of ranks=137265rank=15200 of ranks=137265rank=15300 of ranks=137265rank=15400 of ranks=137265rank=15500 of ranks=137265rank=15600 of ranks=137265rank=15700 of ranks=137265rank=15800 of ranks=137265rank=15900 of ranks=137265rank=16000 of ranks=137265rank=16100 of ranks=137265rank=16200 of ranks=137265rank=16300 of ranks=137265rank=16400 of ranks=137265rank=16500 of ranks=137265rank=16600 of ranks=137265rank=16700 of ranks=137265rank=16800 of ranks=137265rank=16900 of ranks=137265rank=17000 of ranks=137265rank=17100 of ranks=137265rank=17200 of ranks=137265rank=17300 of ranks=137265rank=17400 of ranks=137265rank=17500 of ranks=137265rank=17600 of ranks=137265rank=17700 of ranks=137265rank=17800 of ranks=137265rank=17900 of ranks=137265rank=18000 of ranks=137265rank=18100 of ranks=137265rank=18200 of ranks=137265rank=18300 of ranks=137265rank=18400 of ranks=137265rank=18500 of ranks=137265rank=18600 of ranks=137265rank=18700 of ranks=137265rank=18800 of ranks=137265rank=18900 of ranks=137265rank=19000 of ranks=137265rank=19100 of ranks=137265rank=19200 of ranks=137265rank=19300 of ranks=137265rank=19400 of ranks=137265rank=19500 of ranks=137265rank=19600 of ranks=137265rank=19700 of ranks=137265rank=19800 of ranks=137265rank=19900 of ranks=137265rank=20000 of ranks=137265rank=20100 of ranks=137265rank=20200 of ranks=137265rank=20300 of ranks=137265rank=20400 of ranks=137265rank=20500 of ranks=137265rank=20600 of ranks=137265rank=20700 of ranks=137265rank=20800 of ranks=137265rank=20900 of ranks=137265rank=21000 of ranks=137265rank=21100 of ranks=137265rank=21200 of ranks=137265rank=21300 of ranks=137265rank=21400 of ranks=137265rank=21500 of ranks=137265rank=21600 of ranks=137265rank=21700 of ranks=137265rank=21800 of ranks=137265rank=21900 of ranks=137265rank=22000 of ranks=137265rank=22100 of ranks=137265rank=22200 of ranks=137265rank=22300 of ranks=137265rank=22400 of ranks=137265rank=22500 of ranks=137265rank=22600 of ranks=137265rank=22700 of ranks=137265rank=22800 of ranks=137265rank=22900 of ranks=137265rank=23000 of ranks=137265rank=23100 of ranks=137265rank=23200 of ranks=137265rank=23300 of ranks=137265rank=23400 of ranks=137265rank=23500 of ranks=137265rank=23600 of ranks=137265rank=23700 of ranks=137265rank=23800 of ranks=137265rank=23900 of ranks=137265rank=24000 of ranks=137265rank=24100 of ranks=137265rank=24200 of ranks=137265rank=24300 of ranks=137265rank=24400 of ranks=137265rank=24500 of ranks=137265rank=24600 of ranks=137265rank=24700 of ranks=137265rank=24800 of ranks=137265rank=24900 of ranks=137265rank=25000 of ranks=137265rank=25100 of ranks=137265rank=25200 of ranks=137265rank=25300 of ranks=137265rank=25400 of ranks=137265rank=25500 of ranks=137265rank=25600 of ranks=137265rank=25700 of ranks=137265rank=25800 of ranks=137265rank=25900 of ranks=137265rank=26000 of ranks=137265rank=26100 of ranks=137265rank=26200 of ranks=137265rank=26300 of ranks=137265rank=26400 of ranks=137265rank=26500 of ranks=137265rank=26600 of ranks=137265rank=26700 of ranks=137265rank=26800 of ranks=137265rank=26900 of ranks=137265rank=27000 of ranks=137265rank=27100 of ranks=137265rank=27200 of ranks=137265rank=27300 of ranks=137265rank=27400 of ranks=137265rank=27500 of ranks=137265rank=27600 of ranks=137265rank=27700 of ranks=137265rank=27800 of ranks=137265rank=27900 of ranks=137265rank=28000 of ranks=137265rank=28100 of ranks=137265rank=28200 of ranks=137265rank=28300 of ranks=137265rank=28400 of ranks=137265rank=28500 of ranks=137265rank=28600 of ranks=137265rank=28700 of ranks=137265rank=28800 of ranks=137265rank=28900 of ranks=137265rank=29000 of ranks=137265rank=29100 of ranks=137265rank=29200 of ranks=137265rank=29300 of ranks=137265rank=29400 of ranks=137265rank=29500 of ranks=137265rank=29600 of ranks=137265rank=29700 of ranks=137265rank=29800 of ranks=137265rank=29900 of ranks=137265rank=30000 of ranks=137265rank=30100 of ranks=137265rank=30200 of ranks=137265rank=30300 of ranks=137265rank=30400 of ranks=137265rank=30500 of ranks=137265rank=30600 of ranks=137265rank=30700 of ranks=137265rank=30800 of ranks=137265rank=30900 of ranks=137265rank=31000 of ranks=137265rank=31100 of ranks=137265rank=31200 of ranks=137265rank=31300 of ranks=137265rank=31400 of ranks=137265rank=31500 of ranks=137265rank=31600 of ranks=137265rank=31700 of ranks=137265rank=31800 of ranks=137265rank=31900 of ranks=137265rank=32000 of ranks=137265rank=32100 of ranks=137265rank=32200 of ranks=137265rank=32300 of ranks=137265rank=32400 of ranks=137265rank=32500 of ranks=137265rank=32600 of ranks=137265rank=32700 of ranks=137265rank=32800 of ranks=137265rank=32900 of ranks=137265rank=33000 of ranks=137265rank=33100 of ranks=137265rank=33200 of ranks=137265rank=33300 of ranks=137265rank=33400 of ranks=137265rank=33500 of ranks=137265rank=33600 of ranks=137265rank=33700 of ranks=137265rank=33800 of ranks=137265rank=33900 of ranks=137265rank=34000 of ranks=137265rank=34100 of ranks=137265rank=34200 of ranks=137265rank=34300 of ranks=137265rank=34400 of ranks=137265rank=34500 of ranks=137265rank=34600 of ranks=137265rank=34700 of ranks=137265rank=34800 of ranks=137265rank=34900 of ranks=137265rank=35000 of ranks=137265rank=35100 of ranks=137265rank=35200 of ranks=137265rank=35300 of ranks=137265rank=35400 of ranks=137265rank=35500 of ranks=137265rank=35600 of ranks=137265rank=35700 of ranks=137265rank=35800 of ranks=137265rank=35900 of ranks=137265rank=36000 of ranks=137265rank=36100 of ranks=137265rank=36200 of ranks=137265rank=36300 of ranks=137265rank=36400 of ranks=137265rank=36500 of ranks=137265rank=36600 of ranks=137265rank=36700 of ranks=137265rank=36800 of ranks=137265rank=36900 of ranks=137265rank=37000 of ranks=137265rank=37100 of ranks=137265rank=37200 of ranks=137265rank=37300 of ranks=137265rank=37400 of ranks=137265rank=37500 of ranks=137265rank=37600 of ranks=137265rank=37700 of ranks=137265rank=37800 of ranks=137265rank=37900 of ranks=137265rank=38000 of ranks=137265rank=38100 of ranks=137265rank=38200 of ranks=137265rank=38300 of ranks=137265rank=38400 of ranks=137265rank=38500 of ranks=137265rank=38600 of ranks=137265rank=38700 of ranks=137265rank=38800 of ranks=137265rank=38900 of ranks=137265rank=39000 of ranks=137265rank=39100 of ranks=137265rank=39200 of ranks=137265rank=39300 of ranks=137265rank=39400 of ranks=137265rank=39500 of ranks=137265rank=39600 of ranks=137265rank=39700 of ranks=137265rank=39800 of ranks=137265rank=39900 of ranks=137265rank=40000 of ranks=137265rank=40100 of ranks=137265rank=40200 of ranks=137265rank=40300 of ranks=137265rank=40400 of ranks=137265rank=40500 of ranks=137265rank=40600 of ranks=137265rank=40700 of ranks=137265rank=40800 of ranks=137265rank=40900 of ranks=137265rank=41000 of ranks=137265rank=41100 of ranks=137265rank=41200 of ranks=137265rank=41300 of ranks=137265rank=41400 of ranks=137265rank=41500 of ranks=137265rank=41600 of ranks=137265rank=41700 of ranks=137265rank=41800 of ranks=137265rank=41900 of ranks=137265rank=42000 of ranks=137265rank=42100 of ranks=137265rank=42200 of ranks=137265rank=42300 of ranks=137265rank=42400 of ranks=137265rank=42500 of ranks=137265rank=42600 of ranks=137265rank=42700 of ranks=137265rank=42800 of ranks=137265rank=42900 of ranks=137265rank=43000 of ranks=137265rank=43100 of ranks=137265rank=43200 of ranks=137265rank=43300 of ranks=137265rank=43400 of ranks=137265rank=43500 of ranks=137265rank=43600 of ranks=137265rank=43700 of ranks=137265rank=43800 of ranks=137265rank=43900 of ranks=137265rank=44000 of ranks=137265rank=44100 of ranks=137265rank=44200 of ranks=137265rank=44300 of ranks=137265rank=44400 of ranks=137265rank=44500 of ranks=137265rank=44600 of ranks=137265rank=44700 of ranks=137265rank=44800 of ranks=137265rank=44900 of ranks=137265rank=45000 of ranks=137265rank=45100 of ranks=137265rank=45200 of ranks=137265rank=45300 of ranks=137265rank=45400 of ranks=137265rank=45500 of ranks=137265rank=45600 of ranks=137265rank=45700 of ranks=137265rank=45800 of ranks=137265rank=45900 of ranks=137265rank=46000 of ranks=137265rank=46100 of ranks=137265rank=46200 of ranks=137265rank=46300 of ranks=137265rank=46400 of ranks=137265rank=46500 of ranks=137265rank=46600 of ranks=137265rank=46700 of ranks=137265rank=46800 of ranks=137265rank=46900 of ranks=137265rank=47000 of ranks=137265rank=47100 of ranks=137265rank=47200 of ranks=137265rank=47300 of ranks=137265rank=47400 of ranks=137265rank=47500 of ranks=137265rank=47600 of ranks=137265rank=47700 of ranks=137265rank=47800 of ranks=137265rank=47900 of ranks=137265rank=48000 of ranks=137265rank=48100 of ranks=137265rank=48200 of ranks=137265rank=48300 of ranks=137265rank=48400 of ranks=137265rank=48500 of ranks=137265rank=48600 of ranks=137265rank=48700 of ranks=137265rank=48800 of ranks=137265rank=48900 of ranks=137265rank=49000 of ranks=137265rank=49100 of ranks=137265rank=49200 of ranks=137265rank=49300 of ranks=137265rank=49400 of ranks=137265rank=49500 of ranks=137265rank=49600 of ranks=137265rank=49700 of ranks=137265rank=49800 of ranks=137265rank=49900 of ranks=137265rank=50000 of ranks=137265rank=50100 of ranks=137265rank=50200 of ranks=137265rank=50300 of ranks=137265rank=50400 of ranks=137265rank=50500 of ranks=137265rank=50600 of ranks=137265rank=50700 of ranks=137265rank=50800 of ranks=137265rank=50900 of ranks=137265rank=51000 of ranks=137265rank=51100 of ranks=137265rank=51200 of ranks=137265rank=51300 of ranks=137265rank=51400 of ranks=137265rank=51500 of ranks=137265rank=51600 of ranks=137265rank=51700 of ranks=137265rank=51800 of ranks=137265rank=51900 of ranks=137265rank=52000 of ranks=137265rank=52100 of ranks=137265rank=52200 of ranks=137265rank=52300 of ranks=137265rank=52400 of ranks=137265rank=52500 of ranks=137265rank=52600 of ranks=137265rank=52700 of ranks=137265rank=52800 of ranks=137265rank=52900 of ranks=137265rank=53000 of ranks=137265rank=53100 of ranks=137265rank=53200 of ranks=137265rank=53300 of ranks=137265rank=53400 of ranks=137265rank=53500 of ranks=137265rank=53600 of ranks=137265rank=53700 of ranks=137265rank=53800 of ranks=137265rank=53900 of ranks=137265rank=54000 of ranks=137265rank=54100 of ranks=137265rank=54200 of ranks=137265rank=54300 of ranks=137265rank=54400 of ranks=137265rank=54500 of ranks=137265rank=54600 of ranks=137265rank=54700 of ranks=137265rank=54800 of ranks=137265rank=54900 of ranks=137265rank=55000 of ranks=137265rank=55100 of ranks=137265rank=55200 of ranks=137265rank=55300 of ranks=137265rank=55400 of ranks=137265rank=55500 of ranks=137265rank=55600 of ranks=137265rank=55700 of ranks=137265rank=55800 of ranks=137265rank=55900 of ranks=137265rank=56000 of ranks=137265rank=56100 of ranks=137265rank=56200 of ranks=137265rank=56300 of ranks=137265rank=56400 of ranks=137265rank=56500 of ranks=137265rank=56600 of ranks=137265rank=56700 of ranks=137265rank=56800 of ranks=137265rank=56900 of ranks=137265rank=57000 of ranks=137265rank=57100 of ranks=137265rank=57200 of ranks=137265rank=57300 of ranks=137265rank=57400 of ranks=137265rank=57500 of ranks=137265rank=57600 of ranks=137265rank=57700 of ranks=137265rank=57800 of ranks=137265rank=57900 of ranks=137265rank=58000 of ranks=137265rank=58100 of ranks=137265rank=58200 of ranks=137265rank=58300 of ranks=137265rank=58400 of ranks=137265rank=58500 of ranks=137265rank=58600 of ranks=137265rank=58700 of ranks=137265rank=58800 of ranks=137265rank=58900 of ranks=137265rank=59000 of ranks=137265rank=59100 of ranks=137265rank=59200 of ranks=137265rank=59300 of ranks=137265rank=59400 of ranks=137265rank=59500 of ranks=137265rank=59600 of ranks=137265rank=59700 of ranks=137265rank=59800 of ranks=137265rank=59900 of ranks=137265rank=60000 of ranks=137265rank=60100 of ranks=137265rank=60200 of ranks=137265rank=60300 of ranks=137265rank=60400 of ranks=137265rank=60500 of ranks=137265rank=60600 of ranks=137265rank=60700 of ranks=137265rank=60800 of ranks=137265rank=60900 of ranks=137265rank=61000 of ranks=137265rank=61100 of ranks=137265rank=61200 of ranks=137265rank=61300 of ranks=137265rank=61400 of ranks=137265rank=61500 of ranks=137265rank=61600 of ranks=137265rank=61700 of ranks=137265rank=61800 of ranks=137265rank=61900 of ranks=137265rank=62000 of ranks=137265rank=62100 of ranks=137265rank=62200 of ranks=137265rank=62300 of ranks=137265rank=62400 of ranks=137265rank=62500 of ranks=137265rank=62600 of ranks=137265rank=62700 of ranks=137265rank=62800 of ranks=137265rank=62900 of ranks=137265rank=63000 of ranks=137265rank=63100 of ranks=137265rank=63200 of ranks=137265rank=63300 of ranks=137265rank=63400 of ranks=137265rank=63500 of ranks=137265rank=63600 of ranks=137265rank=63700 of ranks=137265rank=63800 of ranks=137265rank=63900 of ranks=137265rank=64000 of ranks=137265rank=64100 of ranks=137265rank=64200 of ranks=137265rank=64300 of ranks=137265rank=64400 of ranks=137265rank=64500 of ranks=137265rank=64600 of ranks=137265rank=64700 of ranks=137265rank=64800 of ranks=137265rank=64900 of ranks=137265rank=65000 of ranks=137265rank=65100 of ranks=137265rank=65200 of ranks=137265rank=65300 of ranks=137265rank=65400 of ranks=137265rank=65500 of ranks=137265rank=65600 of ranks=137265rank=65700 of ranks=137265rank=65800 of ranks=137265rank=65900 of ranks=137265rank=66000 of ranks=137265rank=66100 of ranks=137265rank=66200 of ranks=137265rank=66300 of ranks=137265rank=66400 of ranks=137265rank=66500 of ranks=137265rank=66600 of ranks=137265rank=66700 of ranks=137265rank=66800 of ranks=137265rank=66900 of ranks=137265rank=67000 of ranks=137265rank=67100 of ranks=137265rank=67200 of ranks=137265rank=67300 of ranks=137265rank=67400 of ranks=137265rank=67500 of ranks=137265rank=67600 of ranks=137265rank=67700 of ranks=137265rank=67800 of ranks=137265rank=67900 of ranks=137265rank=68000 of ranks=137265rank=68100 of ranks=137265rank=68200 of ranks=137265rank=68300 of ranks=137265rank=68400 of ranks=137265rank=68500 of ranks=137265rank=68600 of ranks=137265rank=68700 of ranks=137265rank=68800 of ranks=137265rank=68900 of ranks=137265rank=69000 of ranks=137265rank=69100 of ranks=137265rank=69200 of ranks=137265rank=69300 of ranks=137265rank=69400 of ranks=137265rank=69500 of ranks=137265rank=69600 of ranks=137265rank=69700 of ranks=137265rank=69800 of ranks=137265rank=69900 of ranks=137265rank=70000 of ranks=137265rank=70100 of ranks=137265rank=70200 of ranks=137265rank=70300 of ranks=137265rank=70400 of ranks=137265rank=70500 of ranks=137265rank=70600 of ranks=137265rank=70700 of ranks=137265rank=70800 of ranks=137265rank=70900 of ranks=137265rank=71000 of ranks=137265rank=71100 of ranks=137265rank=71200 of ranks=137265rank=71300 of ranks=137265rank=71400 of ranks=137265rank=71500 of ranks=137265rank=71600 of ranks=137265rank=71700 of ranks=137265rank=71800 of ranks=137265rank=71900 of ranks=137265rank=72000 of ranks=137265rank=72100 of ranks=137265rank=72200 of ranks=137265rank=72300 of ranks=137265rank=72400 of ranks=137265rank=72500 of ranks=137265rank=72600 of ranks=137265rank=72700 of ranks=137265rank=72800 of ranks=137265rank=72900 of ranks=137265rank=73000 of ranks=137265rank=73100 of ranks=137265rank=73200 of ranks=137265rank=73300 of ranks=137265rank=73400 of ranks=137265rank=73500 of ranks=137265rank=73600 of ranks=137265rank=73700 of ranks=137265rank=73800 of ranks=137265rank=73900 of ranks=137265rank=74000 of ranks=137265rank=74100 of ranks=137265rank=74200 of ranks=137265rank=74300 of ranks=137265rank=74400 of ranks=137265rank=74500 of ranks=137265rank=74600 of ranks=137265rank=74700 of ranks=137265rank=74800 of ranks=137265rank=74900 of ranks=137265rank=75000 of ranks=137265rank=75100 of ranks=137265rank=75200 of ranks=137265rank=75300 of ranks=137265rank=75400 of ranks=137265rank=75500 of ranks=137265rank=75600 of ranks=137265rank=75700 of ranks=137265rank=75800 of ranks=137265rank=75900 of ranks=137265rank=76000 of ranks=137265rank=76100 of ranks=137265rank=76200 of ranks=137265rank=76300 of ranks=137265rank=76400 of ranks=137265rank=76500 of ranks=137265rank=76600 of ranks=137265rank=76700 of ranks=137265rank=76800 of ranks=137265rank=76900 of ranks=137265rank=77000 of ranks=137265rank=77100 of ranks=137265rank=77200 of ranks=137265rank=77300 of ranks=137265rank=77400 of ranks=137265rank=77500 of ranks=137265rank=77600 of ranks=137265rank=77700 of ranks=137265rank=77800 of ranks=137265rank=77900 of ranks=137265rank=78000 of ranks=137265rank=78100 of ranks=137265rank=78200 of ranks=137265rank=78300 of ranks=137265rank=78400 of ranks=137265rank=78500 of ranks=137265rank=78600 of ranks=137265rank=78700 of ranks=137265rank=78800 of ranks=137265rank=78900 of ranks=137265rank=79000 of ranks=137265rank=79100 of ranks=137265rank=79200 of ranks=137265rank=79300 of ranks=137265rank=79400 of ranks=137265rank=79500 of ranks=137265rank=79600 of ranks=137265rank=79700 of ranks=137265rank=79800 of ranks=137265rank=79900 of ranks=137265rank=80000 of ranks=137265rank=80100 of ranks=137265rank=80200 of ranks=137265rank=80300 of ranks=137265rank=80400 of ranks=137265rank=80500 of ranks=137265rank=80600 of ranks=137265rank=80700 of ranks=137265rank=80800 of ranks=137265rank=80900 of ranks=137265rank=81000 of ranks=137265rank=81100 of ranks=137265rank=81200 of ranks=137265rank=81300 of ranks=137265rank=81400 of ranks=137265rank=81500 of ranks=137265rank=81600 of ranks=137265rank=81700 of ranks=137265rank=81800 of ranks=137265rank=81900 of ranks=137265rank=82000 of ranks=137265rank=82100 of ranks=137265rank=82200 of ranks=137265rank=82300 of ranks=137265rank=82400 of ranks=137265rank=82500 of ranks=137265rank=82600 of ranks=137265rank=82700 of ranks=137265rank=82800 of ranks=137265rank=82900 of ranks=137265rank=83000 of ranks=137265rank=83100 of ranks=137265rank=83200 of ranks=137265rank=83300 of ranks=137265rank=83400 of ranks=137265rank=83500 of ranks=137265rank=83600 of ranks=137265rank=83700 of ranks=137265rank=83800 of ranks=137265rank=83900 of ranks=137265rank=84000 of ranks=137265rank=84100 of ranks=137265rank=84200 of ranks=137265rank=84300 of ranks=137265rank=84400 of ranks=137265rank=84500 of ranks=137265rank=84600 of ranks=137265rank=84700 of ranks=137265rank=84800 of ranks=137265rank=84900 of ranks=137265rank=85000 of ranks=137265rank=85100 of ranks=137265rank=85200 of ranks=137265rank=85300 of ranks=137265rank=85400 of ranks=137265rank=85500 of ranks=137265rank=85600 of ranks=137265rank=85700 of ranks=137265rank=85800 of ranks=137265rank=85900 of ranks=137265rank=86000 of ranks=137265rank=86100 of ranks=137265rank=86200 of ranks=137265rank=86300 of ranks=137265rank=86400 of ranks=137265rank=86500 of ranks=137265rank=86600 of ranks=137265rank=86700 of ranks=137265rank=86800 of ranks=137265rank=86900 of ranks=137265rank=87000 of ranks=137265rank=87100 of ranks=137265rank=87200 of ranks=137265rank=87300 of ranks=137265rank=87400 of ranks=137265rank=87500 of ranks=137265rank=87600 of ranks=137265rank=87700 of ranks=137265rank=87800 of ranks=137265rank=87900 of ranks=137265rank=88000 of ranks=137265rank=88100 of ranks=137265rank=88200 of ranks=137265rank=88300 of ranks=137265rank=88400 of ranks=137265rank=88500 of ranks=137265rank=88600 of ranks=137265rank=88700 of ranks=137265rank=88800 of ranks=137265rank=88900 of ranks=137265rank=89000 of ranks=137265rank=89100 of ranks=137265rank=89200 of ranks=137265rank=89300 of ranks=137265rank=89400 of ranks=137265rank=89500 of ranks=137265rank=89600 of ranks=137265rank=89700 of ranks=137265rank=89800 of ranks=137265rank=89900 of ranks=137265rank=90000 of ranks=137265rank=90100 of ranks=137265rank=90200 of ranks=137265rank=90300 of ranks=137265rank=90400 of ranks=137265rank=90500 of ranks=137265rank=90600 of ranks=137265rank=90700 of ranks=137265rank=90800 of ranks=137265rank=90900 of ranks=137265rank=91000 of ranks=137265rank=91100 of ranks=137265rank=91200 of ranks=137265rank=91300 of ranks=137265rank=91400 of ranks=137265rank=91500 of ranks=137265rank=91600 of ranks=137265rank=91700 of ranks=137265rank=91800 of ranks=137265rank=91900 of ranks=137265rank=92000 of ranks=137265rank=92100 of ranks=137265rank=92200 of ranks=137265rank=92300 of ranks=137265rank=92400 of ranks=137265rank=92500 of ranks=137265rank=92600 of ranks=137265rank=92700 of ranks=137265rank=92800 of ranks=137265rank=92900 of ranks=137265rank=93000 of ranks=137265rank=93100 of ranks=137265rank=93200 of ranks=137265rank=93300 of ranks=137265rank=93400 of ranks=137265rank=93500 of ranks=137265rank=93600 of ranks=137265rank=93700 of ranks=137265rank=93800 of ranks=137265rank=93900 of ranks=137265rank=94000 of ranks=137265rank=94100 of ranks=137265rank=94200 of ranks=137265rank=94300 of ranks=137265rank=94400 of ranks=137265rank=94500 of ranks=137265rank=94600 of ranks=137265rank=94700 of ranks=137265rank=94800 of ranks=137265rank=94900 of ranks=137265rank=95000 of ranks=137265rank=95100 of ranks=137265rank=95200 of ranks=137265rank=95300 of ranks=137265rank=95400 of ranks=137265rank=95500 of ranks=137265rank=95600 of ranks=137265rank=95700 of ranks=137265rank=95800 of ranks=137265rank=95900 of ranks=137265rank=96000 of ranks=137265rank=96100 of ranks=137265rank=96200 of ranks=137265rank=96300 of ranks=137265rank=96400 of ranks=137265rank=96500 of ranks=137265rank=96600 of ranks=137265rank=96700 of ranks=137265rank=96800 of ranks=137265rank=96900 of ranks=137265rank=97000 of ranks=137265rank=97100 of ranks=137265rank=97200 of ranks=137265rank=97300 of ranks=137265rank=97400 of ranks=137265rank=97500 of ranks=137265rank=97600 of ranks=137265rank=97700 of ranks=137265rank=97800 of ranks=137265rank=97900 of ranks=137265rank=98000 of ranks=137265rank=98100 of ranks=137265rank=98200 of ranks=137265rank=98300 of ranks=137265rank=98400 of ranks=137265rank=98500 of ranks=137265rank=98600 of ranks=137265rank=98700 of ranks=137265rank=98800 of ranks=137265rank=98900 of ranks=137265rank=99000 of ranks=137265rank=99100 of ranks=137265rank=99200 of ranks=137265rank=99300 of ranks=137265rank=99400 of ranks=137265rank=99500 of ranks=137265rank=99600 of ranks=137265rank=99700 of ranks=137265rank=99800 of ranks=137265rank=99900 of ranks=137265rank=100000 of ranks=137265rank=100100 of ranks=137265rank=100200 of ranks=137265rank=100300 of ranks=137265rank=100400 of ranks=137265rank=100500 of ranks=137265rank=100600 of ranks=137265rank=100700 of ranks=137265rank=100800 of ranks=137265rank=100900 of ranks=137265rank=101000 of ranks=137265rank=101100 of ranks=137265rank=101200 of ranks=137265rank=101300 of ranks=137265rank=101400 of ranks=137265rank=101500 of ranks=137265rank=101600 of ranks=137265rank=101700 of ranks=137265rank=101800 of ranks=137265rank=101900 of ranks=137265rank=102000 of ranks=137265rank=102100 of ranks=137265rank=102200 of ranks=137265rank=102300 of ranks=137265rank=102400 of ranks=137265rank=102500 of ranks=137265rank=102600 of ranks=137265rank=102700 of ranks=137265rank=102800 of ranks=137265rank=102900 of ranks=137265rank=103000 of ranks=137265rank=103100 of ranks=137265rank=103200 of ranks=137265rank=103300 of ranks=137265rank=103400 of ranks=137265rank=103500 of ranks=137265rank=103600 of ranks=137265rank=103700 of ranks=137265rank=103800 of ranks=137265rank=103900 of ranks=137265rank=104000 of ranks=137265rank=104100 of ranks=137265rank=104200 of ranks=137265rank=104300 of ranks=137265rank=104400 of ranks=137265rank=104500 of ranks=137265rank=104600 of ranks=137265rank=104700 of ranks=137265rank=104800 of ranks=137265rank=104900 of ranks=137265rank=105000 of ranks=137265rank=105100 of ranks=137265rank=105200 of ranks=137265rank=105300 of ranks=137265rank=105400 of ranks=137265rank=105500 of ranks=137265rank=105600 of ranks=137265rank=105700 of ranks=137265rank=105800 of ranks=137265rank=105900 of ranks=137265rank=106000 of ranks=137265rank=106100 of ranks=137265rank=106200 of ranks=137265rank=106300 of ranks=137265rank=106400 of ranks=137265rank=106500 of ranks=137265rank=106600 of ranks=137265rank=106700 of ranks=137265rank=106800 of ranks=137265rank=106900 of ranks=137265rank=107000 of ranks=137265rank=107100 of ranks=137265rank=107200 of ranks=137265rank=107300 of ranks=137265rank=107400 of ranks=137265rank=107500 of ranks=137265rank=107600 of ranks=137265rank=107700 of ranks=137265rank=107800 of ranks=137265rank=107900 of ranks=137265rank=108000 of ranks=137265rank=108100 of ranks=137265rank=108200 of ranks=137265rank=108300 of ranks=137265rank=108400 of ranks=137265rank=108500 of ranks=137265rank=108600 of ranks=137265rank=108700 of ranks=137265rank=108800 of ranks=137265rank=108900 of ranks=137265rank=109000 of ranks=137265rank=109100 of ranks=137265rank=109200 of ranks=137265rank=109300 of ranks=137265rank=109400 of ranks=137265rank=109500 of ranks=137265rank=109600 of ranks=137265rank=109700 of ranks=137265rank=109800 of ranks=137265rank=109900 of ranks=137265rank=110000 of ranks=137265rank=110100 of ranks=137265rank=110200 of ranks=137265rank=110300 of ranks=137265rank=110400 of ranks=137265rank=110500 of ranks=137265rank=110600 of ranks=137265rank=110700 of ranks=137265rank=110800 of ranks=137265rank=110900 of ranks=137265rank=111000 of ranks=137265rank=111100 of ranks=137265rank=111200 of ranks=137265rank=111300 of ranks=137265rank=111400 of ranks=137265rank=111500 of ranks=137265rank=111600 of ranks=137265rank=111700 of ranks=137265rank=111800 of ranks=137265rank=111900 of ranks=137265rank=112000 of ranks=137265rank=112100 of ranks=137265rank=112200 of ranks=137265rank=112300 of ranks=137265rank=112400 of ranks=137265rank=112500 of ranks=137265rank=112600 of ranks=137265rank=112700 of ranks=137265rank=112800 of ranks=137265rank=112900 of ranks=137265rank=113000 of ranks=137265rank=113100 of ranks=137265rank=113200 of ranks=137265rank=113300 of ranks=137265rank=113400 of ranks=137265rank=113500 of ranks=137265rank=113600 of ranks=137265rank=113700 of ranks=137265rank=113800 of ranks=137265rank=113900 of ranks=137265rank=114000 of ranks=137265rank=114100 of ranks=137265rank=114200 of ranks=137265rank=114300 of ranks=137265rank=114400 of ranks=137265rank=114500 of ranks=137265rank=114600 of ranks=137265rank=114700 of ranks=137265rank=114800 of ranks=137265rank=114900 of ranks=137265rank=115000 of ranks=137265rank=115100 of ranks=137265rank=115200 of ranks=137265rank=115300 of ranks=137265rank=115400 of ranks=137265rank=115500 of ranks=137265rank=115600 of ranks=137265rank=115700 of ranks=137265rank=115800 of ranks=137265rank=115900 of ranks=137265rank=116000 of ranks=137265rank=116100 of ranks=137265rank=116200 of ranks=137265rank=116300 of ranks=137265rank=116400 of ranks=137265rank=116500 of ranks=137265rank=116600 of ranks=137265rank=116700 of ranks=137265rank=116800 of ranks=137265rank=116900 of ranks=137265rank=117000 of ranks=137265rank=117100 of ranks=137265rank=117200 of ranks=137265rank=117300 of ranks=137265rank=117400 of ranks=137265rank=117500 of ranks=137265rank=117600 of ranks=137265rank=117700 of ranks=137265rank=117800 of ranks=137265rank=117900 of ranks=137265rank=118000 of ranks=137265rank=118100 of ranks=137265rank=118200 of ranks=137265rank=118300 of ranks=137265rank=118400 of ranks=137265rank=118500 of ranks=137265rank=118600 of ranks=137265rank=118700 of ranks=137265rank=118800 of ranks=137265rank=118900 of ranks=137265rank=119000 of ranks=137265rank=119100 of ranks=137265rank=119200 of ranks=137265rank=119300 of ranks=137265rank=119400 of ranks=137265rank=119500 of ranks=137265rank=119600 of ranks=137265rank=119700 of ranks=137265rank=119800 of ranks=137265rank=119900 of ranks=137265rank=120000 of ranks=137265rank=120100 of ranks=137265rank=120200 of ranks=137265rank=120300 of ranks=137265rank=120400 of ranks=137265rank=120500 of ranks=137265rank=120600 of ranks=137265rank=120700 of ranks=137265rank=120800 of ranks=137265rank=120900 of ranks=137265rank=121000 of ranks=137265rank=121100 of ranks=137265rank=121200 of ranks=137265rank=121300 of ranks=137265rank=121400 of ranks=137265rank=121500 of ranks=137265rank=121600 of ranks=137265rank=121700 of ranks=137265rank=121800 of ranks=137265rank=121900 of ranks=137265rank=122000 of ranks=137265rank=122100 of ranks=137265rank=122200 of ranks=137265rank=122300 of ranks=137265rank=122400 of ranks=137265rank=122500 of ranks=137265rank=122600 of ranks=137265rank=122700 of ranks=137265rank=122800 of ranks=137265rank=122900 of ranks=137265rank=123000 of ranks=137265rank=123100 of ranks=137265rank=123200 of ranks=137265rank=123300 of ranks=137265rank=123400 of ranks=137265rank=123500 of ranks=137265rank=123600 of ranks=137265rank=123700 of ranks=137265rank=123800 of ranks=137265rank=123900 of ranks=137265rank=124000 of ranks=137265rank=124100 of ranks=137265rank=124200 of ranks=137265rank=124300 of ranks=137265rank=124400 of ranks=137265rank=124500 of ranks=137265rank=124600 of ranks=137265rank=124700 of ranks=137265rank=124800 of ranks=137265rank=124900 of ranks=137265rank=125000 of ranks=137265rank=125100 of ranks=137265rank=125200 of ranks=137265rank=125300 of ranks=137265rank=125400 of ranks=137265rank=125500 of ranks=137265rank=125600 of ranks=137265rank=125700 of ranks=137265rank=125800 of ranks=137265rank=125900 of ranks=137265rank=126000 of ranks=137265rank=126100 of ranks=137265rank=126200 of ranks=137265rank=126300 of ranks=137265rank=126400 of ranks=137265rank=126500 of ranks=137265rank=126600 of ranks=137265rank=126700 of ranks=137265rank=126800 of ranks=137265rank=126900 of ranks=137265rank=127000 of ranks=137265rank=127100 of ranks=137265rank=127200 of ranks=137265rank=127300 of ranks=137265rank=127400 of ranks=137265rank=127500 of ranks=137265rank=127600 of ranks=137265rank=127700 of ranks=137265rank=127800 of ranks=137265rank=127900 of ranks=137265rank=128000 of ranks=137265rank=128100 of ranks=137265rank=128200 of ranks=137265rank=128300 of ranks=137265rank=128400 of ranks=137265rank=128500 of ranks=137265rank=128600 of ranks=137265rank=128700 of ranks=137265rank=128800 of ranks=137265rank=128900 of ranks=137265rank=129000 of ranks=137265rank=129100 of ranks=137265rank=129200 of ranks=137265rank=129300 of ranks=137265rank=129400 of ranks=137265rank=129500 of ranks=137265rank=129600 of ranks=137265rank=129700 of ranks=137265rank=129800 of ranks=137265rank=129900 of ranks=137265rank=130000 of ranks=137265rank=130100 of ranks=137265rank=130200 of ranks=137265rank=130300 of ranks=137265rank=130400 of ranks=137265rank=130500 of ranks=137265rank=130600 of ranks=137265rank=130700 of ranks=137265rank=130800 of ranks=137265rank=130900 of ranks=137265rank=131000 of ranks=137265rank=131100 of ranks=137265rank=131200 of ranks=137265rank=131300 of ranks=137265rank=131400 of ranks=137265rank=131500 of ranks=137265rank=131600 of ranks=137265rank=131700 of ranks=137265rank=131800 of ranks=137265rank=131900 of ranks=137265rank=132000 of ranks=137265rank=132100 of ranks=137265rank=132200 of ranks=137265rank=132300 of ranks=137265rank=132400 of ranks=137265rank=132500 of ranks=137265rank=132600 of ranks=137265rank=132700 of ranks=137265rank=132800 of ranks=137265rank=132900 of ranks=137265rank=133000 of ranks=137265rank=133100 of ranks=137265rank=133200 of ranks=137265rank=133300 of ranks=137265rank=133400 of ranks=137265rank=133500 of ranks=137265rank=133600 of ranks=137265rank=133700 of ranks=137265rank=133800 of ranks=137265rank=133900 of ranks=137265rank=134000 of ranks=137265rank=134100 of ranks=137265rank=134200 of ranks=137265rank=134300 of ranks=137265rank=134400 of ranks=137265rank=134500 of ranks=137265rank=134600 of ranks=137265rank=134700 of ranks=137265rank=134800 of ranks=137265rank=134900 of ranks=137265rank=135000 of ranks=137265rank=135100 of ranks=137265rank=135200 of ranks=137265rank=135300 of ranks=137265rank=135400 of ranks=137265rank=135500 of ranks=137265rank=135600 of ranks=137265rank=135700 of ranks=137265rank=135800 of ranks=137265rank=135900 of ranks=137265rank=136000 of ranks=137265rank=136100 of ranks=137265rank=136200 of ranks=137265rank=136300 of ranks=137265rank=136400 of ranks=137265rank=136500 of ranks=137265rank=136600 of ranks=137265rank=136700 of ranks=137265rank=136800 of ranks=137265rank=136900 of ranks=137265rank=137000 of ranks=137265rank=137100 of ranks=137265rank=137200 of ranks=137265

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              93.6026    481   3263     17    498           73.0532
   1 car                    97.9228  49924  43467    392  50316           77.0104
   2 truck                  92.4887   1806  13085     19   1825           52.5309
   3 bus                    85.1387    360   4833      6    366           46.8351
   4 pedestrian             93.3713   4115  15931    144   4259           62.0592

for conf_thresh=0.25, precision=0.85, recall=0.94, F1 score=0.89
for conf_thresh=0.25, TP=53975, FP=9493, FN=3289, average IoU=74.66%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=92.50%
Total detection time: 184 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
New best mAP, saving weights!
Saving weights to /workspace/.cache/splits/combined_best.weights
4249: loss=3.272, avg loss=3.552, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 271936 images, time remaining=4.5 hours
4250: loss=3.108, avg loss=3.508, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 272000 images, time remaining=4.5 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4251: loss=4.691, avg loss=3.626, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=4.5 seconds, train=6.0 seconds, 272064 images, time remaining=4.5 hours
4252: loss=4.696, avg loss=3.733, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=5.9 seconds, 272128 images, time remaining=4.5 hours
4253: loss=5.026, avg loss=3.862, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 272192 images, time remaining=4.5 hours
4254: loss=4.139, avg loss=3.890, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 272256 images, time remaining=4.5 hours
4255: loss=4.015, avg loss=3.902, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.3 seconds, train=5.7 seconds, 272320 images, time remaining=4.5 hours
4256: loss=4.762, avg loss=3.988, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.9 seconds, 272384 images, time remaining=4.5 hours
4257: loss=5.544, avg loss=4.144, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.3 seconds, train=5.8 seconds, 272448 images, time remaining=4.5 hours
4258: loss=4.225, avg loss=4.152, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=5.8 seconds, 272512 images, time remaining=4.5 hours
4259: loss=4.779, avg loss=4.215, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 272576 images, time remaining=4.5 hours
4260: loss=4.428, avg loss=4.236, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 272640 images, time remaining=4.5 hours
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14b83b200000
4261: loss=4.731, avg loss=4.286, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 272704 images, time remaining=4.5 hours
4262: loss=3.601, avg loss=4.217, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 272768 images, time remaining=4.5 hours
4263: loss=3.923, avg loss=4.188, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 272832 images, time remaining=4.5 hours
4264: loss=3.572, avg loss=4.126, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 272896 images, time remaining=4.5 hours
4265: loss=4.274, avg loss=4.141, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 272960 images, time remaining=4.5 hours
4266: loss=3.429, avg loss=4.070, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 273024 images, time remaining=4.5 hours
4267: loss=3.436, avg loss=4.006, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 273088 images, time remaining=4.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4268: loss=4.434, avg loss=4.049, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=7.9 seconds, train=1.8 seconds, 273152 images, time remaining=4.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4269: loss=3.700, avg loss=4.014, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=4.1 seconds, train=2.2 seconds, 273216 images, time remaining=4.5 hours
4270: loss=4.191, avg loss=4.032, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 273280 images, time remaining=4.5 hours
Resizing, random_coef=1.40, batch=4, 1216x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4271: loss=7.221, avg loss=4.351, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 273344 images, time remaining=4.5 hours
4272: loss=5.768, avg loss=4.493, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 273408 images, time remaining=4.5 hours
4273: loss=5.151, avg loss=4.558, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.2 seconds, 273472 images, time remaining=4.5 hours
4274: loss=4.459, avg loss=4.548, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=5.2 seconds, 273536 images, time remaining=4.5 hours
4275: loss=4.425, avg loss=4.536, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.2 seconds, 273600 images, time remaining=4.5 hours
4276: loss=4.462, avg loss=4.529, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.2 seconds, 273664 images, time remaining=4.5 hours
4277: loss=4.321, avg loss=4.508, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.1 seconds, 273728 images, time remaining=4.5 hours
4278: loss=5.494, avg loss=4.607, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=3.1 seconds, train=5.1 seconds, 273792 images, time remaining=4.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4279: loss=4.659, avg loss=4.612, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=5.3 seconds, train=5.2 seconds, 273856 images, time remaining=4.5 hours
4280: loss=4.884, avg loss=4.639, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.2 seconds, 273920 images, time remaining=4.5 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b7c7a00000
4281: loss=5.622, avg loss=4.737, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 273984 images, time remaining=4.5 hours
4282: loss=5.315, avg loss=4.795, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 274048 images, time remaining=4.5 hours
4283: loss=3.578, avg loss=4.673, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 274112 images, time remaining=4.5 hours
4284: loss=4.224, avg loss=4.628, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 274176 images, time remaining=4.5 hours
4285: loss=4.519, avg loss=4.617, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 274240 images, time remaining=4.5 hours
4286: loss=4.244, avg loss=4.580, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 274304 images, time remaining=4.5 hours
4287: loss=4.186, avg loss=4.541, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=2.1 seconds, 274368 images, time remaining=4.5 hours
4288: loss=3.731, avg loss=4.460, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 274432 images, time remaining=4.5 hours
4289: loss=3.720, avg loss=4.386, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 274496 images, time remaining=4.5 hours
4290: loss=4.599, avg loss=4.407, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 274560 images, time remaining=4.5 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b30e000000
4291: loss=6.034, avg loss=4.570, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 274624 images, time remaining=4.5 hours
4292: loss=5.108, avg loss=4.624, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 274688 images, time remaining=4.5 hours
4293: loss=4.632, avg loss=4.625, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 274752 images, time remaining=4.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4294: loss=5.007, avg loss=4.663, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.7 seconds, train=2.7 seconds, 274816 images, time remaining=4.5 hours
4295: loss=4.157, avg loss=4.612, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.2 seconds, train=2.8 seconds, 274880 images, time remaining=4.5 hours
4296: loss=3.640, avg loss=4.515, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 274944 images, time remaining=4.5 hours
4297: loss=3.733, avg loss=4.437, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 275008 images, time remaining=4.5 hours
4298: loss=4.202, avg loss=4.413, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 275072 images, time remaining=4.5 hours
4299: loss=3.762, avg loss=4.348, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 275136 images, time remaining=4.5 hours
4300: loss=3.975, avg loss=4.311, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 275200 images, time remaining=4.5 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4301: loss=4.941, avg loss=4.374, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=4.1 seconds, 275264 images, time remaining=4.5 hours
4302: loss=4.454, avg loss=4.382, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=4.2 seconds, 275328 images, time remaining=4.5 hours
4303: loss=4.032, avg loss=4.347, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.5 seconds, train=4.1 seconds, 275392 images, time remaining=4.5 hours
4304: loss=4.986, avg loss=4.411, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 275456 images, time remaining=4.5 hours
4305: loss=4.570, avg loss=4.427, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=3.6 seconds, train=4.1 seconds, 275520 images, time remaining=4.5 hours
4306: loss=3.883, avg loss=4.372, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.3 seconds, train=4.1 seconds, 275584 images, time remaining=4.4 hours
4307: loss=4.195, avg loss=4.355, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=4.1 seconds, 275648 images, time remaining=4.4 hours
4308: loss=4.286, avg loss=4.348, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 275712 images, time remaining=4.4 hours
4309: loss=3.519, avg loss=4.265, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 275776 images, time remaining=4.4 hours
4310: loss=3.815, avg loss=4.220, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 275840 images, time remaining=4.4 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4311: loss=3.776, avg loss=4.175, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 275904 images, time remaining=4.4 hours
4312: loss=3.781, avg loss=4.136, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 275968 images, time remaining=4.4 hours
4313: loss=3.411, avg loss=4.064, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=4.3 seconds, 276032 images, time remaining=4.4 hours
4314: loss=4.276, avg loss=4.085, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 276096 images, time remaining=4.4 hours
4315: loss=3.714, avg loss=4.048, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 276160 images, time remaining=4.4 hours
4316: loss=5.594, avg loss=4.202, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 276224 images, time remaining=4.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4317: loss=3.924, avg loss=4.174, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=5.7 seconds, train=4.1 seconds, 276288 images, time remaining=4.4 hours
4318: loss=2.950, avg loss=4.052, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=4.3 seconds, 276352 images, time remaining=4.4 hours
4319: loss=3.760, avg loss=4.023, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=4.3 seconds, 276416 images, time remaining=4.4 hours
4320: loss=3.624, avg loss=3.983, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 276480 images, time remaining=4.4 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4321: loss=4.032, avg loss=3.988, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 276544 images, time remaining=4.4 hours
4322: loss=4.109, avg loss=4.000, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.3 seconds, train=5.2 seconds, 276608 images, time remaining=4.4 hours
4323: loss=3.781, avg loss=3.978, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 276672 images, time remaining=4.4 hours
4324: loss=3.916, avg loss=3.972, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.2 seconds, train=5.2 seconds, 276736 images, time remaining=4.4 hours
4325: loss=3.562, avg loss=3.931, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 276800 images, time remaining=4.4 hours
4326: loss=4.048, avg loss=3.942, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.9 seconds, train=5.4 seconds, 276864 images, time remaining=4.4 hours
4327: loss=4.120, avg loss=3.960, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.1 seconds, 276928 images, time remaining=4.4 hours
4328: loss=4.006, avg loss=3.965, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=4.6 seconds, train=5.2 seconds, 276992 images, time remaining=4.4 hours
4329: loss=4.198, avg loss=3.988, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.3 seconds, 277056 images, time remaining=4.4 hours
4330: loss=4.381, avg loss=4.027, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.3 seconds, 277120 images, time remaining=4.4 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4331: loss=3.926, avg loss=4.017, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=4.8 seconds, 277184 images, time remaining=4.4 hours
4332: loss=3.381, avg loss=3.954, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=4.9 seconds, 277248 images, time remaining=4.4 hours
4333: loss=4.409, avg loss=3.999, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 277312 images, time remaining=4.4 hours
4334: loss=4.068, avg loss=4.006, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.6 seconds, train=4.9 seconds, 277376 images, time remaining=4.4 hours
4335: loss=4.030, avg loss=4.008, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 277440 images, time remaining=4.4 hours
4336: loss=3.940, avg loss=4.002, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.3 seconds, train=4.9 seconds, 277504 images, time remaining=4.4 hours
4337: loss=4.065, avg loss=4.008, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=4.8 seconds, 277568 images, time remaining=4.4 hours
4338: loss=4.142, avg loss=4.021, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 277632 images, time remaining=4.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4339: loss=3.400, avg loss=3.959, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=5.2 seconds, train=4.8 seconds, 277696 images, time remaining=4.4 hours
4340: loss=4.315, avg loss=3.995, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.0 seconds, 277760 images, time remaining=4.4 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4341: loss=3.601, avg loss=3.955, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.9 seconds, 277824 images, time remaining=4.4 hours
4342: loss=4.375, avg loss=3.997, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.2 seconds, train=5.7 seconds, 277888 images, time remaining=4.4 hours
4343: loss=3.859, avg loss=3.983, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 277952 images, time remaining=4.4 hours
4344: loss=4.594, avg loss=4.044, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 278016 images, time remaining=4.4 hours
4345: loss=3.163, avg loss=3.956, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.5 seconds, train=5.9 seconds, 278080 images, time remaining=4.4 hours
4346: loss=3.408, avg loss=3.902, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 278144 images, time remaining=4.4 hours
4347: loss=4.114, avg loss=3.923, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 278208 images, time remaining=4.4 hours
4348: loss=4.909, avg loss=4.021, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=5.9 seconds, 278272 images, time remaining=4.4 hours
4349: loss=3.889, avg loss=4.008, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 278336 images, time remaining=4.4 hours
4350: loss=4.736, avg loss=4.081, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 278400 images, time remaining=4.4 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4351: loss=3.493, avg loss=4.022, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 278464 images, time remaining=4.4 hours
4352: loss=3.989, avg loss=4.019, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.4 seconds, train=4.7 seconds, 278528 images, time remaining=4.4 hours
4353: loss=3.280, avg loss=3.945, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.8 seconds, train=4.7 seconds, 278592 images, time remaining=4.4 hours
4354: loss=3.560, avg loss=3.906, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 278656 images, time remaining=4.4 hours
4355: loss=4.007, avg loss=3.916, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 278720 images, time remaining=4.4 hours
4356: loss=3.797, avg loss=3.904, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=4.8 seconds, 278784 images, time remaining=4.4 hours
4357: loss=4.705, avg loss=3.984, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 278848 images, time remaining=4.4 hours
4358: loss=3.387, avg loss=3.925, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 278912 images, time remaining=4.4 hours
4359: loss=4.952, avg loss=4.027, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 278976 images, time remaining=4.4 hours
4360: loss=3.975, avg loss=4.022, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.9 seconds, train=4.6 seconds, 279040 images, time remaining=4.4 hours
Resizing, random_coef=1.40, batch=4, 736x544
GPU #0: allocating workspace: 302.4 MiB begins at 0x14b75c400000
4361: loss=4.598, avg loss=4.080, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 279104 images, time remaining=4.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4362: loss=4.607, avg loss=4.133, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.3 seconds, train=1.8 seconds, 279168 images, time remaining=4.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4363: loss=4.319, avg loss=4.151, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=1.9 seconds, 279232 images, time remaining=4.4 hours
4364: loss=4.125, avg loss=4.149, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 279296 images, time remaining=4.4 hours
4365: loss=4.309, avg loss=4.165, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=1.9 seconds, 279360 images, time remaining=4.4 hours
4366: loss=4.262, avg loss=4.174, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 279424 images, time remaining=4.4 hours
4367: loss=3.604, avg loss=4.117, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 279488 images, time remaining=4.4 hours
4368: loss=4.152, avg loss=4.121, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=1.8 seconds, 279552 images, time remaining=4.4 hours
4369: loss=4.040, avg loss=4.113, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 279616 images, time remaining=4.4 hours
4370: loss=3.663, avg loss=4.068, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 279680 images, time remaining=4.4 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4371: loss=7.248, avg loss=4.386, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.2 seconds, train=6.0 seconds, 279744 images, time remaining=4.4 hours
4372: loss=6.480, avg loss=4.595, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 279808 images, time remaining=4.4 hours
4373: loss=6.858, avg loss=4.821, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 279872 images, time remaining=4.4 hours
4374: loss=5.428, avg loss=4.882, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 279936 images, time remaining=4.4 hours
4375: loss=4.676, avg loss=4.861, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 280000 images, time remaining=4.4 hours
4376: loss=4.027, avg loss=4.778, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 280064 images, time remaining=4.4 hours
4377: loss=5.419, avg loss=4.842, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 280128 images, time remaining=4.4 hours
4378: loss=5.604, avg loss=4.918, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 280192 images, time remaining=4.4 hours
4379: loss=5.094, avg loss=4.936, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 280256 images, time remaining=4.4 hours
4380: loss=4.346, avg loss=4.877, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 280320 images, time remaining=4.4 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b84b000000
4381: loss=7.113, avg loss=5.100, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 280384 images, time remaining=4.4 hours
4382: loss=6.025, avg loss=5.193, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 280448 images, time remaining=4.4 hours
4383: loss=5.320, avg loss=5.206, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 280512 images, time remaining=4.4 hours
4384: loss=4.949, avg loss=5.180, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 280576 images, time remaining=4.4 hours
4385: loss=4.304, avg loss=5.092, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 280640 images, time remaining=4.4 hours
4386: loss=3.980, avg loss=4.981, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 280704 images, time remaining=4.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4387: loss=4.424, avg loss=4.925, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.5 seconds, train=1.9 seconds, 280768 images, time remaining=4.4 hours
4388: loss=5.018, avg loss=4.935, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 280832 images, time remaining=4.4 hours
4389: loss=4.965, avg loss=4.938, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 280896 images, time remaining=4.4 hours
4390: loss=3.867, avg loss=4.831, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 280960 images, time remaining=4.4 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4391: loss=10.045, avg loss=5.352, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 281024 images, time remaining=4.4 hours
4392: loss=8.952, avg loss=5.712, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 281088 images, time remaining=4.4 hours
4393: loss=7.670, avg loss=5.908, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 281152 images, time remaining=4.4 hours
4394: loss=5.704, avg loss=5.887, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 281216 images, time remaining=4.4 hours
4395: loss=4.696, avg loss=5.768, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 281280 images, time remaining=4.4 hours
4396: loss=5.157, avg loss=5.707, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.6 seconds, 281344 images, time remaining=4.4 hours
4397: loss=4.710, avg loss=5.608, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 281408 images, time remaining=4.3 hours
4398: loss=5.618, avg loss=5.609, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 281472 images, time remaining=4.3 hours
4399: loss=6.390, avg loss=5.687, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.7 seconds, 281536 images, time remaining=4.3 hours
4400: loss=6.728, avg loss=5.791, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.2 seconds, train=5.7 seconds, 281600 images, time remaining=4.3 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4401: loss=5.508, avg loss=5.763, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 281664 images, time remaining=4.3 hours
4402: loss=5.276, avg loss=5.714, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 281728 images, time remaining=4.3 hours
4403: loss=5.642, avg loss=5.707, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 281792 images, time remaining=4.3 hours
4404: loss=4.475, avg loss=5.584, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 281856 images, time remaining=4.3 hours
4405: loss=4.624, avg loss=5.488, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 281920 images, time remaining=4.3 hours
4406: loss=4.727, avg loss=5.412, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 281984 images, time remaining=4.3 hours
4407: loss=4.364, avg loss=5.307, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 282048 images, time remaining=4.3 hours
4408: loss=5.238, avg loss=5.300, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 282112 images, time remaining=4.3 hours
4409: loss=4.173, avg loss=5.187, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 282176 images, time remaining=4.3 hours
4410: loss=3.988, avg loss=5.067, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 282240 images, time remaining=4.3 hours
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14b794600000
4411: loss=4.539, avg loss=5.015, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 282304 images, time remaining=4.3 hours
4412: loss=4.446, avg loss=4.958, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 282368 images, time remaining=4.3 hours
4413: loss=4.849, avg loss=4.947, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 282432 images, time remaining=4.3 hours
4414: loss=4.504, avg loss=4.903, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 282496 images, time remaining=4.3 hours
4415: loss=3.822, avg loss=4.795, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 282560 images, time remaining=4.3 hours
4416: loss=4.370, avg loss=4.752, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 282624 images, time remaining=4.3 hours
4417: loss=3.659, avg loss=4.643, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 282688 images, time remaining=4.3 hours
4418: loss=4.653, avg loss=4.644, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 282752 images, time remaining=4.3 hours
4419: loss=3.283, avg loss=4.508, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 282816 images, time remaining=4.3 hours
4420: loss=3.862, avg loss=4.443, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 282880 images, time remaining=4.3 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b30e000000
4421: loss=3.315, avg loss=4.330, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 282944 images, time remaining=4.3 hours
4422: loss=3.936, avg loss=4.291, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=2.9 seconds, 283008 images, time remaining=4.3 hours
4423: loss=4.684, avg loss=4.330, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 283072 images, time remaining=4.3 hours
4424: loss=4.165, avg loss=4.314, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 283136 images, time remaining=4.3 hours
4425: loss=4.180, avg loss=4.300, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 283200 images, time remaining=4.3 hours
4426: loss=3.453, avg loss=4.216, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 283264 images, time remaining=4.3 hours
4427: loss=3.624, avg loss=4.157, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 283328 images, time remaining=4.3 hours
4428: loss=3.630, avg loss=4.104, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 283392 images, time remaining=4.3 hours
4429: loss=4.076, avg loss=4.101, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 283456 images, time remaining=4.3 hours
4430: loss=4.336, avg loss=4.124, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 283520 images, time remaining=4.3 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4431: loss=4.704, avg loss=4.182, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.2 seconds, train=5.5 seconds, 283584 images, time remaining=4.3 hours
4432: loss=4.403, avg loss=4.204, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 283648 images, time remaining=4.3 hours
4433: loss=4.438, avg loss=4.228, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 283712 images, time remaining=4.3 hours
4434: loss=3.889, avg loss=4.194, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 283776 images, time remaining=4.3 hours
4435: loss=4.611, avg loss=4.236, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=5.4 seconds, 283840 images, time remaining=4.3 hours
4436: loss=4.212, avg loss=4.233, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.4 seconds, train=5.4 seconds, 283904 images, time remaining=4.3 hours
4437: loss=4.483, avg loss=4.258, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.5 seconds, 283968 images, time remaining=4.3 hours
4438: loss=4.004, avg loss=4.233, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 284032 images, time remaining=4.3 hours
4439: loss=4.340, avg loss=4.243, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.5 seconds, 284096 images, time remaining=4.3 hours
4440: loss=4.643, avg loss=4.283, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.4 seconds, 284160 images, time remaining=4.3 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4441: loss=4.559, avg loss=4.311, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.6 seconds, 284224 images, time remaining=4.3 hours
4442: loss=4.356, avg loss=4.315, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.4 seconds, 284288 images, time remaining=4.3 hours
4443: loss=3.850, avg loss=4.269, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 284352 images, time remaining=4.3 hours
4444: loss=3.934, avg loss=4.235, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 284416 images, time remaining=4.3 hours
4445: loss=4.848, avg loss=4.297, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.2 seconds, train=5.6 seconds, 284480 images, time remaining=4.3 hours
4446: loss=3.605, avg loss=4.227, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 284544 images, time remaining=4.3 hours
4447: loss=4.681, avg loss=4.273, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.5 seconds, 284608 images, time remaining=4.3 hours
4448: loss=5.013, avg loss=4.347, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 284672 images, time remaining=4.3 hours
4449: loss=4.452, avg loss=4.357, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 284736 images, time remaining=4.3 hours
4450: loss=4.503, avg loss=4.372, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.5 seconds, 284800 images, time remaining=4.3 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b6d8200000
4451: loss=5.157, avg loss=4.450, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 284864 images, time remaining=4.3 hours
4452: loss=5.123, avg loss=4.518, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=1.8 seconds, 284928 images, time remaining=4.3 hours
4453: loss=4.164, avg loss=4.482, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 284992 images, time remaining=4.3 hours
4454: loss=3.789, avg loss=4.413, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 285056 images, time remaining=4.3 hours
4455: loss=3.933, avg loss=4.365, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 285120 images, time remaining=4.3 hours
4456: loss=4.462, avg loss=4.375, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=2.0 seconds, 285184 images, time remaining=4.3 hours
4457: loss=3.835, avg loss=4.321, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 285248 images, time remaining=4.3 hours
4458: loss=4.318, avg loss=4.320, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 285312 images, time remaining=4.3 hours
4459: loss=3.540, avg loss=4.242, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 285376 images, time remaining=4.3 hours
4460: loss=3.851, avg loss=4.203, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=1.9 seconds, 285440 images, time remaining=4.3 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14affc000000
4461: loss=5.506, avg loss=4.334, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 285504 images, time remaining=4.3 hours
4462: loss=6.000, avg loss=4.500, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 285568 images, time remaining=4.3 hours
4463: loss=5.137, avg loss=4.564, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=5.2 seconds, 285632 images, time remaining=4.3 hours
4464: loss=4.979, avg loss=4.605, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 285696 images, time remaining=4.3 hours
4465: loss=4.030, avg loss=4.548, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 285760 images, time remaining=4.3 hours
4466: loss=4.401, avg loss=4.533, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 285824 images, time remaining=4.3 hours
4467: loss=4.076, avg loss=4.487, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 285888 images, time remaining=4.3 hours
4468: loss=5.327, avg loss=4.571, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 285952 images, time remaining=4.3 hours
4469: loss=5.708, avg loss=4.685, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=5.3 seconds, 286016 images, time remaining=4.3 hours
4470: loss=4.958, avg loss=4.712, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 286080 images, time remaining=4.3 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4471: loss=5.706, avg loss=4.812, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 286144 images, time remaining=4.3 hours
4472: loss=4.402, avg loss=4.771, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 286208 images, time remaining=4.3 hours
4473: loss=4.434, avg loss=4.737, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 286272 images, time remaining=4.3 hours
4474: loss=4.212, avg loss=4.685, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.2 seconds, train=5.7 seconds, 286336 images, time remaining=4.3 hours
4475: loss=4.022, avg loss=4.618, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 286400 images, time remaining=4.3 hours
4476: loss=4.463, avg loss=4.603, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 286464 images, time remaining=4.3 hours
4477: loss=4.678, avg loss=4.610, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 286528 images, time remaining=4.3 hours
4478: loss=4.506, avg loss=4.600, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.7 seconds, 286592 images, time remaining=4.3 hours
4479: loss=4.181, avg loss=4.558, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=5.7 seconds, 286656 images, time remaining=4.3 hours
4480: loss=4.468, avg loss=4.549, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 286720 images, time remaining=4.3 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14af00000000
4481: loss=4.011, avg loss=4.495, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.9 seconds, 286784 images, time remaining=4.3 hours
4482: loss=4.623, avg loss=4.508, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 286848 images, time remaining=4.3 hours
4483: loss=4.102, avg loss=4.467, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 286912 images, time remaining=4.2 hours
4484: loss=4.288, avg loss=4.450, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 286976 images, time remaining=4.2 hours
4485: loss=5.271, avg loss=4.532, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 287040 images, time remaining=4.2 hours
4486: loss=4.389, avg loss=4.517, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 287104 images, time remaining=4.2 hours
4487: loss=4.352, avg loss=4.501, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 287168 images, time remaining=4.2 hours
4488: loss=4.234, avg loss=4.474, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 287232 images, time remaining=4.2 hours
4489: loss=3.659, avg loss=4.393, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 287296 images, time remaining=4.2 hours
4490: loss=4.453, avg loss=4.399, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 287360 images, time remaining=4.2 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b6d0c00000
4491: loss=4.067, avg loss=4.365, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 287424 images, time remaining=4.2 hours
4492: loss=5.387, avg loss=4.468, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 287488 images, time remaining=4.2 hours
4493: loss=4.983, avg loss=4.519, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 287552 images, time remaining=4.2 hours
4494: loss=4.454, avg loss=4.513, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 287616 images, time remaining=4.2 hours
4495: loss=4.336, avg loss=4.495, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.1 seconds, train=2.0 seconds, 287680 images, time remaining=4.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4496: loss=3.537, avg loss=4.399, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=2.0 seconds, 287744 images, time remaining=4.2 hours
4497: loss=4.157, avg loss=4.375, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 287808 images, time remaining=4.2 hours
4498: loss=3.925, avg loss=4.330, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 287872 images, time remaining=4.2 hours
4499: loss=3.971, avg loss=4.294, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=2.0 seconds, 287936 images, time remaining=4.2 hours
4500: loss=4.668, avg loss=4.331, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 288000 images, time remaining=4.2 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b528200000
4501: loss=4.573, avg loss=4.356, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.5 seconds, train=2.8 seconds, 288064 images, time remaining=4.2 hours
4502: loss=4.993, avg loss=4.419, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=2.7 seconds, 288128 images, time remaining=4.2 hours
4503: loss=4.075, avg loss=4.385, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=2.8 seconds, 288192 images, time remaining=4.2 hours
4504: loss=3.778, avg loss=4.324, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=2.8 seconds, 288256 images, time remaining=4.2 hours
4505: loss=3.783, avg loss=4.270, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 288320 images, time remaining=4.2 hours
4506: loss=3.223, avg loss=4.166, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 288384 images, time remaining=4.2 hours
4507: loss=3.444, avg loss=4.093, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 288448 images, time remaining=4.2 hours
4508: loss=3.451, avg loss=4.029, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 288512 images, time remaining=4.2 hours
4509: loss=4.360, avg loss=4.062, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 288576 images, time remaining=4.2 hours
4510: loss=3.532, avg loss=4.009, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.2 seconds, train=2.8 seconds, 288640 images, time remaining=4.2 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4511: loss=3.915, avg loss=4.000, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.2 seconds, train=5.4 seconds, 288704 images, time remaining=4.2 hours
4512: loss=3.343, avg loss=3.934, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 288768 images, time remaining=4.2 hours
4513: loss=4.205, avg loss=3.961, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 288832 images, time remaining=4.2 hours
4514: loss=4.838, avg loss=4.049, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 288896 images, time remaining=4.2 hours
4515: loss=4.066, avg loss=4.051, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 288960 images, time remaining=4.2 hours
4516: loss=3.954, avg loss=4.041, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 289024 images, time remaining=4.2 hours
4517: loss=4.346, avg loss=4.071, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 289088 images, time remaining=4.2 hours
4518: loss=4.072, avg loss=4.071, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 289152 images, time remaining=4.2 hours
4519: loss=4.199, avg loss=4.084, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.4 seconds, 289216 images, time remaining=4.2 hours
4520: loss=3.882, avg loss=4.064, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 289280 images, time remaining=4.2 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2e4000000
4521: loss=3.790, avg loss=4.037, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.2 seconds, train=2.7 seconds, 289344 images, time remaining=4.2 hours
4522: loss=3.168, avg loss=3.950, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 289408 images, time remaining=4.2 hours
4523: loss=3.738, avg loss=3.929, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 289472 images, time remaining=4.2 hours
4524: loss=3.099, avg loss=3.846, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 289536 images, time remaining=4.2 hours
4525: loss=3.662, avg loss=3.827, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 289600 images, time remaining=4.2 hours
4526: loss=3.650, avg loss=3.809, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 289664 images, time remaining=4.2 hours
4527: loss=2.682, avg loss=3.697, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 289728 images, time remaining=4.2 hours
4528: loss=3.658, avg loss=3.693, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 289792 images, time remaining=4.2 hours
4529: loss=3.414, avg loss=3.665, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 289856 images, time remaining=4.2 hours
4530: loss=3.517, avg loss=3.650, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.2 seconds, train=2.7 seconds, 289920 images, time remaining=4.2 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b81c400000
4531: loss=4.143, avg loss=3.699, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.1 seconds, train=2.0 seconds, 289984 images, time remaining=4.2 hours
4532: loss=3.501, avg loss=3.680, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 290048 images, time remaining=4.2 hours
4533: loss=3.913, avg loss=3.703, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 290112 images, time remaining=4.2 hours
4534: loss=4.417, avg loss=3.774, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 290176 images, time remaining=4.2 hours
4535: loss=3.100, avg loss=3.707, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 290240 images, time remaining=4.2 hours
4536: loss=3.253, avg loss=3.661, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 290304 images, time remaining=4.2 hours
4537: loss=3.386, avg loss=3.634, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=1.7 seconds, 290368 images, time remaining=4.2 hours
4538: loss=3.358, avg loss=3.606, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 290432 images, time remaining=4.2 hours
4539: loss=3.891, avg loss=3.635, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 290496 images, time remaining=4.2 hours
4540: loss=4.107, avg loss=3.682, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 290560 images, time remaining=4.2 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4541: loss=5.744, avg loss=3.888, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 290624 images, time remaining=4.2 hours
4542: loss=5.572, avg loss=4.057, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 290688 images, time remaining=4.2 hours
4543: loss=5.066, avg loss=4.158, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 290752 images, time remaining=4.2 hours
4544: loss=3.692, avg loss=4.111, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 290816 images, time remaining=4.2 hours
4545: loss=3.721, avg loss=4.072, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 290880 images, time remaining=4.2 hours
4546: loss=4.113, avg loss=4.076, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 290944 images, time remaining=4.2 hours
4547: loss=3.629, avg loss=4.031, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.5 seconds, train=5.4 seconds, 291008 images, time remaining=4.2 hours
4548: loss=4.520, avg loss=4.080, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 291072 images, time remaining=4.2 hours
4549: loss=5.211, avg loss=4.193, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=5.3 seconds, 291136 images, time remaining=4.2 hours
4550: loss=4.538, avg loss=4.228, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 291200 images, time remaining=4.2 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4551: loss=3.430, avg loss=4.148, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 291264 images, time remaining=4.2 hours
4552: loss=4.410, avg loss=4.174, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 291328 images, time remaining=4.2 hours
4553: loss=4.313, avg loss=4.188, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 291392 images, time remaining=4.2 hours
4554: loss=4.212, avg loss=4.191, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.2 seconds, train=4.7 seconds, 291456 images, time remaining=4.2 hours
4555: loss=4.832, avg loss=4.255, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 291520 images, time remaining=4.2 hours
4556: loss=4.410, avg loss=4.270, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.0 seconds, 291584 images, time remaining=4.2 hours
4557: loss=5.041, avg loss=4.347, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 291648 images, time remaining=4.2 hours
4558: loss=4.587, avg loss=4.371, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 291712 images, time remaining=4.2 hours
4559: loss=4.583, avg loss=4.392, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 291776 images, time remaining=4.2 hours
4560: loss=5.576, avg loss=4.511, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=4.9 seconds, 291840 images, time remaining=4.2 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4561: loss=4.056, avg loss=4.465, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=5.0 seconds, 291904 images, time remaining=4.2 hours
4562: loss=3.496, avg loss=4.368, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.0 seconds, 291968 images, time remaining=4.1 hours
4563: loss=4.030, avg loss=4.335, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=4.9 seconds, 292032 images, time remaining=4.1 hours
4564: loss=3.805, avg loss=4.282, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 292096 images, time remaining=4.1 hours
4565: loss=4.584, avg loss=4.312, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 292160 images, time remaining=4.1 hours
4566: loss=3.048, avg loss=4.185, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 292224 images, time remaining=4.1 hours
4567: loss=3.580, avg loss=4.125, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 292288 images, time remaining=4.1 hours
4568: loss=3.916, avg loss=4.104, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=4.9 seconds, 292352 images, time remaining=4.1 hours
4569: loss=3.133, avg loss=4.007, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 292416 images, time remaining=4.1 hours
4570: loss=4.266, avg loss=4.033, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=4.9 seconds, 292480 images, time remaining=4.1 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b61aa00000
4571: loss=3.801, avg loss=4.010, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 292544 images, time remaining=4.1 hours
4572: loss=3.807, avg loss=3.989, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 292608 images, time remaining=4.1 hours
4573: loss=4.365, avg loss=4.027, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 292672 images, time remaining=4.1 hours
4574: loss=3.905, avg loss=4.015, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 292736 images, time remaining=4.1 hours
4575: loss=4.438, avg loss=4.057, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 292800 images, time remaining=4.1 hours
4576: loss=3.499, avg loss=4.001, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 292864 images, time remaining=4.1 hours
4577: loss=2.858, avg loss=3.887, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 292928 images, time remaining=4.1 hours
4578: loss=3.763, avg loss=3.875, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 292992 images, time remaining=4.1 hours
4579: loss=3.642, avg loss=3.851, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 293056 images, time remaining=4.1 hours
4580: loss=3.698, avg loss=3.836, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=2.3 seconds, 293120 images, time remaining=4.1 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4581: loss=4.095, avg loss=3.862, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=4.0 seconds, 293184 images, time remaining=4.1 hours
4582: loss=4.026, avg loss=3.878, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 293248 images, time remaining=4.1 hours
4583: loss=4.192, avg loss=3.910, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=3.9 seconds, 293312 images, time remaining=4.1 hours
4584: loss=3.694, avg loss=3.888, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 293376 images, time remaining=4.1 hours
4585: loss=4.429, avg loss=3.942, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 293440 images, time remaining=4.1 hours
4586: loss=3.465, avg loss=3.894, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 293504 images, time remaining=4.1 hours
4587: loss=2.704, avg loss=3.775, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 293568 images, time remaining=4.1 hours
4588: loss=3.311, avg loss=3.729, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 293632 images, time remaining=4.1 hours
4589: loss=3.415, avg loss=3.698, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 293696 images, time remaining=4.1 hours
4590: loss=4.289, avg loss=3.757, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 293760 images, time remaining=4.1 hours
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14b841c00000
4591: loss=3.181, avg loss=3.699, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 293824 images, time remaining=4.1 hours
4592: loss=3.951, avg loss=3.724, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 293888 images, time remaining=4.1 hours
4593: loss=3.663, avg loss=3.718, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 293952 images, time remaining=4.1 hours
4594: loss=3.785, avg loss=3.725, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 294016 images, time remaining=4.1 hours
4595: loss=3.098, avg loss=3.662, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 294080 images, time remaining=4.1 hours
4596: loss=3.445, avg loss=3.641, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 294144 images, time remaining=4.1 hours
4597: loss=2.778, avg loss=3.554, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 294208 images, time remaining=4.1 hours
4598: loss=3.384, avg loss=3.537, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 294272 images, time remaining=4.1 hours
4599: loss=3.456, avg loss=3.529, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 294336 images, time remaining=4.1 hours
4600: loss=3.613, avg loss=3.537, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 294400 images, time remaining=4.1 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b4e9c00000
4601: loss=3.728, avg loss=3.557, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 294464 images, time remaining=4.1 hours
4602: loss=3.992, avg loss=3.600, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 294528 images, time remaining=4.1 hours
4603: loss=3.591, avg loss=3.599, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 294592 images, time remaining=4.1 hours
4604: loss=3.234, avg loss=3.563, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 294656 images, time remaining=4.1 hours
4605: loss=4.296, avg loss=3.636, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 294720 images, time remaining=4.1 hours
4606: loss=3.187, avg loss=3.591, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 294784 images, time remaining=4.1 hours
4607: loss=3.723, avg loss=3.604, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 294848 images, time remaining=4.1 hours
4608: loss=3.281, avg loss=3.572, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 294912 images, time remaining=4.1 hours
4609: loss=3.359, avg loss=3.551, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 294976 images, time remaining=4.1 hours
4610: loss=3.292, avg loss=3.525, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 295040 images, time remaining=4.1 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4611: loss=4.146, avg loss=3.587, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 295104 images, time remaining=4.1 hours
4612: loss=3.646, avg loss=3.593, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=4.2 seconds, 295168 images, time remaining=4.1 hours
4613: loss=4.245, avg loss=3.658, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 295232 images, time remaining=4.1 hours
4614: loss=3.693, avg loss=3.661, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.3 seconds, train=4.2 seconds, 295296 images, time remaining=4.1 hours
4615: loss=3.187, avg loss=3.614, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 295360 images, time remaining=4.1 hours
4616: loss=3.344, avg loss=3.587, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 295424 images, time remaining=4.1 hours
4617: loss=3.342, avg loss=3.562, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 295488 images, time remaining=4.1 hours
4618: loss=3.685, avg loss=3.575, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 295552 images, time remaining=4.1 hours
4619: loss=3.511, avg loss=3.568, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=4.1 seconds, 295616 images, time remaining=4.1 hours
4620: loss=3.164, avg loss=3.528, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 295680 images, time remaining=4.1 hours
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4621: loss=3.454, avg loss=3.520, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=4.1 seconds, 295744 images, time remaining=4.1 hours
4622: loss=3.832, avg loss=3.552, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 295808 images, time remaining=4.1 hours
4623: loss=2.828, avg loss=3.479, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=4.1 seconds, 295872 images, time remaining=4.1 hours
4624: loss=3.824, avg loss=3.514, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 295936 images, time remaining=4.1 hours
4625: loss=4.373, avg loss=3.600, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 296000 images, time remaining=4.1 hours
4626: loss=3.341, avg loss=3.574, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 296064 images, time remaining=4.1 hours
4627: loss=3.887, avg loss=3.605, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 296128 images, time remaining=4.1 hours
4628: loss=2.883, avg loss=3.533, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 296192 images, time remaining=4.1 hours
4629: loss=3.883, avg loss=3.568, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.2 seconds, train=3.9 seconds, 296256 images, time remaining=4.1 hours
4630: loss=3.448, avg loss=3.556, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=4.0 seconds, 296320 images, time remaining=4.1 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4631: loss=3.960, avg loss=3.596, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.2 seconds, train=4.8 seconds, 296384 images, time remaining=4.1 hours
4632: loss=4.244, avg loss=3.661, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=4.7 seconds, 296448 images, time remaining=4.1 hours
4633: loss=4.002, avg loss=3.695, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 296512 images, time remaining=4.1 hours
4634: loss=2.918, avg loss=3.617, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 296576 images, time remaining=4.1 hours
4635: loss=3.736, avg loss=3.629, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=4.6 seconds, 296640 images, time remaining=4.1 hours
4636: loss=3.615, avg loss=3.628, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=4.7 seconds, 296704 images, time remaining=4.1 hours
4637: loss=3.553, avg loss=3.620, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=4.6 seconds, 296768 images, time remaining=4 hours
4638: loss=3.901, avg loss=3.648, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=3.2 seconds, train=4.7 seconds, 296832 images, time remaining=4 hours
4639: loss=4.407, avg loss=3.724, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.7 seconds, train=4.7 seconds, 296896 images, time remaining=4 hours
4640: loss=3.743, avg loss=3.726, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.9 seconds, train=4.7 seconds, 296960 images, time remaining=4 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4641: loss=3.814, avg loss=3.735, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.6 seconds, train=5.9 seconds, 297024 images, time remaining=4 hours
4642: loss=3.918, avg loss=3.753, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.1 seconds, train=5.9 seconds, 297088 images, time remaining=4 hours
4643: loss=3.999, avg loss=3.778, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 297152 images, time remaining=4 hours
4644: loss=4.224, avg loss=3.822, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 297216 images, time remaining=4 hours
4645: loss=3.989, avg loss=3.839, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.2 seconds, train=5.7 seconds, 297280 images, time remaining=4 hours
4646: loss=3.504, avg loss=3.806, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.3 seconds, train=5.8 seconds, 297344 images, time remaining=4 hours
4647: loss=4.179, avg loss=3.843, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.4 seconds, train=5.9 seconds, 297408 images, time remaining=4 hours
4648: loss=3.804, avg loss=3.839, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.9 seconds, 297472 images, time remaining=4 hours
4649: loss=3.827, avg loss=3.838, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 297536 images, time remaining=4 hours
4650: loss=4.204, avg loss=3.874, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 297600 images, time remaining=4 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b773e00000
4651: loss=3.885, avg loss=3.875, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.8 seconds, train=2.0 seconds, 297664 images, time remaining=4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4652: loss=4.140, avg loss=3.902, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=2.2 seconds, train=2.1 seconds, 297728 images, time remaining=4 hours
4653: loss=4.181, avg loss=3.930, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 297792 images, time remaining=4 hours
4654: loss=4.455, avg loss=3.982, last=92.50%, best=92.50%, next=4654, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 297856 images, time remaining=4 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2e4000000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=158328, unique_truth_count=57264
rank=0 of ranks=158328rank=100 of ranks=158328rank=200 of ranks=158328rank=300 of ranks=158328rank=400 of ranks=158328rank=500 of ranks=158328rank=600 of ranks=158328rank=700 of ranks=158328rank=800 of ranks=158328rank=900 of ranks=158328rank=1000 of ranks=158328rank=1100 of ranks=158328rank=1200 of ranks=158328rank=1300 of ranks=158328rank=1400 of ranks=158328rank=1500 of ranks=158328rank=1600 of ranks=158328rank=1700 of ranks=158328rank=1800 of ranks=158328rank=1900 of ranks=158328rank=2000 of ranks=158328rank=2100 of ranks=158328rank=2200 of ranks=158328rank=2300 of ranks=158328rank=2400 of ranks=158328rank=2500 of ranks=158328rank=2600 of ranks=158328rank=2700 of ranks=158328rank=2800 of ranks=158328rank=2900 of ranks=158328rank=3000 of ranks=158328rank=3100 of ranks=158328rank=3200 of ranks=158328rank=3300 of ranks=158328rank=3400 of ranks=158328rank=3500 of ranks=158328rank=3600 of ranks=158328rank=3700 of ranks=158328rank=3800 of ranks=158328rank=3900 of ranks=158328rank=4000 of ranks=158328rank=4100 of ranks=158328rank=4200 of ranks=158328rank=4300 of ranks=158328rank=4400 of ranks=158328rank=4500 of ranks=158328rank=4600 of ranks=158328rank=4700 of ranks=158328rank=4800 of ranks=158328rank=4900 of ranks=158328rank=5000 of ranks=158328rank=5100 of ranks=158328rank=5200 of ranks=158328rank=5300 of ranks=158328rank=5400 of ranks=158328rank=5500 of ranks=158328rank=5600 of ranks=158328rank=5700 of ranks=158328rank=5800 of ranks=158328rank=5900 of ranks=158328rank=6000 of ranks=158328rank=6100 of ranks=158328rank=6200 of ranks=158328rank=6300 of ranks=158328rank=6400 of ranks=158328rank=6500 of ranks=158328rank=6600 of ranks=158328rank=6700 of ranks=158328rank=6800 of ranks=158328rank=6900 of ranks=158328rank=7000 of ranks=158328rank=7100 of ranks=158328rank=7200 of ranks=158328rank=7300 of ranks=158328rank=7400 of ranks=158328rank=7500 of ranks=158328rank=7600 of ranks=158328rank=7700 of ranks=158328rank=7800 of ranks=158328rank=7900 of ranks=158328rank=8000 of ranks=158328rank=8100 of ranks=158328rank=8200 of ranks=158328rank=8300 of ranks=158328rank=8400 of ranks=158328rank=8500 of ranks=158328rank=8600 of ranks=158328rank=8700 of ranks=158328rank=8800 of ranks=158328rank=8900 of ranks=158328rank=9000 of ranks=158328rank=9100 of ranks=158328rank=9200 of ranks=158328rank=9300 of ranks=158328rank=9400 of ranks=158328rank=9500 of ranks=158328rank=9600 of ranks=158328rank=9700 of ranks=158328rank=9800 of ranks=158328rank=9900 of ranks=158328rank=10000 of ranks=158328rank=10100 of ranks=158328rank=10200 of ranks=158328rank=10300 of ranks=158328rank=10400 of ranks=158328rank=10500 of ranks=158328rank=10600 of ranks=158328rank=10700 of ranks=158328rank=10800 of ranks=158328rank=10900 of ranks=158328rank=11000 of ranks=158328rank=11100 of ranks=158328rank=11200 of ranks=158328rank=11300 of ranks=158328rank=11400 of ranks=158328rank=11500 of ranks=158328rank=11600 of ranks=158328rank=11700 of ranks=158328rank=11800 of ranks=158328rank=11900 of ranks=158328rank=12000 of ranks=158328rank=12100 of ranks=158328rank=12200 of ranks=158328rank=12300 of ranks=158328rank=12400 of ranks=158328rank=12500 of ranks=158328rank=12600 of ranks=158328rank=12700 of ranks=158328rank=12800 of ranks=158328rank=12900 of ranks=158328rank=13000 of ranks=158328rank=13100 of ranks=158328rank=13200 of ranks=158328rank=13300 of ranks=158328rank=13400 of ranks=158328rank=13500 of ranks=158328rank=13600 of ranks=158328rank=13700 of ranks=158328rank=13800 of ranks=158328rank=13900 of ranks=158328rank=14000 of ranks=158328rank=14100 of ranks=158328rank=14200 of ranks=158328rank=14300 of ranks=158328rank=14400 of ranks=158328rank=14500 of ranks=158328rank=14600 of ranks=158328rank=14700 of ranks=158328rank=14800 of ranks=158328rank=14900 of ranks=158328rank=15000 of ranks=158328rank=15100 of ranks=158328rank=15200 of ranks=158328rank=15300 of ranks=158328rank=15400 of ranks=158328rank=15500 of ranks=158328rank=15600 of ranks=158328rank=15700 of ranks=158328rank=15800 of ranks=158328rank=15900 of ranks=158328rank=16000 of ranks=158328rank=16100 of ranks=158328rank=16200 of ranks=158328rank=16300 of ranks=158328rank=16400 of ranks=158328rank=16500 of ranks=158328rank=16600 of ranks=158328rank=16700 of ranks=158328rank=16800 of ranks=158328rank=16900 of ranks=158328rank=17000 of ranks=158328rank=17100 of ranks=158328rank=17200 of ranks=158328rank=17300 of ranks=158328rank=17400 of ranks=158328rank=17500 of ranks=158328rank=17600 of ranks=158328rank=17700 of ranks=158328rank=17800 of ranks=158328rank=17900 of ranks=158328rank=18000 of ranks=158328rank=18100 of ranks=158328rank=18200 of ranks=158328rank=18300 of ranks=158328rank=18400 of ranks=158328rank=18500 of ranks=158328rank=18600 of ranks=158328rank=18700 of ranks=158328rank=18800 of ranks=158328rank=18900 of ranks=158328rank=19000 of ranks=158328rank=19100 of ranks=158328rank=19200 of ranks=158328rank=19300 of ranks=158328rank=19400 of ranks=158328rank=19500 of ranks=158328rank=19600 of ranks=158328rank=19700 of ranks=158328rank=19800 of ranks=158328rank=19900 of ranks=158328rank=20000 of ranks=158328rank=20100 of ranks=158328rank=20200 of ranks=158328rank=20300 of ranks=158328rank=20400 of ranks=158328rank=20500 of ranks=158328rank=20600 of ranks=158328rank=20700 of ranks=158328rank=20800 of ranks=158328rank=20900 of ranks=158328rank=21000 of ranks=158328rank=21100 of ranks=158328rank=21200 of ranks=158328rank=21300 of ranks=158328rank=21400 of ranks=158328rank=21500 of ranks=158328rank=21600 of ranks=158328rank=21700 of ranks=158328rank=21800 of ranks=158328rank=21900 of ranks=158328rank=22000 of ranks=158328rank=22100 of ranks=158328rank=22200 of ranks=158328rank=22300 of ranks=158328rank=22400 of ranks=158328rank=22500 of ranks=158328rank=22600 of ranks=158328rank=22700 of ranks=158328rank=22800 of ranks=158328rank=22900 of ranks=158328rank=23000 of ranks=158328rank=23100 of ranks=158328rank=23200 of ranks=158328rank=23300 of ranks=158328rank=23400 of ranks=158328rank=23500 of ranks=158328rank=23600 of ranks=158328rank=23700 of ranks=158328rank=23800 of ranks=158328rank=23900 of ranks=158328rank=24000 of ranks=158328rank=24100 of ranks=158328rank=24200 of ranks=158328rank=24300 of ranks=158328rank=24400 of ranks=158328rank=24500 of ranks=158328rank=24600 of ranks=158328rank=24700 of ranks=158328rank=24800 of ranks=158328rank=24900 of ranks=158328rank=25000 of ranks=158328rank=25100 of ranks=158328rank=25200 of ranks=158328rank=25300 of ranks=158328rank=25400 of ranks=158328rank=25500 of ranks=158328rank=25600 of ranks=158328rank=25700 of ranks=158328rank=25800 of ranks=158328rank=25900 of ranks=158328rank=26000 of ranks=158328rank=26100 of ranks=158328rank=26200 of ranks=158328rank=26300 of ranks=158328rank=26400 of ranks=158328rank=26500 of ranks=158328rank=26600 of ranks=158328rank=26700 of ranks=158328rank=26800 of ranks=158328rank=26900 of ranks=158328rank=27000 of ranks=158328rank=27100 of ranks=158328rank=27200 of ranks=158328rank=27300 of ranks=158328rank=27400 of ranks=158328rank=27500 of ranks=158328rank=27600 of ranks=158328rank=27700 of ranks=158328rank=27800 of ranks=158328rank=27900 of ranks=158328rank=28000 of ranks=158328rank=28100 of ranks=158328rank=28200 of ranks=158328rank=28300 of ranks=158328rank=28400 of ranks=158328rank=28500 of ranks=158328rank=28600 of ranks=158328rank=28700 of ranks=158328rank=28800 of ranks=158328rank=28900 of ranks=158328rank=29000 of ranks=158328rank=29100 of ranks=158328rank=29200 of ranks=158328rank=29300 of ranks=158328rank=29400 of ranks=158328rank=29500 of ranks=158328rank=29600 of ranks=158328rank=29700 of ranks=158328rank=29800 of ranks=158328rank=29900 of ranks=158328rank=30000 of ranks=158328rank=30100 of ranks=158328rank=30200 of ranks=158328rank=30300 of ranks=158328rank=30400 of ranks=158328rank=30500 of ranks=158328rank=30600 of ranks=158328rank=30700 of ranks=158328rank=30800 of ranks=158328rank=30900 of ranks=158328rank=31000 of ranks=158328rank=31100 of ranks=158328rank=31200 of ranks=158328rank=31300 of ranks=158328rank=31400 of ranks=158328rank=31500 of ranks=158328rank=31600 of ranks=158328rank=31700 of ranks=158328rank=31800 of ranks=158328rank=31900 of ranks=158328rank=32000 of ranks=158328rank=32100 of ranks=158328rank=32200 of ranks=158328rank=32300 of ranks=158328rank=32400 of ranks=158328rank=32500 of ranks=158328rank=32600 of ranks=158328rank=32700 of ranks=158328rank=32800 of ranks=158328rank=32900 of ranks=158328rank=33000 of ranks=158328rank=33100 of ranks=158328rank=33200 of ranks=158328rank=33300 of ranks=158328rank=33400 of ranks=158328rank=33500 of ranks=158328rank=33600 of ranks=158328rank=33700 of ranks=158328rank=33800 of ranks=158328rank=33900 of ranks=158328rank=34000 of ranks=158328rank=34100 of ranks=158328rank=34200 of ranks=158328rank=34300 of ranks=158328rank=34400 of ranks=158328rank=34500 of ranks=158328rank=34600 of ranks=158328rank=34700 of ranks=158328rank=34800 of ranks=158328rank=34900 of ranks=158328rank=35000 of ranks=158328rank=35100 of ranks=158328rank=35200 of ranks=158328rank=35300 of ranks=158328rank=35400 of ranks=158328rank=35500 of ranks=158328rank=35600 of ranks=158328rank=35700 of ranks=158328rank=35800 of ranks=158328rank=35900 of ranks=158328rank=36000 of ranks=158328rank=36100 of ranks=158328rank=36200 of ranks=158328rank=36300 of ranks=158328rank=36400 of ranks=158328rank=36500 of ranks=158328rank=36600 of ranks=158328rank=36700 of ranks=158328rank=36800 of ranks=158328rank=36900 of ranks=158328rank=37000 of ranks=158328rank=37100 of ranks=158328rank=37200 of ranks=158328rank=37300 of ranks=158328rank=37400 of ranks=158328rank=37500 of ranks=158328rank=37600 of ranks=158328rank=37700 of ranks=158328rank=37800 of ranks=158328rank=37900 of ranks=158328rank=38000 of ranks=158328rank=38100 of ranks=158328rank=38200 of ranks=158328rank=38300 of ranks=158328rank=38400 of ranks=158328rank=38500 of ranks=158328rank=38600 of ranks=158328rank=38700 of ranks=158328rank=38800 of ranks=158328rank=38900 of ranks=158328rank=39000 of ranks=158328rank=39100 of ranks=158328rank=39200 of ranks=158328rank=39300 of ranks=158328rank=39400 of ranks=158328rank=39500 of ranks=158328rank=39600 of ranks=158328rank=39700 of ranks=158328rank=39800 of ranks=158328rank=39900 of ranks=158328rank=40000 of ranks=158328rank=40100 of ranks=158328rank=40200 of ranks=158328rank=40300 of ranks=158328rank=40400 of ranks=158328rank=40500 of ranks=158328rank=40600 of ranks=158328rank=40700 of ranks=158328rank=40800 of ranks=158328rank=40900 of ranks=158328rank=41000 of ranks=158328rank=41100 of ranks=158328rank=41200 of ranks=158328rank=41300 of ranks=158328rank=41400 of ranks=158328rank=41500 of ranks=158328rank=41600 of ranks=158328rank=41700 of ranks=158328rank=41800 of ranks=158328rank=41900 of ranks=158328rank=42000 of ranks=158328rank=42100 of ranks=158328rank=42200 of ranks=158328rank=42300 of ranks=158328rank=42400 of ranks=158328rank=42500 of ranks=158328rank=42600 of ranks=158328rank=42700 of ranks=158328rank=42800 of ranks=158328rank=42900 of ranks=158328rank=43000 of ranks=158328rank=43100 of ranks=158328rank=43200 of ranks=158328rank=43300 of ranks=158328rank=43400 of ranks=158328rank=43500 of ranks=158328rank=43600 of ranks=158328rank=43700 of ranks=158328rank=43800 of ranks=158328rank=43900 of ranks=158328rank=44000 of ranks=158328rank=44100 of ranks=158328rank=44200 of ranks=158328rank=44300 of ranks=158328rank=44400 of ranks=158328rank=44500 of ranks=158328rank=44600 of ranks=158328rank=44700 of ranks=158328rank=44800 of ranks=158328rank=44900 of ranks=158328rank=45000 of ranks=158328rank=45100 of ranks=158328rank=45200 of ranks=158328rank=45300 of ranks=158328rank=45400 of ranks=158328rank=45500 of ranks=158328rank=45600 of ranks=158328rank=45700 of ranks=158328rank=45800 of ranks=158328rank=45900 of ranks=158328rank=46000 of ranks=158328rank=46100 of ranks=158328rank=46200 of ranks=158328rank=46300 of ranks=158328rank=46400 of ranks=158328rank=46500 of ranks=158328rank=46600 of ranks=158328rank=46700 of ranks=158328rank=46800 of ranks=158328rank=46900 of ranks=158328rank=47000 of ranks=158328rank=47100 of ranks=158328rank=47200 of ranks=158328rank=47300 of ranks=158328rank=47400 of ranks=158328rank=47500 of ranks=158328rank=47600 of ranks=158328rank=47700 of ranks=158328rank=47800 of ranks=158328rank=47900 of ranks=158328rank=48000 of ranks=158328rank=48100 of ranks=158328rank=48200 of ranks=158328rank=48300 of ranks=158328rank=48400 of ranks=158328rank=48500 of ranks=158328rank=48600 of ranks=158328rank=48700 of ranks=158328rank=48800 of ranks=158328rank=48900 of ranks=158328rank=49000 of ranks=158328rank=49100 of ranks=158328rank=49200 of ranks=158328rank=49300 of ranks=158328rank=49400 of ranks=158328rank=49500 of ranks=158328rank=49600 of ranks=158328rank=49700 of ranks=158328rank=49800 of ranks=158328rank=49900 of ranks=158328rank=50000 of ranks=158328rank=50100 of ranks=158328rank=50200 of ranks=158328rank=50300 of ranks=158328rank=50400 of ranks=158328rank=50500 of ranks=158328rank=50600 of ranks=158328rank=50700 of ranks=158328rank=50800 of ranks=158328rank=50900 of ranks=158328rank=51000 of ranks=158328rank=51100 of ranks=158328rank=51200 of ranks=158328rank=51300 of ranks=158328rank=51400 of ranks=158328rank=51500 of ranks=158328rank=51600 of ranks=158328rank=51700 of ranks=158328rank=51800 of ranks=158328rank=51900 of ranks=158328rank=52000 of ranks=158328rank=52100 of ranks=158328rank=52200 of ranks=158328rank=52300 of ranks=158328rank=52400 of ranks=158328rank=52500 of ranks=158328rank=52600 of ranks=158328rank=52700 of ranks=158328rank=52800 of ranks=158328rank=52900 of ranks=158328rank=53000 of ranks=158328rank=53100 of ranks=158328rank=53200 of ranks=158328rank=53300 of ranks=158328rank=53400 of ranks=158328rank=53500 of ranks=158328rank=53600 of ranks=158328rank=53700 of ranks=158328rank=53800 of ranks=158328rank=53900 of ranks=158328rank=54000 of ranks=158328rank=54100 of ranks=158328rank=54200 of ranks=158328rank=54300 of ranks=158328rank=54400 of ranks=158328rank=54500 of ranks=158328rank=54600 of ranks=158328rank=54700 of ranks=158328rank=54800 of ranks=158328rank=54900 of ranks=158328rank=55000 of ranks=158328rank=55100 of ranks=158328rank=55200 of ranks=158328rank=55300 of ranks=158328rank=55400 of ranks=158328rank=55500 of ranks=158328rank=55600 of ranks=158328rank=55700 of ranks=158328rank=55800 of ranks=158328rank=55900 of ranks=158328rank=56000 of ranks=158328rank=56100 of ranks=158328rank=56200 of ranks=158328rank=56300 of ranks=158328rank=56400 of ranks=158328rank=56500 of ranks=158328rank=56600 of ranks=158328rank=56700 of ranks=158328rank=56800 of ranks=158328rank=56900 of ranks=158328rank=57000 of ranks=158328rank=57100 of ranks=158328rank=57200 of ranks=158328rank=57300 of ranks=158328rank=57400 of ranks=158328rank=57500 of ranks=158328rank=57600 of ranks=158328rank=57700 of ranks=158328rank=57800 of ranks=158328rank=57900 of ranks=158328rank=58000 of ranks=158328rank=58100 of ranks=158328rank=58200 of ranks=158328rank=58300 of ranks=158328rank=58400 of ranks=158328rank=58500 of ranks=158328rank=58600 of ranks=158328rank=58700 of ranks=158328rank=58800 of ranks=158328rank=58900 of ranks=158328rank=59000 of ranks=158328rank=59100 of ranks=158328rank=59200 of ranks=158328rank=59300 of ranks=158328rank=59400 of ranks=158328rank=59500 of ranks=158328rank=59600 of ranks=158328rank=59700 of ranks=158328rank=59800 of ranks=158328rank=59900 of ranks=158328rank=60000 of ranks=158328rank=60100 of ranks=158328rank=60200 of ranks=158328rank=60300 of ranks=158328rank=60400 of ranks=158328rank=60500 of ranks=158328rank=60600 of ranks=158328rank=60700 of ranks=158328rank=60800 of ranks=158328rank=60900 of ranks=158328rank=61000 of ranks=158328rank=61100 of ranks=158328rank=61200 of ranks=158328rank=61300 of ranks=158328rank=61400 of ranks=158328rank=61500 of ranks=158328rank=61600 of ranks=158328rank=61700 of ranks=158328rank=61800 of ranks=158328rank=61900 of ranks=158328rank=62000 of ranks=158328rank=62100 of ranks=158328rank=62200 of ranks=158328rank=62300 of ranks=158328rank=62400 of ranks=158328rank=62500 of ranks=158328rank=62600 of ranks=158328rank=62700 of ranks=158328rank=62800 of ranks=158328rank=62900 of ranks=158328rank=63000 of ranks=158328rank=63100 of ranks=158328rank=63200 of ranks=158328rank=63300 of ranks=158328rank=63400 of ranks=158328rank=63500 of ranks=158328rank=63600 of ranks=158328rank=63700 of ranks=158328rank=63800 of ranks=158328rank=63900 of ranks=158328rank=64000 of ranks=158328rank=64100 of ranks=158328rank=64200 of ranks=158328rank=64300 of ranks=158328rank=64400 of ranks=158328rank=64500 of ranks=158328rank=64600 of ranks=158328rank=64700 of ranks=158328rank=64800 of ranks=158328rank=64900 of ranks=158328rank=65000 of ranks=158328rank=65100 of ranks=158328rank=65200 of ranks=158328rank=65300 of ranks=158328rank=65400 of ranks=158328rank=65500 of ranks=158328rank=65600 of ranks=158328rank=65700 of ranks=158328rank=65800 of ranks=158328rank=65900 of ranks=158328rank=66000 of ranks=158328rank=66100 of ranks=158328rank=66200 of ranks=158328rank=66300 of ranks=158328rank=66400 of ranks=158328rank=66500 of ranks=158328rank=66600 of ranks=158328rank=66700 of ranks=158328rank=66800 of ranks=158328rank=66900 of ranks=158328rank=67000 of ranks=158328rank=67100 of ranks=158328rank=67200 of ranks=158328rank=67300 of ranks=158328rank=67400 of ranks=158328rank=67500 of ranks=158328rank=67600 of ranks=158328rank=67700 of ranks=158328rank=67800 of ranks=158328rank=67900 of ranks=158328rank=68000 of ranks=158328rank=68100 of ranks=158328rank=68200 of ranks=158328rank=68300 of ranks=158328rank=68400 of ranks=158328rank=68500 of ranks=158328rank=68600 of ranks=158328rank=68700 of ranks=158328rank=68800 of ranks=158328rank=68900 of ranks=158328rank=69000 of ranks=158328rank=69100 of ranks=158328rank=69200 of ranks=158328rank=69300 of ranks=158328rank=69400 of ranks=158328rank=69500 of ranks=158328rank=69600 of ranks=158328rank=69700 of ranks=158328rank=69800 of ranks=158328rank=69900 of ranks=158328rank=70000 of ranks=158328rank=70100 of ranks=158328rank=70200 of ranks=158328rank=70300 of ranks=158328rank=70400 of ranks=158328rank=70500 of ranks=158328rank=70600 of ranks=158328rank=70700 of ranks=158328rank=70800 of ranks=158328rank=70900 of ranks=158328rank=71000 of ranks=158328rank=71100 of ranks=158328rank=71200 of ranks=158328rank=71300 of ranks=158328rank=71400 of ranks=158328rank=71500 of ranks=158328rank=71600 of ranks=158328rank=71700 of ranks=158328rank=71800 of ranks=158328rank=71900 of ranks=158328rank=72000 of ranks=158328rank=72100 of ranks=158328rank=72200 of ranks=158328rank=72300 of ranks=158328rank=72400 of ranks=158328rank=72500 of ranks=158328rank=72600 of ranks=158328rank=72700 of ranks=158328rank=72800 of ranks=158328rank=72900 of ranks=158328rank=73000 of ranks=158328rank=73100 of ranks=158328rank=73200 of ranks=158328rank=73300 of ranks=158328rank=73400 of ranks=158328rank=73500 of ranks=158328rank=73600 of ranks=158328rank=73700 of ranks=158328rank=73800 of ranks=158328rank=73900 of ranks=158328rank=74000 of ranks=158328rank=74100 of ranks=158328rank=74200 of ranks=158328rank=74300 of ranks=158328rank=74400 of ranks=158328rank=74500 of ranks=158328rank=74600 of ranks=158328rank=74700 of ranks=158328rank=74800 of ranks=158328rank=74900 of ranks=158328rank=75000 of ranks=158328rank=75100 of ranks=158328rank=75200 of ranks=158328rank=75300 of ranks=158328rank=75400 of ranks=158328rank=75500 of ranks=158328rank=75600 of ranks=158328rank=75700 of ranks=158328rank=75800 of ranks=158328rank=75900 of ranks=158328rank=76000 of ranks=158328rank=76100 of ranks=158328rank=76200 of ranks=158328rank=76300 of ranks=158328rank=76400 of ranks=158328rank=76500 of ranks=158328rank=76600 of ranks=158328rank=76700 of ranks=158328rank=76800 of ranks=158328rank=76900 of ranks=158328rank=77000 of ranks=158328rank=77100 of ranks=158328rank=77200 of ranks=158328rank=77300 of ranks=158328rank=77400 of ranks=158328rank=77500 of ranks=158328rank=77600 of ranks=158328rank=77700 of ranks=158328rank=77800 of ranks=158328rank=77900 of ranks=158328rank=78000 of ranks=158328rank=78100 of ranks=158328rank=78200 of ranks=158328rank=78300 of ranks=158328rank=78400 of ranks=158328rank=78500 of ranks=158328rank=78600 of ranks=158328rank=78700 of ranks=158328rank=78800 of ranks=158328rank=78900 of ranks=158328rank=79000 of ranks=158328rank=79100 of ranks=158328rank=79200 of ranks=158328rank=79300 of ranks=158328rank=79400 of ranks=158328rank=79500 of ranks=158328rank=79600 of ranks=158328rank=79700 of ranks=158328rank=79800 of ranks=158328rank=79900 of ranks=158328rank=80000 of ranks=158328rank=80100 of ranks=158328rank=80200 of ranks=158328rank=80300 of ranks=158328rank=80400 of ranks=158328rank=80500 of ranks=158328rank=80600 of ranks=158328rank=80700 of ranks=158328rank=80800 of ranks=158328rank=80900 of ranks=158328rank=81000 of ranks=158328rank=81100 of ranks=158328rank=81200 of ranks=158328rank=81300 of ranks=158328rank=81400 of ranks=158328rank=81500 of ranks=158328rank=81600 of ranks=158328rank=81700 of ranks=158328rank=81800 of ranks=158328rank=81900 of ranks=158328rank=82000 of ranks=158328rank=82100 of ranks=158328rank=82200 of ranks=158328rank=82300 of ranks=158328rank=82400 of ranks=158328rank=82500 of ranks=158328rank=82600 of ranks=158328rank=82700 of ranks=158328rank=82800 of ranks=158328rank=82900 of ranks=158328rank=83000 of ranks=158328rank=83100 of ranks=158328rank=83200 of ranks=158328rank=83300 of ranks=158328rank=83400 of ranks=158328rank=83500 of ranks=158328rank=83600 of ranks=158328rank=83700 of ranks=158328rank=83800 of ranks=158328rank=83900 of ranks=158328rank=84000 of ranks=158328rank=84100 of ranks=158328rank=84200 of ranks=158328rank=84300 of ranks=158328rank=84400 of ranks=158328rank=84500 of ranks=158328rank=84600 of ranks=158328rank=84700 of ranks=158328rank=84800 of ranks=158328rank=84900 of ranks=158328rank=85000 of ranks=158328rank=85100 of ranks=158328rank=85200 of ranks=158328rank=85300 of ranks=158328rank=85400 of ranks=158328rank=85500 of ranks=158328rank=85600 of ranks=158328rank=85700 of ranks=158328rank=85800 of ranks=158328rank=85900 of ranks=158328rank=86000 of ranks=158328rank=86100 of ranks=158328rank=86200 of ranks=158328rank=86300 of ranks=158328rank=86400 of ranks=158328rank=86500 of ranks=158328rank=86600 of ranks=158328rank=86700 of ranks=158328rank=86800 of ranks=158328rank=86900 of ranks=158328rank=87000 of ranks=158328rank=87100 of ranks=158328rank=87200 of ranks=158328rank=87300 of ranks=158328rank=87400 of ranks=158328rank=87500 of ranks=158328rank=87600 of ranks=158328rank=87700 of ranks=158328rank=87800 of ranks=158328rank=87900 of ranks=158328rank=88000 of ranks=158328rank=88100 of ranks=158328rank=88200 of ranks=158328rank=88300 of ranks=158328rank=88400 of ranks=158328rank=88500 of ranks=158328rank=88600 of ranks=158328rank=88700 of ranks=158328rank=88800 of ranks=158328rank=88900 of ranks=158328rank=89000 of ranks=158328rank=89100 of ranks=158328rank=89200 of ranks=158328rank=89300 of ranks=158328rank=89400 of ranks=158328rank=89500 of ranks=158328rank=89600 of ranks=158328rank=89700 of ranks=158328rank=89800 of ranks=158328rank=89900 of ranks=158328rank=90000 of ranks=158328rank=90100 of ranks=158328rank=90200 of ranks=158328rank=90300 of ranks=158328rank=90400 of ranks=158328rank=90500 of ranks=158328rank=90600 of ranks=158328rank=90700 of ranks=158328rank=90800 of ranks=158328rank=90900 of ranks=158328rank=91000 of ranks=158328rank=91100 of ranks=158328rank=91200 of ranks=158328rank=91300 of ranks=158328rank=91400 of ranks=158328rank=91500 of ranks=158328rank=91600 of ranks=158328rank=91700 of ranks=158328rank=91800 of ranks=158328rank=91900 of ranks=158328rank=92000 of ranks=158328rank=92100 of ranks=158328rank=92200 of ranks=158328rank=92300 of ranks=158328rank=92400 of ranks=158328rank=92500 of ranks=158328rank=92600 of ranks=158328rank=92700 of ranks=158328rank=92800 of ranks=158328rank=92900 of ranks=158328rank=93000 of ranks=158328rank=93100 of ranks=158328rank=93200 of ranks=158328rank=93300 of ranks=158328rank=93400 of ranks=158328rank=93500 of ranks=158328rank=93600 of ranks=158328rank=93700 of ranks=158328rank=93800 of ranks=158328rank=93900 of ranks=158328rank=94000 of ranks=158328rank=94100 of ranks=158328rank=94200 of ranks=158328rank=94300 of ranks=158328rank=94400 of ranks=158328rank=94500 of ranks=158328rank=94600 of ranks=158328rank=94700 of ranks=158328rank=94800 of ranks=158328rank=94900 of ranks=158328rank=95000 of ranks=158328rank=95100 of ranks=158328rank=95200 of ranks=158328rank=95300 of ranks=158328rank=95400 of ranks=158328rank=95500 of ranks=158328rank=95600 of ranks=158328rank=95700 of ranks=158328rank=95800 of ranks=158328rank=95900 of ranks=158328rank=96000 of ranks=158328rank=96100 of ranks=158328rank=96200 of ranks=158328rank=96300 of ranks=158328rank=96400 of ranks=158328rank=96500 of ranks=158328rank=96600 of ranks=158328rank=96700 of ranks=158328rank=96800 of ranks=158328rank=96900 of ranks=158328rank=97000 of ranks=158328rank=97100 of ranks=158328rank=97200 of ranks=158328rank=97300 of ranks=158328rank=97400 of ranks=158328rank=97500 of ranks=158328rank=97600 of ranks=158328rank=97700 of ranks=158328rank=97800 of ranks=158328rank=97900 of ranks=158328rank=98000 of ranks=158328rank=98100 of ranks=158328rank=98200 of ranks=158328rank=98300 of ranks=158328rank=98400 of ranks=158328rank=98500 of ranks=158328rank=98600 of ranks=158328rank=98700 of ranks=158328rank=98800 of ranks=158328rank=98900 of ranks=158328rank=99000 of ranks=158328rank=99100 of ranks=158328rank=99200 of ranks=158328rank=99300 of ranks=158328rank=99400 of ranks=158328rank=99500 of ranks=158328rank=99600 of ranks=158328rank=99700 of ranks=158328rank=99800 of ranks=158328rank=99900 of ranks=158328rank=100000 of ranks=158328rank=100100 of ranks=158328rank=100200 of ranks=158328rank=100300 of ranks=158328rank=100400 of ranks=158328rank=100500 of ranks=158328rank=100600 of ranks=158328rank=100700 of ranks=158328rank=100800 of ranks=158328rank=100900 of ranks=158328rank=101000 of ranks=158328rank=101100 of ranks=158328rank=101200 of ranks=158328rank=101300 of ranks=158328rank=101400 of ranks=158328rank=101500 of ranks=158328rank=101600 of ranks=158328rank=101700 of ranks=158328rank=101800 of ranks=158328rank=101900 of ranks=158328rank=102000 of ranks=158328rank=102100 of ranks=158328rank=102200 of ranks=158328rank=102300 of ranks=158328rank=102400 of ranks=158328rank=102500 of ranks=158328rank=102600 of ranks=158328rank=102700 of ranks=158328rank=102800 of ranks=158328rank=102900 of ranks=158328rank=103000 of ranks=158328rank=103100 of ranks=158328rank=103200 of ranks=158328rank=103300 of ranks=158328rank=103400 of ranks=158328rank=103500 of ranks=158328rank=103600 of ranks=158328rank=103700 of ranks=158328rank=103800 of ranks=158328rank=103900 of ranks=158328rank=104000 of ranks=158328rank=104100 of ranks=158328rank=104200 of ranks=158328rank=104300 of ranks=158328rank=104400 of ranks=158328rank=104500 of ranks=158328rank=104600 of ranks=158328rank=104700 of ranks=158328rank=104800 of ranks=158328rank=104900 of ranks=158328rank=105000 of ranks=158328rank=105100 of ranks=158328rank=105200 of ranks=158328rank=105300 of ranks=158328rank=105400 of ranks=158328rank=105500 of ranks=158328rank=105600 of ranks=158328rank=105700 of ranks=158328rank=105800 of ranks=158328rank=105900 of ranks=158328rank=106000 of ranks=158328rank=106100 of ranks=158328rank=106200 of ranks=158328rank=106300 of ranks=158328rank=106400 of ranks=158328rank=106500 of ranks=158328rank=106600 of ranks=158328rank=106700 of ranks=158328rank=106800 of ranks=158328rank=106900 of ranks=158328rank=107000 of ranks=158328rank=107100 of ranks=158328rank=107200 of ranks=158328rank=107300 of ranks=158328rank=107400 of ranks=158328rank=107500 of ranks=158328rank=107600 of ranks=158328rank=107700 of ranks=158328rank=107800 of ranks=158328rank=107900 of ranks=158328rank=108000 of ranks=158328rank=108100 of ranks=158328rank=108200 of ranks=158328rank=108300 of ranks=158328rank=108400 of ranks=158328rank=108500 of ranks=158328rank=108600 of ranks=158328rank=108700 of ranks=158328rank=108800 of ranks=158328rank=108900 of ranks=158328rank=109000 of ranks=158328rank=109100 of ranks=158328rank=109200 of ranks=158328rank=109300 of ranks=158328rank=109400 of ranks=158328rank=109500 of ranks=158328rank=109600 of ranks=158328rank=109700 of ranks=158328rank=109800 of ranks=158328rank=109900 of ranks=158328rank=110000 of ranks=158328rank=110100 of ranks=158328rank=110200 of ranks=158328rank=110300 of ranks=158328rank=110400 of ranks=158328rank=110500 of ranks=158328rank=110600 of ranks=158328rank=110700 of ranks=158328rank=110800 of ranks=158328rank=110900 of ranks=158328rank=111000 of ranks=158328rank=111100 of ranks=158328rank=111200 of ranks=158328rank=111300 of ranks=158328rank=111400 of ranks=158328rank=111500 of ranks=158328rank=111600 of ranks=158328rank=111700 of ranks=158328rank=111800 of ranks=158328rank=111900 of ranks=158328rank=112000 of ranks=158328rank=112100 of ranks=158328rank=112200 of ranks=158328rank=112300 of ranks=158328rank=112400 of ranks=158328rank=112500 of ranks=158328rank=112600 of ranks=158328rank=112700 of ranks=158328rank=112800 of ranks=158328rank=112900 of ranks=158328rank=113000 of ranks=158328rank=113100 of ranks=158328rank=113200 of ranks=158328rank=113300 of ranks=158328rank=113400 of ranks=158328rank=113500 of ranks=158328rank=113600 of ranks=158328rank=113700 of ranks=158328rank=113800 of ranks=158328rank=113900 of ranks=158328rank=114000 of ranks=158328rank=114100 of ranks=158328rank=114200 of ranks=158328rank=114300 of ranks=158328rank=114400 of ranks=158328rank=114500 of ranks=158328rank=114600 of ranks=158328rank=114700 of ranks=158328rank=114800 of ranks=158328rank=114900 of ranks=158328rank=115000 of ranks=158328rank=115100 of ranks=158328rank=115200 of ranks=158328rank=115300 of ranks=158328rank=115400 of ranks=158328rank=115500 of ranks=158328rank=115600 of ranks=158328rank=115700 of ranks=158328rank=115800 of ranks=158328rank=115900 of ranks=158328rank=116000 of ranks=158328rank=116100 of ranks=158328rank=116200 of ranks=158328rank=116300 of ranks=158328rank=116400 of ranks=158328rank=116500 of ranks=158328rank=116600 of ranks=158328rank=116700 of ranks=158328rank=116800 of ranks=158328rank=116900 of ranks=158328rank=117000 of ranks=158328rank=117100 of ranks=158328rank=117200 of ranks=158328rank=117300 of ranks=158328rank=117400 of ranks=158328rank=117500 of ranks=158328rank=117600 of ranks=158328rank=117700 of ranks=158328rank=117800 of ranks=158328rank=117900 of ranks=158328rank=118000 of ranks=158328rank=118100 of ranks=158328rank=118200 of ranks=158328rank=118300 of ranks=158328rank=118400 of ranks=158328rank=118500 of ranks=158328rank=118600 of ranks=158328rank=118700 of ranks=158328rank=118800 of ranks=158328rank=118900 of ranks=158328rank=119000 of ranks=158328rank=119100 of ranks=158328rank=119200 of ranks=158328rank=119300 of ranks=158328rank=119400 of ranks=158328rank=119500 of ranks=158328rank=119600 of ranks=158328rank=119700 of ranks=158328rank=119800 of ranks=158328rank=119900 of ranks=158328rank=120000 of ranks=158328rank=120100 of ranks=158328rank=120200 of ranks=158328rank=120300 of ranks=158328rank=120400 of ranks=158328rank=120500 of ranks=158328rank=120600 of ranks=158328rank=120700 of ranks=158328rank=120800 of ranks=158328rank=120900 of ranks=158328rank=121000 of ranks=158328rank=121100 of ranks=158328rank=121200 of ranks=158328rank=121300 of ranks=158328rank=121400 of ranks=158328rank=121500 of ranks=158328rank=121600 of ranks=158328rank=121700 of ranks=158328rank=121800 of ranks=158328rank=121900 of ranks=158328rank=122000 of ranks=158328rank=122100 of ranks=158328rank=122200 of ranks=158328rank=122300 of ranks=158328rank=122400 of ranks=158328rank=122500 of ranks=158328rank=122600 of ranks=158328rank=122700 of ranks=158328rank=122800 of ranks=158328rank=122900 of ranks=158328rank=123000 of ranks=158328rank=123100 of ranks=158328rank=123200 of ranks=158328rank=123300 of ranks=158328rank=123400 of ranks=158328rank=123500 of ranks=158328rank=123600 of ranks=158328rank=123700 of ranks=158328rank=123800 of ranks=158328rank=123900 of ranks=158328rank=124000 of ranks=158328rank=124100 of ranks=158328rank=124200 of ranks=158328rank=124300 of ranks=158328rank=124400 of ranks=158328rank=124500 of ranks=158328rank=124600 of ranks=158328rank=124700 of ranks=158328rank=124800 of ranks=158328rank=124900 of ranks=158328rank=125000 of ranks=158328rank=125100 of ranks=158328rank=125200 of ranks=158328rank=125300 of ranks=158328rank=125400 of ranks=158328rank=125500 of ranks=158328rank=125600 of ranks=158328rank=125700 of ranks=158328rank=125800 of ranks=158328rank=125900 of ranks=158328rank=126000 of ranks=158328rank=126100 of ranks=158328rank=126200 of ranks=158328rank=126300 of ranks=158328rank=126400 of ranks=158328rank=126500 of ranks=158328rank=126600 of ranks=158328rank=126700 of ranks=158328rank=126800 of ranks=158328rank=126900 of ranks=158328rank=127000 of ranks=158328rank=127100 of ranks=158328rank=127200 of ranks=158328rank=127300 of ranks=158328rank=127400 of ranks=158328rank=127500 of ranks=158328rank=127600 of ranks=158328rank=127700 of ranks=158328rank=127800 of ranks=158328rank=127900 of ranks=158328rank=128000 of ranks=158328rank=128100 of ranks=158328rank=128200 of ranks=158328rank=128300 of ranks=158328rank=128400 of ranks=158328rank=128500 of ranks=158328rank=128600 of ranks=158328rank=128700 of ranks=158328rank=128800 of ranks=158328rank=128900 of ranks=158328rank=129000 of ranks=158328rank=129100 of ranks=158328rank=129200 of ranks=158328rank=129300 of ranks=158328rank=129400 of ranks=158328rank=129500 of ranks=158328rank=129600 of ranks=158328rank=129700 of ranks=158328rank=129800 of ranks=158328rank=129900 of ranks=158328rank=130000 of ranks=158328rank=130100 of ranks=158328rank=130200 of ranks=158328rank=130300 of ranks=158328rank=130400 of ranks=158328rank=130500 of ranks=158328rank=130600 of ranks=158328rank=130700 of ranks=158328rank=130800 of ranks=158328rank=130900 of ranks=158328rank=131000 of ranks=158328rank=131100 of ranks=158328rank=131200 of ranks=158328rank=131300 of ranks=158328rank=131400 of ranks=158328rank=131500 of ranks=158328rank=131600 of ranks=158328rank=131700 of ranks=158328rank=131800 of ranks=158328rank=131900 of ranks=158328rank=132000 of ranks=158328rank=132100 of ranks=158328rank=132200 of ranks=158328rank=132300 of ranks=158328rank=132400 of ranks=158328rank=132500 of ranks=158328rank=132600 of ranks=158328rank=132700 of ranks=158328rank=132800 of ranks=158328rank=132900 of ranks=158328rank=133000 of ranks=158328rank=133100 of ranks=158328rank=133200 of ranks=158328rank=133300 of ranks=158328rank=133400 of ranks=158328rank=133500 of ranks=158328rank=133600 of ranks=158328rank=133700 of ranks=158328rank=133800 of ranks=158328rank=133900 of ranks=158328rank=134000 of ranks=158328rank=134100 of ranks=158328rank=134200 of ranks=158328rank=134300 of ranks=158328rank=134400 of ranks=158328rank=134500 of ranks=158328rank=134600 of ranks=158328rank=134700 of ranks=158328rank=134800 of ranks=158328rank=134900 of ranks=158328rank=135000 of ranks=158328rank=135100 of ranks=158328rank=135200 of ranks=158328rank=135300 of ranks=158328rank=135400 of ranks=158328rank=135500 of ranks=158328rank=135600 of ranks=158328rank=135700 of ranks=158328rank=135800 of ranks=158328rank=135900 of ranks=158328rank=136000 of ranks=158328rank=136100 of ranks=158328rank=136200 of ranks=158328rank=136300 of ranks=158328rank=136400 of ranks=158328rank=136500 of ranks=158328rank=136600 of ranks=158328rank=136700 of ranks=158328rank=136800 of ranks=158328rank=136900 of ranks=158328rank=137000 of ranks=158328rank=137100 of ranks=158328rank=137200 of ranks=158328rank=137300 of ranks=158328rank=137400 of ranks=158328rank=137500 of ranks=158328rank=137600 of ranks=158328rank=137700 of ranks=158328rank=137800 of ranks=158328rank=137900 of ranks=158328rank=138000 of ranks=158328rank=138100 of ranks=158328rank=138200 of ranks=158328rank=138300 of ranks=158328rank=138400 of ranks=158328rank=138500 of ranks=158328rank=138600 of ranks=158328rank=138700 of ranks=158328rank=138800 of ranks=158328rank=138900 of ranks=158328rank=139000 of ranks=158328rank=139100 of ranks=158328rank=139200 of ranks=158328rank=139300 of ranks=158328rank=139400 of ranks=158328rank=139500 of ranks=158328rank=139600 of ranks=158328rank=139700 of ranks=158328rank=139800 of ranks=158328rank=139900 of ranks=158328rank=140000 of ranks=158328rank=140100 of ranks=158328rank=140200 of ranks=158328rank=140300 of ranks=158328rank=140400 of ranks=158328rank=140500 of ranks=158328rank=140600 of ranks=158328rank=140700 of ranks=158328rank=140800 of ranks=158328rank=140900 of ranks=158328rank=141000 of ranks=158328rank=141100 of ranks=158328rank=141200 of ranks=158328rank=141300 of ranks=158328rank=141400 of ranks=158328rank=141500 of ranks=158328rank=141600 of ranks=158328rank=141700 of ranks=158328rank=141800 of ranks=158328rank=141900 of ranks=158328rank=142000 of ranks=158328rank=142100 of ranks=158328rank=142200 of ranks=158328rank=142300 of ranks=158328rank=142400 of ranks=158328rank=142500 of ranks=158328rank=142600 of ranks=158328rank=142700 of ranks=158328rank=142800 of ranks=158328rank=142900 of ranks=158328rank=143000 of ranks=158328rank=143100 of ranks=158328rank=143200 of ranks=158328rank=143300 of ranks=158328rank=143400 of ranks=158328rank=143500 of ranks=158328rank=143600 of ranks=158328rank=143700 of ranks=158328rank=143800 of ranks=158328rank=143900 of ranks=158328rank=144000 of ranks=158328rank=144100 of ranks=158328rank=144200 of ranks=158328rank=144300 of ranks=158328rank=144400 of ranks=158328rank=144500 of ranks=158328rank=144600 of ranks=158328rank=144700 of ranks=158328rank=144800 of ranks=158328rank=144900 of ranks=158328rank=145000 of ranks=158328rank=145100 of ranks=158328rank=145200 of ranks=158328rank=145300 of ranks=158328rank=145400 of ranks=158328rank=145500 of ranks=158328rank=145600 of ranks=158328rank=145700 of ranks=158328rank=145800 of ranks=158328rank=145900 of ranks=158328rank=146000 of ranks=158328rank=146100 of ranks=158328rank=146200 of ranks=158328rank=146300 of ranks=158328rank=146400 of ranks=158328rank=146500 of ranks=158328rank=146600 of ranks=158328rank=146700 of ranks=158328rank=146800 of ranks=158328rank=146900 of ranks=158328rank=147000 of ranks=158328rank=147100 of ranks=158328rank=147200 of ranks=158328rank=147300 of ranks=158328rank=147400 of ranks=158328rank=147500 of ranks=158328rank=147600 of ranks=158328rank=147700 of ranks=158328rank=147800 of ranks=158328rank=147900 of ranks=158328rank=148000 of ranks=158328rank=148100 of ranks=158328rank=148200 of ranks=158328rank=148300 of ranks=158328rank=148400 of ranks=158328rank=148500 of ranks=158328rank=148600 of ranks=158328rank=148700 of ranks=158328rank=148800 of ranks=158328rank=148900 of ranks=158328rank=149000 of ranks=158328rank=149100 of ranks=158328rank=149200 of ranks=158328rank=149300 of ranks=158328rank=149400 of ranks=158328rank=149500 of ranks=158328rank=149600 of ranks=158328rank=149700 of ranks=158328rank=149800 of ranks=158328rank=149900 of ranks=158328rank=150000 of ranks=158328rank=150100 of ranks=158328rank=150200 of ranks=158328rank=150300 of ranks=158328rank=150400 of ranks=158328rank=150500 of ranks=158328rank=150600 of ranks=158328rank=150700 of ranks=158328rank=150800 of ranks=158328rank=150900 of ranks=158328rank=151000 of ranks=158328rank=151100 of ranks=158328rank=151200 of ranks=158328rank=151300 of ranks=158328rank=151400 of ranks=158328rank=151500 of ranks=158328rank=151600 of ranks=158328rank=151700 of ranks=158328rank=151800 of ranks=158328rank=151900 of ranks=158328rank=152000 of ranks=158328rank=152100 of ranks=158328rank=152200 of ranks=158328rank=152300 of ranks=158328rank=152400 of ranks=158328rank=152500 of ranks=158328rank=152600 of ranks=158328rank=152700 of ranks=158328rank=152800 of ranks=158328rank=152900 of ranks=158328rank=153000 of ranks=158328rank=153100 of ranks=158328rank=153200 of ranks=158328rank=153300 of ranks=158328rank=153400 of ranks=158328rank=153500 of ranks=158328rank=153600 of ranks=158328rank=153700 of ranks=158328rank=153800 of ranks=158328rank=153900 of ranks=158328rank=154000 of ranks=158328rank=154100 of ranks=158328rank=154200 of ranks=158328rank=154300 of ranks=158328rank=154400 of ranks=158328rank=154500 of ranks=158328rank=154600 of ranks=158328rank=154700 of ranks=158328rank=154800 of ranks=158328rank=154900 of ranks=158328rank=155000 of ranks=158328rank=155100 of ranks=158328rank=155200 of ranks=158328rank=155300 of ranks=158328rank=155400 of ranks=158328rank=155500 of ranks=158328rank=155600 of ranks=158328rank=155700 of ranks=158328rank=155800 of ranks=158328rank=155900 of ranks=158328rank=156000 of ranks=158328rank=156100 of ranks=158328rank=156200 of ranks=158328rank=156300 of ranks=158328rank=156400 of ranks=158328rank=156500 of ranks=158328rank=156600 of ranks=158328rank=156700 of ranks=158328rank=156800 of ranks=158328rank=156900 of ranks=158328rank=157000 of ranks=158328rank=157100 of ranks=158328rank=157200 of ranks=158328rank=157300 of ranks=158328rank=157400 of ranks=158328rank=157500 of ranks=158328rank=157600 of ranks=158328rank=157700 of ranks=158328rank=157800 of ranks=158328rank=157900 of ranks=158328rank=158000 of ranks=158328rank=158100 of ranks=158328rank=158200 of ranks=158328rank=158300 of ranks=158328

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              92.9914    482   8769     16    498           67.2832
   1 car                    98.0114  49968  49540    348  50316           73.1188
   2 truck                  93.9252   1805  16055     20   1825           59.7961
   3 bus                    85.8422    356   6542     10    366           63.1605
   4 pedestrian             93.2289   4124  20687    135   4259           62.4676

for conf_thresh=0.25, precision=0.84, recall=0.95, F1 score=0.89
for conf_thresh=0.25, TP=54208, FP=10414, FN=3056, average IoU=71.78%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=92.80%
Total detection time: 138 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
New best mAP, saving weights!
Saving weights to /workspace/.cache/splits/combined_best.weights
4655: loss=2.929, avg loss=3.877, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 297920 images, time remaining=4.1 hours
4656: loss=3.745, avg loss=3.864, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 297984 images, time remaining=4.1 hours
4657: loss=3.125, avg loss=3.790, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 298048 images, time remaining=4.1 hours
4658: loss=3.458, avg loss=3.757, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 298112 images, time remaining=4.1 hours
4659: loss=4.044, avg loss=3.785, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 298176 images, time remaining=4.1 hours
4660: loss=3.991, avg loss=3.806, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.9 seconds, 298240 images, time remaining=4.1 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4661: loss=4.338, avg loss=3.859, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=4.4 seconds, 298304 images, time remaining=4.1 hours
4662: loss=3.554, avg loss=3.829, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 298368 images, time remaining=4 hours
4663: loss=3.086, avg loss=3.754, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 298432 images, time remaining=4 hours
4664: loss=4.464, avg loss=3.825, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 298496 images, time remaining=4 hours
4665: loss=3.858, avg loss=3.829, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=4.4 seconds, 298560 images, time remaining=4 hours
4666: loss=3.289, avg loss=3.775, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=4.5 seconds, 298624 images, time remaining=4 hours
4667: loss=3.466, avg loss=3.744, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 298688 images, time remaining=4 hours
4668: loss=3.766, avg loss=3.746, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 298752 images, time remaining=4 hours
4669: loss=4.044, avg loss=3.776, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 298816 images, time remaining=4 hours
4670: loss=3.327, avg loss=3.731, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 298880 images, time remaining=4 hours
Resizing, random_coef=1.40, batch=4, 896x672
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b545400000
4671: loss=3.842, avg loss=3.742, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 298944 images, time remaining=4 hours
4672: loss=3.078, avg loss=3.676, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 299008 images, time remaining=4 hours
4673: loss=4.567, avg loss=3.765, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 299072 images, time remaining=4 hours
4674: loss=3.081, avg loss=3.696, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 299136 images, time remaining=4 hours
4675: loss=3.842, avg loss=3.711, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 299200 images, time remaining=4 hours
4676: loss=2.863, avg loss=3.626, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=2.5 seconds, 299264 images, time remaining=4 hours
4677: loss=3.802, avg loss=3.644, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 299328 images, time remaining=4 hours
4678: loss=3.354, avg loss=3.615, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 299392 images, time remaining=4 hours
4679: loss=4.086, avg loss=3.662, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 299456 images, time remaining=4 hours
4680: loss=3.178, avg loss=3.613, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 299520 images, time remaining=4 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b545400000
4681: loss=3.497, avg loss=3.602, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 299584 images, time remaining=4 hours
4682: loss=4.164, avg loss=3.658, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 299648 images, time remaining=4 hours
4683: loss=4.749, avg loss=3.767, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.5 seconds, 299712 images, time remaining=4 hours
4684: loss=3.318, avg loss=3.722, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 299776 images, time remaining=4 hours
4685: loss=3.005, avg loss=3.650, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 299840 images, time remaining=4 hours
4686: loss=3.216, avg loss=3.607, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.0 seconds, train=2.4 seconds, 299904 images, time remaining=4 hours
4687: loss=3.174, avg loss=3.564, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 299968 images, time remaining=4 hours
4688: loss=3.284, avg loss=3.536, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 300032 images, time remaining=4 hours
4689: loss=3.321, avg loss=3.514, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 300096 images, time remaining=4 hours
4690: loss=3.591, avg loss=3.522, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 300160 images, time remaining=4 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b739600000
4691: loss=3.622, avg loss=3.532, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 300224 images, time remaining=4 hours
4692: loss=3.970, avg loss=3.576, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 300288 images, time remaining=4 hours
4693: loss=4.171, avg loss=3.635, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 300352 images, time remaining=4 hours
4694: loss=4.081, avg loss=3.680, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 300416 images, time remaining=4 hours
4695: loss=3.312, avg loss=3.643, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 300480 images, time remaining=4 hours
4696: loss=2.538, avg loss=3.533, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 300544 images, time remaining=4 hours
4697: loss=4.474, avg loss=3.627, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 300608 images, time remaining=4 hours
4698: loss=3.167, avg loss=3.581, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 300672 images, time remaining=4 hours
4699: loss=3.598, avg loss=3.582, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.1 seconds, train=1.9 seconds, 300736 images, time remaining=4 hours
4700: loss=3.673, avg loss=3.591, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.1 seconds, train=1.9 seconds, 300800 images, time remaining=4 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4701: loss=4.198, avg loss=3.652, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=5.0 seconds, 300864 images, time remaining=4 hours
4702: loss=5.513, avg loss=3.838, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=5.0 seconds, 300928 images, time remaining=4 hours
4703: loss=3.833, avg loss=3.838, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 300992 images, time remaining=4 hours
4704: loss=4.138, avg loss=3.868, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 301056 images, time remaining=4 hours
4705: loss=3.827, avg loss=3.864, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.3 seconds, train=4.9 seconds, 301120 images, time remaining=4 hours
4706: loss=3.749, avg loss=3.852, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 301184 images, time remaining=4 hours
4707: loss=3.950, avg loss=3.862, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 301248 images, time remaining=4 hours
4708: loss=2.686, avg loss=3.744, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 301312 images, time remaining=4 hours
4709: loss=3.403, avg loss=3.710, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 301376 images, time remaining=4 hours
4710: loss=3.381, avg loss=3.677, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.2 seconds, train=4.8 seconds, 301440 images, time remaining=4 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4711: loss=3.801, avg loss=3.690, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 301504 images, time remaining=4 hours
4712: loss=3.901, avg loss=3.711, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 301568 images, time remaining=4 hours
4713: loss=3.504, avg loss=3.690, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=4.7 seconds, 301632 images, time remaining=4 hours
4714: loss=3.418, avg loss=3.663, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.7 seconds, train=4.6 seconds, 301696 images, time remaining=4 hours
4715: loss=4.046, avg loss=3.701, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.3 seconds, train=4.7 seconds, 301760 images, time remaining=4 hours
4716: loss=3.460, avg loss=3.677, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.1 seconds, train=4.6 seconds, 301824 images, time remaining=4 hours
4717: loss=3.226, avg loss=3.632, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.7 seconds, train=4.7 seconds, 301888 images, time remaining=4 hours
4718: loss=3.856, avg loss=3.654, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.1 seconds, train=4.7 seconds, 301952 images, time remaining=4 hours
4719: loss=3.684, avg loss=3.657, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=4.6 seconds, 302016 images, time remaining=4 hours
4720: loss=3.575, avg loss=3.649, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.3 seconds, train=4.7 seconds, 302080 images, time remaining=4 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b6f0c00000
4721: loss=4.149, avg loss=3.699, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 302144 images, time remaining=4 hours
4722: loss=4.198, avg loss=3.749, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 302208 images, time remaining=4 hours
4723: loss=3.191, avg loss=3.693, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 302272 images, time remaining=4 hours
4724: loss=3.623, avg loss=3.686, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 302336 images, time remaining=4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4725: loss=3.116, avg loss=3.629, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=3.6 seconds, train=2.1 seconds, 302400 images, time remaining=4 hours
4726: loss=3.795, avg loss=3.646, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 302464 images, time remaining=4 hours
4727: loss=4.590, avg loss=3.740, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 302528 images, time remaining=4 hours
4728: loss=3.387, avg loss=3.705, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 302592 images, time remaining=4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4729: loss=3.840, avg loss=3.718, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.4 seconds, train=2.1 seconds, 302656 images, time remaining=4 hours
4730: loss=3.520, avg loss=3.698, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 302720 images, time remaining=4 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2e4000000
4731: loss=3.546, avg loss=3.683, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 302784 images, time remaining=4 hours
4732: loss=3.177, avg loss=3.633, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 302848 images, time remaining=4 hours
4733: loss=3.489, avg loss=3.618, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 302912 images, time remaining=4 hours
4734: loss=3.171, avg loss=3.573, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 302976 images, time remaining=4 hours
4735: loss=2.586, avg loss=3.475, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 303040 images, time remaining=3.9 hours
4736: loss=3.354, avg loss=3.463, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 303104 images, time remaining=3.9 hours
4737: loss=3.831, avg loss=3.499, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.9 seconds, 303168 images, time remaining=3.9 hours
4738: loss=4.138, avg loss=3.563, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 303232 images, time remaining=3.9 hours
4739: loss=3.199, avg loss=3.527, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=2.9 seconds, 303296 images, time remaining=3.9 hours
4740: loss=3.928, avg loss=3.567, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 303360 images, time remaining=3.9 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b4e2e00000
4741: loss=2.950, avg loss=3.505, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 303424 images, time remaining=3.9 hours
4742: loss=3.587, avg loss=3.513, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 303488 images, time remaining=3.9 hours
4743: loss=3.325, avg loss=3.495, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 303552 images, time remaining=3.9 hours
4744: loss=3.759, avg loss=3.521, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 303616 images, time remaining=3.9 hours
4745: loss=3.411, avg loss=3.510, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 303680 images, time remaining=3.9 hours
4746: loss=3.197, avg loss=3.479, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 303744 images, time remaining=3.9 hours
4747: loss=3.234, avg loss=3.454, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 303808 images, time remaining=3.9 hours
4748: loss=3.615, avg loss=3.470, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 303872 images, time remaining=3.9 hours
4749: loss=3.041, avg loss=3.428, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 303936 images, time remaining=3.9 hours
4750: loss=3.129, avg loss=3.398, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 304000 images, time remaining=3.9 hours
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14bf40000000
4751: loss=4.071, avg loss=3.465, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 304064 images, time remaining=3.9 hours
4752: loss=2.866, avg loss=3.405, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 304128 images, time remaining=3.9 hours
4753: loss=3.489, avg loss=3.413, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 304192 images, time remaining=3.9 hours
4754: loss=3.300, avg loss=3.402, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 304256 images, time remaining=3.9 hours
4755: loss=2.947, avg loss=3.357, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 304320 images, time remaining=3.9 hours
4756: loss=3.557, avg loss=3.377, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 304384 images, time remaining=3.9 hours
4757: loss=2.821, avg loss=3.321, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 304448 images, time remaining=3.9 hours
4758: loss=3.000, avg loss=3.289, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 304512 images, time remaining=3.9 hours
4759: loss=2.598, avg loss=3.220, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 304576 images, time remaining=3.9 hours
4760: loss=3.331, avg loss=3.231, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 304640 images, time remaining=3.9 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b783400000
4761: loss=2.805, avg loss=3.188, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 304704 images, time remaining=3.9 hours
4762: loss=3.132, avg loss=3.183, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 304768 images, time remaining=3.9 hours
4763: loss=2.445, avg loss=3.109, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 304832 images, time remaining=3.9 hours
4764: loss=2.476, avg loss=3.046, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 304896 images, time remaining=3.9 hours
4765: loss=3.618, avg loss=3.103, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 304960 images, time remaining=3.9 hours
4766: loss=2.995, avg loss=3.092, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.4 seconds, 305024 images, time remaining=3.9 hours
4767: loss=2.966, avg loss=3.079, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 305088 images, time remaining=3.9 hours
4768: loss=3.412, avg loss=3.113, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 305152 images, time remaining=3.9 hours
4769: loss=3.223, avg loss=3.124, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 305216 images, time remaining=3.9 hours
4770: loss=3.406, avg loss=3.152, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 305280 images, time remaining=3.9 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b783400000
4771: loss=3.501, avg loss=3.187, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 305344 images, time remaining=3.9 hours
4772: loss=3.359, avg loss=3.204, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=2.4 seconds, 305408 images, time remaining=3.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4773: loss=2.623, avg loss=3.146, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.6 seconds, train=2.3 seconds, 305472 images, time remaining=3.9 hours
4774: loss=3.203, avg loss=3.152, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.4 seconds, 305536 images, time remaining=3.9 hours
4775: loss=3.205, avg loss=3.157, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 305600 images, time remaining=3.9 hours
4776: loss=2.791, avg loss=3.121, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 305664 images, time remaining=3.9 hours
4777: loss=3.408, avg loss=3.149, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 305728 images, time remaining=3.9 hours
4778: loss=2.441, avg loss=3.078, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 305792 images, time remaining=3.9 hours
4779: loss=3.426, avg loss=3.113, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 305856 images, time remaining=3.9 hours
4780: loss=3.053, avg loss=3.107, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 305920 images, time remaining=3.9 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b783400000
4781: loss=2.693, avg loss=3.066, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.1 seconds, train=1.9 seconds, 305984 images, time remaining=3.9 hours
4782: loss=2.393, avg loss=2.998, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 306048 images, time remaining=3.9 hours
4783: loss=3.963, avg loss=3.095, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 306112 images, time remaining=3.9 hours
4784: loss=3.899, avg loss=3.175, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 306176 images, time remaining=3.9 hours
4785: loss=3.333, avg loss=3.191, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 306240 images, time remaining=3.9 hours
4786: loss=3.365, avg loss=3.208, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 306304 images, time remaining=3.9 hours
4787: loss=2.864, avg loss=3.174, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 306368 images, time remaining=3.9 hours
4788: loss=2.956, avg loss=3.152, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 306432 images, time remaining=3.9 hours
4789: loss=2.960, avg loss=3.133, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 306496 images, time remaining=3.9 hours
4790: loss=3.138, avg loss=3.133, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 306560 images, time remaining=3.9 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b7dca00000
4791: loss=2.986, avg loss=3.119, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 306624 images, time remaining=3.9 hours
4792: loss=3.001, avg loss=3.107, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 306688 images, time remaining=3.9 hours
4793: loss=2.970, avg loss=3.093, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 306752 images, time remaining=3.9 hours
4794: loss=3.209, avg loss=3.105, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 306816 images, time remaining=3.9 hours
4795: loss=2.885, avg loss=3.083, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 306880 images, time remaining=3.9 hours
4796: loss=3.124, avg loss=3.087, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 306944 images, time remaining=3.9 hours
4797: loss=2.542, avg loss=3.032, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 307008 images, time remaining=3.9 hours
4798: loss=3.087, avg loss=3.038, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 307072 images, time remaining=3.9 hours
4799: loss=2.851, avg loss=3.019, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 307136 images, time remaining=3.8 hours
4800: loss=2.944, avg loss=3.012, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 307200 images, time remaining=3.8 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b8b1a00000
4801: loss=3.157, avg loss=3.026, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 307264 images, time remaining=3.8 hours
4802: loss=2.916, avg loss=3.015, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 307328 images, time remaining=3.8 hours
4803: loss=3.349, avg loss=3.049, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 307392 images, time remaining=3.8 hours
4804: loss=2.375, avg loss=2.981, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 307456 images, time remaining=3.8 hours
4805: loss=3.004, avg loss=2.983, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 307520 images, time remaining=3.8 hours
4806: loss=3.227, avg loss=3.008, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 307584 images, time remaining=3.8 hours
4807: loss=3.144, avg loss=3.021, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 307648 images, time remaining=3.8 hours
4808: loss=3.317, avg loss=3.051, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=2.4 seconds, 307712 images, time remaining=3.8 hours
4809: loss=2.641, avg loss=3.010, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 307776 images, time remaining=3.8 hours
4810: loss=2.974, avg loss=3.006, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 307840 images, time remaining=3.8 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b8b1a00000
4811: loss=2.846, avg loss=2.990, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 307904 images, time remaining=3.8 hours
4812: loss=3.356, avg loss=3.027, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 307968 images, time remaining=3.8 hours
4813: loss=3.087, avg loss=3.033, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 308032 images, time remaining=3.8 hours
4814: loss=3.694, avg loss=3.099, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 308096 images, time remaining=3.8 hours
4815: loss=2.731, avg loss=3.062, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 308160 images, time remaining=3.8 hours
4816: loss=3.420, avg loss=3.098, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 308224 images, time remaining=3.8 hours
4817: loss=3.516, avg loss=3.140, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 308288 images, time remaining=3.8 hours
4818: loss=2.508, avg loss=3.077, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 308352 images, time remaining=3.8 hours
4819: loss=3.700, avg loss=3.139, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=2.4 seconds, 308416 images, time remaining=3.8 hours
4820: loss=2.605, avg loss=3.086, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 308480 images, time remaining=3.8 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b8b1a00000
4821: loss=2.491, avg loss=3.026, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 308544 images, time remaining=3.8 hours
4822: loss=3.539, avg loss=3.077, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 308608 images, time remaining=3.8 hours
4823: loss=2.890, avg loss=3.059, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 308672 images, time remaining=3.8 hours
4824: loss=2.946, avg loss=3.047, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=2.4 seconds, 308736 images, time remaining=3.8 hours
4825: loss=2.671, avg loss=3.010, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 308800 images, time remaining=3.8 hours
4826: loss=2.941, avg loss=3.003, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 308864 images, time remaining=3.8 hours
4827: loss=3.380, avg loss=3.041, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 308928 images, time remaining=3.8 hours
4828: loss=2.796, avg loss=3.016, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 308992 images, time remaining=3.8 hours
4829: loss=3.617, avg loss=3.076, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 309056 images, time remaining=3.8 hours
4830: loss=3.470, avg loss=3.116, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 309120 images, time remaining=3.8 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b8b1a00000
4831: loss=3.565, avg loss=3.161, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 309184 images, time remaining=3.8 hours
4832: loss=2.932, avg loss=3.138, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 309248 images, time remaining=3.8 hours
4833: loss=2.809, avg loss=3.105, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 309312 images, time remaining=3.8 hours
4834: loss=3.680, avg loss=3.162, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 309376 images, time remaining=3.8 hours
4835: loss=2.708, avg loss=3.117, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 309440 images, time remaining=3.8 hours
4836: loss=3.522, avg loss=3.157, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 309504 images, time remaining=3.8 hours
4837: loss=2.970, avg loss=3.139, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 309568 images, time remaining=3.8 hours
4838: loss=3.419, avg loss=3.167, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 309632 images, time remaining=3.8 hours
4839: loss=3.396, avg loss=3.190, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 309696 images, time remaining=3.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4840: loss=2.918, avg loss=3.162, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.5 seconds, train=2.1 seconds, 309760 images, time remaining=3.8 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4841: loss=4.709, avg loss=3.317, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 309824 images, time remaining=3.8 hours
4842: loss=4.324, avg loss=3.418, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.1 seconds, train=5.3 seconds, 309888 images, time remaining=3.8 hours
4843: loss=5.031, avg loss=3.579, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 309952 images, time remaining=3.8 hours
4844: loss=4.260, avg loss=3.647, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 310016 images, time remaining=3.8 hours
4845: loss=4.237, avg loss=3.706, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 310080 images, time remaining=3.8 hours
4846: loss=4.204, avg loss=3.756, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.8 seconds, train=5.2 seconds, 310144 images, time remaining=3.8 hours
4847: loss=3.906, avg loss=3.771, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.4 seconds, train=5.2 seconds, 310208 images, time remaining=3.8 hours
4848: loss=4.364, avg loss=3.830, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 310272 images, time remaining=3.8 hours
4849: loss=4.207, avg loss=3.868, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 310336 images, time remaining=3.8 hours
4850: loss=3.623, avg loss=3.843, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 310400 images, time remaining=3.8 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4851: loss=3.626, avg loss=3.822, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 310464 images, time remaining=3.8 hours
4852: loss=3.355, avg loss=3.775, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.3 seconds, train=4.3 seconds, 310528 images, time remaining=3.8 hours
4853: loss=3.944, avg loss=3.792, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=3.5 seconds, train=4.3 seconds, 310592 images, time remaining=3.8 hours
4854: loss=3.133, avg loss=3.726, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=4.4 seconds, 310656 images, time remaining=3.8 hours
4855: loss=3.337, avg loss=3.687, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 310720 images, time remaining=3.8 hours
4856: loss=3.331, avg loss=3.652, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 310784 images, time remaining=3.8 hours
4857: loss=3.842, avg loss=3.671, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.1 seconds, train=4.3 seconds, 310848 images, time remaining=3.8 hours
4858: loss=3.448, avg loss=3.648, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 310912 images, time remaining=3.8 hours
4859: loss=3.583, avg loss=3.642, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=4.4 seconds, 310976 images, time remaining=3.8 hours
4860: loss=3.448, avg loss=3.622, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=4.2 seconds, 311040 images, time remaining=3.8 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2e4000000
4861: loss=2.981, avg loss=3.558, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 311104 images, time remaining=3.8 hours
4862: loss=3.171, avg loss=3.520, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 311168 images, time remaining=3.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4863: loss=3.196, avg loss=3.487, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.7 seconds, train=2.5 seconds, 311232 images, time remaining=3.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
4864: loss=2.990, avg loss=3.437, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=3.5 seconds, train=2.7 seconds, 311296 images, time remaining=3.8 hours
4865: loss=3.190, avg loss=3.413, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.0 seconds, train=2.8 seconds, 311360 images, time remaining=3.8 hours
4866: loss=3.415, avg loss=3.413, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 311424 images, time remaining=3.8 hours
4867: loss=3.104, avg loss=3.382, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 311488 images, time remaining=3.8 hours
4868: loss=3.776, avg loss=3.421, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 311552 images, time remaining=3.8 hours
4869: loss=2.946, avg loss=3.374, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 311616 images, time remaining=3.8 hours
4870: loss=3.311, avg loss=3.368, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 311680 images, time remaining=3.8 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b6e5a00000
4871: loss=2.794, avg loss=3.310, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 311744 images, time remaining=3.7 hours
4872: loss=3.211, avg loss=3.300, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 311808 images, time remaining=3.7 hours
4873: loss=3.661, avg loss=3.336, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 311872 images, time remaining=3.7 hours
4874: loss=3.311, avg loss=3.334, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 311936 images, time remaining=3.7 hours
4875: loss=3.495, avg loss=3.350, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 312000 images, time remaining=3.7 hours
4876: loss=2.737, avg loss=3.289, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 312064 images, time remaining=3.7 hours
4877: loss=3.346, avg loss=3.294, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 312128 images, time remaining=3.7 hours
4878: loss=3.621, avg loss=3.327, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 312192 images, time remaining=3.7 hours
4879: loss=3.177, avg loss=3.312, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 312256 images, time remaining=3.7 hours
4880: loss=2.610, avg loss=3.242, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 312320 images, time remaining=3.7 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b739e00000
4881: loss=2.535, avg loss=3.171, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.1 seconds, train=2.3 seconds, 312384 images, time remaining=3.7 hours
4882: loss=3.415, avg loss=3.196, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 312448 images, time remaining=3.7 hours
4883: loss=2.898, avg loss=3.166, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 312512 images, time remaining=3.7 hours
4884: loss=3.134, avg loss=3.163, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=2.4 seconds, 312576 images, time remaining=3.7 hours
4885: loss=3.405, avg loss=3.187, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 312640 images, time remaining=3.7 hours
4886: loss=3.976, avg loss=3.266, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 312704 images, time remaining=3.7 hours
4887: loss=2.735, avg loss=3.213, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 312768 images, time remaining=3.7 hours
4888: loss=3.239, avg loss=3.215, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 312832 images, time remaining=3.7 hours
4889: loss=2.923, avg loss=3.186, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 312896 images, time remaining=3.7 hours
4890: loss=3.743, avg loss=3.242, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 312960 images, time remaining=3.7 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b872a00000
4891: loss=2.760, avg loss=3.194, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 313024 images, time remaining=3.7 hours
4892: loss=3.003, avg loss=3.175, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 313088 images, time remaining=3.7 hours
4893: loss=3.076, avg loss=3.165, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 313152 images, time remaining=3.7 hours
4894: loss=3.141, avg loss=3.162, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 313216 images, time remaining=3.7 hours
4895: loss=2.618, avg loss=3.108, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 313280 images, time remaining=3.7 hours
4896: loss=3.446, avg loss=3.142, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 313344 images, time remaining=3.7 hours
4897: loss=3.030, avg loss=3.131, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 313408 images, time remaining=3.7 hours
4898: loss=2.542, avg loss=3.072, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 313472 images, time remaining=3.7 hours
4899: loss=2.866, avg loss=3.051, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 313536 images, time remaining=3.7 hours
4900: loss=3.042, avg loss=3.050, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 313600 images, time remaining=3.7 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b4b4000000
4901: loss=2.987, avg loss=3.044, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 313664 images, time remaining=3.7 hours
4902: loss=3.941, avg loss=3.134, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 313728 images, time remaining=3.7 hours
4903: loss=2.948, avg loss=3.115, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.2 seconds, train=2.8 seconds, 313792 images, time remaining=3.7 hours
4904: loss=3.127, avg loss=3.116, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 313856 images, time remaining=3.7 hours
4905: loss=2.576, avg loss=3.062, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 313920 images, time remaining=3.7 hours
4906: loss=3.557, avg loss=3.112, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 313984 images, time remaining=3.7 hours
4907: loss=3.308, avg loss=3.131, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 314048 images, time remaining=3.7 hours
4908: loss=2.889, avg loss=3.107, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 314112 images, time remaining=3.7 hours
4909: loss=3.841, avg loss=3.181, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 314176 images, time remaining=3.7 hours
4910: loss=2.931, avg loss=3.156, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 314240 images, time remaining=3.7 hours
Resizing, random_coef=1.40, batch=4, 1024x768
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4911: loss=3.666, avg loss=3.207, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 314304 images, time remaining=3.7 hours
4912: loss=2.645, avg loss=3.150, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 314368 images, time remaining=3.7 hours
4913: loss=2.960, avg loss=3.131, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 314432 images, time remaining=3.7 hours
4914: loss=3.448, avg loss=3.163, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=4.0 seconds, 314496 images, time remaining=3.7 hours
4915: loss=2.787, avg loss=3.125, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 314560 images, time remaining=3.7 hours
4916: loss=3.429, avg loss=3.156, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 314624 images, time remaining=3.7 hours
4917: loss=2.938, avg loss=3.134, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=3.9 seconds, 314688 images, time remaining=3.7 hours
4918: loss=3.664, avg loss=3.187, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 314752 images, time remaining=3.7 hours
4919: loss=3.673, avg loss=3.236, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 314816 images, time remaining=3.7 hours
4920: loss=2.725, avg loss=3.185, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=3.8 seconds, 314880 images, time remaining=3.7 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b517000000
4921: loss=2.747, avg loss=3.141, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 314944 images, time remaining=3.7 hours
4922: loss=2.880, avg loss=3.115, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 315008 images, time remaining=3.7 hours
4923: loss=3.196, avg loss=3.123, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 315072 images, time remaining=3.7 hours
4924: loss=2.543, avg loss=3.065, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 315136 images, time remaining=3.7 hours
4925: loss=2.287, avg loss=2.987, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 315200 images, time remaining=3.7 hours
4926: loss=3.385, avg loss=3.027, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 315264 images, time remaining=3.7 hours
4927: loss=3.240, avg loss=3.048, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.8 seconds, 315328 images, time remaining=3.7 hours
4928: loss=3.813, avg loss=3.125, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 315392 images, time remaining=3.7 hours
4929: loss=3.337, avg loss=3.146, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.0 seconds, train=2.8 seconds, 315456 images, time remaining=3.7 hours
4930: loss=2.744, avg loss=3.106, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.2 seconds, train=2.8 seconds, 315520 images, time remaining=3.7 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b517000000
4931: loss=3.117, avg loss=3.107, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 315584 images, time remaining=3.7 hours
4932: loss=2.845, avg loss=3.081, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=2.1 seconds, 315648 images, time remaining=3.7 hours
4933: loss=2.751, avg loss=3.048, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 315712 images, time remaining=3.7 hours
4934: loss=2.506, avg loss=2.994, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 315776 images, time remaining=3.7 hours
4935: loss=2.475, avg loss=2.942, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 315840 images, time remaining=3.7 hours
4936: loss=3.203, avg loss=2.968, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 315904 images, time remaining=3.7 hours
4937: loss=3.236, avg loss=2.995, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 315968 images, time remaining=3.7 hours
4938: loss=3.128, avg loss=3.008, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.0 seconds, train=2.1 seconds, 316032 images, time remaining=3.7 hours
4939: loss=2.920, avg loss=2.999, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 316096 images, time remaining=3.7 hours
4940: loss=3.632, avg loss=3.062, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 316160 images, time remaining=3.6 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4941: loss=4.539, avg loss=3.210, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=3.6 seconds, train=5.9 seconds, 316224 images, time remaining=3.6 hours
4942: loss=4.991, avg loss=3.388, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 316288 images, time remaining=3.6 hours
4943: loss=4.892, avg loss=3.539, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.4 seconds, train=5.7 seconds, 316352 images, time remaining=3.6 hours
4944: loss=3.473, avg loss=3.532, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 316416 images, time remaining=3.6 hours
4945: loss=4.596, avg loss=3.638, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 316480 images, time remaining=3.6 hours
4946: loss=4.666, avg loss=3.741, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.0 seconds, train=5.7 seconds, 316544 images, time remaining=3.6 hours
4947: loss=4.876, avg loss=3.855, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 316608 images, time remaining=3.6 hours
4948: loss=4.330, avg loss=3.902, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 316672 images, time remaining=3.6 hours
4949: loss=4.680, avg loss=3.980, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.2 seconds, train=5.6 seconds, 316736 images, time remaining=3.6 hours
4950: loss=4.887, avg loss=4.071, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.2 seconds, train=5.7 seconds, 316800 images, time remaining=3.6 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b688000000
4951: loss=3.022, avg loss=3.966, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.4 seconds, 316864 images, time remaining=3.6 hours
4952: loss=3.760, avg loss=3.945, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 316928 images, time remaining=3.6 hours
4953: loss=3.688, avg loss=3.919, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 316992 images, time remaining=3.6 hours
4954: loss=2.654, avg loss=3.793, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 317056 images, time remaining=3.6 hours
4955: loss=3.480, avg loss=3.762, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 317120 images, time remaining=3.6 hours
4956: loss=2.795, avg loss=3.665, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=2.3 seconds, 317184 images, time remaining=3.6 hours
4957: loss=2.885, avg loss=3.587, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.4 seconds, 317248 images, time remaining=3.6 hours
4958: loss=4.027, avg loss=3.631, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 317312 images, time remaining=3.6 hours
4959: loss=3.406, avg loss=3.608, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 317376 images, time remaining=3.6 hours
4960: loss=4.089, avg loss=3.656, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 317440 images, time remaining=3.6 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4961: loss=6.506, avg loss=3.941, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 317504 images, time remaining=3.6 hours
4962: loss=4.664, avg loss=4.014, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 317568 images, time remaining=3.6 hours
4963: loss=4.064, avg loss=4.019, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.0 seconds, train=5.2 seconds, 317632 images, time remaining=3.6 hours
4964: loss=3.978, avg loss=4.015, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 317696 images, time remaining=3.6 hours
4965: loss=3.392, avg loss=3.952, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=3.0 seconds, train=5.3 seconds, 317760 images, time remaining=3.6 hours
4966: loss=3.720, avg loss=3.929, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 317824 images, time remaining=3.6 hours
4967: loss=4.059, avg loss=3.942, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 317888 images, time remaining=3.6 hours
4968: loss=4.400, avg loss=3.988, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.0 seconds, train=5.3 seconds, 317952 images, time remaining=3.6 hours
4969: loss=3.636, avg loss=3.953, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.1 seconds, train=5.2 seconds, 318016 images, time remaining=3.6 hours
4970: loss=5.554, avg loss=4.113, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 318080 images, time remaining=3.6 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b5ce000000
4971: loss=4.150, avg loss=4.117, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 318144 images, time remaining=3.6 hours
4972: loss=4.652, avg loss=4.170, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 318208 images, time remaining=3.6 hours
4973: loss=4.663, avg loss=4.219, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 318272 images, time remaining=3.6 hours
4974: loss=4.368, avg loss=4.234, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 318336 images, time remaining=3.6 hours
4975: loss=3.814, avg loss=4.192, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=2.1 seconds, 318400 images, time remaining=3.6 hours
4976: loss=4.140, avg loss=4.187, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.0 seconds, train=2.1 seconds, 318464 images, time remaining=3.6 hours
4977: loss=3.679, avg loss=4.136, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 318528 images, time remaining=3.6 hours
4978: loss=3.476, avg loss=4.070, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 318592 images, time remaining=3.6 hours
4979: loss=2.972, avg loss=3.960, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 318656 images, time remaining=3.6 hours
4980: loss=3.886, avg loss=3.953, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 318720 images, time remaining=3.6 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b8ab000000
4981: loss=4.756, avg loss=4.033, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 318784 images, time remaining=3.6 hours
4982: loss=4.347, avg loss=4.065, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 318848 images, time remaining=3.6 hours
4983: loss=3.448, avg loss=4.003, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 318912 images, time remaining=3.6 hours
4984: loss=3.637, avg loss=3.966, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 318976 images, time remaining=3.6 hours
4985: loss=3.283, avg loss=3.898, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 319040 images, time remaining=3.6 hours
4986: loss=2.812, avg loss=3.789, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 319104 images, time remaining=3.6 hours
4987: loss=3.564, avg loss=3.767, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 319168 images, time remaining=3.6 hours
4988: loss=3.690, avg loss=3.759, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 319232 images, time remaining=3.6 hours
4989: loss=3.915, avg loss=3.775, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 319296 images, time remaining=3.6 hours
4990: loss=3.205, avg loss=3.718, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 319360 images, time remaining=3.6 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
4991: loss=3.527, avg loss=3.699, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 319424 images, time remaining=3.6 hours
4992: loss=4.464, avg loss=3.775, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 319488 images, time remaining=3.6 hours
4993: loss=5.018, avg loss=3.900, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 319552 images, time remaining=3.6 hours
4994: loss=4.096, avg loss=3.919, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 319616 images, time remaining=3.6 hours
4995: loss=3.585, avg loss=3.886, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 319680 images, time remaining=3.6 hours
4996: loss=4.267, avg loss=3.924, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 319744 images, time remaining=3.6 hours
4997: loss=3.734, avg loss=3.905, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 319808 images, time remaining=3.6 hours
4998: loss=3.518, avg loss=3.866, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=4.7 seconds, 319872 images, time remaining=3.6 hours
4999: loss=4.288, avg loss=3.908, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 319936 images, time remaining=3.6 hours
5000: loss=3.969, avg loss=3.914, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 320000 images, time remaining=3.6 hours
Saving weights to /workspace/.cache/splits/combined_5000.weights
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b2ec000000
5001: loss=4.171, avg loss=3.940, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 320064 images, time remaining=3.6 hours
5002: loss=4.496, avg loss=3.996, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 320128 images, time remaining=3.6 hours
5003: loss=3.718, avg loss=3.968, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 320192 images, time remaining=3.6 hours
5004: loss=3.749, avg loss=3.946, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 320256 images, time remaining=3.6 hours
5005: loss=3.008, avg loss=3.852, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 320320 images, time remaining=3.6 hours
5006: loss=3.393, avg loss=3.806, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 320384 images, time remaining=3.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5007: loss=3.768, avg loss=3.802, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=3.3 seconds, train=2.2 seconds, 320448 images, time remaining=3.6 hours
5008: loss=3.364, avg loss=3.759, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 320512 images, time remaining=3.6 hours
5009: loss=3.701, avg loss=3.753, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 320576 images, time remaining=3.6 hours
5010: loss=3.446, avg loss=3.722, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 320640 images, time remaining=3.6 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5011: loss=7.877, avg loss=4.138, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 320704 images, time remaining=3.6 hours
5012: loss=6.102, avg loss=4.334, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.0 seconds, train=5.5 seconds, 320768 images, time remaining=3.6 hours
5013: loss=5.593, avg loss=4.460, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 320832 images, time remaining=3.6 hours
5014: loss=6.244, avg loss=4.638, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 320896 images, time remaining=3.6 hours
5015: loss=4.725, avg loss=4.647, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 320960 images, time remaining=3.6 hours
5016: loss=5.442, avg loss=4.726, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 321024 images, time remaining=3.6 hours
5017: loss=4.796, avg loss=4.733, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 321088 images, time remaining=3.6 hours
5018: loss=4.452, avg loss=4.705, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 321152 images, time remaining=3.6 hours
5019: loss=5.010, avg loss=4.736, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 321216 images, time remaining=3.6 hours
5020: loss=4.206, avg loss=4.683, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 321280 images, time remaining=3.6 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b4dfc00000
5021: loss=4.384, avg loss=4.653, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 321344 images, time remaining=3.6 hours
5022: loss=4.214, avg loss=4.609, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 321408 images, time remaining=3.5 hours
5023: loss=3.775, avg loss=4.526, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 321472 images, time remaining=3.5 hours
5024: loss=3.716, avg loss=4.445, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 321536 images, time remaining=3.5 hours
5025: loss=3.291, avg loss=4.329, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.8 seconds, train=2.4 seconds, 321600 images, time remaining=3.5 hours
5026: loss=3.561, avg loss=4.252, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 321664 images, time remaining=3.5 hours
5027: loss=4.096, avg loss=4.237, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 321728 images, time remaining=3.5 hours
5028: loss=3.580, avg loss=4.171, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 321792 images, time remaining=3.5 hours
5029: loss=3.320, avg loss=4.086, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 321856 images, time remaining=3.5 hours
5030: loss=4.227, avg loss=4.100, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.2 seconds, train=2.3 seconds, 321920 images, time remaining=3.5 hours
Resizing, random_coef=1.40, batch=4, 704x544
GPU #0: allocating workspace: 289.6 MiB begins at 0x14b7d7600000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5031: loss=3.832, avg loss=4.073, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=2.4 seconds, train=1.9 seconds, 321984 images, time remaining=3.5 hours
5032: loss=3.403, avg loss=4.006, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 322048 images, time remaining=3.5 hours
5033: loss=3.739, avg loss=3.980, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 322112 images, time remaining=3.5 hours
5034: loss=3.736, avg loss=3.955, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=1.8 seconds, 322176 images, time remaining=3.5 hours
5035: loss=4.671, avg loss=4.027, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 322240 images, time remaining=3.5 hours
5036: loss=3.574, avg loss=3.982, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=1.8 seconds, 322304 images, time remaining=3.5 hours
5037: loss=3.938, avg loss=3.977, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 322368 images, time remaining=3.5 hours
5038: loss=3.881, avg loss=3.968, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 322432 images, time remaining=3.5 hours
5039: loss=3.468, avg loss=3.918, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 322496 images, time remaining=3.5 hours
5040: loss=4.069, avg loss=3.933, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 322560 images, time remaining=3.5 hours
Resizing, random_coef=1.40, batch=4, 1088x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5041: loss=5.854, avg loss=4.125, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 322624 images, time remaining=3.5 hours
5042: loss=3.961, avg loss=4.109, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 322688 images, time remaining=3.5 hours
5043: loss=5.257, avg loss=4.223, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 322752 images, time remaining=3.5 hours
5044: loss=4.307, avg loss=4.232, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=4.2 seconds, 322816 images, time remaining=3.5 hours
5045: loss=2.879, avg loss=4.097, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 322880 images, time remaining=3.5 hours
5046: loss=3.953, avg loss=4.082, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 322944 images, time remaining=3.5 hours
5047: loss=3.562, avg loss=4.030, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 323008 images, time remaining=3.5 hours
5048: loss=4.074, avg loss=4.035, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 323072 images, time remaining=3.5 hours
5049: loss=3.729, avg loss=4.004, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 323136 images, time remaining=3.5 hours
5050: loss=5.226, avg loss=4.126, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 323200 images, time remaining=3.5 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2e4000000
5051: loss=4.236, avg loss=4.137, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 323264 images, time remaining=3.5 hours
5052: loss=4.689, avg loss=4.192, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 323328 images, time remaining=3.5 hours
5053: loss=3.463, avg loss=4.119, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.7 seconds, 323392 images, time remaining=3.5 hours
5054: loss=3.281, avg loss=4.036, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 323456 images, time remaining=3.5 hours
5055: loss=3.381, avg loss=3.970, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 323520 images, time remaining=3.5 hours
5056: loss=3.727, avg loss=3.946, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 323584 images, time remaining=3.5 hours
5057: loss=3.845, avg loss=3.936, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 323648 images, time remaining=3.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5058: loss=3.385, avg loss=3.881, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=3.3 seconds, train=2.7 seconds, 323712 images, time remaining=3.5 hours
5059: loss=3.223, avg loss=3.815, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 323776 images, time remaining=3.5 hours
5060: loss=3.567, avg loss=3.790, last=92.80%, best=92.80%, next=5060, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 323840 images, time remaining=3.5 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b53ca00000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=164807, unique_truth_count=57264
rank=0 of ranks=164807rank=100 of ranks=164807rank=200 of ranks=164807rank=300 of ranks=164807rank=400 of ranks=164807rank=500 of ranks=164807rank=600 of ranks=164807rank=700 of ranks=164807rank=800 of ranks=164807rank=900 of ranks=164807rank=1000 of ranks=164807rank=1100 of ranks=164807rank=1200 of ranks=164807rank=1300 of ranks=164807rank=1400 of ranks=164807rank=1500 of ranks=164807rank=1600 of ranks=164807rank=1700 of ranks=164807rank=1800 of ranks=164807rank=1900 of ranks=164807rank=2000 of ranks=164807rank=2100 of ranks=164807rank=2200 of ranks=164807rank=2300 of ranks=164807rank=2400 of ranks=164807rank=2500 of ranks=164807rank=2600 of ranks=164807rank=2700 of ranks=164807rank=2800 of ranks=164807rank=2900 of ranks=164807rank=3000 of ranks=164807rank=3100 of ranks=164807rank=3200 of ranks=164807rank=3300 of ranks=164807rank=3400 of ranks=164807rank=3500 of ranks=164807rank=3600 of ranks=164807rank=3700 of ranks=164807rank=3800 of ranks=164807rank=3900 of ranks=164807rank=4000 of ranks=164807rank=4100 of ranks=164807rank=4200 of ranks=164807rank=4300 of ranks=164807rank=4400 of ranks=164807rank=4500 of ranks=164807rank=4600 of ranks=164807rank=4700 of ranks=164807rank=4800 of ranks=164807rank=4900 of ranks=164807rank=5000 of ranks=164807rank=5100 of ranks=164807rank=5200 of ranks=164807rank=5300 of ranks=164807rank=5400 of ranks=164807rank=5500 of ranks=164807rank=5600 of ranks=164807rank=5700 of ranks=164807rank=5800 of ranks=164807rank=5900 of ranks=164807rank=6000 of ranks=164807rank=6100 of ranks=164807rank=6200 of ranks=164807rank=6300 of ranks=164807rank=6400 of ranks=164807rank=6500 of ranks=164807rank=6600 of ranks=164807rank=6700 of ranks=164807rank=6800 of ranks=164807rank=6900 of ranks=164807rank=7000 of ranks=164807rank=7100 of ranks=164807rank=7200 of ranks=164807rank=7300 of ranks=164807rank=7400 of ranks=164807rank=7500 of ranks=164807rank=7600 of ranks=164807rank=7700 of ranks=164807rank=7800 of ranks=164807rank=7900 of ranks=164807rank=8000 of ranks=164807rank=8100 of ranks=164807rank=8200 of ranks=164807rank=8300 of ranks=164807rank=8400 of ranks=164807rank=8500 of ranks=164807rank=8600 of ranks=164807rank=8700 of ranks=164807rank=8800 of ranks=164807rank=8900 of ranks=164807rank=9000 of ranks=164807rank=9100 of ranks=164807rank=9200 of ranks=164807rank=9300 of ranks=164807rank=9400 of ranks=164807rank=9500 of ranks=164807rank=9600 of ranks=164807rank=9700 of ranks=164807rank=9800 of ranks=164807rank=9900 of ranks=164807rank=10000 of ranks=164807rank=10100 of ranks=164807rank=10200 of ranks=164807rank=10300 of ranks=164807rank=10400 of ranks=164807rank=10500 of ranks=164807rank=10600 of ranks=164807rank=10700 of ranks=164807rank=10800 of ranks=164807rank=10900 of ranks=164807rank=11000 of ranks=164807rank=11100 of ranks=164807rank=11200 of ranks=164807rank=11300 of ranks=164807rank=11400 of ranks=164807rank=11500 of ranks=164807rank=11600 of ranks=164807rank=11700 of ranks=164807rank=11800 of ranks=164807rank=11900 of ranks=164807rank=12000 of ranks=164807rank=12100 of ranks=164807rank=12200 of ranks=164807rank=12300 of ranks=164807rank=12400 of ranks=164807rank=12500 of ranks=164807rank=12600 of ranks=164807rank=12700 of ranks=164807rank=12800 of ranks=164807rank=12900 of ranks=164807rank=13000 of ranks=164807rank=13100 of ranks=164807rank=13200 of ranks=164807rank=13300 of ranks=164807rank=13400 of ranks=164807rank=13500 of ranks=164807rank=13600 of ranks=164807rank=13700 of ranks=164807rank=13800 of ranks=164807rank=13900 of ranks=164807rank=14000 of ranks=164807rank=14100 of ranks=164807rank=14200 of ranks=164807rank=14300 of ranks=164807rank=14400 of ranks=164807rank=14500 of ranks=164807rank=14600 of ranks=164807rank=14700 of ranks=164807rank=14800 of ranks=164807rank=14900 of ranks=164807rank=15000 of ranks=164807rank=15100 of ranks=164807rank=15200 of ranks=164807rank=15300 of ranks=164807rank=15400 of ranks=164807rank=15500 of ranks=164807rank=15600 of ranks=164807rank=15700 of ranks=164807rank=15800 of ranks=164807rank=15900 of ranks=164807rank=16000 of ranks=164807rank=16100 of ranks=164807rank=16200 of ranks=164807rank=16300 of ranks=164807rank=16400 of ranks=164807rank=16500 of ranks=164807rank=16600 of ranks=164807rank=16700 of ranks=164807rank=16800 of ranks=164807rank=16900 of ranks=164807rank=17000 of ranks=164807rank=17100 of ranks=164807rank=17200 of ranks=164807rank=17300 of ranks=164807rank=17400 of ranks=164807rank=17500 of ranks=164807rank=17600 of ranks=164807rank=17700 of ranks=164807rank=17800 of ranks=164807rank=17900 of ranks=164807rank=18000 of ranks=164807rank=18100 of ranks=164807rank=18200 of ranks=164807rank=18300 of ranks=164807rank=18400 of ranks=164807rank=18500 of ranks=164807rank=18600 of ranks=164807rank=18700 of ranks=164807rank=18800 of ranks=164807rank=18900 of ranks=164807rank=19000 of ranks=164807rank=19100 of ranks=164807rank=19200 of ranks=164807rank=19300 of ranks=164807rank=19400 of ranks=164807rank=19500 of ranks=164807rank=19600 of ranks=164807rank=19700 of ranks=164807rank=19800 of ranks=164807rank=19900 of ranks=164807rank=20000 of ranks=164807rank=20100 of ranks=164807rank=20200 of ranks=164807rank=20300 of ranks=164807rank=20400 of ranks=164807rank=20500 of ranks=164807rank=20600 of ranks=164807rank=20700 of ranks=164807rank=20800 of ranks=164807rank=20900 of ranks=164807rank=21000 of ranks=164807rank=21100 of ranks=164807rank=21200 of ranks=164807rank=21300 of ranks=164807rank=21400 of ranks=164807rank=21500 of ranks=164807rank=21600 of ranks=164807rank=21700 of ranks=164807rank=21800 of ranks=164807rank=21900 of ranks=164807rank=22000 of ranks=164807rank=22100 of ranks=164807rank=22200 of ranks=164807rank=22300 of ranks=164807rank=22400 of ranks=164807rank=22500 of ranks=164807rank=22600 of ranks=164807rank=22700 of ranks=164807rank=22800 of ranks=164807rank=22900 of ranks=164807rank=23000 of ranks=164807rank=23100 of ranks=164807rank=23200 of ranks=164807rank=23300 of ranks=164807rank=23400 of ranks=164807rank=23500 of ranks=164807rank=23600 of ranks=164807rank=23700 of ranks=164807rank=23800 of ranks=164807rank=23900 of ranks=164807rank=24000 of ranks=164807rank=24100 of ranks=164807rank=24200 of ranks=164807rank=24300 of ranks=164807rank=24400 of ranks=164807rank=24500 of ranks=164807rank=24600 of ranks=164807rank=24700 of ranks=164807rank=24800 of ranks=164807rank=24900 of ranks=164807rank=25000 of ranks=164807rank=25100 of ranks=164807rank=25200 of ranks=164807rank=25300 of ranks=164807rank=25400 of ranks=164807rank=25500 of ranks=164807rank=25600 of ranks=164807rank=25700 of ranks=164807rank=25800 of ranks=164807rank=25900 of ranks=164807rank=26000 of ranks=164807rank=26100 of ranks=164807rank=26200 of ranks=164807rank=26300 of ranks=164807rank=26400 of ranks=164807rank=26500 of ranks=164807rank=26600 of ranks=164807rank=26700 of ranks=164807rank=26800 of ranks=164807rank=26900 of ranks=164807rank=27000 of ranks=164807rank=27100 of ranks=164807rank=27200 of ranks=164807rank=27300 of ranks=164807rank=27400 of ranks=164807rank=27500 of ranks=164807rank=27600 of ranks=164807rank=27700 of ranks=164807rank=27800 of ranks=164807rank=27900 of ranks=164807rank=28000 of ranks=164807rank=28100 of ranks=164807rank=28200 of ranks=164807rank=28300 of ranks=164807rank=28400 of ranks=164807rank=28500 of ranks=164807rank=28600 of ranks=164807rank=28700 of ranks=164807rank=28800 of ranks=164807rank=28900 of ranks=164807rank=29000 of ranks=164807rank=29100 of ranks=164807rank=29200 of ranks=164807rank=29300 of ranks=164807rank=29400 of ranks=164807rank=29500 of ranks=164807rank=29600 of ranks=164807rank=29700 of ranks=164807rank=29800 of ranks=164807rank=29900 of ranks=164807rank=30000 of ranks=164807rank=30100 of ranks=164807rank=30200 of ranks=164807rank=30300 of ranks=164807rank=30400 of ranks=164807rank=30500 of ranks=164807rank=30600 of ranks=164807rank=30700 of ranks=164807rank=30800 of ranks=164807rank=30900 of ranks=164807rank=31000 of ranks=164807rank=31100 of ranks=164807rank=31200 of ranks=164807rank=31300 of ranks=164807rank=31400 of ranks=164807rank=31500 of ranks=164807rank=31600 of ranks=164807rank=31700 of ranks=164807rank=31800 of ranks=164807rank=31900 of ranks=164807rank=32000 of ranks=164807rank=32100 of ranks=164807rank=32200 of ranks=164807rank=32300 of ranks=164807rank=32400 of ranks=164807rank=32500 of ranks=164807rank=32600 of ranks=164807rank=32700 of ranks=164807rank=32800 of ranks=164807rank=32900 of ranks=164807rank=33000 of ranks=164807rank=33100 of ranks=164807rank=33200 of ranks=164807rank=33300 of ranks=164807rank=33400 of ranks=164807rank=33500 of ranks=164807rank=33600 of ranks=164807rank=33700 of ranks=164807rank=33800 of ranks=164807rank=33900 of ranks=164807rank=34000 of ranks=164807rank=34100 of ranks=164807rank=34200 of ranks=164807rank=34300 of ranks=164807rank=34400 of ranks=164807rank=34500 of ranks=164807rank=34600 of ranks=164807rank=34700 of ranks=164807rank=34800 of ranks=164807rank=34900 of ranks=164807rank=35000 of ranks=164807rank=35100 of ranks=164807rank=35200 of ranks=164807rank=35300 of ranks=164807rank=35400 of ranks=164807rank=35500 of ranks=164807rank=35600 of ranks=164807rank=35700 of ranks=164807rank=35800 of ranks=164807rank=35900 of ranks=164807rank=36000 of ranks=164807rank=36100 of ranks=164807rank=36200 of ranks=164807rank=36300 of ranks=164807rank=36400 of ranks=164807rank=36500 of ranks=164807rank=36600 of ranks=164807rank=36700 of ranks=164807rank=36800 of ranks=164807rank=36900 of ranks=164807rank=37000 of ranks=164807rank=37100 of ranks=164807rank=37200 of ranks=164807rank=37300 of ranks=164807rank=37400 of ranks=164807rank=37500 of ranks=164807rank=37600 of ranks=164807rank=37700 of ranks=164807rank=37800 of ranks=164807rank=37900 of ranks=164807rank=38000 of ranks=164807rank=38100 of ranks=164807rank=38200 of ranks=164807rank=38300 of ranks=164807rank=38400 of ranks=164807rank=38500 of ranks=164807rank=38600 of ranks=164807rank=38700 of ranks=164807rank=38800 of ranks=164807rank=38900 of ranks=164807rank=39000 of ranks=164807rank=39100 of ranks=164807rank=39200 of ranks=164807rank=39300 of ranks=164807rank=39400 of ranks=164807rank=39500 of ranks=164807rank=39600 of ranks=164807rank=39700 of ranks=164807rank=39800 of ranks=164807rank=39900 of ranks=164807rank=40000 of ranks=164807rank=40100 of ranks=164807rank=40200 of ranks=164807rank=40300 of ranks=164807rank=40400 of ranks=164807rank=40500 of ranks=164807rank=40600 of ranks=164807rank=40700 of ranks=164807rank=40800 of ranks=164807rank=40900 of ranks=164807rank=41000 of ranks=164807rank=41100 of ranks=164807rank=41200 of ranks=164807rank=41300 of ranks=164807rank=41400 of ranks=164807rank=41500 of ranks=164807rank=41600 of ranks=164807rank=41700 of ranks=164807rank=41800 of ranks=164807rank=41900 of ranks=164807rank=42000 of ranks=164807rank=42100 of ranks=164807rank=42200 of ranks=164807rank=42300 of ranks=164807rank=42400 of ranks=164807rank=42500 of ranks=164807rank=42600 of ranks=164807rank=42700 of ranks=164807rank=42800 of ranks=164807rank=42900 of ranks=164807rank=43000 of ranks=164807rank=43100 of ranks=164807rank=43200 of ranks=164807rank=43300 of ranks=164807rank=43400 of ranks=164807rank=43500 of ranks=164807rank=43600 of ranks=164807rank=43700 of ranks=164807rank=43800 of ranks=164807rank=43900 of ranks=164807rank=44000 of ranks=164807rank=44100 of ranks=164807rank=44200 of ranks=164807rank=44300 of ranks=164807rank=44400 of ranks=164807rank=44500 of ranks=164807rank=44600 of ranks=164807rank=44700 of ranks=164807rank=44800 of ranks=164807rank=44900 of ranks=164807rank=45000 of ranks=164807rank=45100 of ranks=164807rank=45200 of ranks=164807rank=45300 of ranks=164807rank=45400 of ranks=164807rank=45500 of ranks=164807rank=45600 of ranks=164807rank=45700 of ranks=164807rank=45800 of ranks=164807rank=45900 of ranks=164807rank=46000 of ranks=164807rank=46100 of ranks=164807rank=46200 of ranks=164807rank=46300 of ranks=164807rank=46400 of ranks=164807rank=46500 of ranks=164807rank=46600 of ranks=164807rank=46700 of ranks=164807rank=46800 of ranks=164807rank=46900 of ranks=164807rank=47000 of ranks=164807rank=47100 of ranks=164807rank=47200 of ranks=164807rank=47300 of ranks=164807rank=47400 of ranks=164807rank=47500 of ranks=164807rank=47600 of ranks=164807rank=47700 of ranks=164807rank=47800 of ranks=164807rank=47900 of ranks=164807rank=48000 of ranks=164807rank=48100 of ranks=164807rank=48200 of ranks=164807rank=48300 of ranks=164807rank=48400 of ranks=164807rank=48500 of ranks=164807rank=48600 of ranks=164807rank=48700 of ranks=164807rank=48800 of ranks=164807rank=48900 of ranks=164807rank=49000 of ranks=164807rank=49100 of ranks=164807rank=49200 of ranks=164807rank=49300 of ranks=164807rank=49400 of ranks=164807rank=49500 of ranks=164807rank=49600 of ranks=164807rank=49700 of ranks=164807rank=49800 of ranks=164807rank=49900 of ranks=164807rank=50000 of ranks=164807rank=50100 of ranks=164807rank=50200 of ranks=164807rank=50300 of ranks=164807rank=50400 of ranks=164807rank=50500 of ranks=164807rank=50600 of ranks=164807rank=50700 of ranks=164807rank=50800 of ranks=164807rank=50900 of ranks=164807rank=51000 of ranks=164807rank=51100 of ranks=164807rank=51200 of ranks=164807rank=51300 of ranks=164807rank=51400 of ranks=164807rank=51500 of ranks=164807rank=51600 of ranks=164807rank=51700 of ranks=164807rank=51800 of ranks=164807rank=51900 of ranks=164807rank=52000 of ranks=164807rank=52100 of ranks=164807rank=52200 of ranks=164807rank=52300 of ranks=164807rank=52400 of ranks=164807rank=52500 of ranks=164807rank=52600 of ranks=164807rank=52700 of ranks=164807rank=52800 of ranks=164807rank=52900 of ranks=164807rank=53000 of ranks=164807rank=53100 of ranks=164807rank=53200 of ranks=164807rank=53300 of ranks=164807rank=53400 of ranks=164807rank=53500 of ranks=164807rank=53600 of ranks=164807rank=53700 of ranks=164807rank=53800 of ranks=164807rank=53900 of ranks=164807rank=54000 of ranks=164807rank=54100 of ranks=164807rank=54200 of ranks=164807rank=54300 of ranks=164807rank=54400 of ranks=164807rank=54500 of ranks=164807rank=54600 of ranks=164807rank=54700 of ranks=164807rank=54800 of ranks=164807rank=54900 of ranks=164807rank=55000 of ranks=164807rank=55100 of ranks=164807rank=55200 of ranks=164807rank=55300 of ranks=164807rank=55400 of ranks=164807rank=55500 of ranks=164807rank=55600 of ranks=164807rank=55700 of ranks=164807rank=55800 of ranks=164807rank=55900 of ranks=164807rank=56000 of ranks=164807rank=56100 of ranks=164807rank=56200 of ranks=164807rank=56300 of ranks=164807rank=56400 of ranks=164807rank=56500 of ranks=164807rank=56600 of ranks=164807rank=56700 of ranks=164807rank=56800 of ranks=164807rank=56900 of ranks=164807rank=57000 of ranks=164807rank=57100 of ranks=164807rank=57200 of ranks=164807rank=57300 of ranks=164807rank=57400 of ranks=164807rank=57500 of ranks=164807rank=57600 of ranks=164807rank=57700 of ranks=164807rank=57800 of ranks=164807rank=57900 of ranks=164807rank=58000 of ranks=164807rank=58100 of ranks=164807rank=58200 of ranks=164807rank=58300 of ranks=164807rank=58400 of ranks=164807rank=58500 of ranks=164807rank=58600 of ranks=164807rank=58700 of ranks=164807rank=58800 of ranks=164807rank=58900 of ranks=164807rank=59000 of ranks=164807rank=59100 of ranks=164807rank=59200 of ranks=164807rank=59300 of ranks=164807rank=59400 of ranks=164807rank=59500 of ranks=164807rank=59600 of ranks=164807rank=59700 of ranks=164807rank=59800 of ranks=164807rank=59900 of ranks=164807rank=60000 of ranks=164807rank=60100 of ranks=164807rank=60200 of ranks=164807rank=60300 of ranks=164807rank=60400 of ranks=164807rank=60500 of ranks=164807rank=60600 of ranks=164807rank=60700 of ranks=164807rank=60800 of ranks=164807rank=60900 of ranks=164807rank=61000 of ranks=164807rank=61100 of ranks=164807rank=61200 of ranks=164807rank=61300 of ranks=164807rank=61400 of ranks=164807rank=61500 of ranks=164807rank=61600 of ranks=164807rank=61700 of ranks=164807rank=61800 of ranks=164807rank=61900 of ranks=164807rank=62000 of ranks=164807rank=62100 of ranks=164807rank=62200 of ranks=164807rank=62300 of ranks=164807rank=62400 of ranks=164807rank=62500 of ranks=164807rank=62600 of ranks=164807rank=62700 of ranks=164807rank=62800 of ranks=164807rank=62900 of ranks=164807rank=63000 of ranks=164807rank=63100 of ranks=164807rank=63200 of ranks=164807rank=63300 of ranks=164807rank=63400 of ranks=164807rank=63500 of ranks=164807rank=63600 of ranks=164807rank=63700 of ranks=164807rank=63800 of ranks=164807rank=63900 of ranks=164807rank=64000 of ranks=164807rank=64100 of ranks=164807rank=64200 of ranks=164807rank=64300 of ranks=164807rank=64400 of ranks=164807rank=64500 of ranks=164807rank=64600 of ranks=164807rank=64700 of ranks=164807rank=64800 of ranks=164807rank=64900 of ranks=164807rank=65000 of ranks=164807rank=65100 of ranks=164807rank=65200 of ranks=164807rank=65300 of ranks=164807rank=65400 of ranks=164807rank=65500 of ranks=164807rank=65600 of ranks=164807rank=65700 of ranks=164807rank=65800 of ranks=164807rank=65900 of ranks=164807rank=66000 of ranks=164807rank=66100 of ranks=164807rank=66200 of ranks=164807rank=66300 of ranks=164807rank=66400 of ranks=164807rank=66500 of ranks=164807rank=66600 of ranks=164807rank=66700 of ranks=164807rank=66800 of ranks=164807rank=66900 of ranks=164807rank=67000 of ranks=164807rank=67100 of ranks=164807rank=67200 of ranks=164807rank=67300 of ranks=164807rank=67400 of ranks=164807rank=67500 of ranks=164807rank=67600 of ranks=164807rank=67700 of ranks=164807rank=67800 of ranks=164807rank=67900 of ranks=164807rank=68000 of ranks=164807rank=68100 of ranks=164807rank=68200 of ranks=164807rank=68300 of ranks=164807rank=68400 of ranks=164807rank=68500 of ranks=164807rank=68600 of ranks=164807rank=68700 of ranks=164807rank=68800 of ranks=164807rank=68900 of ranks=164807rank=69000 of ranks=164807rank=69100 of ranks=164807rank=69200 of ranks=164807rank=69300 of ranks=164807rank=69400 of ranks=164807rank=69500 of ranks=164807rank=69600 of ranks=164807rank=69700 of ranks=164807rank=69800 of ranks=164807rank=69900 of ranks=164807rank=70000 of ranks=164807rank=70100 of ranks=164807rank=70200 of ranks=164807rank=70300 of ranks=164807rank=70400 of ranks=164807rank=70500 of ranks=164807rank=70600 of ranks=164807rank=70700 of ranks=164807rank=70800 of ranks=164807rank=70900 of ranks=164807rank=71000 of ranks=164807rank=71100 of ranks=164807rank=71200 of ranks=164807rank=71300 of ranks=164807rank=71400 of ranks=164807rank=71500 of ranks=164807rank=71600 of ranks=164807rank=71700 of ranks=164807rank=71800 of ranks=164807rank=71900 of ranks=164807rank=72000 of ranks=164807rank=72100 of ranks=164807rank=72200 of ranks=164807rank=72300 of ranks=164807rank=72400 of ranks=164807rank=72500 of ranks=164807rank=72600 of ranks=164807rank=72700 of ranks=164807rank=72800 of ranks=164807rank=72900 of ranks=164807rank=73000 of ranks=164807rank=73100 of ranks=164807rank=73200 of ranks=164807rank=73300 of ranks=164807rank=73400 of ranks=164807rank=73500 of ranks=164807rank=73600 of ranks=164807rank=73700 of ranks=164807rank=73800 of ranks=164807rank=73900 of ranks=164807rank=74000 of ranks=164807rank=74100 of ranks=164807rank=74200 of ranks=164807rank=74300 of ranks=164807rank=74400 of ranks=164807rank=74500 of ranks=164807rank=74600 of ranks=164807rank=74700 of ranks=164807rank=74800 of ranks=164807rank=74900 of ranks=164807rank=75000 of ranks=164807rank=75100 of ranks=164807rank=75200 of ranks=164807rank=75300 of ranks=164807rank=75400 of ranks=164807rank=75500 of ranks=164807rank=75600 of ranks=164807rank=75700 of ranks=164807rank=75800 of ranks=164807rank=75900 of ranks=164807rank=76000 of ranks=164807rank=76100 of ranks=164807rank=76200 of ranks=164807rank=76300 of ranks=164807rank=76400 of ranks=164807rank=76500 of ranks=164807rank=76600 of ranks=164807rank=76700 of ranks=164807rank=76800 of ranks=164807rank=76900 of ranks=164807rank=77000 of ranks=164807rank=77100 of ranks=164807rank=77200 of ranks=164807rank=77300 of ranks=164807rank=77400 of ranks=164807rank=77500 of ranks=164807rank=77600 of ranks=164807rank=77700 of ranks=164807rank=77800 of ranks=164807rank=77900 of ranks=164807rank=78000 of ranks=164807rank=78100 of ranks=164807rank=78200 of ranks=164807rank=78300 of ranks=164807rank=78400 of ranks=164807rank=78500 of ranks=164807rank=78600 of ranks=164807rank=78700 of ranks=164807rank=78800 of ranks=164807rank=78900 of ranks=164807rank=79000 of ranks=164807rank=79100 of ranks=164807rank=79200 of ranks=164807rank=79300 of ranks=164807rank=79400 of ranks=164807rank=79500 of ranks=164807rank=79600 of ranks=164807rank=79700 of ranks=164807rank=79800 of ranks=164807rank=79900 of ranks=164807rank=80000 of ranks=164807rank=80100 of ranks=164807rank=80200 of ranks=164807rank=80300 of ranks=164807rank=80400 of ranks=164807rank=80500 of ranks=164807rank=80600 of ranks=164807rank=80700 of ranks=164807rank=80800 of ranks=164807rank=80900 of ranks=164807rank=81000 of ranks=164807rank=81100 of ranks=164807rank=81200 of ranks=164807rank=81300 of ranks=164807rank=81400 of ranks=164807rank=81500 of ranks=164807rank=81600 of ranks=164807rank=81700 of ranks=164807rank=81800 of ranks=164807rank=81900 of ranks=164807rank=82000 of ranks=164807rank=82100 of ranks=164807rank=82200 of ranks=164807rank=82300 of ranks=164807rank=82400 of ranks=164807rank=82500 of ranks=164807rank=82600 of ranks=164807rank=82700 of ranks=164807rank=82800 of ranks=164807rank=82900 of ranks=164807rank=83000 of ranks=164807rank=83100 of ranks=164807rank=83200 of ranks=164807rank=83300 of ranks=164807rank=83400 of ranks=164807rank=83500 of ranks=164807rank=83600 of ranks=164807rank=83700 of ranks=164807rank=83800 of ranks=164807rank=83900 of ranks=164807rank=84000 of ranks=164807rank=84100 of ranks=164807rank=84200 of ranks=164807rank=84300 of ranks=164807rank=84400 of ranks=164807rank=84500 of ranks=164807rank=84600 of ranks=164807rank=84700 of ranks=164807rank=84800 of ranks=164807rank=84900 of ranks=164807rank=85000 of ranks=164807rank=85100 of ranks=164807rank=85200 of ranks=164807rank=85300 of ranks=164807rank=85400 of ranks=164807rank=85500 of ranks=164807rank=85600 of ranks=164807rank=85700 of ranks=164807rank=85800 of ranks=164807rank=85900 of ranks=164807rank=86000 of ranks=164807rank=86100 of ranks=164807rank=86200 of ranks=164807rank=86300 of ranks=164807rank=86400 of ranks=164807rank=86500 of ranks=164807rank=86600 of ranks=164807rank=86700 of ranks=164807rank=86800 of ranks=164807rank=86900 of ranks=164807rank=87000 of ranks=164807rank=87100 of ranks=164807rank=87200 of ranks=164807rank=87300 of ranks=164807rank=87400 of ranks=164807rank=87500 of ranks=164807rank=87600 of ranks=164807rank=87700 of ranks=164807rank=87800 of ranks=164807rank=87900 of ranks=164807rank=88000 of ranks=164807rank=88100 of ranks=164807rank=88200 of ranks=164807rank=88300 of ranks=164807rank=88400 of ranks=164807rank=88500 of ranks=164807rank=88600 of ranks=164807rank=88700 of ranks=164807rank=88800 of ranks=164807rank=88900 of ranks=164807rank=89000 of ranks=164807rank=89100 of ranks=164807rank=89200 of ranks=164807rank=89300 of ranks=164807rank=89400 of ranks=164807rank=89500 of ranks=164807rank=89600 of ranks=164807rank=89700 of ranks=164807rank=89800 of ranks=164807rank=89900 of ranks=164807rank=90000 of ranks=164807rank=90100 of ranks=164807rank=90200 of ranks=164807rank=90300 of ranks=164807rank=90400 of ranks=164807rank=90500 of ranks=164807rank=90600 of ranks=164807rank=90700 of ranks=164807rank=90800 of ranks=164807rank=90900 of ranks=164807rank=91000 of ranks=164807rank=91100 of ranks=164807rank=91200 of ranks=164807rank=91300 of ranks=164807rank=91400 of ranks=164807rank=91500 of ranks=164807rank=91600 of ranks=164807rank=91700 of ranks=164807rank=91800 of ranks=164807rank=91900 of ranks=164807rank=92000 of ranks=164807rank=92100 of ranks=164807rank=92200 of ranks=164807rank=92300 of ranks=164807rank=92400 of ranks=164807rank=92500 of ranks=164807rank=92600 of ranks=164807rank=92700 of ranks=164807rank=92800 of ranks=164807rank=92900 of ranks=164807rank=93000 of ranks=164807rank=93100 of ranks=164807rank=93200 of ranks=164807rank=93300 of ranks=164807rank=93400 of ranks=164807rank=93500 of ranks=164807rank=93600 of ranks=164807rank=93700 of ranks=164807rank=93800 of ranks=164807rank=93900 of ranks=164807rank=94000 of ranks=164807rank=94100 of ranks=164807rank=94200 of ranks=164807rank=94300 of ranks=164807rank=94400 of ranks=164807rank=94500 of ranks=164807rank=94600 of ranks=164807rank=94700 of ranks=164807rank=94800 of ranks=164807rank=94900 of ranks=164807rank=95000 of ranks=164807rank=95100 of ranks=164807rank=95200 of ranks=164807rank=95300 of ranks=164807rank=95400 of ranks=164807rank=95500 of ranks=164807rank=95600 of ranks=164807rank=95700 of ranks=164807rank=95800 of ranks=164807rank=95900 of ranks=164807rank=96000 of ranks=164807rank=96100 of ranks=164807rank=96200 of ranks=164807rank=96300 of ranks=164807rank=96400 of ranks=164807rank=96500 of ranks=164807rank=96600 of ranks=164807rank=96700 of ranks=164807rank=96800 of ranks=164807rank=96900 of ranks=164807rank=97000 of ranks=164807rank=97100 of ranks=164807rank=97200 of ranks=164807rank=97300 of ranks=164807rank=97400 of ranks=164807rank=97500 of ranks=164807rank=97600 of ranks=164807rank=97700 of ranks=164807rank=97800 of ranks=164807rank=97900 of ranks=164807rank=98000 of ranks=164807rank=98100 of ranks=164807rank=98200 of ranks=164807rank=98300 of ranks=164807rank=98400 of ranks=164807rank=98500 of ranks=164807rank=98600 of ranks=164807rank=98700 of ranks=164807rank=98800 of ranks=164807rank=98900 of ranks=164807rank=99000 of ranks=164807rank=99100 of ranks=164807rank=99200 of ranks=164807rank=99300 of ranks=164807rank=99400 of ranks=164807rank=99500 of ranks=164807rank=99600 of ranks=164807rank=99700 of ranks=164807rank=99800 of ranks=164807rank=99900 of ranks=164807rank=100000 of ranks=164807rank=100100 of ranks=164807rank=100200 of ranks=164807rank=100300 of ranks=164807rank=100400 of ranks=164807rank=100500 of ranks=164807rank=100600 of ranks=164807rank=100700 of ranks=164807rank=100800 of ranks=164807rank=100900 of ranks=164807rank=101000 of ranks=164807rank=101100 of ranks=164807rank=101200 of ranks=164807rank=101300 of ranks=164807rank=101400 of ranks=164807rank=101500 of ranks=164807rank=101600 of ranks=164807rank=101700 of ranks=164807rank=101800 of ranks=164807rank=101900 of ranks=164807rank=102000 of ranks=164807rank=102100 of ranks=164807rank=102200 of ranks=164807rank=102300 of ranks=164807rank=102400 of ranks=164807rank=102500 of ranks=164807rank=102600 of ranks=164807rank=102700 of ranks=164807rank=102800 of ranks=164807rank=102900 of ranks=164807rank=103000 of ranks=164807rank=103100 of ranks=164807rank=103200 of ranks=164807rank=103300 of ranks=164807rank=103400 of ranks=164807rank=103500 of ranks=164807rank=103600 of ranks=164807rank=103700 of ranks=164807rank=103800 of ranks=164807rank=103900 of ranks=164807rank=104000 of ranks=164807rank=104100 of ranks=164807rank=104200 of ranks=164807rank=104300 of ranks=164807rank=104400 of ranks=164807rank=104500 of ranks=164807rank=104600 of ranks=164807rank=104700 of ranks=164807rank=104800 of ranks=164807rank=104900 of ranks=164807rank=105000 of ranks=164807rank=105100 of ranks=164807rank=105200 of ranks=164807rank=105300 of ranks=164807rank=105400 of ranks=164807rank=105500 of ranks=164807rank=105600 of ranks=164807rank=105700 of ranks=164807rank=105800 of ranks=164807rank=105900 of ranks=164807rank=106000 of ranks=164807rank=106100 of ranks=164807rank=106200 of ranks=164807rank=106300 of ranks=164807rank=106400 of ranks=164807rank=106500 of ranks=164807rank=106600 of ranks=164807rank=106700 of ranks=164807rank=106800 of ranks=164807rank=106900 of ranks=164807rank=107000 of ranks=164807rank=107100 of ranks=164807rank=107200 of ranks=164807rank=107300 of ranks=164807rank=107400 of ranks=164807rank=107500 of ranks=164807rank=107600 of ranks=164807rank=107700 of ranks=164807rank=107800 of ranks=164807rank=107900 of ranks=164807rank=108000 of ranks=164807rank=108100 of ranks=164807rank=108200 of ranks=164807rank=108300 of ranks=164807rank=108400 of ranks=164807rank=108500 of ranks=164807rank=108600 of ranks=164807rank=108700 of ranks=164807rank=108800 of ranks=164807rank=108900 of ranks=164807rank=109000 of ranks=164807rank=109100 of ranks=164807rank=109200 of ranks=164807rank=109300 of ranks=164807rank=109400 of ranks=164807rank=109500 of ranks=164807rank=109600 of ranks=164807rank=109700 of ranks=164807rank=109800 of ranks=164807rank=109900 of ranks=164807rank=110000 of ranks=164807rank=110100 of ranks=164807rank=110200 of ranks=164807rank=110300 of ranks=164807rank=110400 of ranks=164807rank=110500 of ranks=164807rank=110600 of ranks=164807rank=110700 of ranks=164807rank=110800 of ranks=164807rank=110900 of ranks=164807rank=111000 of ranks=164807rank=111100 of ranks=164807rank=111200 of ranks=164807rank=111300 of ranks=164807rank=111400 of ranks=164807rank=111500 of ranks=164807rank=111600 of ranks=164807rank=111700 of ranks=164807rank=111800 of ranks=164807rank=111900 of ranks=164807rank=112000 of ranks=164807rank=112100 of ranks=164807rank=112200 of ranks=164807rank=112300 of ranks=164807rank=112400 of ranks=164807rank=112500 of ranks=164807rank=112600 of ranks=164807rank=112700 of ranks=164807rank=112800 of ranks=164807rank=112900 of ranks=164807rank=113000 of ranks=164807rank=113100 of ranks=164807rank=113200 of ranks=164807rank=113300 of ranks=164807rank=113400 of ranks=164807rank=113500 of ranks=164807rank=113600 of ranks=164807rank=113700 of ranks=164807rank=113800 of ranks=164807rank=113900 of ranks=164807rank=114000 of ranks=164807rank=114100 of ranks=164807rank=114200 of ranks=164807rank=114300 of ranks=164807rank=114400 of ranks=164807rank=114500 of ranks=164807rank=114600 of ranks=164807rank=114700 of ranks=164807rank=114800 of ranks=164807rank=114900 of ranks=164807rank=115000 of ranks=164807rank=115100 of ranks=164807rank=115200 of ranks=164807rank=115300 of ranks=164807rank=115400 of ranks=164807rank=115500 of ranks=164807rank=115600 of ranks=164807rank=115700 of ranks=164807rank=115800 of ranks=164807rank=115900 of ranks=164807rank=116000 of ranks=164807rank=116100 of ranks=164807rank=116200 of ranks=164807rank=116300 of ranks=164807rank=116400 of ranks=164807rank=116500 of ranks=164807rank=116600 of ranks=164807rank=116700 of ranks=164807rank=116800 of ranks=164807rank=116900 of ranks=164807rank=117000 of ranks=164807rank=117100 of ranks=164807rank=117200 of ranks=164807rank=117300 of ranks=164807rank=117400 of ranks=164807rank=117500 of ranks=164807rank=117600 of ranks=164807rank=117700 of ranks=164807rank=117800 of ranks=164807rank=117900 of ranks=164807rank=118000 of ranks=164807rank=118100 of ranks=164807rank=118200 of ranks=164807rank=118300 of ranks=164807rank=118400 of ranks=164807rank=118500 of ranks=164807rank=118600 of ranks=164807rank=118700 of ranks=164807rank=118800 of ranks=164807rank=118900 of ranks=164807rank=119000 of ranks=164807rank=119100 of ranks=164807rank=119200 of ranks=164807rank=119300 of ranks=164807rank=119400 of ranks=164807rank=119500 of ranks=164807rank=119600 of ranks=164807rank=119700 of ranks=164807rank=119800 of ranks=164807rank=119900 of ranks=164807rank=120000 of ranks=164807rank=120100 of ranks=164807rank=120200 of ranks=164807rank=120300 of ranks=164807rank=120400 of ranks=164807rank=120500 of ranks=164807rank=120600 of ranks=164807rank=120700 of ranks=164807rank=120800 of ranks=164807rank=120900 of ranks=164807rank=121000 of ranks=164807rank=121100 of ranks=164807rank=121200 of ranks=164807rank=121300 of ranks=164807rank=121400 of ranks=164807rank=121500 of ranks=164807rank=121600 of ranks=164807rank=121700 of ranks=164807rank=121800 of ranks=164807rank=121900 of ranks=164807rank=122000 of ranks=164807rank=122100 of ranks=164807rank=122200 of ranks=164807rank=122300 of ranks=164807rank=122400 of ranks=164807rank=122500 of ranks=164807rank=122600 of ranks=164807rank=122700 of ranks=164807rank=122800 of ranks=164807rank=122900 of ranks=164807rank=123000 of ranks=164807rank=123100 of ranks=164807rank=123200 of ranks=164807rank=123300 of ranks=164807rank=123400 of ranks=164807rank=123500 of ranks=164807rank=123600 of ranks=164807rank=123700 of ranks=164807rank=123800 of ranks=164807rank=123900 of ranks=164807rank=124000 of ranks=164807rank=124100 of ranks=164807rank=124200 of ranks=164807rank=124300 of ranks=164807rank=124400 of ranks=164807rank=124500 of ranks=164807rank=124600 of ranks=164807rank=124700 of ranks=164807rank=124800 of ranks=164807rank=124900 of ranks=164807rank=125000 of ranks=164807rank=125100 of ranks=164807rank=125200 of ranks=164807rank=125300 of ranks=164807rank=125400 of ranks=164807rank=125500 of ranks=164807rank=125600 of ranks=164807rank=125700 of ranks=164807rank=125800 of ranks=164807rank=125900 of ranks=164807rank=126000 of ranks=164807rank=126100 of ranks=164807rank=126200 of ranks=164807rank=126300 of ranks=164807rank=126400 of ranks=164807rank=126500 of ranks=164807rank=126600 of ranks=164807rank=126700 of ranks=164807rank=126800 of ranks=164807rank=126900 of ranks=164807rank=127000 of ranks=164807rank=127100 of ranks=164807rank=127200 of ranks=164807rank=127300 of ranks=164807rank=127400 of ranks=164807rank=127500 of ranks=164807rank=127600 of ranks=164807rank=127700 of ranks=164807rank=127800 of ranks=164807rank=127900 of ranks=164807rank=128000 of ranks=164807rank=128100 of ranks=164807rank=128200 of ranks=164807rank=128300 of ranks=164807rank=128400 of ranks=164807rank=128500 of ranks=164807rank=128600 of ranks=164807rank=128700 of ranks=164807rank=128800 of ranks=164807rank=128900 of ranks=164807rank=129000 of ranks=164807rank=129100 of ranks=164807rank=129200 of ranks=164807rank=129300 of ranks=164807rank=129400 of ranks=164807rank=129500 of ranks=164807rank=129600 of ranks=164807rank=129700 of ranks=164807rank=129800 of ranks=164807rank=129900 of ranks=164807rank=130000 of ranks=164807rank=130100 of ranks=164807rank=130200 of ranks=164807rank=130300 of ranks=164807rank=130400 of ranks=164807rank=130500 of ranks=164807rank=130600 of ranks=164807rank=130700 of ranks=164807rank=130800 of ranks=164807rank=130900 of ranks=164807rank=131000 of ranks=164807rank=131100 of ranks=164807rank=131200 of ranks=164807rank=131300 of ranks=164807rank=131400 of ranks=164807rank=131500 of ranks=164807rank=131600 of ranks=164807rank=131700 of ranks=164807rank=131800 of ranks=164807rank=131900 of ranks=164807rank=132000 of ranks=164807rank=132100 of ranks=164807rank=132200 of ranks=164807rank=132300 of ranks=164807rank=132400 of ranks=164807rank=132500 of ranks=164807rank=132600 of ranks=164807rank=132700 of ranks=164807rank=132800 of ranks=164807rank=132900 of ranks=164807rank=133000 of ranks=164807rank=133100 of ranks=164807rank=133200 of ranks=164807rank=133300 of ranks=164807rank=133400 of ranks=164807rank=133500 of ranks=164807rank=133600 of ranks=164807rank=133700 of ranks=164807rank=133800 of ranks=164807rank=133900 of ranks=164807rank=134000 of ranks=164807rank=134100 of ranks=164807rank=134200 of ranks=164807rank=134300 of ranks=164807rank=134400 of ranks=164807rank=134500 of ranks=164807rank=134600 of ranks=164807rank=134700 of ranks=164807rank=134800 of ranks=164807rank=134900 of ranks=164807rank=135000 of ranks=164807rank=135100 of ranks=164807rank=135200 of ranks=164807rank=135300 of ranks=164807rank=135400 of ranks=164807rank=135500 of ranks=164807rank=135600 of ranks=164807rank=135700 of ranks=164807rank=135800 of ranks=164807rank=135900 of ranks=164807rank=136000 of ranks=164807rank=136100 of ranks=164807rank=136200 of ranks=164807rank=136300 of ranks=164807rank=136400 of ranks=164807rank=136500 of ranks=164807rank=136600 of ranks=164807rank=136700 of ranks=164807rank=136800 of ranks=164807rank=136900 of ranks=164807rank=137000 of ranks=164807rank=137100 of ranks=164807rank=137200 of ranks=164807rank=137300 of ranks=164807rank=137400 of ranks=164807rank=137500 of ranks=164807rank=137600 of ranks=164807rank=137700 of ranks=164807rank=137800 of ranks=164807rank=137900 of ranks=164807rank=138000 of ranks=164807rank=138100 of ranks=164807rank=138200 of ranks=164807rank=138300 of ranks=164807rank=138400 of ranks=164807rank=138500 of ranks=164807rank=138600 of ranks=164807rank=138700 of ranks=164807rank=138800 of ranks=164807rank=138900 of ranks=164807rank=139000 of ranks=164807rank=139100 of ranks=164807rank=139200 of ranks=164807rank=139300 of ranks=164807rank=139400 of ranks=164807rank=139500 of ranks=164807rank=139600 of ranks=164807rank=139700 of ranks=164807rank=139800 of ranks=164807rank=139900 of ranks=164807rank=140000 of ranks=164807rank=140100 of ranks=164807rank=140200 of ranks=164807rank=140300 of ranks=164807rank=140400 of ranks=164807rank=140500 of ranks=164807rank=140600 of ranks=164807rank=140700 of ranks=164807rank=140800 of ranks=164807rank=140900 of ranks=164807rank=141000 of ranks=164807rank=141100 of ranks=164807rank=141200 of ranks=164807rank=141300 of ranks=164807rank=141400 of ranks=164807rank=141500 of ranks=164807rank=141600 of ranks=164807rank=141700 of ranks=164807rank=141800 of ranks=164807rank=141900 of ranks=164807rank=142000 of ranks=164807rank=142100 of ranks=164807rank=142200 of ranks=164807rank=142300 of ranks=164807rank=142400 of ranks=164807rank=142500 of ranks=164807rank=142600 of ranks=164807rank=142700 of ranks=164807rank=142800 of ranks=164807rank=142900 of ranks=164807rank=143000 of ranks=164807rank=143100 of ranks=164807rank=143200 of ranks=164807rank=143300 of ranks=164807rank=143400 of ranks=164807rank=143500 of ranks=164807rank=143600 of ranks=164807rank=143700 of ranks=164807rank=143800 of ranks=164807rank=143900 of ranks=164807rank=144000 of ranks=164807rank=144100 of ranks=164807rank=144200 of ranks=164807rank=144300 of ranks=164807rank=144400 of ranks=164807rank=144500 of ranks=164807rank=144600 of ranks=164807rank=144700 of ranks=164807rank=144800 of ranks=164807rank=144900 of ranks=164807rank=145000 of ranks=164807rank=145100 of ranks=164807rank=145200 of ranks=164807rank=145300 of ranks=164807rank=145400 of ranks=164807rank=145500 of ranks=164807rank=145600 of ranks=164807rank=145700 of ranks=164807rank=145800 of ranks=164807rank=145900 of ranks=164807rank=146000 of ranks=164807rank=146100 of ranks=164807rank=146200 of ranks=164807rank=146300 of ranks=164807rank=146400 of ranks=164807rank=146500 of ranks=164807rank=146600 of ranks=164807rank=146700 of ranks=164807rank=146800 of ranks=164807rank=146900 of ranks=164807rank=147000 of ranks=164807rank=147100 of ranks=164807rank=147200 of ranks=164807rank=147300 of ranks=164807rank=147400 of ranks=164807rank=147500 of ranks=164807rank=147600 of ranks=164807rank=147700 of ranks=164807rank=147800 of ranks=164807rank=147900 of ranks=164807rank=148000 of ranks=164807rank=148100 of ranks=164807rank=148200 of ranks=164807rank=148300 of ranks=164807rank=148400 of ranks=164807rank=148500 of ranks=164807rank=148600 of ranks=164807rank=148700 of ranks=164807rank=148800 of ranks=164807rank=148900 of ranks=164807rank=149000 of ranks=164807rank=149100 of ranks=164807rank=149200 of ranks=164807rank=149300 of ranks=164807rank=149400 of ranks=164807rank=149500 of ranks=164807rank=149600 of ranks=164807rank=149700 of ranks=164807rank=149800 of ranks=164807rank=149900 of ranks=164807rank=150000 of ranks=164807rank=150100 of ranks=164807rank=150200 of ranks=164807rank=150300 of ranks=164807rank=150400 of ranks=164807rank=150500 of ranks=164807rank=150600 of ranks=164807rank=150700 of ranks=164807rank=150800 of ranks=164807rank=150900 of ranks=164807rank=151000 of ranks=164807rank=151100 of ranks=164807rank=151200 of ranks=164807rank=151300 of ranks=164807rank=151400 of ranks=164807rank=151500 of ranks=164807rank=151600 of ranks=164807rank=151700 of ranks=164807rank=151800 of ranks=164807rank=151900 of ranks=164807rank=152000 of ranks=164807rank=152100 of ranks=164807rank=152200 of ranks=164807rank=152300 of ranks=164807rank=152400 of ranks=164807rank=152500 of ranks=164807rank=152600 of ranks=164807rank=152700 of ranks=164807rank=152800 of ranks=164807rank=152900 of ranks=164807rank=153000 of ranks=164807rank=153100 of ranks=164807rank=153200 of ranks=164807rank=153300 of ranks=164807rank=153400 of ranks=164807rank=153500 of ranks=164807rank=153600 of ranks=164807rank=153700 of ranks=164807rank=153800 of ranks=164807rank=153900 of ranks=164807rank=154000 of ranks=164807rank=154100 of ranks=164807rank=154200 of ranks=164807rank=154300 of ranks=164807rank=154400 of ranks=164807rank=154500 of ranks=164807rank=154600 of ranks=164807rank=154700 of ranks=164807rank=154800 of ranks=164807rank=154900 of ranks=164807rank=155000 of ranks=164807rank=155100 of ranks=164807rank=155200 of ranks=164807rank=155300 of ranks=164807rank=155400 of ranks=164807rank=155500 of ranks=164807rank=155600 of ranks=164807rank=155700 of ranks=164807rank=155800 of ranks=164807rank=155900 of ranks=164807rank=156000 of ranks=164807rank=156100 of ranks=164807rank=156200 of ranks=164807rank=156300 of ranks=164807rank=156400 of ranks=164807rank=156500 of ranks=164807rank=156600 of ranks=164807rank=156700 of ranks=164807rank=156800 of ranks=164807rank=156900 of ranks=164807rank=157000 of ranks=164807rank=157100 of ranks=164807rank=157200 of ranks=164807rank=157300 of ranks=164807rank=157400 of ranks=164807rank=157500 of ranks=164807rank=157600 of ranks=164807rank=157700 of ranks=164807rank=157800 of ranks=164807rank=157900 of ranks=164807rank=158000 of ranks=164807rank=158100 of ranks=164807rank=158200 of ranks=164807rank=158300 of ranks=164807rank=158400 of ranks=164807rank=158500 of ranks=164807rank=158600 of ranks=164807rank=158700 of ranks=164807rank=158800 of ranks=164807rank=158900 of ranks=164807rank=159000 of ranks=164807rank=159100 of ranks=164807rank=159200 of ranks=164807rank=159300 of ranks=164807rank=159400 of ranks=164807rank=159500 of ranks=164807rank=159600 of ranks=164807rank=159700 of ranks=164807rank=159800 of ranks=164807rank=159900 of ranks=164807rank=160000 of ranks=164807rank=160100 of ranks=164807rank=160200 of ranks=164807rank=160300 of ranks=164807rank=160400 of ranks=164807rank=160500 of ranks=164807rank=160600 of ranks=164807rank=160700 of ranks=164807rank=160800 of ranks=164807rank=160900 of ranks=164807rank=161000 of ranks=164807rank=161100 of ranks=164807rank=161200 of ranks=164807rank=161300 of ranks=164807rank=161400 of ranks=164807rank=161500 of ranks=164807rank=161600 of ranks=164807rank=161700 of ranks=164807rank=161800 of ranks=164807rank=161900 of ranks=164807rank=162000 of ranks=164807rank=162100 of ranks=164807rank=162200 of ranks=164807rank=162300 of ranks=164807rank=162400 of ranks=164807rank=162500 of ranks=164807rank=162600 of ranks=164807rank=162700 of ranks=164807rank=162800 of ranks=164807rank=162900 of ranks=164807rank=163000 of ranks=164807rank=163100 of ranks=164807rank=163200 of ranks=164807rank=163300 of ranks=164807rank=163400 of ranks=164807rank=163500 of ranks=164807rank=163600 of ranks=164807rank=163700 of ranks=164807rank=163800 of ranks=164807rank=163900 of ranks=164807rank=164000 of ranks=164807rank=164100 of ranks=164807rank=164200 of ranks=164807rank=164300 of ranks=164807rank=164400 of ranks=164807rank=164500 of ranks=164807rank=164600 of ranks=164807rank=164700 of ranks=164807rank=164800 of ranks=164807

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              93.3275    478   4226     20    498           70.0060
   1 car                    97.9297  49996  76903    320  50316           69.1431
   2 truck                  93.4634   1807  10008     18   1825           58.7859
   3 bus                    87.8078    359   3630      7    366           63.6425
   4 pedestrian             93.9339   4112  13288    147   4259           67.0629

for conf_thresh=0.25, precision=0.79, recall=0.95, F1 score=0.86
for conf_thresh=0.25, TP=54666, FP=14871, FN=2598, average IoU=68.66%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=93.29%
Total detection time: 133 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
New best mAP, saving weights!
Saving weights to /workspace/.cache/splits/combined_best.weights
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b53ca00000
5061: loss=4.030, avg loss=3.814, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 323904 images, time remaining=3.5 hours
5062: loss=3.106, avg loss=3.743, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=2.9 seconds, 323968 images, time remaining=3.5 hours
5063: loss=3.425, avg loss=3.711, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 324032 images, time remaining=3.5 hours
5064: loss=3.485, avg loss=3.689, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 324096 images, time remaining=3.5 hours
5065: loss=3.350, avg loss=3.655, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 324160 images, time remaining=3.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5066: loss=3.518, avg loss=3.641, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=3.2 seconds, train=3.0 seconds, 324224 images, time remaining=3.5 hours
5067: loss=3.243, avg loss=3.601, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 324288 images, time remaining=3.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5068: loss=3.056, avg loss=3.547, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=3.3 seconds, train=2.7 seconds, 324352 images, time remaining=3.5 hours
5069: loss=3.781, avg loss=3.570, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 324416 images, time remaining=3.5 hours
5070: loss=2.692, avg loss=3.482, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 324480 images, time remaining=3.5 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5071: loss=3.802, avg loss=3.514, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 324544 images, time remaining=3.5 hours
5072: loss=4.363, avg loss=3.599, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.0 seconds, train=5.9 seconds, 324608 images, time remaining=3.5 hours
5073: loss=4.303, avg loss=3.670, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 324672 images, time remaining=3.5 hours
5074: loss=4.971, avg loss=3.800, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 324736 images, time remaining=3.5 hours
5075: loss=4.003, avg loss=3.820, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=3.7 seconds, train=5.9 seconds, 324800 images, time remaining=3.5 hours
5076: loss=3.771, avg loss=3.815, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.8 seconds, train=5.8 seconds, 324864 images, time remaining=3.5 hours
5077: loss=3.579, avg loss=3.792, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 324928 images, time remaining=3.5 hours
5078: loss=3.981, avg loss=3.811, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 324992 images, time remaining=3.5 hours
5079: loss=3.487, avg loss=3.778, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 325056 images, time remaining=3.5 hours
5080: loss=4.370, avg loss=3.837, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 325120 images, time remaining=3.5 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b5fa000000
5081: loss=4.691, avg loss=3.923, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 325184 images, time remaining=3.5 hours
5082: loss=4.727, avg loss=4.003, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 325248 images, time remaining=3.5 hours
5083: loss=4.148, avg loss=4.018, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 325312 images, time remaining=3.5 hours
5084: loss=4.390, avg loss=4.055, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 325376 images, time remaining=3.5 hours
5085: loss=4.799, avg loss=4.129, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 325440 images, time remaining=3.5 hours
5086: loss=4.786, avg loss=4.195, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 325504 images, time remaining=3.5 hours
5087: loss=3.624, avg loss=4.138, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 325568 images, time remaining=3.5 hours
5088: loss=3.392, avg loss=4.063, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 325632 images, time remaining=3.5 hours
5089: loss=3.666, avg loss=4.024, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 325696 images, time remaining=3.5 hours
5090: loss=4.360, avg loss=4.057, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 325760 images, time remaining=3.5 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b4b4000000
5091: loss=4.254, avg loss=4.077, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 325824 images, time remaining=3.5 hours
5092: loss=5.583, avg loss=4.227, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 325888 images, time remaining=3.5 hours
5093: loss=4.755, avg loss=4.280, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 325952 images, time remaining=3.5 hours
5094: loss=3.929, avg loss=4.245, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 326016 images, time remaining=3.5 hours
5095: loss=4.129, avg loss=4.233, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 326080 images, time remaining=3.5 hours
5096: loss=3.107, avg loss=4.121, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 326144 images, time remaining=3.5 hours
5097: loss=3.526, avg loss=4.061, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 326208 images, time remaining=3.5 hours
5098: loss=3.900, avg loss=4.045, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 326272 images, time remaining=3.5 hours
5099: loss=4.029, avg loss=4.044, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 326336 images, time remaining=3.5 hours
5100: loss=3.140, avg loss=3.953, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 326400 images, time remaining=3.5 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5101: loss=5.050, avg loss=4.063, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=5.7 seconds, 326464 images, time remaining=3.5 hours
5102: loss=4.433, avg loss=4.100, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.0 seconds, train=5.6 seconds, 326528 images, time remaining=3.5 hours
5103: loss=5.462, avg loss=4.236, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.0 seconds, train=5.7 seconds, 326592 images, time remaining=3.5 hours
5104: loss=4.957, avg loss=4.308, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 326656 images, time remaining=3.5 hours
5105: loss=4.032, avg loss=4.281, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 326720 images, time remaining=3.5 hours
5106: loss=3.937, avg loss=4.246, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 326784 images, time remaining=3.5 hours
5107: loss=4.185, avg loss=4.240, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 326848 images, time remaining=3.5 hours
5108: loss=4.752, avg loss=4.291, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.0 seconds, train=5.6 seconds, 326912 images, time remaining=3.5 hours
5109: loss=5.985, avg loss=4.461, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=5.7 seconds, 326976 images, time remaining=3.5 hours
5110: loss=4.019, avg loss=4.416, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 327040 images, time remaining=3.5 hours
Resizing, random_coef=1.40, batch=4, 896x672
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2e4000000
5111: loss=4.157, avg loss=4.391, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 327104 images, time remaining=3.5 hours
5112: loss=3.622, avg loss=4.314, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.9 seconds, train=2.5 seconds, 327168 images, time remaining=3.5 hours
5113: loss=3.358, avg loss=4.218, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 327232 images, time remaining=3.5 hours
5114: loss=3.404, avg loss=4.137, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 327296 images, time remaining=3.5 hours
5115: loss=3.110, avg loss=4.034, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 327360 images, time remaining=3.5 hours
5116: loss=3.478, avg loss=3.978, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 327424 images, time remaining=3.4 hours
5117: loss=2.575, avg loss=3.838, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.5 seconds, 327488 images, time remaining=3.4 hours
5118: loss=4.112, avg loss=3.866, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.6 seconds, 327552 images, time remaining=3.4 hours
5119: loss=4.297, avg loss=3.909, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 327616 images, time remaining=3.4 hours
5120: loss=3.357, avg loss=3.854, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 327680 images, time remaining=3.4 hours
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5121: loss=6.468, avg loss=4.115, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 327744 images, time remaining=3.4 hours
5122: loss=6.061, avg loss=4.310, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 327808 images, time remaining=3.4 hours
5123: loss=5.966, avg loss=4.475, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 327872 images, time remaining=3.4 hours
5124: loss=4.886, avg loss=4.516, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.1 seconds, train=5.7 seconds, 327936 images, time remaining=3.4 hours
5125: loss=4.320, avg loss=4.497, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 328000 images, time remaining=3.4 hours
5126: loss=4.330, avg loss=4.480, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 328064 images, time remaining=3.4 hours
5127: loss=4.211, avg loss=4.453, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 328128 images, time remaining=3.4 hours
5128: loss=4.361, avg loss=4.444, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 328192 images, time remaining=3.4 hours
5129: loss=3.464, avg loss=4.346, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 328256 images, time remaining=3.4 hours
5130: loss=4.309, avg loss=4.342, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 328320 images, time remaining=3.4 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b2ec000000
5131: loss=5.354, avg loss=4.443, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 328384 images, time remaining=3.4 hours
5132: loss=4.692, avg loss=4.468, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 328448 images, time remaining=3.4 hours
5133: loss=4.553, avg loss=4.477, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 328512 images, time remaining=3.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5134: loss=4.415, avg loss=4.471, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=3.0 seconds, train=2.1 seconds, 328576 images, time remaining=3.4 hours
5135: loss=3.107, avg loss=4.334, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 328640 images, time remaining=3.4 hours
5136: loss=3.866, avg loss=4.287, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 328704 images, time remaining=3.4 hours
5137: loss=3.884, avg loss=4.247, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 328768 images, time remaining=3.4 hours
5138: loss=3.452, avg loss=4.167, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 328832 images, time remaining=3.4 hours
5139: loss=3.003, avg loss=4.051, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 328896 images, time remaining=3.4 hours
5140: loss=4.060, avg loss=4.052, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 328960 images, time remaining=3.4 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5141: loss=6.619, avg loss=4.309, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.9 seconds, train=5.0 seconds, 329024 images, time remaining=3.4 hours
5142: loss=5.980, avg loss=4.476, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 329088 images, time remaining=3.4 hours
5143: loss=6.113, avg loss=4.639, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 329152 images, time remaining=3.4 hours
5144: loss=4.977, avg loss=4.673, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=5.0 seconds, 329216 images, time remaining=3.4 hours
5145: loss=5.700, avg loss=4.776, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 329280 images, time remaining=3.4 hours
5146: loss=4.073, avg loss=4.706, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=5.1 seconds, 329344 images, time remaining=3.4 hours
5147: loss=4.098, avg loss=4.645, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 329408 images, time remaining=3.4 hours
5148: loss=4.899, avg loss=4.670, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 329472 images, time remaining=3.4 hours
5149: loss=4.380, avg loss=4.641, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 329536 images, time remaining=3.4 hours
5150: loss=4.863, avg loss=4.663, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 329600 images, time remaining=3.4 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5151: loss=4.678, avg loss=4.665, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=4.2 seconds, 329664 images, time remaining=3.4 hours
5152: loss=4.156, avg loss=4.614, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 329728 images, time remaining=3.4 hours
5153: loss=3.903, avg loss=4.543, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.2 seconds, 329792 images, time remaining=3.4 hours
5154: loss=4.090, avg loss=4.498, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 329856 images, time remaining=3.4 hours
5155: loss=3.964, avg loss=4.444, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 329920 images, time remaining=3.4 hours
5156: loss=5.008, avg loss=4.501, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 329984 images, time remaining=3.4 hours
5157: loss=3.961, avg loss=4.447, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.2 seconds, 330048 images, time remaining=3.4 hours
5158: loss=3.390, avg loss=4.341, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 330112 images, time remaining=3.4 hours
5159: loss=3.662, avg loss=4.273, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 330176 images, time remaining=3.4 hours
5160: loss=3.542, avg loss=4.200, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 330240 images, time remaining=3.4 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5161: loss=4.700, avg loss=4.250, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.5 seconds, 330304 images, time remaining=3.4 hours
5162: loss=4.213, avg loss=4.246, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 330368 images, time remaining=3.4 hours
5163: loss=4.705, avg loss=4.292, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 330432 images, time remaining=3.4 hours
5164: loss=3.981, avg loss=4.261, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 330496 images, time remaining=3.4 hours
5165: loss=3.254, avg loss=4.160, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 330560 images, time remaining=3.4 hours
5166: loss=3.591, avg loss=4.103, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.9 seconds, train=4.4 seconds, 330624 images, time remaining=3.4 hours
5167: loss=4.054, avg loss=4.098, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 330688 images, time remaining=3.4 hours
5168: loss=3.574, avg loss=4.046, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 330752 images, time remaining=3.4 hours
5169: loss=3.444, avg loss=3.986, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 330816 images, time remaining=3.4 hours
5170: loss=4.336, avg loss=4.021, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 330880 images, time remaining=3.4 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5171: loss=3.689, avg loss=3.988, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.3 seconds, 330944 images, time remaining=3.4 hours
5172: loss=3.514, avg loss=3.940, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.4 seconds, 331008 images, time remaining=3.4 hours
5173: loss=3.013, avg loss=3.848, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 331072 images, time remaining=3.4 hours
5174: loss=3.159, avg loss=3.779, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 331136 images, time remaining=3.4 hours
5175: loss=3.614, avg loss=3.762, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 331200 images, time remaining=3.4 hours
5176: loss=3.340, avg loss=3.720, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 331264 images, time remaining=3.4 hours
5177: loss=3.856, avg loss=3.734, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.2 seconds, 331328 images, time remaining=3.4 hours
5178: loss=3.600, avg loss=3.720, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.1 seconds, train=4.4 seconds, 331392 images, time remaining=3.4 hours
5179: loss=3.686, avg loss=3.717, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.2 seconds, train=4.4 seconds, 331456 images, time remaining=3.4 hours
5180: loss=3.215, avg loss=3.667, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 331520 images, time remaining=3.4 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b500e00000
5181: loss=3.489, avg loss=3.649, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 331584 images, time remaining=3.4 hours
5182: loss=3.811, avg loss=3.665, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 331648 images, time remaining=3.4 hours
5183: loss=3.586, avg loss=3.657, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 331712 images, time remaining=3.4 hours
5184: loss=4.375, avg loss=3.729, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 331776 images, time remaining=3.4 hours
5185: loss=3.424, avg loss=3.698, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 331840 images, time remaining=3.4 hours
5186: loss=3.756, avg loss=3.704, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 331904 images, time remaining=3.4 hours
5187: loss=3.420, avg loss=3.676, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 331968 images, time remaining=3.4 hours
5188: loss=2.917, avg loss=3.600, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 332032 images, time remaining=3.4 hours
5189: loss=3.063, avg loss=3.546, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 332096 images, time remaining=3.4 hours
5190: loss=2.890, avg loss=3.481, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=1.9 seconds, 332160 images, time remaining=3.4 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b8ab800000
5191: loss=3.678, avg loss=3.500, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 332224 images, time remaining=3.4 hours
5192: loss=3.572, avg loss=3.507, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 332288 images, time remaining=3.4 hours
5193: loss=4.126, avg loss=3.569, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 332352 images, time remaining=3.4 hours
5194: loss=3.671, avg loss=3.579, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 332416 images, time remaining=3.4 hours
5195: loss=3.256, avg loss=3.547, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 332480 images, time remaining=3.4 hours
5196: loss=3.007, avg loss=3.493, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 332544 images, time remaining=3.4 hours
5197: loss=3.087, avg loss=3.453, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 332608 images, time remaining=3.3 hours
5198: loss=3.491, avg loss=3.456, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 332672 images, time remaining=3.3 hours
5199: loss=3.617, avg loss=3.472, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 332736 images, time remaining=3.3 hours
5200: loss=3.470, avg loss=3.472, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 332800 images, time remaining=3.3 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1184x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5201: loss=4.047, avg loss=3.530, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 332864 images, time remaining=3.3 hours
5202: loss=3.748, avg loss=3.552, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 332928 images, time remaining=3.3 hours
5203: loss=3.404, avg loss=3.537, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 332992 images, time remaining=3.3 hours
5204: loss=3.535, avg loss=3.537, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 333056 images, time remaining=3.3 hours
5205: loss=3.458, avg loss=3.529, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.5 seconds, 333120 images, time remaining=3.3 hours
5206: loss=3.300, avg loss=3.506, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.1 seconds, train=4.6 seconds, 333184 images, time remaining=3.3 hours
5207: loss=4.002, avg loss=3.556, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 333248 images, time remaining=3.3 hours
5208: loss=3.396, avg loss=3.540, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.1 seconds, train=4.6 seconds, 333312 images, time remaining=3.3 hours
5209: loss=3.497, avg loss=3.535, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 333376 images, time remaining=3.3 hours
5210: loss=3.653, avg loss=3.547, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.5 seconds, 333440 images, time remaining=3.3 hours
Resizing, random_coef=1.40, batch=4, 1184x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5211: loss=3.503, avg loss=3.543, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.5 seconds, 333504 images, time remaining=3.3 hours
5212: loss=3.803, avg loss=3.569, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.1 seconds, train=4.5 seconds, 333568 images, time remaining=3.3 hours
5213: loss=3.197, avg loss=3.532, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 333632 images, time remaining=3.3 hours
5214: loss=3.690, avg loss=3.547, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 333696 images, time remaining=3.3 hours
5215: loss=3.391, avg loss=3.532, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 333760 images, time remaining=3.3 hours
5216: loss=3.418, avg loss=3.520, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 333824 images, time remaining=3.3 hours
5217: loss=2.794, avg loss=3.448, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=4.4 seconds, 333888 images, time remaining=3.3 hours
5218: loss=3.490, avg loss=3.452, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=4.6 seconds, 333952 images, time remaining=3.3 hours
5219: loss=3.487, avg loss=3.456, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 334016 images, time remaining=3.3 hours
5220: loss=3.432, avg loss=3.453, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 334080 images, time remaining=3.3 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b6fd000000
5221: loss=3.154, avg loss=3.423, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 334144 images, time remaining=3.3 hours
5222: loss=2.971, avg loss=3.378, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.9 seconds, train=2.3 seconds, 334208 images, time remaining=3.3 hours
5223: loss=3.024, avg loss=3.343, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 334272 images, time remaining=3.3 hours
5224: loss=3.650, avg loss=3.373, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 334336 images, time remaining=3.3 hours
5225: loss=3.183, avg loss=3.354, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 334400 images, time remaining=3.3 hours
5226: loss=3.240, avg loss=3.343, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 334464 images, time remaining=3.3 hours
5227: loss=3.123, avg loss=3.321, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 334528 images, time remaining=3.3 hours
5228: loss=3.536, avg loss=3.342, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 334592 images, time remaining=3.3 hours
5229: loss=3.180, avg loss=3.326, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 334656 images, time remaining=3.3 hours
5230: loss=2.743, avg loss=3.268, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 334720 images, time remaining=3.3 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b6bfe00000
5231: loss=3.186, avg loss=3.260, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.7 seconds, 334784 images, time remaining=3.3 hours
5232: loss=3.216, avg loss=3.255, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 334848 images, time remaining=3.3 hours
5233: loss=2.804, avg loss=3.210, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 334912 images, time remaining=3.3 hours
5234: loss=3.295, avg loss=3.219, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 334976 images, time remaining=3.3 hours
5235: loss=3.248, avg loss=3.222, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 335040 images, time remaining=3.3 hours
5236: loss=3.002, avg loss=3.200, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.6 seconds, 335104 images, time remaining=3.3 hours
5237: loss=2.794, avg loss=3.159, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 335168 images, time remaining=3.3 hours
5238: loss=3.219, avg loss=3.165, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 335232 images, time remaining=3.3 hours
5239: loss=3.043, avg loss=3.153, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 335296 images, time remaining=3.3 hours
5240: loss=2.876, avg loss=3.125, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 335360 images, time remaining=3.3 hours
Resizing, random_coef=1.40, batch=4, 992x768
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5241: loss=3.020, avg loss=3.115, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=3.9 seconds, 335424 images, time remaining=3.3 hours
5242: loss=2.729, avg loss=3.076, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=3.8 seconds, 335488 images, time remaining=3.3 hours
5243: loss=3.266, avg loss=3.095, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=3.8 seconds, 335552 images, time remaining=3.3 hours
5244: loss=3.090, avg loss=3.095, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=3.9 seconds, 335616 images, time remaining=3.3 hours
5245: loss=3.682, avg loss=3.154, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=3.8 seconds, 335680 images, time remaining=3.3 hours
5246: loss=2.901, avg loss=3.128, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=3.8 seconds, 335744 images, time remaining=3.3 hours
5247: loss=3.216, avg loss=3.137, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=3.8 seconds, 335808 images, time remaining=3.3 hours
5248: loss=2.810, avg loss=3.104, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=3.7 seconds, 335872 images, time remaining=3.3 hours
5249: loss=3.230, avg loss=3.117, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=3.9 seconds, 335936 images, time remaining=3.3 hours
5250: loss=2.851, avg loss=3.090, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 336000 images, time remaining=3.3 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5251: loss=3.856, avg loss=3.167, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 336064 images, time remaining=3.3 hours
5252: loss=3.274, avg loss=3.178, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 336128 images, time remaining=3.3 hours
5253: loss=4.094, avg loss=3.269, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.9 seconds, train=5.5 seconds, 336192 images, time remaining=3.3 hours
5254: loss=3.301, avg loss=3.272, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.1 seconds, train=5.4 seconds, 336256 images, time remaining=3.3 hours
5255: loss=2.744, avg loss=3.220, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=4.2 seconds, train=5.6 seconds, 336320 images, time remaining=3.3 hours
5256: loss=3.589, avg loss=3.256, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 336384 images, time remaining=3.3 hours
5257: loss=3.337, avg loss=3.264, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 336448 images, time remaining=3.3 hours
5258: loss=3.423, avg loss=3.280, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 336512 images, time remaining=3.3 hours
5259: loss=3.650, avg loss=3.317, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 336576 images, time remaining=3.3 hours
5260: loss=3.286, avg loss=3.314, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 336640 images, time remaining=3.3 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b736600000
5261: loss=3.285, avg loss=3.311, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 336704 images, time remaining=3.3 hours
5262: loss=3.629, avg loss=3.343, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 336768 images, time remaining=3.3 hours
5263: loss=3.273, avg loss=3.336, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 336832 images, time remaining=3.3 hours
5264: loss=3.117, avg loss=3.314, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 336896 images, time remaining=3.3 hours
5265: loss=4.401, avg loss=3.423, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 336960 images, time remaining=3.3 hours
5266: loss=2.908, avg loss=3.371, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 337024 images, time remaining=3.3 hours
5267: loss=2.774, avg loss=3.312, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 337088 images, time remaining=3.3 hours
5268: loss=2.817, avg loss=3.262, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 337152 images, time remaining=3.3 hours
5269: loss=3.584, avg loss=3.294, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 337216 images, time remaining=3.3 hours
5270: loss=3.240, avg loss=3.289, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 337280 images, time remaining=3.3 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5271: loss=3.872, avg loss=3.347, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 337344 images, time remaining=3.3 hours
5272: loss=4.466, avg loss=3.459, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 337408 images, time remaining=3.3 hours
5273: loss=4.954, avg loss=3.608, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 337472 images, time remaining=3.3 hours
5274: loss=2.431, avg loss=3.491, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=4.3 seconds, 337536 images, time remaining=3.3 hours
5275: loss=3.340, avg loss=3.476, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 337600 images, time remaining=3.3 hours
5276: loss=3.081, avg loss=3.436, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 337664 images, time remaining=3.3 hours
5277: loss=3.880, avg loss=3.480, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 337728 images, time remaining=3.2 hours
5278: loss=2.820, avg loss=3.414, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 337792 images, time remaining=3.2 hours
5279: loss=2.920, avg loss=3.365, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 337856 images, time remaining=3.2 hours
5280: loss=3.318, avg loss=3.360, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 337920 images, time remaining=3.2 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b771c00000
5281: loss=3.658, avg loss=3.390, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 337984 images, time remaining=3.2 hours
5282: loss=4.177, avg loss=3.469, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 338048 images, time remaining=3.2 hours
5283: loss=4.177, avg loss=3.540, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 338112 images, time remaining=3.2 hours
5284: loss=4.086, avg loss=3.594, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 338176 images, time remaining=3.2 hours
5285: loss=3.212, avg loss=3.556, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 338240 images, time remaining=3.2 hours
5286: loss=2.753, avg loss=3.476, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 338304 images, time remaining=3.2 hours
5287: loss=2.865, avg loss=3.415, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 338368 images, time remaining=3.2 hours
5288: loss=3.446, avg loss=3.418, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 338432 images, time remaining=3.2 hours
5289: loss=3.770, avg loss=3.453, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 338496 images, time remaining=3.2 hours
5290: loss=3.910, avg loss=3.499, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 338560 images, time remaining=3.2 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b783800000
5291: loss=3.533, avg loss=3.502, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.0 seconds, train=2.4 seconds, 338624 images, time remaining=3.2 hours
5292: loss=3.051, avg loss=3.457, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 338688 images, time remaining=3.2 hours
5293: loss=3.424, avg loss=3.454, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=2.5 seconds, 338752 images, time remaining=3.2 hours
5294: loss=3.151, avg loss=3.423, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 338816 images, time remaining=3.2 hours
5295: loss=3.986, avg loss=3.480, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 338880 images, time remaining=3.2 hours
5296: loss=2.698, avg loss=3.402, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 338944 images, time remaining=3.2 hours
5297: loss=3.185, avg loss=3.380, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 339008 images, time remaining=3.2 hours
5298: loss=2.711, avg loss=3.313, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 339072 images, time remaining=3.2 hours
5299: loss=3.327, avg loss=3.314, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 339136 images, time remaining=3.2 hours
5300: loss=3.773, avg loss=3.360, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 339200 images, time remaining=3.2 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5301: loss=3.056, avg loss=3.330, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=5.0 seconds, 339264 images, time remaining=3.2 hours
5302: loss=2.959, avg loss=3.293, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 339328 images, time remaining=3.2 hours
5303: loss=2.599, avg loss=3.223, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 339392 images, time remaining=3.2 hours
5304: loss=3.978, avg loss=3.299, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 339456 images, time remaining=3.2 hours
5305: loss=3.269, avg loss=3.296, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 339520 images, time remaining=3.2 hours
5306: loss=3.633, avg loss=3.330, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 339584 images, time remaining=3.2 hours
5307: loss=3.073, avg loss=3.304, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.7 seconds, train=4.8 seconds, 339648 images, time remaining=3.2 hours
5308: loss=3.303, avg loss=3.304, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 339712 images, time remaining=3.2 hours
5309: loss=3.231, avg loss=3.297, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=3.0 seconds, train=4.7 seconds, 339776 images, time remaining=3.2 hours
5310: loss=3.251, avg loss=3.292, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=3.1 seconds, train=4.8 seconds, 339840 images, time remaining=3.2 hours
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5311: loss=3.531, avg loss=3.316, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 339904 images, time remaining=3.2 hours
5312: loss=3.695, avg loss=3.354, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 339968 images, time remaining=3.2 hours
5313: loss=3.411, avg loss=3.360, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.9 seconds, train=3.9 seconds, 340032 images, time remaining=3.2 hours
5314: loss=3.431, avg loss=3.367, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.5 seconds, train=4.0 seconds, 340096 images, time remaining=3.2 hours
5315: loss=2.870, avg loss=3.317, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 340160 images, time remaining=3.2 hours
5316: loss=3.111, avg loss=3.296, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 340224 images, time remaining=3.2 hours
5317: loss=2.708, avg loss=3.237, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 340288 images, time remaining=3.2 hours
5318: loss=3.578, avg loss=3.272, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 340352 images, time remaining=3.2 hours
5319: loss=2.948, avg loss=3.239, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 340416 images, time remaining=3.2 hours
5320: loss=3.138, avg loss=3.229, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 340480 images, time remaining=3.2 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5321: loss=3.264, avg loss=3.233, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 340544 images, time remaining=3.2 hours
5322: loss=4.073, avg loss=3.317, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 340608 images, time remaining=3.2 hours
5323: loss=3.112, avg loss=3.296, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 340672 images, time remaining=3.2 hours
5324: loss=3.984, avg loss=3.365, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=5.0 seconds, 340736 images, time remaining=3.2 hours
5325: loss=3.586, avg loss=3.387, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 340800 images, time remaining=3.2 hours
5326: loss=2.517, avg loss=3.300, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 340864 images, time remaining=3.2 hours
5327: loss=3.403, avg loss=3.310, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.9 seconds, 340928 images, time remaining=3.2 hours
5328: loss=2.971, avg loss=3.276, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 340992 images, time remaining=3.2 hours
5329: loss=3.342, avg loss=3.283, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 341056 images, time remaining=3.2 hours
5330: loss=3.644, avg loss=3.319, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 341120 images, time remaining=3.2 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b64b800000
5331: loss=3.274, avg loss=3.315, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 341184 images, time remaining=3.2 hours
5332: loss=3.541, avg loss=3.337, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 341248 images, time remaining=3.2 hours
5333: loss=2.904, avg loss=3.294, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 341312 images, time remaining=3.2 hours
5334: loss=3.022, avg loss=3.267, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 341376 images, time remaining=3.2 hours
5335: loss=2.920, avg loss=3.232, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 341440 images, time remaining=3.2 hours
5336: loss=3.114, avg loss=3.220, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 341504 images, time remaining=3.2 hours
5337: loss=3.524, avg loss=3.251, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 341568 images, time remaining=3.2 hours
5338: loss=3.374, avg loss=3.263, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 341632 images, time remaining=3.2 hours
5339: loss=3.047, avg loss=3.241, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 341696 images, time remaining=3.2 hours
5340: loss=3.146, avg loss=3.232, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 341760 images, time remaining=3.2 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b5ea600000
5341: loss=3.150, avg loss=3.224, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 341824 images, time remaining=3.2 hours
5342: loss=3.077, avg loss=3.209, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 341888 images, time remaining=3.2 hours
5343: loss=2.589, avg loss=3.147, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 341952 images, time remaining=3.2 hours
5344: loss=3.542, avg loss=3.186, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 342016 images, time remaining=3.2 hours
5345: loss=2.266, avg loss=3.094, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 342080 images, time remaining=3.2 hours
5346: loss=2.734, avg loss=3.058, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 342144 images, time remaining=3.2 hours
5347: loss=3.045, avg loss=3.057, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 342208 images, time remaining=3.2 hours
5348: loss=2.891, avg loss=3.040, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 342272 images, time remaining=3.2 hours
5349: loss=2.732, avg loss=3.010, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 342336 images, time remaining=3.2 hours
5350: loss=3.744, avg loss=3.083, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 342400 images, time remaining=3.2 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b83a400000
5351: loss=3.176, avg loss=3.092, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 342464 images, time remaining=3.2 hours
5352: loss=2.768, avg loss=3.060, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 342528 images, time remaining=3.2 hours
5353: loss=3.446, avg loss=3.099, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 342592 images, time remaining=3.2 hours
5354: loss=3.065, avg loss=3.095, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 342656 images, time remaining=3.1 hours
5355: loss=3.556, avg loss=3.141, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=2.6 seconds, 342720 images, time remaining=3.1 hours
5356: loss=3.046, avg loss=3.132, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 342784 images, time remaining=3.1 hours
5357: loss=2.852, avg loss=3.104, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 342848 images, time remaining=3.1 hours
5358: loss=2.616, avg loss=3.055, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 342912 images, time remaining=3.1 hours
5359: loss=3.112, avg loss=3.061, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 342976 images, time remaining=3.1 hours
5360: loss=3.114, avg loss=3.066, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 343040 images, time remaining=3.1 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5361: loss=2.615, avg loss=3.021, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 343104 images, time remaining=3.1 hours
5362: loss=3.300, avg loss=3.049, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.2 seconds, 343168 images, time remaining=3.1 hours
5363: loss=3.313, avg loss=3.075, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.2 seconds, 343232 images, time remaining=3.1 hours
5364: loss=3.160, avg loss=3.084, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 343296 images, time remaining=3.1 hours
5365: loss=3.456, avg loss=3.121, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=4.2 seconds, 343360 images, time remaining=3.1 hours
5366: loss=2.526, avg loss=3.061, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 343424 images, time remaining=3.1 hours
5367: loss=3.681, avg loss=3.123, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 343488 images, time remaining=3.1 hours
5368: loss=3.291, avg loss=3.140, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 343552 images, time remaining=3.1 hours
5369: loss=2.923, avg loss=3.118, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 343616 images, time remaining=3.1 hours
5370: loss=3.478, avg loss=3.154, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 343680 images, time remaining=3.1 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5371: loss=3.576, avg loss=3.197, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 343744 images, time remaining=3.1 hours
5372: loss=3.351, avg loss=3.212, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 343808 images, time remaining=3.1 hours
5373: loss=3.457, avg loss=3.236, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 343872 images, time remaining=3.1 hours
5374: loss=3.246, avg loss=3.237, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 343936 images, time remaining=3.1 hours
5375: loss=3.306, avg loss=3.244, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 344000 images, time remaining=3.1 hours
5376: loss=4.153, avg loss=3.335, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=5.3 seconds, 344064 images, time remaining=3.1 hours
5377: loss=3.821, avg loss=3.384, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 344128 images, time remaining=3.1 hours
5378: loss=2.729, avg loss=3.318, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 344192 images, time remaining=3.1 hours
5379: loss=4.645, avg loss=3.451, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 344256 images, time remaining=3.1 hours
5380: loss=3.661, avg loss=3.472, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.6 seconds, train=5.2 seconds, 344320 images, time remaining=3.1 hours
Resizing, random_coef=1.40, batch=4, 704x544
GPU #0: allocating workspace: 289.6 MiB begins at 0x14b856000000
5381: loss=3.926, avg loss=3.517, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.1 seconds, train=1.8 seconds, 344384 images, time remaining=3.1 hours
5382: loss=3.772, avg loss=3.543, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=1.8 seconds, 344448 images, time remaining=3.1 hours
5383: loss=3.440, avg loss=3.533, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.1 seconds, train=1.8 seconds, 344512 images, time remaining=3.1 hours
5384: loss=3.344, avg loss=3.514, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=1.8 seconds, 344576 images, time remaining=3.1 hours
5385: loss=3.173, avg loss=3.480, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 344640 images, time remaining=3.1 hours
5386: loss=3.024, avg loss=3.434, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 344704 images, time remaining=3.1 hours
5387: loss=2.879, avg loss=3.379, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 344768 images, time remaining=3.1 hours
5388: loss=3.595, avg loss=3.400, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=1.8 seconds, 344832 images, time remaining=3.1 hours
5389: loss=3.483, avg loss=3.408, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 344896 images, time remaining=3.1 hours
5390: loss=3.392, avg loss=3.407, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=1.8 seconds, 344960 images, time remaining=3.1 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b8c0600000
5391: loss=3.211, avg loss=3.387, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 345024 images, time remaining=3.1 hours
5392: loss=3.803, avg loss=3.429, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.1 seconds, train=2.3 seconds, 345088 images, time remaining=3.1 hours
5393: loss=3.221, avg loss=3.408, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 345152 images, time remaining=3.1 hours
5394: loss=2.866, avg loss=3.354, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 345216 images, time remaining=3.1 hours
5395: loss=2.585, avg loss=3.277, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 345280 images, time remaining=3.1 hours
5396: loss=3.036, avg loss=3.253, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 345344 images, time remaining=3.1 hours
5397: loss=2.858, avg loss=3.213, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 345408 images, time remaining=3.1 hours
5398: loss=2.807, avg loss=3.173, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 345472 images, time remaining=3.1 hours
5399: loss=2.896, avg loss=3.145, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 345536 images, time remaining=3.1 hours
5400: loss=3.385, avg loss=3.169, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 345600 images, time remaining=3.1 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5401: loss=2.532, avg loss=3.105, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.5 seconds, 345664 images, time remaining=3.1 hours
5402: loss=3.161, avg loss=3.111, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 345728 images, time remaining=3.1 hours
5403: loss=2.990, avg loss=3.099, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 345792 images, time remaining=3.1 hours
5404: loss=3.222, avg loss=3.111, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 345856 images, time remaining=3.1 hours
5405: loss=3.919, avg loss=3.192, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.3 seconds, 345920 images, time remaining=3.1 hours
5406: loss=3.562, avg loss=3.229, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 345984 images, time remaining=3.1 hours
5407: loss=3.131, avg loss=3.219, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 346048 images, time remaining=3.1 hours
5408: loss=3.087, avg loss=3.206, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 346112 images, time remaining=3.1 hours
5409: loss=3.295, avg loss=3.215, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 346176 images, time remaining=3.1 hours
5410: loss=3.175, avg loss=3.211, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 346240 images, time remaining=3.1 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5411: loss=3.426, avg loss=3.232, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.3 seconds, 346304 images, time remaining=3.1 hours
5412: loss=3.624, avg loss=3.272, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 346368 images, time remaining=3.1 hours
5413: loss=3.498, avg loss=3.294, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 346432 images, time remaining=3.1 hours
5414: loss=3.314, avg loss=3.296, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.2 seconds, 346496 images, time remaining=3.1 hours
5415: loss=2.945, avg loss=3.261, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 346560 images, time remaining=3.1 hours
5416: loss=3.069, avg loss=3.242, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.5 seconds, 346624 images, time remaining=3.1 hours
5417: loss=4.032, avg loss=3.321, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 346688 images, time remaining=3.1 hours
5418: loss=3.514, avg loss=3.340, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 346752 images, time remaining=3.1 hours
5419: loss=3.119, avg loss=3.318, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.3 seconds, 346816 images, time remaining=3.1 hours
5420: loss=3.477, avg loss=3.334, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.3 seconds, 346880 images, time remaining=3.1 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5421: loss=3.655, avg loss=3.366, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 346944 images, time remaining=3.1 hours
5422: loss=3.888, avg loss=3.418, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 347008 images, time remaining=3.1 hours
5423: loss=3.144, avg loss=3.391, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 347072 images, time remaining=3.1 hours
5424: loss=3.169, avg loss=3.369, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.2 seconds, train=4.6 seconds, 347136 images, time remaining=3.1 hours
5425: loss=3.188, avg loss=3.351, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 347200 images, time remaining=3.1 hours
5426: loss=3.391, avg loss=3.355, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 347264 images, time remaining=3.1 hours
5427: loss=3.300, avg loss=3.349, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 347328 images, time remaining=3.1 hours
5428: loss=3.136, avg loss=3.328, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 347392 images, time remaining=3.1 hours
5429: loss=3.475, avg loss=3.343, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 347456 images, time remaining=3.1 hours
5430: loss=3.522, avg loss=3.361, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.7 seconds, 347520 images, time remaining=3.1 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b802200000
5431: loss=2.723, avg loss=3.297, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 347584 images, time remaining=3.1 hours
5432: loss=3.151, avg loss=3.282, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 347648 images, time remaining=3.1 hours
5433: loss=2.794, avg loss=3.233, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 347712 images, time remaining=3.1 hours
5434: loss=2.801, avg loss=3.190, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.1 seconds, train=2.2 seconds, 347776 images, time remaining=3.1 hours
5435: loss=3.662, avg loss=3.237, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 347840 images, time remaining=3 hours
5436: loss=2.744, avg loss=3.188, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.0 seconds, train=2.2 seconds, 347904 images, time remaining=3 hours
5437: loss=3.525, avg loss=3.222, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.1 seconds, train=2.2 seconds, 347968 images, time remaining=3 hours
5438: loss=2.721, avg loss=3.172, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 348032 images, time remaining=3 hours
5439: loss=3.107, avg loss=3.165, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 348096 images, time remaining=3 hours
5440: loss=3.074, avg loss=3.156, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 348160 images, time remaining=3 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2e4000000
5441: loss=3.152, avg loss=3.156, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 348224 images, time remaining=3 hours
5442: loss=3.581, avg loss=3.198, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.2 seconds, train=2.8 seconds, 348288 images, time remaining=3 hours
5443: loss=3.019, avg loss=3.180, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 348352 images, time remaining=3 hours
5444: loss=3.082, avg loss=3.170, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 348416 images, time remaining=3 hours
5445: loss=2.332, avg loss=3.087, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 348480 images, time remaining=3 hours
5446: loss=2.911, avg loss=3.069, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 348544 images, time remaining=3 hours
5447: loss=3.180, avg loss=3.080, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=2.4 seconds, train=2.7 seconds, 348608 images, time remaining=3 hours
5448: loss=3.424, avg loss=3.114, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 348672 images, time remaining=3 hours
5449: loss=3.251, avg loss=3.128, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 348736 images, time remaining=3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5450: loss=3.261, avg loss=3.141, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=3.1 seconds, train=2.7 seconds, 348800 images, time remaining=3 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b5f9c00000
5451: loss=2.723, avg loss=3.100, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 348864 images, time remaining=3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5452: loss=2.562, avg loss=3.046, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=3.0 seconds, train=2.8 seconds, 348928 images, time remaining=3 hours
5453: loss=3.026, avg loss=3.044, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 348992 images, time remaining=3 hours
5454: loss=3.177, avg loss=3.057, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.2 seconds, train=2.8 seconds, 349056 images, time remaining=3 hours
5455: loss=3.560, avg loss=3.107, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 349120 images, time remaining=3 hours
5456: loss=3.273, avg loss=3.124, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 349184 images, time remaining=3 hours
5457: loss=3.090, avg loss=3.121, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 349248 images, time remaining=3 hours
5458: loss=3.465, avg loss=3.155, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 349312 images, time remaining=3 hours
5459: loss=3.092, avg loss=3.149, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 349376 images, time remaining=3 hours
5460: loss=2.745, avg loss=3.108, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 349440 images, time remaining=3 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5461: loss=2.877, avg loss=3.085, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.2 seconds, 349504 images, time remaining=3 hours
5462: loss=4.136, avg loss=3.190, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 349568 images, time remaining=3 hours
5463: loss=2.995, avg loss=3.171, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 349632 images, time remaining=3 hours
5464: loss=3.450, avg loss=3.199, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 349696 images, time remaining=3 hours
5465: loss=3.710, avg loss=3.250, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 349760 images, time remaining=3 hours
5466: loss=3.502, avg loss=3.275, last=93.29%, best=93.29%, next=5466, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 349824 images, time remaining=3 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b704a00000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=121041, unique_truth_count=57264
rank=0 of ranks=121041rank=100 of ranks=121041rank=200 of ranks=121041rank=300 of ranks=121041rank=400 of ranks=121041rank=500 of ranks=121041rank=600 of ranks=121041rank=700 of ranks=121041rank=800 of ranks=121041rank=900 of ranks=121041rank=1000 of ranks=121041rank=1100 of ranks=121041rank=1200 of ranks=121041rank=1300 of ranks=121041rank=1400 of ranks=121041rank=1500 of ranks=121041rank=1600 of ranks=121041rank=1700 of ranks=121041rank=1800 of ranks=121041rank=1900 of ranks=121041rank=2000 of ranks=121041rank=2100 of ranks=121041rank=2200 of ranks=121041rank=2300 of ranks=121041rank=2400 of ranks=121041rank=2500 of ranks=121041rank=2600 of ranks=121041rank=2700 of ranks=121041rank=2800 of ranks=121041rank=2900 of ranks=121041rank=3000 of ranks=121041rank=3100 of ranks=121041rank=3200 of ranks=121041rank=3300 of ranks=121041rank=3400 of ranks=121041rank=3500 of ranks=121041rank=3600 of ranks=121041rank=3700 of ranks=121041rank=3800 of ranks=121041rank=3900 of ranks=121041rank=4000 of ranks=121041rank=4100 of ranks=121041rank=4200 of ranks=121041rank=4300 of ranks=121041rank=4400 of ranks=121041rank=4500 of ranks=121041rank=4600 of ranks=121041rank=4700 of ranks=121041rank=4800 of ranks=121041rank=4900 of ranks=121041rank=5000 of ranks=121041rank=5100 of ranks=121041rank=5200 of ranks=121041rank=5300 of ranks=121041rank=5400 of ranks=121041rank=5500 of ranks=121041rank=5600 of ranks=121041rank=5700 of ranks=121041rank=5800 of ranks=121041rank=5900 of ranks=121041rank=6000 of ranks=121041rank=6100 of ranks=121041rank=6200 of ranks=121041rank=6300 of ranks=121041rank=6400 of ranks=121041rank=6500 of ranks=121041rank=6600 of ranks=121041rank=6700 of ranks=121041rank=6800 of ranks=121041rank=6900 of ranks=121041rank=7000 of ranks=121041rank=7100 of ranks=121041rank=7200 of ranks=121041rank=7300 of ranks=121041rank=7400 of ranks=121041rank=7500 of ranks=121041rank=7600 of ranks=121041rank=7700 of ranks=121041rank=7800 of ranks=121041rank=7900 of ranks=121041rank=8000 of ranks=121041rank=8100 of ranks=121041rank=8200 of ranks=121041rank=8300 of ranks=121041rank=8400 of ranks=121041rank=8500 of ranks=121041rank=8600 of ranks=121041rank=8700 of ranks=121041rank=8800 of ranks=121041rank=8900 of ranks=121041rank=9000 of ranks=121041rank=9100 of ranks=121041rank=9200 of ranks=121041rank=9300 of ranks=121041rank=9400 of ranks=121041rank=9500 of ranks=121041rank=9600 of ranks=121041rank=9700 of ranks=121041rank=9800 of ranks=121041rank=9900 of ranks=121041rank=10000 of ranks=121041rank=10100 of ranks=121041rank=10200 of ranks=121041rank=10300 of ranks=121041rank=10400 of ranks=121041rank=10500 of ranks=121041rank=10600 of ranks=121041rank=10700 of ranks=121041rank=10800 of ranks=121041rank=10900 of ranks=121041rank=11000 of ranks=121041rank=11100 of ranks=121041rank=11200 of ranks=121041rank=11300 of ranks=121041rank=11400 of ranks=121041rank=11500 of ranks=121041rank=11600 of ranks=121041rank=11700 of ranks=121041rank=11800 of ranks=121041rank=11900 of ranks=121041rank=12000 of ranks=121041rank=12100 of ranks=121041rank=12200 of ranks=121041rank=12300 of ranks=121041rank=12400 of ranks=121041rank=12500 of ranks=121041rank=12600 of ranks=121041rank=12700 of ranks=121041rank=12800 of ranks=121041rank=12900 of ranks=121041rank=13000 of ranks=121041rank=13100 of ranks=121041rank=13200 of ranks=121041rank=13300 of ranks=121041rank=13400 of ranks=121041rank=13500 of ranks=121041rank=13600 of ranks=121041rank=13700 of ranks=121041rank=13800 of ranks=121041rank=13900 of ranks=121041rank=14000 of ranks=121041rank=14100 of ranks=121041rank=14200 of ranks=121041rank=14300 of ranks=121041rank=14400 of ranks=121041rank=14500 of ranks=121041rank=14600 of ranks=121041rank=14700 of ranks=121041rank=14800 of ranks=121041rank=14900 of ranks=121041rank=15000 of ranks=121041rank=15100 of ranks=121041rank=15200 of ranks=121041rank=15300 of ranks=121041rank=15400 of ranks=121041rank=15500 of ranks=121041rank=15600 of ranks=121041rank=15700 of ranks=121041rank=15800 of ranks=121041rank=15900 of ranks=121041rank=16000 of ranks=121041rank=16100 of ranks=121041rank=16200 of ranks=121041rank=16300 of ranks=121041rank=16400 of ranks=121041rank=16500 of ranks=121041rank=16600 of ranks=121041rank=16700 of ranks=121041rank=16800 of ranks=121041rank=16900 of ranks=121041rank=17000 of ranks=121041rank=17100 of ranks=121041rank=17200 of ranks=121041rank=17300 of ranks=121041rank=17400 of ranks=121041rank=17500 of ranks=121041rank=17600 of ranks=121041rank=17700 of ranks=121041rank=17800 of ranks=121041rank=17900 of ranks=121041rank=18000 of ranks=121041rank=18100 of ranks=121041rank=18200 of ranks=121041rank=18300 of ranks=121041rank=18400 of ranks=121041rank=18500 of ranks=121041rank=18600 of ranks=121041rank=18700 of ranks=121041rank=18800 of ranks=121041rank=18900 of ranks=121041rank=19000 of ranks=121041rank=19100 of ranks=121041rank=19200 of ranks=121041rank=19300 of ranks=121041rank=19400 of ranks=121041rank=19500 of ranks=121041rank=19600 of ranks=121041rank=19700 of ranks=121041rank=19800 of ranks=121041rank=19900 of ranks=121041rank=20000 of ranks=121041rank=20100 of ranks=121041rank=20200 of ranks=121041rank=20300 of ranks=121041rank=20400 of ranks=121041rank=20500 of ranks=121041rank=20600 of ranks=121041rank=20700 of ranks=121041rank=20800 of ranks=121041rank=20900 of ranks=121041rank=21000 of ranks=121041rank=21100 of ranks=121041rank=21200 of ranks=121041rank=21300 of ranks=121041rank=21400 of ranks=121041rank=21500 of ranks=121041rank=21600 of ranks=121041rank=21700 of ranks=121041rank=21800 of ranks=121041rank=21900 of ranks=121041rank=22000 of ranks=121041rank=22100 of ranks=121041rank=22200 of ranks=121041rank=22300 of ranks=121041rank=22400 of ranks=121041rank=22500 of ranks=121041rank=22600 of ranks=121041rank=22700 of ranks=121041rank=22800 of ranks=121041rank=22900 of ranks=121041rank=23000 of ranks=121041rank=23100 of ranks=121041rank=23200 of ranks=121041rank=23300 of ranks=121041rank=23400 of ranks=121041rank=23500 of ranks=121041rank=23600 of ranks=121041rank=23700 of ranks=121041rank=23800 of ranks=121041rank=23900 of ranks=121041rank=24000 of ranks=121041rank=24100 of ranks=121041rank=24200 of ranks=121041rank=24300 of ranks=121041rank=24400 of ranks=121041rank=24500 of ranks=121041rank=24600 of ranks=121041rank=24700 of ranks=121041rank=24800 of ranks=121041rank=24900 of ranks=121041rank=25000 of ranks=121041rank=25100 of ranks=121041rank=25200 of ranks=121041rank=25300 of ranks=121041rank=25400 of ranks=121041rank=25500 of ranks=121041rank=25600 of ranks=121041rank=25700 of ranks=121041rank=25800 of ranks=121041rank=25900 of ranks=121041rank=26000 of ranks=121041rank=26100 of ranks=121041rank=26200 of ranks=121041rank=26300 of ranks=121041rank=26400 of ranks=121041rank=26500 of ranks=121041rank=26600 of ranks=121041rank=26700 of ranks=121041rank=26800 of ranks=121041rank=26900 of ranks=121041rank=27000 of ranks=121041rank=27100 of ranks=121041rank=27200 of ranks=121041rank=27300 of ranks=121041rank=27400 of ranks=121041rank=27500 of ranks=121041rank=27600 of ranks=121041rank=27700 of ranks=121041rank=27800 of ranks=121041rank=27900 of ranks=121041rank=28000 of ranks=121041rank=28100 of ranks=121041rank=28200 of ranks=121041rank=28300 of ranks=121041rank=28400 of ranks=121041rank=28500 of ranks=121041rank=28600 of ranks=121041rank=28700 of ranks=121041rank=28800 of ranks=121041rank=28900 of ranks=121041rank=29000 of ranks=121041rank=29100 of ranks=121041rank=29200 of ranks=121041rank=29300 of ranks=121041rank=29400 of ranks=121041rank=29500 of ranks=121041rank=29600 of ranks=121041rank=29700 of ranks=121041rank=29800 of ranks=121041rank=29900 of ranks=121041rank=30000 of ranks=121041rank=30100 of ranks=121041rank=30200 of ranks=121041rank=30300 of ranks=121041rank=30400 of ranks=121041rank=30500 of ranks=121041rank=30600 of ranks=121041rank=30700 of ranks=121041rank=30800 of ranks=121041rank=30900 of ranks=121041rank=31000 of ranks=121041rank=31100 of ranks=121041rank=31200 of ranks=121041rank=31300 of ranks=121041rank=31400 of ranks=121041rank=31500 of ranks=121041rank=31600 of ranks=121041rank=31700 of ranks=121041rank=31800 of ranks=121041rank=31900 of ranks=121041rank=32000 of ranks=121041rank=32100 of ranks=121041rank=32200 of ranks=121041rank=32300 of ranks=121041rank=32400 of ranks=121041rank=32500 of ranks=121041rank=32600 of ranks=121041rank=32700 of ranks=121041rank=32800 of ranks=121041rank=32900 of ranks=121041rank=33000 of ranks=121041rank=33100 of ranks=121041rank=33200 of ranks=121041rank=33300 of ranks=121041rank=33400 of ranks=121041rank=33500 of ranks=121041rank=33600 of ranks=121041rank=33700 of ranks=121041rank=33800 of ranks=121041rank=33900 of ranks=121041rank=34000 of ranks=121041rank=34100 of ranks=121041rank=34200 of ranks=121041rank=34300 of ranks=121041rank=34400 of ranks=121041rank=34500 of ranks=121041rank=34600 of ranks=121041rank=34700 of ranks=121041rank=34800 of ranks=121041rank=34900 of ranks=121041rank=35000 of ranks=121041rank=35100 of ranks=121041rank=35200 of ranks=121041rank=35300 of ranks=121041rank=35400 of ranks=121041rank=35500 of ranks=121041rank=35600 of ranks=121041rank=35700 of ranks=121041rank=35800 of ranks=121041rank=35900 of ranks=121041rank=36000 of ranks=121041rank=36100 of ranks=121041rank=36200 of ranks=121041rank=36300 of ranks=121041rank=36400 of ranks=121041rank=36500 of ranks=121041rank=36600 of ranks=121041rank=36700 of ranks=121041rank=36800 of ranks=121041rank=36900 of ranks=121041rank=37000 of ranks=121041rank=37100 of ranks=121041rank=37200 of ranks=121041rank=37300 of ranks=121041rank=37400 of ranks=121041rank=37500 of ranks=121041rank=37600 of ranks=121041rank=37700 of ranks=121041rank=37800 of ranks=121041rank=37900 of ranks=121041rank=38000 of ranks=121041rank=38100 of ranks=121041rank=38200 of ranks=121041rank=38300 of ranks=121041rank=38400 of ranks=121041rank=38500 of ranks=121041rank=38600 of ranks=121041rank=38700 of ranks=121041rank=38800 of ranks=121041rank=38900 of ranks=121041rank=39000 of ranks=121041rank=39100 of ranks=121041rank=39200 of ranks=121041rank=39300 of ranks=121041rank=39400 of ranks=121041rank=39500 of ranks=121041rank=39600 of ranks=121041rank=39700 of ranks=121041rank=39800 of ranks=121041rank=39900 of ranks=121041rank=40000 of ranks=121041rank=40100 of ranks=121041rank=40200 of ranks=121041rank=40300 of ranks=121041rank=40400 of ranks=121041rank=40500 of ranks=121041rank=40600 of ranks=121041rank=40700 of ranks=121041rank=40800 of ranks=121041rank=40900 of ranks=121041rank=41000 of ranks=121041rank=41100 of ranks=121041rank=41200 of ranks=121041rank=41300 of ranks=121041rank=41400 of ranks=121041rank=41500 of ranks=121041rank=41600 of ranks=121041rank=41700 of ranks=121041rank=41800 of ranks=121041rank=41900 of ranks=121041rank=42000 of ranks=121041rank=42100 of ranks=121041rank=42200 of ranks=121041rank=42300 of ranks=121041rank=42400 of ranks=121041rank=42500 of ranks=121041rank=42600 of ranks=121041rank=42700 of ranks=121041rank=42800 of ranks=121041rank=42900 of ranks=121041rank=43000 of ranks=121041rank=43100 of ranks=121041rank=43200 of ranks=121041rank=43300 of ranks=121041rank=43400 of ranks=121041rank=43500 of ranks=121041rank=43600 of ranks=121041rank=43700 of ranks=121041rank=43800 of ranks=121041rank=43900 of ranks=121041rank=44000 of ranks=121041rank=44100 of ranks=121041rank=44200 of ranks=121041rank=44300 of ranks=121041rank=44400 of ranks=121041rank=44500 of ranks=121041rank=44600 of ranks=121041rank=44700 of ranks=121041rank=44800 of ranks=121041rank=44900 of ranks=121041rank=45000 of ranks=121041rank=45100 of ranks=121041rank=45200 of ranks=121041rank=45300 of ranks=121041rank=45400 of ranks=121041rank=45500 of ranks=121041rank=45600 of ranks=121041rank=45700 of ranks=121041rank=45800 of ranks=121041rank=45900 of ranks=121041rank=46000 of ranks=121041rank=46100 of ranks=121041rank=46200 of ranks=121041rank=46300 of ranks=121041rank=46400 of ranks=121041rank=46500 of ranks=121041rank=46600 of ranks=121041rank=46700 of ranks=121041rank=46800 of ranks=121041rank=46900 of ranks=121041rank=47000 of ranks=121041rank=47100 of ranks=121041rank=47200 of ranks=121041rank=47300 of ranks=121041rank=47400 of ranks=121041rank=47500 of ranks=121041rank=47600 of ranks=121041rank=47700 of ranks=121041rank=47800 of ranks=121041rank=47900 of ranks=121041rank=48000 of ranks=121041rank=48100 of ranks=121041rank=48200 of ranks=121041rank=48300 of ranks=121041rank=48400 of ranks=121041rank=48500 of ranks=121041rank=48600 of ranks=121041rank=48700 of ranks=121041rank=48800 of ranks=121041rank=48900 of ranks=121041rank=49000 of ranks=121041rank=49100 of ranks=121041rank=49200 of ranks=121041rank=49300 of ranks=121041rank=49400 of ranks=121041rank=49500 of ranks=121041rank=49600 of ranks=121041rank=49700 of ranks=121041rank=49800 of ranks=121041rank=49900 of ranks=121041rank=50000 of ranks=121041rank=50100 of ranks=121041rank=50200 of ranks=121041rank=50300 of ranks=121041rank=50400 of ranks=121041rank=50500 of ranks=121041rank=50600 of ranks=121041rank=50700 of ranks=121041rank=50800 of ranks=121041rank=50900 of ranks=121041rank=51000 of ranks=121041rank=51100 of ranks=121041rank=51200 of ranks=121041rank=51300 of ranks=121041rank=51400 of ranks=121041rank=51500 of ranks=121041rank=51600 of ranks=121041rank=51700 of ranks=121041rank=51800 of ranks=121041rank=51900 of ranks=121041rank=52000 of ranks=121041rank=52100 of ranks=121041rank=52200 of ranks=121041rank=52300 of ranks=121041rank=52400 of ranks=121041rank=52500 of ranks=121041rank=52600 of ranks=121041rank=52700 of ranks=121041rank=52800 of ranks=121041rank=52900 of ranks=121041rank=53000 of ranks=121041rank=53100 of ranks=121041rank=53200 of ranks=121041rank=53300 of ranks=121041rank=53400 of ranks=121041rank=53500 of ranks=121041rank=53600 of ranks=121041rank=53700 of ranks=121041rank=53800 of ranks=121041rank=53900 of ranks=121041rank=54000 of ranks=121041rank=54100 of ranks=121041rank=54200 of ranks=121041rank=54300 of ranks=121041rank=54400 of ranks=121041rank=54500 of ranks=121041rank=54600 of ranks=121041rank=54700 of ranks=121041rank=54800 of ranks=121041rank=54900 of ranks=121041rank=55000 of ranks=121041rank=55100 of ranks=121041rank=55200 of ranks=121041rank=55300 of ranks=121041rank=55400 of ranks=121041rank=55500 of ranks=121041rank=55600 of ranks=121041rank=55700 of ranks=121041rank=55800 of ranks=121041rank=55900 of ranks=121041rank=56000 of ranks=121041rank=56100 of ranks=121041rank=56200 of ranks=121041rank=56300 of ranks=121041rank=56400 of ranks=121041rank=56500 of ranks=121041rank=56600 of ranks=121041rank=56700 of ranks=121041rank=56800 of ranks=121041rank=56900 of ranks=121041rank=57000 of ranks=121041rank=57100 of ranks=121041rank=57200 of ranks=121041rank=57300 of ranks=121041rank=57400 of ranks=121041rank=57500 of ranks=121041rank=57600 of ranks=121041rank=57700 of ranks=121041rank=57800 of ranks=121041rank=57900 of ranks=121041rank=58000 of ranks=121041rank=58100 of ranks=121041rank=58200 of ranks=121041rank=58300 of ranks=121041rank=58400 of ranks=121041rank=58500 of ranks=121041rank=58600 of ranks=121041rank=58700 of ranks=121041rank=58800 of ranks=121041rank=58900 of ranks=121041rank=59000 of ranks=121041rank=59100 of ranks=121041rank=59200 of ranks=121041rank=59300 of ranks=121041rank=59400 of ranks=121041rank=59500 of ranks=121041rank=59600 of ranks=121041rank=59700 of ranks=121041rank=59800 of ranks=121041rank=59900 of ranks=121041rank=60000 of ranks=121041rank=60100 of ranks=121041rank=60200 of ranks=121041rank=60300 of ranks=121041rank=60400 of ranks=121041rank=60500 of ranks=121041rank=60600 of ranks=121041rank=60700 of ranks=121041rank=60800 of ranks=121041rank=60900 of ranks=121041rank=61000 of ranks=121041rank=61100 of ranks=121041rank=61200 of ranks=121041rank=61300 of ranks=121041rank=61400 of ranks=121041rank=61500 of ranks=121041rank=61600 of ranks=121041rank=61700 of ranks=121041rank=61800 of ranks=121041rank=61900 of ranks=121041rank=62000 of ranks=121041rank=62100 of ranks=121041rank=62200 of ranks=121041rank=62300 of ranks=121041rank=62400 of ranks=121041rank=62500 of ranks=121041rank=62600 of ranks=121041rank=62700 of ranks=121041rank=62800 of ranks=121041rank=62900 of ranks=121041rank=63000 of ranks=121041rank=63100 of ranks=121041rank=63200 of ranks=121041rank=63300 of ranks=121041rank=63400 of ranks=121041rank=63500 of ranks=121041rank=63600 of ranks=121041rank=63700 of ranks=121041rank=63800 of ranks=121041rank=63900 of ranks=121041rank=64000 of ranks=121041rank=64100 of ranks=121041rank=64200 of ranks=121041rank=64300 of ranks=121041rank=64400 of ranks=121041rank=64500 of ranks=121041rank=64600 of ranks=121041rank=64700 of ranks=121041rank=64800 of ranks=121041rank=64900 of ranks=121041rank=65000 of ranks=121041rank=65100 of ranks=121041rank=65200 of ranks=121041rank=65300 of ranks=121041rank=65400 of ranks=121041rank=65500 of ranks=121041rank=65600 of ranks=121041rank=65700 of ranks=121041rank=65800 of ranks=121041rank=65900 of ranks=121041rank=66000 of ranks=121041rank=66100 of ranks=121041rank=66200 of ranks=121041rank=66300 of ranks=121041rank=66400 of ranks=121041rank=66500 of ranks=121041rank=66600 of ranks=121041rank=66700 of ranks=121041rank=66800 of ranks=121041rank=66900 of ranks=121041rank=67000 of ranks=121041rank=67100 of ranks=121041rank=67200 of ranks=121041rank=67300 of ranks=121041rank=67400 of ranks=121041rank=67500 of ranks=121041rank=67600 of ranks=121041rank=67700 of ranks=121041rank=67800 of ranks=121041rank=67900 of ranks=121041rank=68000 of ranks=121041rank=68100 of ranks=121041rank=68200 of ranks=121041rank=68300 of ranks=121041rank=68400 of ranks=121041rank=68500 of ranks=121041rank=68600 of ranks=121041rank=68700 of ranks=121041rank=68800 of ranks=121041rank=68900 of ranks=121041rank=69000 of ranks=121041rank=69100 of ranks=121041rank=69200 of ranks=121041rank=69300 of ranks=121041rank=69400 of ranks=121041rank=69500 of ranks=121041rank=69600 of ranks=121041rank=69700 of ranks=121041rank=69800 of ranks=121041rank=69900 of ranks=121041rank=70000 of ranks=121041rank=70100 of ranks=121041rank=70200 of ranks=121041rank=70300 of ranks=121041rank=70400 of ranks=121041rank=70500 of ranks=121041rank=70600 of ranks=121041rank=70700 of ranks=121041rank=70800 of ranks=121041rank=70900 of ranks=121041rank=71000 of ranks=121041rank=71100 of ranks=121041rank=71200 of ranks=121041rank=71300 of ranks=121041rank=71400 of ranks=121041rank=71500 of ranks=121041rank=71600 of ranks=121041rank=71700 of ranks=121041rank=71800 of ranks=121041rank=71900 of ranks=121041rank=72000 of ranks=121041rank=72100 of ranks=121041rank=72200 of ranks=121041rank=72300 of ranks=121041rank=72400 of ranks=121041rank=72500 of ranks=121041rank=72600 of ranks=121041rank=72700 of ranks=121041rank=72800 of ranks=121041rank=72900 of ranks=121041rank=73000 of ranks=121041rank=73100 of ranks=121041rank=73200 of ranks=121041rank=73300 of ranks=121041rank=73400 of ranks=121041rank=73500 of ranks=121041rank=73600 of ranks=121041rank=73700 of ranks=121041rank=73800 of ranks=121041rank=73900 of ranks=121041rank=74000 of ranks=121041rank=74100 of ranks=121041rank=74200 of ranks=121041rank=74300 of ranks=121041rank=74400 of ranks=121041rank=74500 of ranks=121041rank=74600 of ranks=121041rank=74700 of ranks=121041rank=74800 of ranks=121041rank=74900 of ranks=121041rank=75000 of ranks=121041rank=75100 of ranks=121041rank=75200 of ranks=121041rank=75300 of ranks=121041rank=75400 of ranks=121041rank=75500 of ranks=121041rank=75600 of ranks=121041rank=75700 of ranks=121041rank=75800 of ranks=121041rank=75900 of ranks=121041rank=76000 of ranks=121041rank=76100 of ranks=121041rank=76200 of ranks=121041rank=76300 of ranks=121041rank=76400 of ranks=121041rank=76500 of ranks=121041rank=76600 of ranks=121041rank=76700 of ranks=121041rank=76800 of ranks=121041rank=76900 of ranks=121041rank=77000 of ranks=121041rank=77100 of ranks=121041rank=77200 of ranks=121041rank=77300 of ranks=121041rank=77400 of ranks=121041rank=77500 of ranks=121041rank=77600 of ranks=121041rank=77700 of ranks=121041rank=77800 of ranks=121041rank=77900 of ranks=121041rank=78000 of ranks=121041rank=78100 of ranks=121041rank=78200 of ranks=121041rank=78300 of ranks=121041rank=78400 of ranks=121041rank=78500 of ranks=121041rank=78600 of ranks=121041rank=78700 of ranks=121041rank=78800 of ranks=121041rank=78900 of ranks=121041rank=79000 of ranks=121041rank=79100 of ranks=121041rank=79200 of ranks=121041rank=79300 of ranks=121041rank=79400 of ranks=121041rank=79500 of ranks=121041rank=79600 of ranks=121041rank=79700 of ranks=121041rank=79800 of ranks=121041rank=79900 of ranks=121041rank=80000 of ranks=121041rank=80100 of ranks=121041rank=80200 of ranks=121041rank=80300 of ranks=121041rank=80400 of ranks=121041rank=80500 of ranks=121041rank=80600 of ranks=121041rank=80700 of ranks=121041rank=80800 of ranks=121041rank=80900 of ranks=121041rank=81000 of ranks=121041rank=81100 of ranks=121041rank=81200 of ranks=121041rank=81300 of ranks=121041rank=81400 of ranks=121041rank=81500 of ranks=121041rank=81600 of ranks=121041rank=81700 of ranks=121041rank=81800 of ranks=121041rank=81900 of ranks=121041rank=82000 of ranks=121041rank=82100 of ranks=121041rank=82200 of ranks=121041rank=82300 of ranks=121041rank=82400 of ranks=121041rank=82500 of ranks=121041rank=82600 of ranks=121041rank=82700 of ranks=121041rank=82800 of ranks=121041rank=82900 of ranks=121041rank=83000 of ranks=121041rank=83100 of ranks=121041rank=83200 of ranks=121041rank=83300 of ranks=121041rank=83400 of ranks=121041rank=83500 of ranks=121041rank=83600 of ranks=121041rank=83700 of ranks=121041rank=83800 of ranks=121041rank=83900 of ranks=121041rank=84000 of ranks=121041rank=84100 of ranks=121041rank=84200 of ranks=121041rank=84300 of ranks=121041rank=84400 of ranks=121041rank=84500 of ranks=121041rank=84600 of ranks=121041rank=84700 of ranks=121041rank=84800 of ranks=121041rank=84900 of ranks=121041rank=85000 of ranks=121041rank=85100 of ranks=121041rank=85200 of ranks=121041rank=85300 of ranks=121041rank=85400 of ranks=121041rank=85500 of ranks=121041rank=85600 of ranks=121041rank=85700 of ranks=121041rank=85800 of ranks=121041rank=85900 of ranks=121041rank=86000 of ranks=121041rank=86100 of ranks=121041rank=86200 of ranks=121041rank=86300 of ranks=121041rank=86400 of ranks=121041rank=86500 of ranks=121041rank=86600 of ranks=121041rank=86700 of ranks=121041rank=86800 of ranks=121041rank=86900 of ranks=121041rank=87000 of ranks=121041rank=87100 of ranks=121041rank=87200 of ranks=121041rank=87300 of ranks=121041rank=87400 of ranks=121041rank=87500 of ranks=121041rank=87600 of ranks=121041rank=87700 of ranks=121041rank=87800 of ranks=121041rank=87900 of ranks=121041rank=88000 of ranks=121041rank=88100 of ranks=121041rank=88200 of ranks=121041rank=88300 of ranks=121041rank=88400 of ranks=121041rank=88500 of ranks=121041rank=88600 of ranks=121041rank=88700 of ranks=121041rank=88800 of ranks=121041rank=88900 of ranks=121041rank=89000 of ranks=121041rank=89100 of ranks=121041rank=89200 of ranks=121041rank=89300 of ranks=121041rank=89400 of ranks=121041rank=89500 of ranks=121041rank=89600 of ranks=121041rank=89700 of ranks=121041rank=89800 of ranks=121041rank=89900 of ranks=121041rank=90000 of ranks=121041rank=90100 of ranks=121041rank=90200 of ranks=121041rank=90300 of ranks=121041rank=90400 of ranks=121041rank=90500 of ranks=121041rank=90600 of ranks=121041rank=90700 of ranks=121041rank=90800 of ranks=121041rank=90900 of ranks=121041rank=91000 of ranks=121041rank=91100 of ranks=121041rank=91200 of ranks=121041rank=91300 of ranks=121041rank=91400 of ranks=121041rank=91500 of ranks=121041rank=91600 of ranks=121041rank=91700 of ranks=121041rank=91800 of ranks=121041rank=91900 of ranks=121041rank=92000 of ranks=121041rank=92100 of ranks=121041rank=92200 of ranks=121041rank=92300 of ranks=121041rank=92400 of ranks=121041rank=92500 of ranks=121041rank=92600 of ranks=121041rank=92700 of ranks=121041rank=92800 of ranks=121041rank=92900 of ranks=121041rank=93000 of ranks=121041rank=93100 of ranks=121041rank=93200 of ranks=121041rank=93300 of ranks=121041rank=93400 of ranks=121041rank=93500 of ranks=121041rank=93600 of ranks=121041rank=93700 of ranks=121041rank=93800 of ranks=121041rank=93900 of ranks=121041rank=94000 of ranks=121041rank=94100 of ranks=121041rank=94200 of ranks=121041rank=94300 of ranks=121041rank=94400 of ranks=121041rank=94500 of ranks=121041rank=94600 of ranks=121041rank=94700 of ranks=121041rank=94800 of ranks=121041rank=94900 of ranks=121041rank=95000 of ranks=121041rank=95100 of ranks=121041rank=95200 of ranks=121041rank=95300 of ranks=121041rank=95400 of ranks=121041rank=95500 of ranks=121041rank=95600 of ranks=121041rank=95700 of ranks=121041rank=95800 of ranks=121041rank=95900 of ranks=121041rank=96000 of ranks=121041rank=96100 of ranks=121041rank=96200 of ranks=121041rank=96300 of ranks=121041rank=96400 of ranks=121041rank=96500 of ranks=121041rank=96600 of ranks=121041rank=96700 of ranks=121041rank=96800 of ranks=121041rank=96900 of ranks=121041rank=97000 of ranks=121041rank=97100 of ranks=121041rank=97200 of ranks=121041rank=97300 of ranks=121041rank=97400 of ranks=121041rank=97500 of ranks=121041rank=97600 of ranks=121041rank=97700 of ranks=121041rank=97800 of ranks=121041rank=97900 of ranks=121041rank=98000 of ranks=121041rank=98100 of ranks=121041rank=98200 of ranks=121041rank=98300 of ranks=121041rank=98400 of ranks=121041rank=98500 of ranks=121041rank=98600 of ranks=121041rank=98700 of ranks=121041rank=98800 of ranks=121041rank=98900 of ranks=121041rank=99000 of ranks=121041rank=99100 of ranks=121041rank=99200 of ranks=121041rank=99300 of ranks=121041rank=99400 of ranks=121041rank=99500 of ranks=121041rank=99600 of ranks=121041rank=99700 of ranks=121041rank=99800 of ranks=121041rank=99900 of ranks=121041rank=100000 of ranks=121041rank=100100 of ranks=121041rank=100200 of ranks=121041rank=100300 of ranks=121041rank=100400 of ranks=121041rank=100500 of ranks=121041rank=100600 of ranks=121041rank=100700 of ranks=121041rank=100800 of ranks=121041rank=100900 of ranks=121041rank=101000 of ranks=121041rank=101100 of ranks=121041rank=101200 of ranks=121041rank=101300 of ranks=121041rank=101400 of ranks=121041rank=101500 of ranks=121041rank=101600 of ranks=121041rank=101700 of ranks=121041rank=101800 of ranks=121041rank=101900 of ranks=121041rank=102000 of ranks=121041rank=102100 of ranks=121041rank=102200 of ranks=121041rank=102300 of ranks=121041rank=102400 of ranks=121041rank=102500 of ranks=121041rank=102600 of ranks=121041rank=102700 of ranks=121041rank=102800 of ranks=121041rank=102900 of ranks=121041rank=103000 of ranks=121041rank=103100 of ranks=121041rank=103200 of ranks=121041rank=103300 of ranks=121041rank=103400 of ranks=121041rank=103500 of ranks=121041rank=103600 of ranks=121041rank=103700 of ranks=121041rank=103800 of ranks=121041rank=103900 of ranks=121041rank=104000 of ranks=121041rank=104100 of ranks=121041rank=104200 of ranks=121041rank=104300 of ranks=121041rank=104400 of ranks=121041rank=104500 of ranks=121041rank=104600 of ranks=121041rank=104700 of ranks=121041rank=104800 of ranks=121041rank=104900 of ranks=121041rank=105000 of ranks=121041rank=105100 of ranks=121041rank=105200 of ranks=121041rank=105300 of ranks=121041rank=105400 of ranks=121041rank=105500 of ranks=121041rank=105600 of ranks=121041rank=105700 of ranks=121041rank=105800 of ranks=121041rank=105900 of ranks=121041rank=106000 of ranks=121041rank=106100 of ranks=121041rank=106200 of ranks=121041rank=106300 of ranks=121041rank=106400 of ranks=121041rank=106500 of ranks=121041rank=106600 of ranks=121041rank=106700 of ranks=121041rank=106800 of ranks=121041rank=106900 of ranks=121041rank=107000 of ranks=121041rank=107100 of ranks=121041rank=107200 of ranks=121041rank=107300 of ranks=121041rank=107400 of ranks=121041rank=107500 of ranks=121041rank=107600 of ranks=121041rank=107700 of ranks=121041rank=107800 of ranks=121041rank=107900 of ranks=121041rank=108000 of ranks=121041rank=108100 of ranks=121041rank=108200 of ranks=121041rank=108300 of ranks=121041rank=108400 of ranks=121041rank=108500 of ranks=121041rank=108600 of ranks=121041rank=108700 of ranks=121041rank=108800 of ranks=121041rank=108900 of ranks=121041rank=109000 of ranks=121041rank=109100 of ranks=121041rank=109200 of ranks=121041rank=109300 of ranks=121041rank=109400 of ranks=121041rank=109500 of ranks=121041rank=109600 of ranks=121041rank=109700 of ranks=121041rank=109800 of ranks=121041rank=109900 of ranks=121041rank=110000 of ranks=121041rank=110100 of ranks=121041rank=110200 of ranks=121041rank=110300 of ranks=121041rank=110400 of ranks=121041rank=110500 of ranks=121041rank=110600 of ranks=121041rank=110700 of ranks=121041rank=110800 of ranks=121041rank=110900 of ranks=121041rank=111000 of ranks=121041rank=111100 of ranks=121041rank=111200 of ranks=121041rank=111300 of ranks=121041rank=111400 of ranks=121041rank=111500 of ranks=121041rank=111600 of ranks=121041rank=111700 of ranks=121041rank=111800 of ranks=121041rank=111900 of ranks=121041rank=112000 of ranks=121041rank=112100 of ranks=121041rank=112200 of ranks=121041rank=112300 of ranks=121041rank=112400 of ranks=121041rank=112500 of ranks=121041rank=112600 of ranks=121041rank=112700 of ranks=121041rank=112800 of ranks=121041rank=112900 of ranks=121041rank=113000 of ranks=121041rank=113100 of ranks=121041rank=113200 of ranks=121041rank=113300 of ranks=121041rank=113400 of ranks=121041rank=113500 of ranks=121041rank=113600 of ranks=121041rank=113700 of ranks=121041rank=113800 of ranks=121041rank=113900 of ranks=121041rank=114000 of ranks=121041rank=114100 of ranks=121041rank=114200 of ranks=121041rank=114300 of ranks=121041rank=114400 of ranks=121041rank=114500 of ranks=121041rank=114600 of ranks=121041rank=114700 of ranks=121041rank=114800 of ranks=121041rank=114900 of ranks=121041rank=115000 of ranks=121041rank=115100 of ranks=121041rank=115200 of ranks=121041rank=115300 of ranks=121041rank=115400 of ranks=121041rank=115500 of ranks=121041rank=115600 of ranks=121041rank=115700 of ranks=121041rank=115800 of ranks=121041rank=115900 of ranks=121041rank=116000 of ranks=121041rank=116100 of ranks=121041rank=116200 of ranks=121041rank=116300 of ranks=121041rank=116400 of ranks=121041rank=116500 of ranks=121041rank=116600 of ranks=121041rank=116700 of ranks=121041rank=116800 of ranks=121041rank=116900 of ranks=121041rank=117000 of ranks=121041rank=117100 of ranks=121041rank=117200 of ranks=121041rank=117300 of ranks=121041rank=117400 of ranks=121041rank=117500 of ranks=121041rank=117600 of ranks=121041rank=117700 of ranks=121041rank=117800 of ranks=121041rank=117900 of ranks=121041rank=118000 of ranks=121041rank=118100 of ranks=121041rank=118200 of ranks=121041rank=118300 of ranks=121041rank=118400 of ranks=121041rank=118500 of ranks=121041rank=118600 of ranks=121041rank=118700 of ranks=121041rank=118800 of ranks=121041rank=118900 of ranks=121041rank=119000 of ranks=121041rank=119100 of ranks=121041rank=119200 of ranks=121041rank=119300 of ranks=121041rank=119400 of ranks=121041rank=119500 of ranks=121041rank=119600 of ranks=121041rank=119700 of ranks=121041rank=119800 of ranks=121041rank=119900 of ranks=121041rank=120000 of ranks=121041rank=120100 of ranks=121041rank=120200 of ranks=121041rank=120300 of ranks=121041rank=120400 of ranks=121041rank=120500 of ranks=121041rank=120600 of ranks=121041rank=120700 of ranks=121041rank=120800 of ranks=121041rank=120900 of ranks=121041rank=121000 of ranks=121041

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              94.3712    479   3278     19    498           67.9315
   1 car                    98.3406  49996  40979    320  50316           77.3961
   2 truck                  96.3112   1808   7510     17   1825           64.0118
   3 bus                    93.7575    361   3246      5    366           70.6458
   4 pedestrian             94.9582   4128   9256    131   4259           70.1997

for conf_thresh=0.25, precision=0.86, recall=0.96, F1 score=0.91
for conf_thresh=0.25, TP=54952, FP=8905, FN=2312, average IoU=76.30%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=95.55%
Total detection time: 120 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
New best mAP, saving weights!
Saving weights to /workspace/.cache/splits/combined_best.weights
5467: loss=3.251, avg loss=3.273, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 349888 images, time remaining=3 hours
5468: loss=2.348, avg loss=3.180, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 349952 images, time remaining=3 hours
5469: loss=2.920, avg loss=3.154, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 350016 images, time remaining=3 hours
5470: loss=2.486, avg loss=3.087, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 350080 images, time remaining=3 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b704a00000
5471: loss=3.236, avg loss=3.102, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 350144 images, time remaining=3 hours
5472: loss=2.570, avg loss=3.049, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 350208 images, time remaining=3 hours
5473: loss=2.347, avg loss=2.979, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 350272 images, time remaining=3 hours
5474: loss=3.118, avg loss=2.993, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 350336 images, time remaining=3 hours
5475: loss=3.467, avg loss=3.040, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 350400 images, time remaining=3 hours
5476: loss=2.653, avg loss=3.001, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 350464 images, time remaining=3 hours
5477: loss=2.842, avg loss=2.986, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 350528 images, time remaining=3 hours
5478: loss=2.966, avg loss=2.984, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 350592 images, time remaining=3 hours
5479: loss=3.269, avg loss=3.012, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 350656 images, time remaining=3 hours
5480: loss=2.777, avg loss=2.989, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 350720 images, time remaining=3 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5481: loss=4.187, avg loss=3.109, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 350784 images, time remaining=3 hours
5482: loss=3.110, avg loss=3.109, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 350848 images, time remaining=3 hours
5483: loss=3.145, avg loss=3.112, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 350912 images, time remaining=3 hours
5484: loss=2.684, avg loss=3.069, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 350976 images, time remaining=3 hours
5485: loss=3.835, avg loss=3.146, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 351040 images, time remaining=3 hours
5486: loss=3.134, avg loss=3.145, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 351104 images, time remaining=3 hours
5487: loss=3.304, avg loss=3.161, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 351168 images, time remaining=3 hours
5488: loss=3.306, avg loss=3.175, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 351232 images, time remaining=3 hours
5489: loss=3.822, avg loss=3.240, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 351296 images, time remaining=3 hours
5490: loss=3.361, avg loss=3.252, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 351360 images, time remaining=3 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2e4000000
5491: loss=3.850, avg loss=3.312, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 351424 images, time remaining=3 hours
5492: loss=3.246, avg loss=3.305, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 351488 images, time remaining=3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5493: loss=3.478, avg loss=3.323, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.6 seconds, train=2.5 seconds, 351552 images, time remaining=3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5494: loss=3.692, avg loss=3.359, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.0 seconds, train=2.5 seconds, 351616 images, time remaining=3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5495: loss=3.277, avg loss=3.351, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.7 seconds, train=2.4 seconds, 351680 images, time remaining=3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5496: loss=2.780, avg loss=3.294, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.6 seconds, train=2.5 seconds, 351744 images, time remaining=3 hours
5497: loss=2.912, avg loss=3.256, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=2.6 seconds, 351808 images, time remaining=3 hours
5498: loss=2.935, avg loss=3.224, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 351872 images, time remaining=3 hours
5499: loss=2.920, avg loss=3.193, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 351936 images, time remaining=3 hours
5500: loss=3.181, avg loss=3.192, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 352000 images, time remaining=3 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b886200000
5501: loss=2.800, avg loss=3.153, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 352064 images, time remaining=3 hours
5502: loss=3.160, avg loss=3.154, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 352128 images, time remaining=3 hours
5503: loss=2.812, avg loss=3.119, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 352192 images, time remaining=3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5504: loss=2.907, avg loss=3.098, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.4 seconds, train=2.3 seconds, 352256 images, time remaining=3 hours
5505: loss=2.810, avg loss=3.069, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=2.4 seconds, 352320 images, time remaining=3 hours
5506: loss=3.386, avg loss=3.101, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 352384 images, time remaining=3 hours
5507: loss=2.870, avg loss=3.078, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 352448 images, time remaining=3 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5508: loss=3.143, avg loss=3.084, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=4.7 seconds, train=2.3 seconds, 352512 images, time remaining=3 hours
5509: loss=2.883, avg loss=3.064, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 352576 images, time remaining=3 hours
5510: loss=2.997, avg loss=3.058, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 352640 images, time remaining=3 hours
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5511: loss=2.810, avg loss=3.033, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 352704 images, time remaining=3 hours
5512: loss=3.431, avg loss=3.073, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 352768 images, time remaining=3 hours
5513: loss=3.254, avg loss=3.091, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 352832 images, time remaining=3 hours
5514: loss=3.143, avg loss=3.096, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=4.7 seconds, 352896 images, time remaining=3 hours
5515: loss=2.681, avg loss=3.054, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 352960 images, time remaining=3 hours
5516: loss=2.871, avg loss=3.036, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 353024 images, time remaining=3 hours
5517: loss=3.903, avg loss=3.123, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=4.7 seconds, 353088 images, time remaining=3 hours
5518: loss=3.046, avg loss=3.115, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 353152 images, time remaining=3 hours
5519: loss=3.265, avg loss=3.130, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=4.7 seconds, 353216 images, time remaining=3 hours
5520: loss=3.639, avg loss=3.181, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=4.5 seconds, 353280 images, time remaining=3 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2e4000000
5521: loss=3.243, avg loss=3.187, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 353344 images, time remaining=3 hours
5522: loss=2.827, avg loss=3.151, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 353408 images, time remaining=3 hours
5523: loss=2.918, avg loss=3.128, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 353472 images, time remaining=3 hours
5524: loss=3.183, avg loss=3.133, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 353536 images, time remaining=2.9 hours
5525: loss=2.796, avg loss=3.100, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.7 seconds, 353600 images, time remaining=2.9 hours
5526: loss=2.978, avg loss=3.088, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 353664 images, time remaining=2.9 hours
5527: loss=3.227, avg loss=3.101, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 353728 images, time remaining=2.9 hours
5528: loss=2.421, avg loss=3.033, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.2 seconds, train=2.6 seconds, 353792 images, time remaining=2.9 hours
5529: loss=2.694, avg loss=2.999, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=2.6 seconds, 353856 images, time remaining=2.9 hours
5530: loss=3.264, avg loss=3.026, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 353920 images, time remaining=2.9 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2e4000000
5531: loss=3.286, avg loss=3.052, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 353984 images, time remaining=2.9 hours
5532: loss=2.740, avg loss=3.021, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 354048 images, time remaining=2.9 hours
5533: loss=2.847, avg loss=3.003, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.4 seconds, train=2.7 seconds, 354112 images, time remaining=2.9 hours
5534: loss=3.497, avg loss=3.053, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=2.6 seconds, 354176 images, time remaining=2.9 hours
5535: loss=3.396, avg loss=3.087, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=2.8 seconds, 354240 images, time remaining=2.9 hours
5536: loss=2.812, avg loss=3.060, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 354304 images, time remaining=2.9 hours
5537: loss=3.075, avg loss=3.061, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=2.7 seconds, 354368 images, time remaining=2.9 hours
5538: loss=2.868, avg loss=3.042, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=2.7 seconds, 354432 images, time remaining=2.9 hours
5539: loss=2.813, avg loss=3.019, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 354496 images, time remaining=2.9 hours
5540: loss=2.871, avg loss=3.004, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 354560 images, time remaining=2.9 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2e4000000
5541: loss=2.299, avg loss=2.934, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 354624 images, time remaining=2.9 hours
5542: loss=2.421, avg loss=2.882, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 354688 images, time remaining=2.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5543: loss=2.370, avg loss=2.831, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.6 seconds, train=2.6 seconds, 354752 images, time remaining=2.9 hours
5544: loss=2.831, avg loss=2.831, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=2.4 seconds, 354816 images, time remaining=2.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5545: loss=3.409, avg loss=2.889, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=4.1 seconds, train=2.6 seconds, 354880 images, time remaining=2.9 hours
5546: loss=2.695, avg loss=2.870, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 354944 images, time remaining=2.9 hours
5547: loss=2.619, avg loss=2.845, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 355008 images, time remaining=2.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5548: loss=2.904, avg loss=2.851, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.2 seconds, train=2.6 seconds, 355072 images, time remaining=2.9 hours
5549: loss=2.971, avg loss=2.863, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=2.6 seconds, 355136 images, time remaining=2.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5550: loss=2.776, avg loss=2.854, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.2 seconds, train=2.8 seconds, 355200 images, time remaining=2.9 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b2ec000000
5551: loss=3.509, avg loss=2.919, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 355264 images, time remaining=2.9 hours
5552: loss=2.763, avg loss=2.904, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 355328 images, time remaining=2.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5553: loss=2.738, avg loss=2.887, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.4 seconds, train=2.1 seconds, 355392 images, time remaining=2.9 hours
5554: loss=2.648, avg loss=2.863, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 355456 images, time remaining=2.9 hours
5555: loss=2.418, avg loss=2.819, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 355520 images, time remaining=2.9 hours
5556: loss=2.774, avg loss=2.814, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=2.1 seconds, 355584 images, time remaining=2.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5557: loss=3.104, avg loss=2.843, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.4 seconds, train=2.2 seconds, 355648 images, time remaining=2.9 hours
5558: loss=3.185, avg loss=2.877, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 355712 images, time remaining=2.9 hours
5559: loss=3.131, avg loss=2.903, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 355776 images, time remaining=2.9 hours
5560: loss=3.236, avg loss=2.936, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 355840 images, time remaining=2.9 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14c093a00000
5561: loss=3.011, avg loss=2.944, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 355904 images, time remaining=2.9 hours
5562: loss=2.411, avg loss=2.890, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 355968 images, time remaining=2.9 hours
5563: loss=2.830, avg loss=2.884, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 356032 images, time remaining=2.9 hours
5564: loss=2.764, avg loss=2.872, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 356096 images, time remaining=2.9 hours
5565: loss=2.972, avg loss=2.882, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 356160 images, time remaining=2.9 hours
5566: loss=3.123, avg loss=2.906, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 356224 images, time remaining=2.9 hours
5567: loss=2.774, avg loss=2.893, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 356288 images, time remaining=2.9 hours
5568: loss=2.649, avg loss=2.869, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 356352 images, time remaining=2.9 hours
5569: loss=3.109, avg loss=2.893, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 356416 images, time remaining=2.9 hours
5570: loss=3.190, avg loss=2.922, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 356480 images, time remaining=2.9 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5571: loss=3.624, avg loss=2.993, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.1 seconds, train=4.7 seconds, 356544 images, time remaining=2.9 hours
5572: loss=2.968, avg loss=2.990, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 356608 images, time remaining=2.9 hours
5573: loss=4.829, avg loss=3.174, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=4.6 seconds, 356672 images, time remaining=2.9 hours
5574: loss=3.044, avg loss=3.161, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=4.0 seconds, train=4.9 seconds, 356736 images, time remaining=2.9 hours
5575: loss=3.800, avg loss=3.225, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 356800 images, time remaining=2.9 hours
5576: loss=3.594, avg loss=3.262, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 356864 images, time remaining=2.9 hours
5577: loss=4.076, avg loss=3.343, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 356928 images, time remaining=2.9 hours
5578: loss=3.798, avg loss=3.389, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 356992 images, time remaining=2.9 hours
5579: loss=3.369, avg loss=3.387, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 357056 images, time remaining=2.9 hours
5580: loss=2.780, avg loss=3.326, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 357120 images, time remaining=2.9 hours
Resizing, random_coef=1.40, batch=4, 1344x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5581: loss=3.816, avg loss=3.375, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=5.9 seconds, 357184 images, time remaining=2.9 hours
5582: loss=3.929, avg loss=3.430, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.6 seconds, train=5.9 seconds, 357248 images, time remaining=2.9 hours
5583: loss=3.624, avg loss=3.450, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 357312 images, time remaining=2.9 hours
5584: loss=3.929, avg loss=3.498, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=6.0 seconds, 357376 images, time remaining=2.9 hours
5585: loss=4.077, avg loss=3.556, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=5.9 seconds, 357440 images, time remaining=2.9 hours
5586: loss=3.411, avg loss=3.541, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 357504 images, time remaining=2.9 hours
5587: loss=2.970, avg loss=3.484, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 357568 images, time remaining=2.9 hours
5588: loss=3.635, avg loss=3.499, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 357632 images, time remaining=2.9 hours
5589: loss=3.100, avg loss=3.459, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 357696 images, time remaining=2.9 hours
5590: loss=4.089, avg loss=3.522, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 357760 images, time remaining=2.9 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2e4000000
5591: loss=3.348, avg loss=3.505, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 357824 images, time remaining=2.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5592: loss=2.727, avg loss=3.427, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.7 seconds, train=2.6 seconds, 357888 images, time remaining=2.9 hours
5593: loss=3.380, avg loss=3.422, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 357952 images, time remaining=2.9 hours
5594: loss=3.158, avg loss=3.396, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 358016 images, time remaining=2.9 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5595: loss=2.901, avg loss=3.346, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.3 seconds, train=2.6 seconds, 358080 images, time remaining=2.9 hours
5596: loss=2.944, avg loss=3.306, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 358144 images, time remaining=2.9 hours
5597: loss=2.560, avg loss=3.231, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=2.5 seconds, 358208 images, time remaining=2.9 hours
5598: loss=3.287, avg loss=3.237, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.1 seconds, train=2.7 seconds, 358272 images, time remaining=2.9 hours
5599: loss=3.062, avg loss=3.220, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 358336 images, time remaining=2.9 hours
5600: loss=3.323, avg loss=3.230, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 358400 images, time remaining=2.9 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 832x672
GPU #0: allocating workspace: 418.6 MiB begins at 0x14b67be00000
5601: loss=2.408, avg loss=3.148, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 358464 images, time remaining=2.9 hours
5602: loss=2.659, avg loss=3.099, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 358528 images, time remaining=2.9 hours
5603: loss=2.932, avg loss=3.082, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=2.3 seconds, 358592 images, time remaining=2.8 hours
5604: loss=3.102, avg loss=3.084, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 358656 images, time remaining=2.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5605: loss=2.746, avg loss=3.050, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.5 seconds, train=2.4 seconds, 358720 images, time remaining=2.8 hours
5606: loss=2.510, avg loss=2.996, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 358784 images, time remaining=2.8 hours
5607: loss=2.830, avg loss=2.980, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=2.4 seconds, 358848 images, time remaining=2.8 hours
5608: loss=2.673, avg loss=2.949, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 358912 images, time remaining=2.8 hours
5609: loss=2.942, avg loss=2.948, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 358976 images, time remaining=2.8 hours
5610: loss=3.246, avg loss=2.978, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 359040 images, time remaining=2.8 hours
Resizing, random_coef=1.40, batch=4, 1344x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5611: loss=4.902, avg loss=3.170, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=6.1 seconds, 359104 images, time remaining=2.8 hours
5612: loss=4.494, avg loss=3.303, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.1 seconds, train=6.1 seconds, 359168 images, time remaining=2.8 hours
5613: loss=4.236, avg loss=3.396, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 359232 images, time remaining=2.8 hours
5614: loss=3.893, avg loss=3.446, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.0 seconds, train=6.0 seconds, 359296 images, time remaining=2.8 hours
5615: loss=3.871, avg loss=3.488, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 359360 images, time remaining=2.8 hours
5616: loss=4.312, avg loss=3.571, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 359424 images, time remaining=2.8 hours
5617: loss=3.738, avg loss=3.587, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=6.0 seconds, 359488 images, time remaining=2.8 hours
5618: loss=4.583, avg loss=3.687, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 359552 images, time remaining=2.8 hours
5619: loss=3.672, avg loss=3.685, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 359616 images, time remaining=2.8 hours
5620: loss=3.732, avg loss=3.690, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.3 seconds, train=5.9 seconds, 359680 images, time remaining=2.8 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b2e4000000
5621: loss=2.769, avg loss=3.598, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 359744 images, time remaining=2.8 hours
5622: loss=3.594, avg loss=3.598, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 359808 images, time remaining=2.8 hours
5623: loss=3.543, avg loss=3.592, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 359872 images, time remaining=2.8 hours
5624: loss=3.414, avg loss=3.574, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.1 seconds, train=2.8 seconds, 359936 images, time remaining=2.8 hours
5625: loss=2.679, avg loss=3.485, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 360000 images, time remaining=2.8 hours
5626: loss=3.391, avg loss=3.475, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.8 seconds, 360064 images, time remaining=2.8 hours
5627: loss=3.012, avg loss=3.429, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 360128 images, time remaining=2.8 hours
5628: loss=3.687, avg loss=3.455, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 360192 images, time remaining=2.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5629: loss=3.029, avg loss=3.412, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.2 seconds, train=2.9 seconds, 360256 images, time remaining=2.8 hours
5630: loss=3.524, avg loss=3.423, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 360320 images, time remaining=2.8 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b4de400000
5631: loss=3.053, avg loss=3.386, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 360384 images, time remaining=2.8 hours
5632: loss=2.737, avg loss=3.321, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 360448 images, time remaining=2.8 hours
5633: loss=3.677, avg loss=3.357, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 360512 images, time remaining=2.8 hours
5634: loss=2.514, avg loss=3.273, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 360576 images, time remaining=2.8 hours
5635: loss=2.792, avg loss=3.225, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 360640 images, time remaining=2.8 hours
5636: loss=2.596, avg loss=3.162, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.2 seconds, train=2.4 seconds, 360704 images, time remaining=2.8 hours
5637: loss=3.113, avg loss=3.157, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 360768 images, time remaining=2.8 hours
5638: loss=3.056, avg loss=3.147, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 360832 images, time remaining=2.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5639: loss=3.319, avg loss=3.164, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.6 seconds, train=2.1 seconds, 360896 images, time remaining=2.8 hours
5640: loss=2.703, avg loss=3.118, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 360960 images, time remaining=2.8 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b4de400000
5641: loss=3.587, avg loss=3.165, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 361024 images, time remaining=2.8 hours
5642: loss=2.613, avg loss=3.110, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 361088 images, time remaining=2.8 hours
5643: loss=2.861, avg loss=3.085, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 361152 images, time remaining=2.8 hours
5644: loss=2.786, avg loss=3.055, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 361216 images, time remaining=2.8 hours
5645: loss=3.340, avg loss=3.083, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 361280 images, time remaining=2.8 hours
5646: loss=3.243, avg loss=3.099, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 361344 images, time remaining=2.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5647: loss=3.017, avg loss=3.091, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.2 seconds, train=2.2 seconds, 361408 images, time remaining=2.8 hours
5648: loss=2.751, avg loss=3.057, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 361472 images, time remaining=2.8 hours
5649: loss=4.054, avg loss=3.157, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 361536 images, time remaining=2.8 hours
5650: loss=2.920, avg loss=3.133, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 361600 images, time remaining=2.8 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b4b4000000
5651: loss=2.874, avg loss=3.107, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 361664 images, time remaining=2.8 hours
5652: loss=3.233, avg loss=3.120, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 361728 images, time remaining=2.8 hours
5653: loss=2.712, avg loss=3.079, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 361792 images, time remaining=2.8 hours
5654: loss=2.289, avg loss=3.000, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=2.8 seconds, 361856 images, time remaining=2.8 hours
5655: loss=3.167, avg loss=3.017, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=2.8 seconds, 361920 images, time remaining=2.8 hours
5656: loss=2.304, avg loss=2.945, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 361984 images, time remaining=2.8 hours
5657: loss=2.503, avg loss=2.901, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=2.9 seconds, 362048 images, time remaining=2.8 hours
5658: loss=3.172, avg loss=2.928, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 362112 images, time remaining=2.8 hours
5659: loss=2.574, avg loss=2.893, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 362176 images, time remaining=2.8 hours
5660: loss=2.505, avg loss=2.854, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 362240 images, time remaining=2.8 hours
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5661: loss=3.576, avg loss=2.926, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=5.6 seconds, 362304 images, time remaining=2.8 hours
5662: loss=3.387, avg loss=2.972, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 362368 images, time remaining=2.8 hours
5663: loss=3.858, avg loss=3.061, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=5.6 seconds, 362432 images, time remaining=2.8 hours
5664: loss=3.269, avg loss=3.082, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.2 seconds, train=5.3 seconds, 362496 images, time remaining=2.8 hours
5665: loss=3.895, avg loss=3.163, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 362560 images, time remaining=2.8 hours
5666: loss=2.928, avg loss=3.140, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 362624 images, time remaining=2.8 hours
5667: loss=3.421, avg loss=3.168, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=5.5 seconds, 362688 images, time remaining=2.8 hours
5668: loss=4.207, avg loss=3.272, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=5.4 seconds, 362752 images, time remaining=2.8 hours
5669: loss=3.749, avg loss=3.319, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 362816 images, time remaining=2.8 hours
5670: loss=3.524, avg loss=3.340, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 362880 images, time remaining=2.8 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b861800000
5671: loss=4.234, avg loss=3.429, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 362944 images, time remaining=2.8 hours
5672: loss=3.627, avg loss=3.449, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.4 seconds, 363008 images, time remaining=2.8 hours
5673: loss=3.057, avg loss=3.410, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 363072 images, time remaining=2.8 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5674: loss=3.001, avg loss=3.369, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.2 seconds, train=2.2 seconds, 363136 images, time remaining=2.8 hours
5675: loss=3.317, avg loss=3.364, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 363200 images, time remaining=2.8 hours
5676: loss=3.122, avg loss=3.340, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 363264 images, time remaining=2.8 hours
5677: loss=2.801, avg loss=3.286, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.3 seconds, train=2.3 seconds, 363328 images, time remaining=2.8 hours
5678: loss=2.884, avg loss=3.246, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 363392 images, time remaining=2.8 hours
5679: loss=3.023, avg loss=3.223, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 363456 images, time remaining=2.8 hours
5680: loss=2.527, avg loss=3.154, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 363520 images, time remaining=2.8 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b55bc00000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5681: loss=3.401, avg loss=3.178, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=5.1 seconds, train=2.7 seconds, 363584 images, time remaining=2.8 hours
5682: loss=3.495, avg loss=3.210, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 363648 images, time remaining=2.7 hours
5683: loss=3.094, avg loss=3.198, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 363712 images, time remaining=2.7 hours
5684: loss=2.963, avg loss=3.175, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 363776 images, time remaining=2.7 hours
5685: loss=3.207, avg loss=3.178, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=2.7 seconds, 363840 images, time remaining=2.7 hours
5686: loss=3.531, avg loss=3.213, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 363904 images, time remaining=2.7 hours
5687: loss=2.620, avg loss=3.154, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=2.8 seconds, 363968 images, time remaining=2.7 hours
5688: loss=3.277, avg loss=3.166, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 364032 images, time remaining=2.7 hours
5689: loss=3.373, avg loss=3.187, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 364096 images, time remaining=2.7 hours
5690: loss=3.576, avg loss=3.226, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 364160 images, time remaining=2.7 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b4b4000000
5691: loss=3.007, avg loss=3.204, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=2.8 seconds, 364224 images, time remaining=2.7 hours
5692: loss=2.935, avg loss=3.177, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.1 seconds, train=2.9 seconds, 364288 images, time remaining=2.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5693: loss=2.895, avg loss=3.149, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.7 seconds, train=2.7 seconds, 364352 images, time remaining=2.7 hours
5694: loss=2.750, avg loss=3.109, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 364416 images, time remaining=2.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5695: loss=2.774, avg loss=3.076, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.7 seconds, train=2.7 seconds, 364480 images, time remaining=2.7 hours
5696: loss=2.907, avg loss=3.059, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=2.9 seconds, 364544 images, time remaining=2.7 hours
5697: loss=2.925, avg loss=3.045, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 364608 images, time remaining=2.7 hours
5698: loss=3.177, avg loss=3.058, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=2.9 seconds, 364672 images, time remaining=2.7 hours
5699: loss=2.970, avg loss=3.050, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 364736 images, time remaining=2.7 hours
5700: loss=2.738, avg loss=3.018, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 364800 images, time remaining=2.7 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b4b4000000
5701: loss=2.845, avg loss=3.001, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 364864 images, time remaining=2.7 hours
5702: loss=3.393, avg loss=3.040, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 364928 images, time remaining=2.7 hours
5703: loss=3.169, avg loss=3.053, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 364992 images, time remaining=2.7 hours
5704: loss=2.934, avg loss=3.041, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 365056 images, time remaining=2.7 hours
5705: loss=2.337, avg loss=2.971, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.1 seconds, train=2.2 seconds, 365120 images, time remaining=2.7 hours
5706: loss=3.054, avg loss=2.979, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 365184 images, time remaining=2.7 hours
5707: loss=3.445, avg loss=3.026, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 365248 images, time remaining=2.7 hours
5708: loss=3.095, avg loss=3.033, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=2.2 seconds, 365312 images, time remaining=2.7 hours
5709: loss=2.762, avg loss=3.006, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=2.2 seconds, 365376 images, time remaining=2.7 hours
5710: loss=3.036, avg loss=3.009, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 365440 images, time remaining=2.7 hours
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5711: loss=4.748, avg loss=3.183, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 365504 images, time remaining=2.7 hours
5712: loss=5.506, avg loss=3.415, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 365568 images, time remaining=2.7 hours
5713: loss=3.783, avg loss=3.452, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 365632 images, time remaining=2.7 hours
5714: loss=4.237, avg loss=3.530, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=5.6 seconds, 365696 images, time remaining=2.7 hours
5715: loss=3.712, avg loss=3.548, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=5.7 seconds, 365760 images, time remaining=2.7 hours
5716: loss=3.418, avg loss=3.535, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 365824 images, time remaining=2.7 hours
5717: loss=3.805, avg loss=3.562, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 365888 images, time remaining=2.7 hours
5718: loss=4.154, avg loss=3.622, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 365952 images, time remaining=2.7 hours
5719: loss=3.947, avg loss=3.654, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 366016 images, time remaining=2.7 hours
5720: loss=4.574, avg loss=3.746, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 366080 images, time remaining=2.7 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b893400000
5721: loss=4.872, avg loss=3.859, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 366144 images, time remaining=2.7 hours
5722: loss=5.105, avg loss=3.983, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 366208 images, time remaining=2.7 hours
5723: loss=3.846, avg loss=3.970, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 366272 images, time remaining=2.7 hours
5724: loss=3.696, avg loss=3.942, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 366336 images, time remaining=2.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5725: loss=3.704, avg loss=3.918, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.4 seconds, train=1.9 seconds, 366400 images, time remaining=2.7 hours
5726: loss=3.966, avg loss=3.923, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 366464 images, time remaining=2.7 hours
5727: loss=3.875, avg loss=3.918, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 366528 images, time remaining=2.7 hours
5728: loss=3.738, avg loss=3.900, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 366592 images, time remaining=2.7 hours
5729: loss=3.059, avg loss=3.816, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 366656 images, time remaining=2.7 hours
5730: loss=3.784, avg loss=3.813, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 366720 images, time remaining=2.7 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5731: loss=7.169, avg loss=4.148, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.1 seconds, train=4.2 seconds, 366784 images, time remaining=2.7 hours
5732: loss=5.155, avg loss=4.249, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=4.1 seconds, 366848 images, time remaining=2.7 hours
5733: loss=6.064, avg loss=4.431, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 366912 images, time remaining=2.7 hours
5734: loss=4.552, avg loss=4.443, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 366976 images, time remaining=2.7 hours
5735: loss=4.747, avg loss=4.473, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 367040 images, time remaining=2.7 hours
5736: loss=4.009, avg loss=4.427, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.0 seconds, train=4.2 seconds, 367104 images, time remaining=2.7 hours
5737: loss=3.483, avg loss=4.332, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 367168 images, time remaining=2.7 hours
5738: loss=4.019, avg loss=4.301, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 367232 images, time remaining=2.7 hours
5739: loss=4.409, avg loss=4.312, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.2 seconds, train=4.1 seconds, 367296 images, time remaining=2.7 hours
5740: loss=4.227, avg loss=4.303, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=4.2 seconds, 367360 images, time remaining=2.7 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b58b800000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5741: loss=3.831, avg loss=4.256, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=4.3 seconds, train=2.4 seconds, 367424 images, time remaining=2.7 hours
5742: loss=4.734, avg loss=4.304, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 367488 images, time remaining=2.7 hours
5743: loss=3.855, avg loss=4.259, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 367552 images, time remaining=2.7 hours
5744: loss=3.614, avg loss=4.194, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=2.3 seconds, 367616 images, time remaining=2.7 hours
5745: loss=3.451, avg loss=4.120, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 367680 images, time remaining=2.7 hours
5746: loss=3.522, avg loss=4.060, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=2.3 seconds, 367744 images, time remaining=2.7 hours
5747: loss=3.118, avg loss=3.966, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 367808 images, time remaining=2.7 hours
5748: loss=2.589, avg loss=3.828, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 367872 images, time remaining=2.7 hours
5749: loss=2.888, avg loss=3.734, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 367936 images, time remaining=2.7 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5750: loss=3.408, avg loss=3.702, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.3 seconds, train=2.2 seconds, 368000 images, time remaining=2.7 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14afd2000000
5751: loss=7.773, avg loss=4.109, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=6.0 seconds, 368064 images, time remaining=2.7 hours
5752: loss=6.375, avg loss=4.335, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.1 seconds, train=5.9 seconds, 368128 images, time remaining=2.7 hours
5753: loss=5.151, avg loss=4.417, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 368192 images, time remaining=2.7 hours
5754: loss=5.369, avg loss=4.512, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=4.2 seconds, train=5.7 seconds, 368256 images, time remaining=2.7 hours
5755: loss=5.028, avg loss=4.564, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.0 seconds, train=5.8 seconds, 368320 images, time remaining=2.7 hours
5756: loss=3.991, avg loss=4.506, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.4 seconds, train=6.0 seconds, 368384 images, time remaining=2.7 hours
5757: loss=4.808, avg loss=4.537, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.2 seconds, train=5.8 seconds, 368448 images, time remaining=2.7 hours
5758: loss=4.169, avg loss=4.500, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 368512 images, time remaining=2.7 hours
5759: loss=4.479, avg loss=4.498, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 368576 images, time remaining=2.7 hours
5760: loss=3.583, avg loss=4.406, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 368640 images, time remaining=2.7 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b2ec000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5761: loss=4.793, avg loss=4.445, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.3 seconds, train=2.1 seconds, 368704 images, time remaining=2.7 hours
5762: loss=4.682, avg loss=4.469, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 368768 images, time remaining=2.7 hours
5763: loss=3.290, avg loss=4.351, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 368832 images, time remaining=2.6 hours
5764: loss=3.658, avg loss=4.282, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 368896 images, time remaining=2.6 hours
5765: loss=4.126, avg loss=4.266, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 368960 images, time remaining=2.6 hours
5766: loss=3.811, avg loss=4.220, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.1 seconds, train=2.3 seconds, 369024 images, time remaining=2.6 hours
5767: loss=3.280, avg loss=4.126, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 369088 images, time remaining=2.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5768: loss=3.238, avg loss=4.038, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.6 seconds, train=2.2 seconds, 369152 images, time remaining=2.6 hours
5769: loss=3.620, avg loss=3.996, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 369216 images, time remaining=2.6 hours
5770: loss=3.457, avg loss=3.942, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 369280 images, time remaining=2.6 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b33c000000
5771: loss=3.828, avg loss=3.931, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 369344 images, time remaining=2.6 hours
5772: loss=3.583, avg loss=3.896, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 369408 images, time remaining=2.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5773: loss=4.326, avg loss=3.939, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.7 seconds, train=2.6 seconds, 369472 images, time remaining=2.6 hours
5774: loss=3.236, avg loss=3.869, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=2.6 seconds, 369536 images, time remaining=2.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5775: loss=2.427, avg loss=3.724, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.0 seconds, train=2.6 seconds, 369600 images, time remaining=2.6 hours
5776: loss=3.029, avg loss=3.655, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 369664 images, time remaining=2.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5777: loss=3.158, avg loss=3.605, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.4 seconds, train=2.6 seconds, 369728 images, time remaining=2.6 hours
5778: loss=3.163, avg loss=3.561, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 369792 images, time remaining=2.6 hours
5779: loss=3.376, avg loss=3.543, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 369856 images, time remaining=2.6 hours
5780: loss=3.448, avg loss=3.533, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 369920 images, time remaining=2.6 hours
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
5781: loss=3.914, avg loss=3.571, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=5.7 seconds, 369984 images, time remaining=2.6 hours
5782: loss=4.394, avg loss=3.653, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 370048 images, time remaining=2.6 hours
5783: loss=4.555, avg loss=3.744, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 370112 images, time remaining=2.6 hours
5784: loss=3.841, avg loss=3.753, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.5 seconds, 370176 images, time remaining=2.6 hours
5785: loss=3.837, avg loss=3.762, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.6 seconds, train=5.6 seconds, 370240 images, time remaining=2.6 hours
5786: loss=3.489, avg loss=3.734, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=5.6 seconds, 370304 images, time remaining=2.6 hours
5787: loss=3.468, avg loss=3.708, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 370368 images, time remaining=2.6 hours
5788: loss=3.510, avg loss=3.688, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.6 seconds, train=5.6 seconds, 370432 images, time remaining=2.6 hours
5789: loss=4.101, avg loss=3.729, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 370496 images, time remaining=2.6 hours
5790: loss=3.610, avg loss=3.717, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 370560 images, time remaining=2.6 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
5791: loss=4.091, avg loss=3.755, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 370624 images, time remaining=2.6 hours
5792: loss=3.224, avg loss=3.702, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=4.9 seconds, 370688 images, time remaining=2.6 hours
5793: loss=3.095, avg loss=3.641, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 370752 images, time remaining=2.6 hours
5794: loss=3.447, avg loss=3.622, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 370816 images, time remaining=2.6 hours
5795: loss=3.424, avg loss=3.602, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 370880 images, time remaining=2.6 hours
5796: loss=2.994, avg loss=3.541, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.6 seconds, train=4.8 seconds, 370944 images, time remaining=2.6 hours
5797: loss=3.841, avg loss=3.571, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=4.8 seconds, 371008 images, time remaining=2.6 hours
5798: loss=3.292, avg loss=3.543, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.4 seconds, train=4.8 seconds, 371072 images, time remaining=2.6 hours
5799: loss=3.099, avg loss=3.499, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=4.9 seconds, 371136 images, time remaining=2.6 hours
5800: loss=3.694, avg loss=3.518, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.1 seconds, train=4.8 seconds, 371200 images, time remaining=2.6 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14b02a000000
5801: loss=4.024, avg loss=3.569, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=6.0 seconds, 371264 images, time remaining=2.6 hours
5802: loss=4.518, avg loss=3.664, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 371328 images, time remaining=2.6 hours
5803: loss=3.262, avg loss=3.624, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.2 seconds, train=5.9 seconds, 371392 images, time remaining=2.6 hours
5804: loss=3.645, avg loss=3.626, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=5.0 seconds, train=5.8 seconds, 371456 images, time remaining=2.6 hours
5805: loss=3.761, avg loss=3.639, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 371520 images, time remaining=2.6 hours
5806: loss=4.407, avg loss=3.716, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.1 seconds, train=5.9 seconds, 371584 images, time remaining=2.6 hours
5807: loss=4.126, avg loss=3.757, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 371648 images, time remaining=2.6 hours
5808: loss=3.272, avg loss=3.709, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 371712 images, time remaining=2.6 hours
5809: loss=4.194, avg loss=3.757, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 371776 images, time remaining=2.6 hours
5810: loss=3.930, avg loss=3.774, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.7 seconds, train=5.9 seconds, 371840 images, time remaining=2.6 hours
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
5811: loss=3.709, avg loss=3.768, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=6.1 seconds, 371904 images, time remaining=2.6 hours
5812: loss=4.123, avg loss=3.803, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=6.1 seconds, 371968 images, time remaining=2.6 hours
5813: loss=4.020, avg loss=3.825, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.0 seconds, train=6.1 seconds, 372032 images, time remaining=2.6 hours
5814: loss=4.115, avg loss=3.854, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=6.1 seconds, 372096 images, time remaining=2.6 hours
5815: loss=4.178, avg loss=3.886, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.5 seconds, train=6.0 seconds, 372160 images, time remaining=2.6 hours
5816: loss=3.886, avg loss=3.886, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=5.8 seconds, 372224 images, time remaining=2.6 hours
5817: loss=3.885, avg loss=3.886, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.9 seconds, train=6.1 seconds, 372288 images, time remaining=2.6 hours
5818: loss=3.296, avg loss=3.827, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 372352 images, time remaining=2.6 hours
5819: loss=4.047, avg loss=3.849, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 372416 images, time remaining=2.6 hours
5820: loss=3.260, avg loss=3.790, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=6.2 seconds, 372480 images, time remaining=2.6 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b5a4e00000
5821: loss=3.759, avg loss=3.787, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 372544 images, time remaining=2.6 hours
5822: loss=3.397, avg loss=3.748, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 372608 images, time remaining=2.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5823: loss=4.899, avg loss=3.863, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.2 seconds, train=2.2 seconds, 372672 images, time remaining=2.6 hours
5824: loss=3.884, avg loss=3.865, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 372736 images, time remaining=2.6 hours
5825: loss=3.193, avg loss=3.798, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 372800 images, time remaining=2.6 hours
5826: loss=2.577, avg loss=3.676, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.2 seconds, 372864 images, time remaining=2.6 hours
5827: loss=2.890, avg loss=3.597, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 372928 images, time remaining=2.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5828: loss=3.413, avg loss=3.579, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.3 seconds, train=2.0 seconds, 372992 images, time remaining=2.6 hours
5829: loss=4.076, avg loss=3.629, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 373056 images, time remaining=2.6 hours
5830: loss=3.244, avg loss=3.590, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 373120 images, time remaining=2.6 hours
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
5831: loss=5.508, avg loss=3.782, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=6.1 seconds, 373184 images, time remaining=2.6 hours
5832: loss=5.418, avg loss=3.946, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=6.1 seconds, 373248 images, time remaining=2.6 hours
5833: loss=4.495, avg loss=4.001, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.7 seconds, train=6.2 seconds, 373312 images, time remaining=2.6 hours
5834: loss=4.593, avg loss=4.060, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=6.1 seconds, 373376 images, time remaining=2.6 hours
5835: loss=4.174, avg loss=4.071, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=6.1 seconds, 373440 images, time remaining=2.6 hours
5836: loss=4.107, avg loss=4.075, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 373504 images, time remaining=2.6 hours
5837: loss=4.162, avg loss=4.083, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.7 seconds, train=6.1 seconds, 373568 images, time remaining=2.6 hours
5838: loss=4.837, avg loss=4.159, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 373632 images, time remaining=2.6 hours
5839: loss=4.268, avg loss=4.170, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 373696 images, time remaining=2.6 hours
5840: loss=5.267, avg loss=4.279, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.7 seconds, train=6.1 seconds, 373760 images, time remaining=2.6 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
5841: loss=3.270, avg loss=4.178, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 373824 images, time remaining=2.6 hours
5842: loss=3.765, avg loss=4.137, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 373888 images, time remaining=2.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5843: loss=3.683, avg loss=4.092, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.3 seconds, train=2.8 seconds, 373952 images, time remaining=2.6 hours
5844: loss=3.391, avg loss=4.022, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 374016 images, time remaining=2.6 hours
5845: loss=3.653, avg loss=3.985, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 374080 images, time remaining=2.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5846: loss=3.111, avg loss=3.897, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.9 seconds, train=2.7 seconds, 374144 images, time remaining=2.6 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5847: loss=3.894, avg loss=3.897, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.4 seconds, train=2.7 seconds, 374208 images, time remaining=2.6 hours
5848: loss=3.498, avg loss=3.857, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 374272 images, time remaining=2.6 hours
5849: loss=3.624, avg loss=3.834, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.8 seconds, train=2.8 seconds, 374336 images, time remaining=2.6 hours
5850: loss=3.495, avg loss=3.800, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 374400 images, time remaining=2.5 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b645a00000
5851: loss=3.405, avg loss=3.760, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 374464 images, time remaining=2.5 hours
5852: loss=3.036, avg loss=3.688, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 374528 images, time remaining=2.5 hours
5853: loss=3.820, avg loss=3.701, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 374592 images, time remaining=2.5 hours
5854: loss=3.593, avg loss=3.690, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 374656 images, time remaining=2.5 hours
5855: loss=3.278, avg loss=3.649, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 374720 images, time remaining=2.5 hours
5856: loss=2.756, avg loss=3.560, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 374784 images, time remaining=2.5 hours
5857: loss=2.922, avg loss=3.496, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 374848 images, time remaining=2.5 hours
5858: loss=3.397, avg loss=3.486, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 374912 images, time remaining=2.5 hours
5859: loss=2.912, avg loss=3.429, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 374976 images, time remaining=2.5 hours
5860: loss=3.276, avg loss=3.414, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=2.4 seconds, 375040 images, time remaining=2.5 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
5861: loss=3.760, avg loss=3.448, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 375104 images, time remaining=2.5 hours
5862: loss=3.291, avg loss=3.432, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=3.6 seconds, train=4.1 seconds, 375168 images, time remaining=2.5 hours
5863: loss=2.940, avg loss=3.383, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 375232 images, time remaining=2.5 hours
5864: loss=3.397, avg loss=3.385, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=2.3 seconds, train=4.1 seconds, 375296 images, time remaining=2.5 hours
5865: loss=3.103, avg loss=3.356, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 375360 images, time remaining=2.5 hours
5866: loss=3.511, avg loss=3.372, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.7 seconds, train=4.2 seconds, 375424 images, time remaining=2.5 hours
5867: loss=3.516, avg loss=3.386, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=4.2 seconds, 375488 images, time remaining=2.5 hours
5868: loss=3.343, avg loss=3.382, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=4.0 seconds, 375552 images, time remaining=2.5 hours
5869: loss=2.983, avg loss=3.342, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 375616 images, time remaining=2.5 hours
5870: loss=2.519, avg loss=3.260, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.9 seconds, train=4.1 seconds, 375680 images, time remaining=2.5 hours
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
5871: loss=3.012, avg loss=3.235, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=5.0 seconds, 375744 images, time remaining=2.5 hours
5872: loss=3.451, avg loss=3.257, last=95.55%, best=95.55%, next=5872, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 375808 images, time remaining=2.5 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b663800000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=110394, unique_truth_count=57264
rank=0 of ranks=110394rank=100 of ranks=110394rank=200 of ranks=110394rank=300 of ranks=110394rank=400 of ranks=110394rank=500 of ranks=110394rank=600 of ranks=110394rank=700 of ranks=110394rank=800 of ranks=110394rank=900 of ranks=110394rank=1000 of ranks=110394rank=1100 of ranks=110394rank=1200 of ranks=110394rank=1300 of ranks=110394rank=1400 of ranks=110394rank=1500 of ranks=110394rank=1600 of ranks=110394rank=1700 of ranks=110394rank=1800 of ranks=110394rank=1900 of ranks=110394rank=2000 of ranks=110394rank=2100 of ranks=110394rank=2200 of ranks=110394rank=2300 of ranks=110394rank=2400 of ranks=110394rank=2500 of ranks=110394rank=2600 of ranks=110394rank=2700 of ranks=110394rank=2800 of ranks=110394rank=2900 of ranks=110394rank=3000 of ranks=110394rank=3100 of ranks=110394rank=3200 of ranks=110394rank=3300 of ranks=110394rank=3400 of ranks=110394rank=3500 of ranks=110394rank=3600 of ranks=110394rank=3700 of ranks=110394rank=3800 of ranks=110394rank=3900 of ranks=110394rank=4000 of ranks=110394rank=4100 of ranks=110394rank=4200 of ranks=110394rank=4300 of ranks=110394rank=4400 of ranks=110394rank=4500 of ranks=110394rank=4600 of ranks=110394rank=4700 of ranks=110394rank=4800 of ranks=110394rank=4900 of ranks=110394rank=5000 of ranks=110394rank=5100 of ranks=110394rank=5200 of ranks=110394rank=5300 of ranks=110394rank=5400 of ranks=110394rank=5500 of ranks=110394rank=5600 of ranks=110394rank=5700 of ranks=110394rank=5800 of ranks=110394rank=5900 of ranks=110394rank=6000 of ranks=110394rank=6100 of ranks=110394rank=6200 of ranks=110394rank=6300 of ranks=110394rank=6400 of ranks=110394rank=6500 of ranks=110394rank=6600 of ranks=110394rank=6700 of ranks=110394rank=6800 of ranks=110394rank=6900 of ranks=110394rank=7000 of ranks=110394rank=7100 of ranks=110394rank=7200 of ranks=110394rank=7300 of ranks=110394rank=7400 of ranks=110394rank=7500 of ranks=110394rank=7600 of ranks=110394rank=7700 of ranks=110394rank=7800 of ranks=110394rank=7900 of ranks=110394rank=8000 of ranks=110394rank=8100 of ranks=110394rank=8200 of ranks=110394rank=8300 of ranks=110394rank=8400 of ranks=110394rank=8500 of ranks=110394rank=8600 of ranks=110394rank=8700 of ranks=110394rank=8800 of ranks=110394rank=8900 of ranks=110394rank=9000 of ranks=110394rank=9100 of ranks=110394rank=9200 of ranks=110394rank=9300 of ranks=110394rank=9400 of ranks=110394rank=9500 of ranks=110394rank=9600 of ranks=110394rank=9700 of ranks=110394rank=9800 of ranks=110394rank=9900 of ranks=110394rank=10000 of ranks=110394rank=10100 of ranks=110394rank=10200 of ranks=110394rank=10300 of ranks=110394rank=10400 of ranks=110394rank=10500 of ranks=110394rank=10600 of ranks=110394rank=10700 of ranks=110394rank=10800 of ranks=110394rank=10900 of ranks=110394rank=11000 of ranks=110394rank=11100 of ranks=110394rank=11200 of ranks=110394rank=11300 of ranks=110394rank=11400 of ranks=110394rank=11500 of ranks=110394rank=11600 of ranks=110394rank=11700 of ranks=110394rank=11800 of ranks=110394rank=11900 of ranks=110394rank=12000 of ranks=110394rank=12100 of ranks=110394rank=12200 of ranks=110394rank=12300 of ranks=110394rank=12400 of ranks=110394rank=12500 of ranks=110394rank=12600 of ranks=110394rank=12700 of ranks=110394rank=12800 of ranks=110394rank=12900 of ranks=110394rank=13000 of ranks=110394rank=13100 of ranks=110394rank=13200 of ranks=110394rank=13300 of ranks=110394rank=13400 of ranks=110394rank=13500 of ranks=110394rank=13600 of ranks=110394rank=13700 of ranks=110394rank=13800 of ranks=110394rank=13900 of ranks=110394rank=14000 of ranks=110394rank=14100 of ranks=110394rank=14200 of ranks=110394rank=14300 of ranks=110394rank=14400 of ranks=110394rank=14500 of ranks=110394rank=14600 of ranks=110394rank=14700 of ranks=110394rank=14800 of ranks=110394rank=14900 of ranks=110394rank=15000 of ranks=110394rank=15100 of ranks=110394rank=15200 of ranks=110394rank=15300 of ranks=110394rank=15400 of ranks=110394rank=15500 of ranks=110394rank=15600 of ranks=110394rank=15700 of ranks=110394rank=15800 of ranks=110394rank=15900 of ranks=110394rank=16000 of ranks=110394rank=16100 of ranks=110394rank=16200 of ranks=110394rank=16300 of ranks=110394rank=16400 of ranks=110394rank=16500 of ranks=110394rank=16600 of ranks=110394rank=16700 of ranks=110394rank=16800 of ranks=110394rank=16900 of ranks=110394rank=17000 of ranks=110394rank=17100 of ranks=110394rank=17200 of ranks=110394rank=17300 of ranks=110394rank=17400 of ranks=110394rank=17500 of ranks=110394rank=17600 of ranks=110394rank=17700 of ranks=110394rank=17800 of ranks=110394rank=17900 of ranks=110394rank=18000 of ranks=110394rank=18100 of ranks=110394rank=18200 of ranks=110394rank=18300 of ranks=110394rank=18400 of ranks=110394rank=18500 of ranks=110394rank=18600 of ranks=110394rank=18700 of ranks=110394rank=18800 of ranks=110394rank=18900 of ranks=110394rank=19000 of ranks=110394rank=19100 of ranks=110394rank=19200 of ranks=110394rank=19300 of ranks=110394rank=19400 of ranks=110394rank=19500 of ranks=110394rank=19600 of ranks=110394rank=19700 of ranks=110394rank=19800 of ranks=110394rank=19900 of ranks=110394rank=20000 of ranks=110394rank=20100 of ranks=110394rank=20200 of ranks=110394rank=20300 of ranks=110394rank=20400 of ranks=110394rank=20500 of ranks=110394rank=20600 of ranks=110394rank=20700 of ranks=110394rank=20800 of ranks=110394rank=20900 of ranks=110394rank=21000 of ranks=110394rank=21100 of ranks=110394rank=21200 of ranks=110394rank=21300 of ranks=110394rank=21400 of ranks=110394rank=21500 of ranks=110394rank=21600 of ranks=110394rank=21700 of ranks=110394rank=21800 of ranks=110394rank=21900 of ranks=110394rank=22000 of ranks=110394rank=22100 of ranks=110394rank=22200 of ranks=110394rank=22300 of ranks=110394rank=22400 of ranks=110394rank=22500 of ranks=110394rank=22600 of ranks=110394rank=22700 of ranks=110394rank=22800 of ranks=110394rank=22900 of ranks=110394rank=23000 of ranks=110394rank=23100 of ranks=110394rank=23200 of ranks=110394rank=23300 of ranks=110394rank=23400 of ranks=110394rank=23500 of ranks=110394rank=23600 of ranks=110394rank=23700 of ranks=110394rank=23800 of ranks=110394rank=23900 of ranks=110394rank=24000 of ranks=110394rank=24100 of ranks=110394rank=24200 of ranks=110394rank=24300 of ranks=110394rank=24400 of ranks=110394rank=24500 of ranks=110394rank=24600 of ranks=110394rank=24700 of ranks=110394rank=24800 of ranks=110394rank=24900 of ranks=110394rank=25000 of ranks=110394rank=25100 of ranks=110394rank=25200 of ranks=110394rank=25300 of ranks=110394rank=25400 of ranks=110394rank=25500 of ranks=110394rank=25600 of ranks=110394rank=25700 of ranks=110394rank=25800 of ranks=110394rank=25900 of ranks=110394rank=26000 of ranks=110394rank=26100 of ranks=110394rank=26200 of ranks=110394rank=26300 of ranks=110394rank=26400 of ranks=110394rank=26500 of ranks=110394rank=26600 of ranks=110394rank=26700 of ranks=110394rank=26800 of ranks=110394rank=26900 of ranks=110394rank=27000 of ranks=110394rank=27100 of ranks=110394rank=27200 of ranks=110394rank=27300 of ranks=110394rank=27400 of ranks=110394rank=27500 of ranks=110394rank=27600 of ranks=110394rank=27700 of ranks=110394rank=27800 of ranks=110394rank=27900 of ranks=110394rank=28000 of ranks=110394rank=28100 of ranks=110394rank=28200 of ranks=110394rank=28300 of ranks=110394rank=28400 of ranks=110394rank=28500 of ranks=110394rank=28600 of ranks=110394rank=28700 of ranks=110394rank=28800 of ranks=110394rank=28900 of ranks=110394rank=29000 of ranks=110394rank=29100 of ranks=110394rank=29200 of ranks=110394rank=29300 of ranks=110394rank=29400 of ranks=110394rank=29500 of ranks=110394rank=29600 of ranks=110394rank=29700 of ranks=110394rank=29800 of ranks=110394rank=29900 of ranks=110394rank=30000 of ranks=110394rank=30100 of ranks=110394rank=30200 of ranks=110394rank=30300 of ranks=110394rank=30400 of ranks=110394rank=30500 of ranks=110394rank=30600 of ranks=110394rank=30700 of ranks=110394rank=30800 of ranks=110394rank=30900 of ranks=110394rank=31000 of ranks=110394rank=31100 of ranks=110394rank=31200 of ranks=110394rank=31300 of ranks=110394rank=31400 of ranks=110394rank=31500 of ranks=110394rank=31600 of ranks=110394rank=31700 of ranks=110394rank=31800 of ranks=110394rank=31900 of ranks=110394rank=32000 of ranks=110394rank=32100 of ranks=110394rank=32200 of ranks=110394rank=32300 of ranks=110394rank=32400 of ranks=110394rank=32500 of ranks=110394rank=32600 of ranks=110394rank=32700 of ranks=110394rank=32800 of ranks=110394rank=32900 of ranks=110394rank=33000 of ranks=110394rank=33100 of ranks=110394rank=33200 of ranks=110394rank=33300 of ranks=110394rank=33400 of ranks=110394rank=33500 of ranks=110394rank=33600 of ranks=110394rank=33700 of ranks=110394rank=33800 of ranks=110394rank=33900 of ranks=110394rank=34000 of ranks=110394rank=34100 of ranks=110394rank=34200 of ranks=110394rank=34300 of ranks=110394rank=34400 of ranks=110394rank=34500 of ranks=110394rank=34600 of ranks=110394rank=34700 of ranks=110394rank=34800 of ranks=110394rank=34900 of ranks=110394rank=35000 of ranks=110394rank=35100 of ranks=110394rank=35200 of ranks=110394rank=35300 of ranks=110394rank=35400 of ranks=110394rank=35500 of ranks=110394rank=35600 of ranks=110394rank=35700 of ranks=110394rank=35800 of ranks=110394rank=35900 of ranks=110394rank=36000 of ranks=110394rank=36100 of ranks=110394rank=36200 of ranks=110394rank=36300 of ranks=110394rank=36400 of ranks=110394rank=36500 of ranks=110394rank=36600 of ranks=110394rank=36700 of ranks=110394rank=36800 of ranks=110394rank=36900 of ranks=110394rank=37000 of ranks=110394rank=37100 of ranks=110394rank=37200 of ranks=110394rank=37300 of ranks=110394rank=37400 of ranks=110394rank=37500 of ranks=110394rank=37600 of ranks=110394rank=37700 of ranks=110394rank=37800 of ranks=110394rank=37900 of ranks=110394rank=38000 of ranks=110394rank=38100 of ranks=110394rank=38200 of ranks=110394rank=38300 of ranks=110394rank=38400 of ranks=110394rank=38500 of ranks=110394rank=38600 of ranks=110394rank=38700 of ranks=110394rank=38800 of ranks=110394rank=38900 of ranks=110394rank=39000 of ranks=110394rank=39100 of ranks=110394rank=39200 of ranks=110394rank=39300 of ranks=110394rank=39400 of ranks=110394rank=39500 of ranks=110394rank=39600 of ranks=110394rank=39700 of ranks=110394rank=39800 of ranks=110394rank=39900 of ranks=110394rank=40000 of ranks=110394rank=40100 of ranks=110394rank=40200 of ranks=110394rank=40300 of ranks=110394rank=40400 of ranks=110394rank=40500 of ranks=110394rank=40600 of ranks=110394rank=40700 of ranks=110394rank=40800 of ranks=110394rank=40900 of ranks=110394rank=41000 of ranks=110394rank=41100 of ranks=110394rank=41200 of ranks=110394rank=41300 of ranks=110394rank=41400 of ranks=110394rank=41500 of ranks=110394rank=41600 of ranks=110394rank=41700 of ranks=110394rank=41800 of ranks=110394rank=41900 of ranks=110394rank=42000 of ranks=110394rank=42100 of ranks=110394rank=42200 of ranks=110394rank=42300 of ranks=110394rank=42400 of ranks=110394rank=42500 of ranks=110394rank=42600 of ranks=110394rank=42700 of ranks=110394rank=42800 of ranks=110394rank=42900 of ranks=110394rank=43000 of ranks=110394rank=43100 of ranks=110394rank=43200 of ranks=110394rank=43300 of ranks=110394rank=43400 of ranks=110394rank=43500 of ranks=110394rank=43600 of ranks=110394rank=43700 of ranks=110394rank=43800 of ranks=110394rank=43900 of ranks=110394rank=44000 of ranks=110394rank=44100 of ranks=110394rank=44200 of ranks=110394rank=44300 of ranks=110394rank=44400 of ranks=110394rank=44500 of ranks=110394rank=44600 of ranks=110394rank=44700 of ranks=110394rank=44800 of ranks=110394rank=44900 of ranks=110394rank=45000 of ranks=110394rank=45100 of ranks=110394rank=45200 of ranks=110394rank=45300 of ranks=110394rank=45400 of ranks=110394rank=45500 of ranks=110394rank=45600 of ranks=110394rank=45700 of ranks=110394rank=45800 of ranks=110394rank=45900 of ranks=110394rank=46000 of ranks=110394rank=46100 of ranks=110394rank=46200 of ranks=110394rank=46300 of ranks=110394rank=46400 of ranks=110394rank=46500 of ranks=110394rank=46600 of ranks=110394rank=46700 of ranks=110394rank=46800 of ranks=110394rank=46900 of ranks=110394rank=47000 of ranks=110394rank=47100 of ranks=110394rank=47200 of ranks=110394rank=47300 of ranks=110394rank=47400 of ranks=110394rank=47500 of ranks=110394rank=47600 of ranks=110394rank=47700 of ranks=110394rank=47800 of ranks=110394rank=47900 of ranks=110394rank=48000 of ranks=110394rank=48100 of ranks=110394rank=48200 of ranks=110394rank=48300 of ranks=110394rank=48400 of ranks=110394rank=48500 of ranks=110394rank=48600 of ranks=110394rank=48700 of ranks=110394rank=48800 of ranks=110394rank=48900 of ranks=110394rank=49000 of ranks=110394rank=49100 of ranks=110394rank=49200 of ranks=110394rank=49300 of ranks=110394rank=49400 of ranks=110394rank=49500 of ranks=110394rank=49600 of ranks=110394rank=49700 of ranks=110394rank=49800 of ranks=110394rank=49900 of ranks=110394rank=50000 of ranks=110394rank=50100 of ranks=110394rank=50200 of ranks=110394rank=50300 of ranks=110394rank=50400 of ranks=110394rank=50500 of ranks=110394rank=50600 of ranks=110394rank=50700 of ranks=110394rank=50800 of ranks=110394rank=50900 of ranks=110394rank=51000 of ranks=110394rank=51100 of ranks=110394rank=51200 of ranks=110394rank=51300 of ranks=110394rank=51400 of ranks=110394rank=51500 of ranks=110394rank=51600 of ranks=110394rank=51700 of ranks=110394rank=51800 of ranks=110394rank=51900 of ranks=110394rank=52000 of ranks=110394rank=52100 of ranks=110394rank=52200 of ranks=110394rank=52300 of ranks=110394rank=52400 of ranks=110394rank=52500 of ranks=110394rank=52600 of ranks=110394rank=52700 of ranks=110394rank=52800 of ranks=110394rank=52900 of ranks=110394rank=53000 of ranks=110394rank=53100 of ranks=110394rank=53200 of ranks=110394rank=53300 of ranks=110394rank=53400 of ranks=110394rank=53500 of ranks=110394rank=53600 of ranks=110394rank=53700 of ranks=110394rank=53800 of ranks=110394rank=53900 of ranks=110394rank=54000 of ranks=110394rank=54100 of ranks=110394rank=54200 of ranks=110394rank=54300 of ranks=110394rank=54400 of ranks=110394rank=54500 of ranks=110394rank=54600 of ranks=110394rank=54700 of ranks=110394rank=54800 of ranks=110394rank=54900 of ranks=110394rank=55000 of ranks=110394rank=55100 of ranks=110394rank=55200 of ranks=110394rank=55300 of ranks=110394rank=55400 of ranks=110394rank=55500 of ranks=110394rank=55600 of ranks=110394rank=55700 of ranks=110394rank=55800 of ranks=110394rank=55900 of ranks=110394rank=56000 of ranks=110394rank=56100 of ranks=110394rank=56200 of ranks=110394rank=56300 of ranks=110394rank=56400 of ranks=110394rank=56500 of ranks=110394rank=56600 of ranks=110394rank=56700 of ranks=110394rank=56800 of ranks=110394rank=56900 of ranks=110394rank=57000 of ranks=110394rank=57100 of ranks=110394rank=57200 of ranks=110394rank=57300 of ranks=110394rank=57400 of ranks=110394rank=57500 of ranks=110394rank=57600 of ranks=110394rank=57700 of ranks=110394rank=57800 of ranks=110394rank=57900 of ranks=110394rank=58000 of ranks=110394rank=58100 of ranks=110394rank=58200 of ranks=110394rank=58300 of ranks=110394rank=58400 of ranks=110394rank=58500 of ranks=110394rank=58600 of ranks=110394rank=58700 of ranks=110394rank=58800 of ranks=110394rank=58900 of ranks=110394rank=59000 of ranks=110394rank=59100 of ranks=110394rank=59200 of ranks=110394rank=59300 of ranks=110394rank=59400 of ranks=110394rank=59500 of ranks=110394rank=59600 of ranks=110394rank=59700 of ranks=110394rank=59800 of ranks=110394rank=59900 of ranks=110394rank=60000 of ranks=110394rank=60100 of ranks=110394rank=60200 of ranks=110394rank=60300 of ranks=110394rank=60400 of ranks=110394rank=60500 of ranks=110394rank=60600 of ranks=110394rank=60700 of ranks=110394rank=60800 of ranks=110394rank=60900 of ranks=110394rank=61000 of ranks=110394rank=61100 of ranks=110394rank=61200 of ranks=110394rank=61300 of ranks=110394rank=61400 of ranks=110394rank=61500 of ranks=110394rank=61600 of ranks=110394rank=61700 of ranks=110394rank=61800 of ranks=110394rank=61900 of ranks=110394rank=62000 of ranks=110394rank=62100 of ranks=110394rank=62200 of ranks=110394rank=62300 of ranks=110394rank=62400 of ranks=110394rank=62500 of ranks=110394rank=62600 of ranks=110394rank=62700 of ranks=110394rank=62800 of ranks=110394rank=62900 of ranks=110394rank=63000 of ranks=110394rank=63100 of ranks=110394rank=63200 of ranks=110394rank=63300 of ranks=110394rank=63400 of ranks=110394rank=63500 of ranks=110394rank=63600 of ranks=110394rank=63700 of ranks=110394rank=63800 of ranks=110394rank=63900 of ranks=110394rank=64000 of ranks=110394rank=64100 of ranks=110394rank=64200 of ranks=110394rank=64300 of ranks=110394rank=64400 of ranks=110394rank=64500 of ranks=110394rank=64600 of ranks=110394rank=64700 of ranks=110394rank=64800 of ranks=110394rank=64900 of ranks=110394rank=65000 of ranks=110394rank=65100 of ranks=110394rank=65200 of ranks=110394rank=65300 of ranks=110394rank=65400 of ranks=110394rank=65500 of ranks=110394rank=65600 of ranks=110394rank=65700 of ranks=110394rank=65800 of ranks=110394rank=65900 of ranks=110394rank=66000 of ranks=110394rank=66100 of ranks=110394rank=66200 of ranks=110394rank=66300 of ranks=110394rank=66400 of ranks=110394rank=66500 of ranks=110394rank=66600 of ranks=110394rank=66700 of ranks=110394rank=66800 of ranks=110394rank=66900 of ranks=110394rank=67000 of ranks=110394rank=67100 of ranks=110394rank=67200 of ranks=110394rank=67300 of ranks=110394rank=67400 of ranks=110394rank=67500 of ranks=110394rank=67600 of ranks=110394rank=67700 of ranks=110394rank=67800 of ranks=110394rank=67900 of ranks=110394rank=68000 of ranks=110394rank=68100 of ranks=110394rank=68200 of ranks=110394rank=68300 of ranks=110394rank=68400 of ranks=110394rank=68500 of ranks=110394rank=68600 of ranks=110394rank=68700 of ranks=110394rank=68800 of ranks=110394rank=68900 of ranks=110394rank=69000 of ranks=110394rank=69100 of ranks=110394rank=69200 of ranks=110394rank=69300 of ranks=110394rank=69400 of ranks=110394rank=69500 of ranks=110394rank=69600 of ranks=110394rank=69700 of ranks=110394rank=69800 of ranks=110394rank=69900 of ranks=110394rank=70000 of ranks=110394rank=70100 of ranks=110394rank=70200 of ranks=110394rank=70300 of ranks=110394rank=70400 of ranks=110394rank=70500 of ranks=110394rank=70600 of ranks=110394rank=70700 of ranks=110394rank=70800 of ranks=110394rank=70900 of ranks=110394rank=71000 of ranks=110394rank=71100 of ranks=110394rank=71200 of ranks=110394rank=71300 of ranks=110394rank=71400 of ranks=110394rank=71500 of ranks=110394rank=71600 of ranks=110394rank=71700 of ranks=110394rank=71800 of ranks=110394rank=71900 of ranks=110394rank=72000 of ranks=110394rank=72100 of ranks=110394rank=72200 of ranks=110394rank=72300 of ranks=110394rank=72400 of ranks=110394rank=72500 of ranks=110394rank=72600 of ranks=110394rank=72700 of ranks=110394rank=72800 of ranks=110394rank=72900 of ranks=110394rank=73000 of ranks=110394rank=73100 of ranks=110394rank=73200 of ranks=110394rank=73300 of ranks=110394rank=73400 of ranks=110394rank=73500 of ranks=110394rank=73600 of ranks=110394rank=73700 of ranks=110394rank=73800 of ranks=110394rank=73900 of ranks=110394rank=74000 of ranks=110394rank=74100 of ranks=110394rank=74200 of ranks=110394rank=74300 of ranks=110394rank=74400 of ranks=110394rank=74500 of ranks=110394rank=74600 of ranks=110394rank=74700 of ranks=110394rank=74800 of ranks=110394rank=74900 of ranks=110394rank=75000 of ranks=110394rank=75100 of ranks=110394rank=75200 of ranks=110394rank=75300 of ranks=110394rank=75400 of ranks=110394rank=75500 of ranks=110394rank=75600 of ranks=110394rank=75700 of ranks=110394rank=75800 of ranks=110394rank=75900 of ranks=110394rank=76000 of ranks=110394rank=76100 of ranks=110394rank=76200 of ranks=110394rank=76300 of ranks=110394rank=76400 of ranks=110394rank=76500 of ranks=110394rank=76600 of ranks=110394rank=76700 of ranks=110394rank=76800 of ranks=110394rank=76900 of ranks=110394rank=77000 of ranks=110394rank=77100 of ranks=110394rank=77200 of ranks=110394rank=77300 of ranks=110394rank=77400 of ranks=110394rank=77500 of ranks=110394rank=77600 of ranks=110394rank=77700 of ranks=110394rank=77800 of ranks=110394rank=77900 of ranks=110394rank=78000 of ranks=110394rank=78100 of ranks=110394rank=78200 of ranks=110394rank=78300 of ranks=110394rank=78400 of ranks=110394rank=78500 of ranks=110394rank=78600 of ranks=110394rank=78700 of ranks=110394rank=78800 of ranks=110394rank=78900 of ranks=110394rank=79000 of ranks=110394rank=79100 of ranks=110394rank=79200 of ranks=110394rank=79300 of ranks=110394rank=79400 of ranks=110394rank=79500 of ranks=110394rank=79600 of ranks=110394rank=79700 of ranks=110394rank=79800 of ranks=110394rank=79900 of ranks=110394rank=80000 of ranks=110394rank=80100 of ranks=110394rank=80200 of ranks=110394rank=80300 of ranks=110394rank=80400 of ranks=110394rank=80500 of ranks=110394rank=80600 of ranks=110394rank=80700 of ranks=110394rank=80800 of ranks=110394rank=80900 of ranks=110394rank=81000 of ranks=110394rank=81100 of ranks=110394rank=81200 of ranks=110394rank=81300 of ranks=110394rank=81400 of ranks=110394rank=81500 of ranks=110394rank=81600 of ranks=110394rank=81700 of ranks=110394rank=81800 of ranks=110394rank=81900 of ranks=110394rank=82000 of ranks=110394rank=82100 of ranks=110394rank=82200 of ranks=110394rank=82300 of ranks=110394rank=82400 of ranks=110394rank=82500 of ranks=110394rank=82600 of ranks=110394rank=82700 of ranks=110394rank=82800 of ranks=110394rank=82900 of ranks=110394rank=83000 of ranks=110394rank=83100 of ranks=110394rank=83200 of ranks=110394rank=83300 of ranks=110394rank=83400 of ranks=110394rank=83500 of ranks=110394rank=83600 of ranks=110394rank=83700 of ranks=110394rank=83800 of ranks=110394rank=83900 of ranks=110394rank=84000 of ranks=110394rank=84100 of ranks=110394rank=84200 of ranks=110394rank=84300 of ranks=110394rank=84400 of ranks=110394rank=84500 of ranks=110394rank=84600 of ranks=110394rank=84700 of ranks=110394rank=84800 of ranks=110394rank=84900 of ranks=110394rank=85000 of ranks=110394rank=85100 of ranks=110394rank=85200 of ranks=110394rank=85300 of ranks=110394rank=85400 of ranks=110394rank=85500 of ranks=110394rank=85600 of ranks=110394rank=85700 of ranks=110394rank=85800 of ranks=110394rank=85900 of ranks=110394rank=86000 of ranks=110394rank=86100 of ranks=110394rank=86200 of ranks=110394rank=86300 of ranks=110394rank=86400 of ranks=110394rank=86500 of ranks=110394rank=86600 of ranks=110394rank=86700 of ranks=110394rank=86800 of ranks=110394rank=86900 of ranks=110394rank=87000 of ranks=110394rank=87100 of ranks=110394rank=87200 of ranks=110394rank=87300 of ranks=110394rank=87400 of ranks=110394rank=87500 of ranks=110394rank=87600 of ranks=110394rank=87700 of ranks=110394rank=87800 of ranks=110394rank=87900 of ranks=110394rank=88000 of ranks=110394rank=88100 of ranks=110394rank=88200 of ranks=110394rank=88300 of ranks=110394rank=88400 of ranks=110394rank=88500 of ranks=110394rank=88600 of ranks=110394rank=88700 of ranks=110394rank=88800 of ranks=110394rank=88900 of ranks=110394rank=89000 of ranks=110394rank=89100 of ranks=110394rank=89200 of ranks=110394rank=89300 of ranks=110394rank=89400 of ranks=110394rank=89500 of ranks=110394rank=89600 of ranks=110394rank=89700 of ranks=110394rank=89800 of ranks=110394rank=89900 of ranks=110394rank=90000 of ranks=110394rank=90100 of ranks=110394rank=90200 of ranks=110394rank=90300 of ranks=110394rank=90400 of ranks=110394rank=90500 of ranks=110394rank=90600 of ranks=110394rank=90700 of ranks=110394rank=90800 of ranks=110394rank=90900 of ranks=110394rank=91000 of ranks=110394rank=91100 of ranks=110394rank=91200 of ranks=110394rank=91300 of ranks=110394rank=91400 of ranks=110394rank=91500 of ranks=110394rank=91600 of ranks=110394rank=91700 of ranks=110394rank=91800 of ranks=110394rank=91900 of ranks=110394rank=92000 of ranks=110394rank=92100 of ranks=110394rank=92200 of ranks=110394rank=92300 of ranks=110394rank=92400 of ranks=110394rank=92500 of ranks=110394rank=92600 of ranks=110394rank=92700 of ranks=110394rank=92800 of ranks=110394rank=92900 of ranks=110394rank=93000 of ranks=110394rank=93100 of ranks=110394rank=93200 of ranks=110394rank=93300 of ranks=110394rank=93400 of ranks=110394rank=93500 of ranks=110394rank=93600 of ranks=110394rank=93700 of ranks=110394rank=93800 of ranks=110394rank=93900 of ranks=110394rank=94000 of ranks=110394rank=94100 of ranks=110394rank=94200 of ranks=110394rank=94300 of ranks=110394rank=94400 of ranks=110394rank=94500 of ranks=110394rank=94600 of ranks=110394rank=94700 of ranks=110394rank=94800 of ranks=110394rank=94900 of ranks=110394rank=95000 of ranks=110394rank=95100 of ranks=110394rank=95200 of ranks=110394rank=95300 of ranks=110394rank=95400 of ranks=110394rank=95500 of ranks=110394rank=95600 of ranks=110394rank=95700 of ranks=110394rank=95800 of ranks=110394rank=95900 of ranks=110394rank=96000 of ranks=110394rank=96100 of ranks=110394rank=96200 of ranks=110394rank=96300 of ranks=110394rank=96400 of ranks=110394rank=96500 of ranks=110394rank=96600 of ranks=110394rank=96700 of ranks=110394rank=96800 of ranks=110394rank=96900 of ranks=110394rank=97000 of ranks=110394rank=97100 of ranks=110394rank=97200 of ranks=110394rank=97300 of ranks=110394rank=97400 of ranks=110394rank=97500 of ranks=110394rank=97600 of ranks=110394rank=97700 of ranks=110394rank=97800 of ranks=110394rank=97900 of ranks=110394rank=98000 of ranks=110394rank=98100 of ranks=110394rank=98200 of ranks=110394rank=98300 of ranks=110394rank=98400 of ranks=110394rank=98500 of ranks=110394rank=98600 of ranks=110394rank=98700 of ranks=110394rank=98800 of ranks=110394rank=98900 of ranks=110394rank=99000 of ranks=110394rank=99100 of ranks=110394rank=99200 of ranks=110394rank=99300 of ranks=110394rank=99400 of ranks=110394rank=99500 of ranks=110394rank=99600 of ranks=110394rank=99700 of ranks=110394rank=99800 of ranks=110394rank=99900 of ranks=110394rank=100000 of ranks=110394rank=100100 of ranks=110394rank=100200 of ranks=110394rank=100300 of ranks=110394rank=100400 of ranks=110394rank=100500 of ranks=110394rank=100600 of ranks=110394rank=100700 of ranks=110394rank=100800 of ranks=110394rank=100900 of ranks=110394rank=101000 of ranks=110394rank=101100 of ranks=110394rank=101200 of ranks=110394rank=101300 of ranks=110394rank=101400 of ranks=110394rank=101500 of ranks=110394rank=101600 of ranks=110394rank=101700 of ranks=110394rank=101800 of ranks=110394rank=101900 of ranks=110394rank=102000 of ranks=110394rank=102100 of ranks=110394rank=102200 of ranks=110394rank=102300 of ranks=110394rank=102400 of ranks=110394rank=102500 of ranks=110394rank=102600 of ranks=110394rank=102700 of ranks=110394rank=102800 of ranks=110394rank=102900 of ranks=110394rank=103000 of ranks=110394rank=103100 of ranks=110394rank=103200 of ranks=110394rank=103300 of ranks=110394rank=103400 of ranks=110394rank=103500 of ranks=110394rank=103600 of ranks=110394rank=103700 of ranks=110394rank=103800 of ranks=110394rank=103900 of ranks=110394rank=104000 of ranks=110394rank=104100 of ranks=110394rank=104200 of ranks=110394rank=104300 of ranks=110394rank=104400 of ranks=110394rank=104500 of ranks=110394rank=104600 of ranks=110394rank=104700 of ranks=110394rank=104800 of ranks=110394rank=104900 of ranks=110394rank=105000 of ranks=110394rank=105100 of ranks=110394rank=105200 of ranks=110394rank=105300 of ranks=110394rank=105400 of ranks=110394rank=105500 of ranks=110394rank=105600 of ranks=110394rank=105700 of ranks=110394rank=105800 of ranks=110394rank=105900 of ranks=110394rank=106000 of ranks=110394rank=106100 of ranks=110394rank=106200 of ranks=110394rank=106300 of ranks=110394rank=106400 of ranks=110394rank=106500 of ranks=110394rank=106600 of ranks=110394rank=106700 of ranks=110394rank=106800 of ranks=110394rank=106900 of ranks=110394rank=107000 of ranks=110394rank=107100 of ranks=110394rank=107200 of ranks=110394rank=107300 of ranks=110394rank=107400 of ranks=110394rank=107500 of ranks=110394rank=107600 of ranks=110394rank=107700 of ranks=110394rank=107800 of ranks=110394rank=107900 of ranks=110394rank=108000 of ranks=110394rank=108100 of ranks=110394rank=108200 of ranks=110394rank=108300 of ranks=110394rank=108400 of ranks=110394rank=108500 of ranks=110394rank=108600 of ranks=110394rank=108700 of ranks=110394rank=108800 of ranks=110394rank=108900 of ranks=110394rank=109000 of ranks=110394rank=109100 of ranks=110394rank=109200 of ranks=110394rank=109300 of ranks=110394rank=109400 of ranks=110394rank=109500 of ranks=110394rank=109600 of ranks=110394rank=109700 of ranks=110394rank=109800 of ranks=110394rank=109900 of ranks=110394rank=110000 of ranks=110394rank=110100 of ranks=110394rank=110200 of ranks=110394rank=110300 of ranks=110394

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              95.5648    483   2519     15    498           74.0253
   1 car                    98.3240  49978  35907    338  50316           79.7928
   2 truck                  96.4663   1807   5126     18   1825           67.5248
   3 bus                    94.2544    359   3342      7    366           69.0802
   4 pedestrian             95.5080   4132   6741    127   4259           74.1153

for conf_thresh=0.25, precision=0.89, recall=0.96, F1 score=0.92
for conf_thresh=0.25, TP=54734, FP=6793, FN=2530, average IoU=78.87%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=96.02%
Total detection time: 166 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
New best mAP, saving weights!
Saving weights to /workspace/.cache/splits/combined_best.weights
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5873: loss=3.135, avg loss=3.245, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.9 seconds, train=2.8 seconds, 375872 images, time remaining=2.5 hours
5874: loss=2.846, avg loss=3.205, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 375936 images, time remaining=2.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5875: loss=3.519, avg loss=3.236, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=4.7 seconds, train=2.8 seconds, 376000 images, time remaining=2.5 hours
5876: loss=2.706, avg loss=3.183, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 376064 images, time remaining=2.5 hours
5877: loss=2.933, avg loss=3.158, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 376128 images, time remaining=2.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5878: loss=2.698, avg loss=3.112, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=5.0 seconds, train=2.8 seconds, 376192 images, time remaining=2.5 hours
5879: loss=3.108, avg loss=3.112, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 376256 images, time remaining=2.5 hours
5880: loss=2.881, avg loss=3.089, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 376320 images, time remaining=2.5 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
5881: loss=3.977, avg loss=3.178, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=5.5 seconds, 376384 images, time remaining=2.5 hours
5882: loss=3.790, avg loss=3.239, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 376448 images, time remaining=2.5 hours
5883: loss=3.564, avg loss=3.271, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 376512 images, time remaining=2.5 hours
5884: loss=3.307, avg loss=3.275, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 376576 images, time remaining=2.5 hours
5885: loss=2.908, avg loss=3.238, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 376640 images, time remaining=2.5 hours
5886: loss=3.674, avg loss=3.282, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.9 seconds, train=5.4 seconds, 376704 images, time remaining=2.5 hours
5887: loss=3.012, avg loss=3.255, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 376768 images, time remaining=2.5 hours
5888: loss=3.233, avg loss=3.253, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 376832 images, time remaining=2.5 hours
5889: loss=2.965, avg loss=3.224, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=5.4 seconds, 376896 images, time remaining=2.5 hours
5890: loss=3.726, avg loss=3.274, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.5 seconds, 376960 images, time remaining=2.5 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b53ce00000
5891: loss=3.548, avg loss=3.301, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 377024 images, time remaining=2.5 hours
5892: loss=2.795, avg loss=3.251, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 377088 images, time remaining=2.5 hours
5893: loss=3.358, avg loss=3.261, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 377152 images, time remaining=2.5 hours
5894: loss=3.252, avg loss=3.261, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 377216 images, time remaining=2.5 hours
5895: loss=2.400, avg loss=3.175, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 377280 images, time remaining=2.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5896: loss=2.919, avg loss=3.149, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=3.0 seconds, train=2.3 seconds, 377344 images, time remaining=2.5 hours
5897: loss=3.612, avg loss=3.195, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 377408 images, time remaining=2.5 hours
5898: loss=3.023, avg loss=3.178, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=2.3 seconds, 377472 images, time remaining=2.5 hours
5899: loss=3.384, avg loss=3.199, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 377536 images, time remaining=2.5 hours
5900: loss=2.760, avg loss=3.155, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 377600 images, time remaining=2.5 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b53ce00000
5901: loss=2.892, avg loss=3.128, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 377664 images, time remaining=2.5 hours
5902: loss=4.040, avg loss=3.220, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 377728 images, time remaining=2.5 hours
5903: loss=2.711, avg loss=3.169, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 377792 images, time remaining=2.5 hours
5904: loss=3.232, avg loss=3.175, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 377856 images, time remaining=2.5 hours
5905: loss=2.696, avg loss=3.127, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 377920 images, time remaining=2.5 hours
5906: loss=3.261, avg loss=3.141, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 377984 images, time remaining=2.5 hours
5907: loss=3.398, avg loss=3.166, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 378048 images, time remaining=2.5 hours
5908: loss=3.160, avg loss=3.166, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 378112 images, time remaining=2.5 hours
5909: loss=2.538, avg loss=3.103, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 378176 images, time remaining=2.5 hours
5910: loss=3.149, avg loss=3.108, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 378240 images, time remaining=2.5 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b725a00000
5911: loss=3.516, avg loss=3.148, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.3 seconds, train=2.6 seconds, 378304 images, time remaining=2.5 hours
5912: loss=2.552, avg loss=3.089, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 378368 images, time remaining=2.5 hours
5913: loss=3.498, avg loss=3.130, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 378432 images, time remaining=2.5 hours
5914: loss=2.362, avg loss=3.053, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 378496 images, time remaining=2.5 hours
5915: loss=2.909, avg loss=3.039, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 378560 images, time remaining=2.5 hours
5916: loss=2.962, avg loss=3.031, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.7 seconds, 378624 images, time remaining=2.5 hours
5917: loss=2.342, avg loss=2.962, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 378688 images, time remaining=2.5 hours
5918: loss=2.469, avg loss=2.913, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.5 seconds, train=2.6 seconds, 378752 images, time remaining=2.5 hours
5919: loss=2.578, avg loss=2.879, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 378816 images, time remaining=2.5 hours
5920: loss=2.588, avg loss=2.850, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 378880 images, time remaining=2.5 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b70e000000
5921: loss=2.713, avg loss=2.836, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 378944 images, time remaining=2.5 hours
5922: loss=3.484, avg loss=2.901, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 379008 images, time remaining=2.5 hours
5923: loss=3.258, avg loss=2.937, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 379072 images, time remaining=2.5 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5924: loss=3.173, avg loss=2.960, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=3.0 seconds, train=2.8 seconds, 379136 images, time remaining=2.5 hours
5925: loss=3.588, avg loss=3.023, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 379200 images, time remaining=2.5 hours
5926: loss=2.937, avg loss=3.014, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.3 seconds, train=2.6 seconds, 379264 images, time remaining=2.5 hours
5927: loss=3.362, avg loss=3.049, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 379328 images, time remaining=2.5 hours
5928: loss=3.665, avg loss=3.111, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 379392 images, time remaining=2.5 hours
5929: loss=2.917, avg loss=3.091, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 379456 images, time remaining=2.5 hours
5930: loss=3.221, avg loss=3.104, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 379520 images, time remaining=2.5 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
5931: loss=3.204, avg loss=3.114, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 379584 images, time remaining=2.5 hours
5932: loss=4.109, avg loss=3.214, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 379648 images, time remaining=2.5 hours
5933: loss=4.172, avg loss=3.310, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=6.1 seconds, 379712 images, time remaining=2.5 hours
5934: loss=3.155, avg loss=3.294, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 379776 images, time remaining=2.5 hours
5935: loss=3.161, avg loss=3.281, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.4 seconds, train=5.8 seconds, 379840 images, time remaining=2.5 hours
5936: loss=3.933, avg loss=3.346, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 379904 images, time remaining=2.5 hours
5937: loss=3.753, avg loss=3.387, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.1 seconds, train=5.9 seconds, 379968 images, time remaining=2.5 hours
5938: loss=4.161, avg loss=3.464, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.2 seconds, train=5.8 seconds, 380032 images, time remaining=2.5 hours
5939: loss=3.573, avg loss=3.475, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 380096 images, time remaining=2.5 hours
5940: loss=3.235, avg loss=3.451, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 380160 images, time remaining=2.5 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
5941: loss=2.931, avg loss=3.399, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 380224 images, time remaining=2.5 hours
5942: loss=3.565, avg loss=3.416, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=4.4 seconds, 380288 images, time remaining=2.5 hours
5943: loss=2.822, avg loss=3.356, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=4.2 seconds, 380352 images, time remaining=2.5 hours
5944: loss=3.045, avg loss=3.325, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.6 seconds, train=4.4 seconds, 380416 images, time remaining=2.5 hours
5945: loss=3.209, avg loss=3.313, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.2 seconds, 380480 images, time remaining=2.4 hours
5946: loss=2.714, avg loss=3.253, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=3.0 seconds, train=4.4 seconds, 380544 images, time remaining=2.4 hours
5947: loss=3.506, avg loss=3.279, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 380608 images, time remaining=2.4 hours
5948: loss=2.859, avg loss=3.237, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.2 seconds, train=4.2 seconds, 380672 images, time remaining=2.4 hours
5949: loss=3.548, avg loss=3.268, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=3.4 seconds, train=4.4 seconds, 380736 images, time remaining=2.4 hours
5950: loss=3.755, avg loss=3.317, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=4.3 seconds, 380800 images, time remaining=2.4 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
5951: loss=3.293, avg loss=3.314, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=4.1 seconds, 380864 images, time remaining=2.4 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
5952: loss=3.486, avg loss=3.331, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=5.0 seconds, train=4.2 seconds, 380928 images, time remaining=2.4 hours
5953: loss=3.152, avg loss=3.313, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.3 seconds, 380992 images, time remaining=2.4 hours
5954: loss=3.716, avg loss=3.354, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.8 seconds, train=4.3 seconds, 381056 images, time remaining=2.4 hours
5955: loss=3.416, avg loss=3.360, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.3 seconds, train=4.4 seconds, 381120 images, time remaining=2.4 hours
5956: loss=2.508, avg loss=3.275, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.2 seconds, 381184 images, time remaining=2.4 hours
5957: loss=3.009, avg loss=3.248, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=4.3 seconds, 381248 images, time remaining=2.4 hours
5958: loss=4.058, avg loss=3.329, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.6 seconds, train=4.4 seconds, 381312 images, time remaining=2.4 hours
5959: loss=2.762, avg loss=3.272, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.2 seconds, 381376 images, time remaining=2.4 hours
5960: loss=3.172, avg loss=3.262, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 381440 images, time remaining=2.4 hours
Resizing, random_coef=1.40, batch=4, 1184x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
5961: loss=2.926, avg loss=3.229, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=4.6 seconds, 381504 images, time remaining=2.4 hours
5962: loss=3.373, avg loss=3.243, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 381568 images, time remaining=2.4 hours
5963: loss=3.150, avg loss=3.234, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 381632 images, time remaining=2.4 hours
5964: loss=3.722, avg loss=3.283, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 381696 images, time remaining=2.4 hours
5965: loss=3.564, avg loss=3.311, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=4.6 seconds, 381760 images, time remaining=2.4 hours
5966: loss=2.891, avg loss=3.269, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=3.2 seconds, train=4.6 seconds, 381824 images, time remaining=2.4 hours
5967: loss=3.509, avg loss=3.293, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 381888 images, time remaining=2.4 hours
5968: loss=3.230, avg loss=3.287, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.5 seconds, 381952 images, time remaining=2.4 hours
5969: loss=3.193, avg loss=3.277, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 382016 images, time remaining=2.4 hours
5970: loss=2.788, avg loss=3.228, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 382080 images, time remaining=2.4 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
5971: loss=3.014, avg loss=3.207, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 382144 images, time remaining=2.4 hours
5972: loss=2.845, avg loss=3.171, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 382208 images, time remaining=2.4 hours
5973: loss=2.994, avg loss=3.153, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 382272 images, time remaining=2.4 hours
5974: loss=2.913, avg loss=3.129, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=3.9 seconds, 382336 images, time remaining=2.4 hours
5975: loss=3.311, avg loss=3.147, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=3.9 seconds, 382400 images, time remaining=2.4 hours
5976: loss=3.502, avg loss=3.183, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=4.0 seconds, 382464 images, time remaining=2.4 hours
5977: loss=2.845, avg loss=3.149, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=4.0 seconds, 382528 images, time remaining=2.4 hours
5978: loss=3.836, avg loss=3.218, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 382592 images, time remaining=2.4 hours
5979: loss=2.635, avg loss=3.159, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 382656 images, time remaining=2.4 hours
5980: loss=2.762, avg loss=3.120, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=3.9 seconds, 382720 images, time remaining=2.4 hours
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b56f000000
5981: loss=2.766, avg loss=3.084, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 382784 images, time remaining=2.4 hours
5982: loss=3.011, avg loss=3.077, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 382848 images, time remaining=2.4 hours
5983: loss=3.206, avg loss=3.090, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 382912 images, time remaining=2.4 hours
5984: loss=3.355, avg loss=3.116, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 382976 images, time remaining=2.4 hours
5985: loss=3.174, avg loss=3.122, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 383040 images, time remaining=2.4 hours
5986: loss=2.997, avg loss=3.110, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 383104 images, time remaining=2.4 hours
5987: loss=2.386, avg loss=3.037, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.1 seconds, train=2.3 seconds, 383168 images, time remaining=2.4 hours
5988: loss=2.776, avg loss=3.011, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 383232 images, time remaining=2.4 hours
5989: loss=2.994, avg loss=3.009, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 383296 images, time remaining=2.4 hours
5990: loss=2.280, avg loss=2.937, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 383360 images, time remaining=2.4 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b66f000000
5991: loss=3.538, avg loss=2.997, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 383424 images, time remaining=2.4 hours
5992: loss=3.125, avg loss=3.010, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 383488 images, time remaining=2.4 hours
5993: loss=2.607, avg loss=2.969, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 383552 images, time remaining=2.4 hours
5994: loss=3.000, avg loss=2.972, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 383616 images, time remaining=2.4 hours
5995: loss=2.878, avg loss=2.963, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 383680 images, time remaining=2.4 hours
5996: loss=2.926, avg loss=2.959, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 383744 images, time remaining=2.4 hours
5997: loss=2.447, avg loss=2.908, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 383808 images, time remaining=2.4 hours
5998: loss=2.790, avg loss=2.896, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 383872 images, time remaining=2.4 hours
5999: loss=3.723, avg loss=2.979, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 383936 images, time remaining=2.4 hours
6000: loss=2.897, avg loss=2.971, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 384000 images, time remaining=2.4 hours
Saving weights to /workspace/.cache/splits/combined_6000.weights
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1184x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6001: loss=3.669, avg loss=3.041, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 384064 images, time remaining=2.4 hours
6002: loss=3.431, avg loss=3.080, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.6 seconds, 384128 images, time remaining=2.4 hours
6003: loss=2.997, avg loss=3.071, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 384192 images, time remaining=2.4 hours
6004: loss=3.254, avg loss=3.090, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.6 seconds, 384256 images, time remaining=2.4 hours
6005: loss=3.165, avg loss=3.097, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 384320 images, time remaining=2.4 hours
6006: loss=2.943, avg loss=3.082, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 384384 images, time remaining=2.4 hours
6007: loss=3.376, avg loss=3.111, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.5 seconds, 384448 images, time remaining=2.4 hours
6008: loss=3.153, avg loss=3.115, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 384512 images, time remaining=2.4 hours
6009: loss=2.689, avg loss=3.073, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=4.6 seconds, 384576 images, time remaining=2.4 hours
6010: loss=2.857, avg loss=3.051, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 384640 images, time remaining=2.4 hours
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b8b8800000
6011: loss=3.009, avg loss=3.047, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 384704 images, time remaining=2.4 hours
6012: loss=3.124, avg loss=3.055, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 384768 images, time remaining=2.4 hours
6013: loss=3.860, avg loss=3.135, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 384832 images, time remaining=2.4 hours
6014: loss=3.146, avg loss=3.136, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 384896 images, time remaining=2.4 hours
6015: loss=3.535, avg loss=3.176, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 384960 images, time remaining=2.4 hours
6016: loss=2.871, avg loss=3.146, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 385024 images, time remaining=2.4 hours
6017: loss=3.040, avg loss=3.135, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 385088 images, time remaining=2.4 hours
6018: loss=3.587, avg loss=3.180, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 385152 images, time remaining=2.4 hours
6019: loss=2.587, avg loss=3.121, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 385216 images, time remaining=2.4 hours
6020: loss=3.825, avg loss=3.191, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 385280 images, time remaining=2.4 hours
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6021: loss=5.249, avg loss=3.397, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 385344 images, time remaining=2.4 hours
6022: loss=5.336, avg loss=3.591, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=5.5 seconds, 385408 images, time remaining=2.4 hours
6023: loss=4.318, avg loss=3.664, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 385472 images, time remaining=2.4 hours
6024: loss=4.253, avg loss=3.723, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 385536 images, time remaining=2.4 hours
6025: loss=4.510, avg loss=3.801, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 385600 images, time remaining=2.4 hours
6026: loss=3.790, avg loss=3.800, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 385664 images, time remaining=2.3 hours
6027: loss=3.486, avg loss=3.769, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=5.6 seconds, 385728 images, time remaining=2.3 hours
6028: loss=4.813, avg loss=3.873, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 385792 images, time remaining=2.3 hours
6029: loss=3.959, avg loss=3.882, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.7 seconds, 385856 images, time remaining=2.3 hours
6030: loss=3.839, avg loss=3.878, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 385920 images, time remaining=2.3 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
6031: loss=4.097, avg loss=3.899, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 385984 images, time remaining=2.3 hours
6032: loss=3.315, avg loss=3.841, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 386048 images, time remaining=2.3 hours
6033: loss=3.480, avg loss=3.805, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 386112 images, time remaining=2.3 hours
6034: loss=2.572, avg loss=3.682, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 386176 images, time remaining=2.3 hours
6035: loss=2.601, avg loss=3.574, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 386240 images, time remaining=2.3 hours
6036: loss=2.961, avg loss=3.512, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=2.8 seconds, 386304 images, time remaining=2.3 hours
6037: loss=2.658, avg loss=3.427, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 386368 images, time remaining=2.3 hours
6038: loss=3.823, avg loss=3.466, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 386432 images, time remaining=2.3 hours
6039: loss=2.494, avg loss=3.369, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 386496 images, time remaining=2.3 hours
6040: loss=3.739, avg loss=3.406, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 386560 images, time remaining=2.3 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b6ae400000
6041: loss=2.801, avg loss=3.346, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 386624 images, time remaining=2.3 hours
6042: loss=3.021, avg loss=3.313, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 386688 images, time remaining=2.3 hours
6043: loss=3.011, avg loss=3.283, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 386752 images, time remaining=2.3 hours
6044: loss=2.965, avg loss=3.251, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 386816 images, time remaining=2.3 hours
6045: loss=2.964, avg loss=3.222, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 386880 images, time remaining=2.3 hours
6046: loss=3.358, avg loss=3.236, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 386944 images, time remaining=2.3 hours
6047: loss=3.260, avg loss=3.238, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.0 seconds, 387008 images, time remaining=2.3 hours
6048: loss=2.953, avg loss=3.210, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 387072 images, time remaining=2.3 hours
6049: loss=2.547, avg loss=3.144, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 387136 images, time remaining=2.3 hours
6050: loss=3.011, avg loss=3.130, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 387200 images, time remaining=2.3 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6051: loss=4.156, avg loss=3.233, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.8 seconds, 387264 images, time remaining=2.3 hours
6052: loss=3.659, avg loss=3.275, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 387328 images, time remaining=2.3 hours
6053: loss=3.087, avg loss=3.257, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 387392 images, time remaining=2.3 hours
6054: loss=3.467, avg loss=3.278, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 387456 images, time remaining=2.3 hours
6055: loss=2.707, avg loss=3.221, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 387520 images, time remaining=2.3 hours
6056: loss=3.219, avg loss=3.220, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 387584 images, time remaining=2.3 hours
6057: loss=3.392, avg loss=3.238, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 387648 images, time remaining=2.3 hours
6058: loss=3.371, avg loss=3.251, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 387712 images, time remaining=2.3 hours
6059: loss=3.356, avg loss=3.261, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.8 seconds, 387776 images, time remaining=2.3 hours
6060: loss=3.447, avg loss=3.280, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 387840 images, time remaining=2.3 hours
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b1fe000000
6061: loss=4.388, avg loss=3.391, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 387904 images, time remaining=2.3 hours
6062: loss=2.957, avg loss=3.347, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 387968 images, time remaining=2.3 hours
6063: loss=3.316, avg loss=3.344, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 388032 images, time remaining=2.3 hours
6064: loss=4.020, avg loss=3.412, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 388096 images, time remaining=2.3 hours
6065: loss=3.337, avg loss=3.404, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 388160 images, time remaining=2.3 hours
6066: loss=2.534, avg loss=3.317, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.1 seconds, train=2.1 seconds, 388224 images, time remaining=2.3 hours
6067: loss=3.255, avg loss=3.311, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 388288 images, time remaining=2.3 hours
6068: loss=3.111, avg loss=3.291, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 388352 images, time remaining=2.3 hours
6069: loss=3.277, avg loss=3.290, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.1 seconds, train=2.2 seconds, 388416 images, time remaining=2.3 hours
6070: loss=3.512, avg loss=3.312, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 388480 images, time remaining=2.3 hours
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6071: loss=4.673, avg loss=3.448, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=5.6 seconds, 388544 images, time remaining=2.3 hours
6072: loss=4.217, avg loss=3.525, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.7 seconds, 388608 images, time remaining=2.3 hours
6073: loss=5.313, avg loss=3.704, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 388672 images, time remaining=2.3 hours
6074: loss=4.767, avg loss=3.810, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 388736 images, time remaining=2.3 hours
6075: loss=3.988, avg loss=3.828, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 388800 images, time remaining=2.3 hours
6076: loss=3.476, avg loss=3.793, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=5.7 seconds, 388864 images, time remaining=2.3 hours
6077: loss=3.793, avg loss=3.793, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 388928 images, time remaining=2.3 hours
6078: loss=3.442, avg loss=3.758, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 388992 images, time remaining=2.3 hours
6079: loss=3.327, avg loss=3.715, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.6 seconds, 389056 images, time remaining=2.3 hours
6080: loss=4.119, avg loss=3.755, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.6 seconds, 389120 images, time remaining=2.3 hours
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
6081: loss=3.821, avg loss=3.762, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 389184 images, time remaining=2.3 hours
6082: loss=3.143, avg loss=3.700, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 389248 images, time remaining=2.3 hours
6083: loss=4.671, avg loss=3.797, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 389312 images, time remaining=2.3 hours
6084: loss=3.412, avg loss=3.758, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 389376 images, time remaining=2.3 hours
6085: loss=3.400, avg loss=3.722, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 389440 images, time remaining=2.3 hours
6086: loss=3.016, avg loss=3.652, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.7 seconds, 389504 images, time remaining=2.3 hours
6087: loss=2.998, avg loss=3.586, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.6 seconds, 389568 images, time remaining=2.3 hours
6088: loss=2.734, avg loss=3.501, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 389632 images, time remaining=2.3 hours
6089: loss=3.256, avg loss=3.477, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 389696 images, time remaining=2.3 hours
6090: loss=3.348, avg loss=3.464, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=2.6 seconds, 389760 images, time remaining=2.3 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6091: loss=4.298, avg loss=3.547, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 389824 images, time remaining=2.3 hours
6092: loss=5.152, avg loss=3.708, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 389888 images, time remaining=2.3 hours
6093: loss=3.629, avg loss=3.700, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 389952 images, time remaining=2.3 hours
6094: loss=4.248, avg loss=3.755, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.1 seconds, train=5.9 seconds, 390016 images, time remaining=2.3 hours
6095: loss=3.331, avg loss=3.712, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 390080 images, time remaining=2.3 hours
6096: loss=4.838, avg loss=3.825, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.9 seconds, 390144 images, time remaining=2.3 hours
6097: loss=3.684, avg loss=3.811, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=5.9 seconds, 390208 images, time remaining=2.3 hours
6098: loss=3.199, avg loss=3.750, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.8 seconds, 390272 images, time remaining=2.3 hours
6099: loss=3.403, avg loss=3.715, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=6.0 seconds, 390336 images, time remaining=2.3 hours
6100: loss=3.959, avg loss=3.739, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 390400 images, time remaining=2.3 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b757e00000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6101: loss=2.556, avg loss=3.621, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=3.8 seconds, train=2.4 seconds, 390464 images, time remaining=2.3 hours
6102: loss=3.252, avg loss=3.584, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 390528 images, time remaining=2.3 hours
6103: loss=3.795, avg loss=3.605, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.4 seconds, 390592 images, time remaining=2.3 hours
6104: loss=3.116, avg loss=3.556, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 390656 images, time remaining=2.3 hours
6105: loss=2.650, avg loss=3.466, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 390720 images, time remaining=2.3 hours
6106: loss=4.015, avg loss=3.521, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 390784 images, time remaining=2.3 hours
6107: loss=2.979, avg loss=3.466, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=2.4 seconds, 390848 images, time remaining=2.3 hours
6108: loss=2.325, avg loss=3.352, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.4 seconds, 390912 images, time remaining=2.3 hours
6109: loss=3.070, avg loss=3.324, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 390976 images, time remaining=2.2 hours
6110: loss=2.795, avg loss=3.271, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 391040 images, time remaining=2.2 hours
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6111: loss=4.099, avg loss=3.354, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 391104 images, time remaining=2.2 hours
6112: loss=4.043, avg loss=3.423, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.1 seconds, train=5.3 seconds, 391168 images, time remaining=2.2 hours
6113: loss=3.677, avg loss=3.448, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=5.3 seconds, 391232 images, time remaining=2.2 hours
6114: loss=3.836, avg loss=3.487, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 391296 images, time remaining=2.2 hours
6115: loss=4.198, avg loss=3.558, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=5.4 seconds, 391360 images, time remaining=2.2 hours
6116: loss=3.109, avg loss=3.513, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=5.3 seconds, 391424 images, time remaining=2.2 hours
6117: loss=2.767, avg loss=3.439, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 391488 images, time remaining=2.2 hours
6118: loss=2.829, avg loss=3.378, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=5.2 seconds, 391552 images, time remaining=2.2 hours
6119: loss=3.493, avg loss=3.389, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=5.4 seconds, 391616 images, time remaining=2.2 hours
6120: loss=3.820, avg loss=3.432, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 391680 images, time remaining=2.2 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6121: loss=4.037, avg loss=3.493, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.2 seconds, 391744 images, time remaining=2.2 hours
6122: loss=2.903, avg loss=3.434, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 391808 images, time remaining=2.2 hours
6123: loss=3.570, avg loss=3.447, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 391872 images, time remaining=2.2 hours
6124: loss=4.150, avg loss=3.518, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.2 seconds, 391936 images, time remaining=2.2 hours
6125: loss=2.940, avg loss=3.460, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 392000 images, time remaining=2.2 hours
6126: loss=3.521, avg loss=3.466, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 392064 images, time remaining=2.2 hours
6127: loss=2.566, avg loss=3.376, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 392128 images, time remaining=2.2 hours
6128: loss=2.706, avg loss=3.309, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 392192 images, time remaining=2.2 hours
6129: loss=2.786, avg loss=3.257, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 392256 images, time remaining=2.2 hours
6130: loss=3.250, avg loss=3.256, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 392320 images, time remaining=2.2 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b4caa00000
6131: loss=3.146, avg loss=3.245, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 392384 images, time remaining=2.2 hours
6132: loss=2.670, avg loss=3.188, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.1 seconds, train=2.0 seconds, 392448 images, time remaining=2.2 hours
6133: loss=3.312, avg loss=3.200, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 392512 images, time remaining=2.2 hours
6134: loss=2.953, avg loss=3.175, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.1 seconds, train=1.9 seconds, 392576 images, time remaining=2.2 hours
6135: loss=3.196, avg loss=3.177, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 392640 images, time remaining=2.2 hours
6136: loss=3.053, avg loss=3.165, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 392704 images, time remaining=2.2 hours
6137: loss=2.740, avg loss=3.122, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 392768 images, time remaining=2.2 hours
6138: loss=3.421, avg loss=3.152, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 392832 images, time remaining=2.2 hours
6139: loss=3.822, avg loss=3.219, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 392896 images, time remaining=2.2 hours
6140: loss=3.092, avg loss=3.206, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 392960 images, time remaining=2.2 hours
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14bef6000000
6141: loss=2.766, avg loss=3.162, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 393024 images, time remaining=2.2 hours
6142: loss=2.936, avg loss=3.140, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 393088 images, time remaining=2.2 hours
6143: loss=3.648, avg loss=3.191, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 393152 images, time remaining=2.2 hours
6144: loss=2.428, avg loss=3.114, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 393216 images, time remaining=2.2 hours
6145: loss=2.945, avg loss=3.097, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 393280 images, time remaining=2.2 hours
6146: loss=2.832, avg loss=3.071, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 393344 images, time remaining=2.2 hours
6147: loss=2.541, avg loss=3.018, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 393408 images, time remaining=2.2 hours
6148: loss=3.184, avg loss=3.034, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 393472 images, time remaining=2.2 hours
6149: loss=2.661, avg loss=2.997, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 393536 images, time remaining=2.2 hours
6150: loss=3.382, avg loss=3.036, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 393600 images, time remaining=2.2 hours
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6151: loss=3.131, avg loss=3.045, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 393664 images, time remaining=2.2 hours
6152: loss=3.786, avg loss=3.119, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 393728 images, time remaining=2.2 hours
6153: loss=3.971, avg loss=3.204, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 393792 images, time remaining=2.2 hours
6154: loss=3.552, avg loss=3.239, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 393856 images, time remaining=2.2 hours
6155: loss=3.268, avg loss=3.242, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.9 seconds, 393920 images, time remaining=2.2 hours
6156: loss=3.182, avg loss=3.236, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 393984 images, time remaining=2.2 hours
6157: loss=3.354, avg loss=3.248, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 394048 images, time remaining=2.2 hours
6158: loss=3.205, avg loss=3.244, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 394112 images, time remaining=2.2 hours
6159: loss=3.394, avg loss=3.259, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.6 seconds, 394176 images, time remaining=2.2 hours
6160: loss=3.884, avg loss=3.321, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.8 seconds, 394240 images, time remaining=2.2 hours
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6161: loss=2.779, avg loss=3.267, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=4.4 seconds, 394304 images, time remaining=2.2 hours
6162: loss=2.297, avg loss=3.170, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=4.3 seconds, 394368 images, time remaining=2.2 hours
6163: loss=2.280, avg loss=3.081, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.4 seconds, 394432 images, time remaining=2.2 hours
6164: loss=3.045, avg loss=3.077, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=4.3 seconds, 394496 images, time remaining=2.2 hours
6165: loss=2.997, avg loss=3.069, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.0 seconds, train=4.3 seconds, 394560 images, time remaining=2.2 hours
6166: loss=2.969, avg loss=3.059, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=4.3 seconds, 394624 images, time remaining=2.2 hours
6167: loss=3.171, avg loss=3.070, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 394688 images, time remaining=2.2 hours
6168: loss=3.146, avg loss=3.078, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 394752 images, time remaining=2.2 hours
6169: loss=3.595, avg loss=3.130, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.4 seconds, 394816 images, time remaining=2.2 hours
6170: loss=3.516, avg loss=3.168, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.4 seconds, 394880 images, time remaining=2.2 hours
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6171: loss=3.110, avg loss=3.162, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 394944 images, time remaining=2.2 hours
6172: loss=2.653, avg loss=3.112, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=3.9 seconds, 395008 images, time remaining=2.2 hours
6173: loss=3.137, avg loss=3.114, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 395072 images, time remaining=2.2 hours
6174: loss=2.916, avg loss=3.094, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 395136 images, time remaining=2.2 hours
6175: loss=3.224, avg loss=3.107, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=3.9 seconds, 395200 images, time remaining=2.2 hours
6176: loss=3.034, avg loss=3.100, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 395264 images, time remaining=2.2 hours
6177: loss=2.830, avg loss=3.073, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 395328 images, time remaining=2.2 hours
6178: loss=2.977, avg loss=3.063, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=4.0 seconds, 395392 images, time remaining=2.2 hours
6179: loss=2.702, avg loss=3.027, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=4.0 seconds, 395456 images, time remaining=2.2 hours
6180: loss=2.895, avg loss=3.014, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 395520 images, time remaining=2.2 hours
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6181: loss=3.710, avg loss=3.084, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 395584 images, time remaining=2.2 hours
6182: loss=2.118, avg loss=2.987, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 395648 images, time remaining=2.2 hours
6183: loss=2.844, avg loss=2.973, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=4.1 seconds, 395712 images, time remaining=2.2 hours
6184: loss=3.112, avg loss=2.987, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=4.0 seconds, 395776 images, time remaining=2.2 hours
6185: loss=2.874, avg loss=2.975, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 395840 images, time remaining=2.2 hours
6186: loss=2.733, avg loss=2.951, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.0 seconds, 395904 images, time remaining=2.2 hours
6187: loss=2.702, avg loss=2.926, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.0 seconds, 395968 images, time remaining=2.2 hours
6188: loss=2.583, avg loss=2.892, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=3.9 seconds, 396032 images, time remaining=2.2 hours
6189: loss=2.835, avg loss=2.886, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.0 seconds, train=3.9 seconds, 396096 images, time remaining=2.2 hours
6190: loss=3.392, avg loss=2.937, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=4.0 seconds, 396160 images, time remaining=2.2 hours
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6191: loss=2.525, avg loss=2.896, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.0 seconds, 396224 images, time remaining=2.2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6192: loss=3.060, avg loss=2.912, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=5.7 seconds, train=4.0 seconds, 396288 images, time remaining=2.1 hours
6193: loss=3.034, avg loss=2.924, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.2 seconds, 396352 images, time remaining=2.1 hours
6194: loss=3.152, avg loss=2.947, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.2 seconds, 396416 images, time remaining=2.1 hours
6195: loss=2.215, avg loss=2.874, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=4.1 seconds, 396480 images, time remaining=2.1 hours
6196: loss=2.905, avg loss=2.877, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 396544 images, time remaining=2.1 hours
6197: loss=3.027, avg loss=2.892, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 396608 images, time remaining=2.1 hours
6198: loss=3.961, avg loss=2.999, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.0 seconds, train=4.1 seconds, 396672 images, time remaining=2.1 hours
6199: loss=3.334, avg loss=3.032, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=4.1 seconds, 396736 images, time remaining=2.1 hours
6200: loss=2.776, avg loss=3.007, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=4.1 seconds, 396800 images, time remaining=2.1 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 896x672
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6201: loss=2.862, avg loss=2.992, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=3.6 seconds, train=2.5 seconds, 396864 images, time remaining=2.1 hours
6202: loss=2.643, avg loss=2.957, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.2 seconds, train=2.4 seconds, 396928 images, time remaining=2.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6203: loss=2.882, avg loss=2.950, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.7 seconds, train=2.5 seconds, 396992 images, time remaining=2.1 hours
6204: loss=2.479, avg loss=2.903, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.5 seconds, 397056 images, time remaining=2.1 hours
6205: loss=2.746, avg loss=2.887, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 397120 images, time remaining=2.1 hours
6206: loss=2.547, avg loss=2.853, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 397184 images, time remaining=2.1 hours
6207: loss=2.784, avg loss=2.846, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.3 seconds, train=2.5 seconds, 397248 images, time remaining=2.1 hours
6208: loss=2.505, avg loss=2.812, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.0 seconds, train=2.5 seconds, 397312 images, time remaining=2.1 hours
6209: loss=3.110, avg loss=2.842, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 397376 images, time remaining=2.1 hours
6210: loss=2.536, avg loss=2.811, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=2.6 seconds, 397440 images, time remaining=2.1 hours
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b6e7c00000
6211: loss=2.638, avg loss=2.794, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=2.7 seconds, 397504 images, time remaining=2.1 hours
6212: loss=3.032, avg loss=2.818, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.5 seconds, train=2.8 seconds, 397568 images, time remaining=2.1 hours
6213: loss=2.565, avg loss=2.793, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 397632 images, time remaining=2.1 hours
6214: loss=2.666, avg loss=2.780, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 397696 images, time remaining=2.1 hours
6215: loss=2.975, avg loss=2.799, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.8 seconds, 397760 images, time remaining=2.1 hours
6216: loss=3.572, avg loss=2.877, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 397824 images, time remaining=2.1 hours
6217: loss=2.574, avg loss=2.846, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 397888 images, time remaining=2.1 hours
6218: loss=3.091, avg loss=2.871, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 397952 images, time remaining=2.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6219: loss=2.897, avg loss=2.873, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=4.8 seconds, train=2.6 seconds, 398016 images, time remaining=2.1 hours
6220: loss=2.930, avg loss=2.879, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 398080 images, time remaining=2.1 hours
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b65c000000
6221: loss=2.501, avg loss=2.841, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 398144 images, time remaining=2.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6222: loss=3.161, avg loss=2.873, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=3.0 seconds, train=2.2 seconds, 398208 images, time remaining=2.1 hours
6223: loss=2.349, avg loss=2.821, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.3 seconds, 398272 images, time remaining=2.1 hours
6224: loss=2.402, avg loss=2.779, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 398336 images, time remaining=2.1 hours
6225: loss=2.581, avg loss=2.759, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.3 seconds, 398400 images, time remaining=2.1 hours
6226: loss=2.790, avg loss=2.762, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 398464 images, time remaining=2.1 hours
6227: loss=2.661, avg loss=2.752, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 398528 images, time remaining=2.1 hours
6228: loss=2.735, avg loss=2.750, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 398592 images, time remaining=2.1 hours
6229: loss=2.676, avg loss=2.743, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 398656 images, time remaining=2.1 hours
6230: loss=2.868, avg loss=2.755, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 398720 images, time remaining=2.1 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b6c8600000
6231: loss=2.995, avg loss=2.779, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=1.9 seconds, 398784 images, time remaining=2.1 hours
6232: loss=3.379, avg loss=2.839, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.1 seconds, train=1.8 seconds, 398848 images, time remaining=2.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6233: loss=2.790, avg loss=2.834, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=3.6 seconds, train=1.9 seconds, 398912 images, time remaining=2.1 hours
6234: loss=3.226, avg loss=2.873, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 398976 images, time remaining=2.1 hours
6235: loss=2.668, avg loss=2.853, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 399040 images, time remaining=2.1 hours
6236: loss=2.864, avg loss=2.854, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 399104 images, time remaining=2.1 hours
6237: loss=3.363, avg loss=2.905, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=1.7 seconds, 399168 images, time remaining=2.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6238: loss=2.605, avg loss=2.875, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=3.3 seconds, train=1.7 seconds, 399232 images, time remaining=2.1 hours
6239: loss=2.630, avg loss=2.850, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=1.9 seconds, 399296 images, time remaining=2.1 hours
6240: loss=3.792, avg loss=2.945, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.0 seconds, 399360 images, time remaining=2.1 hours
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b63f800000
6241: loss=3.082, avg loss=2.958, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 399424 images, time remaining=2.1 hours
6242: loss=2.761, avg loss=2.939, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 399488 images, time remaining=2.1 hours
6243: loss=2.991, avg loss=2.944, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 399552 images, time remaining=2.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6244: loss=2.680, avg loss=2.917, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=1.9 seconds, 399616 images, time remaining=2.1 hours
6245: loss=2.419, avg loss=2.868, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.0 seconds, train=2.2 seconds, 399680 images, time remaining=2.1 hours
6246: loss=2.571, avg loss=2.838, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 399744 images, time remaining=2.1 hours
6247: loss=2.403, avg loss=2.794, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 399808 images, time remaining=2.1 hours
6248: loss=2.930, avg loss=2.808, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 399872 images, time remaining=2.1 hours
6249: loss=2.930, avg loss=2.820, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.9 seconds, train=2.2 seconds, 399936 images, time remaining=2.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6250: loss=2.804, avg loss=2.819, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=3.0 seconds, train=2.3 seconds, 400000 images, time remaining=2.1 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b6a0400000
6251: loss=2.606, avg loss=2.797, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.1 seconds, train=2.7 seconds, 400064 images, time remaining=2.1 hours
6252: loss=2.759, avg loss=2.793, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 400128 images, time remaining=2.1 hours
6253: loss=2.232, avg loss=2.737, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 400192 images, time remaining=2.1 hours
6254: loss=2.420, avg loss=2.706, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 400256 images, time remaining=2.1 hours
6255: loss=1.923, avg loss=2.627, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 400320 images, time remaining=2.1 hours
6256: loss=2.824, avg loss=2.647, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.5 seconds, 400384 images, time remaining=2.1 hours
6257: loss=2.846, avg loss=2.667, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=2.6 seconds, 400448 images, time remaining=2.1 hours
6258: loss=2.770, avg loss=2.677, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 400512 images, time remaining=2.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6259: loss=2.671, avg loss=2.677, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=3.1 seconds, train=2.6 seconds, 400576 images, time remaining=2.1 hours
6260: loss=2.681, avg loss=2.677, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=2.7 seconds, 400640 images, time remaining=2.1 hours
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b54da00000
6261: loss=3.022, avg loss=2.711, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.1 seconds, train=1.9 seconds, 400704 images, time remaining=2.1 hours
6262: loss=2.761, avg loss=2.716, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 400768 images, time remaining=2.1 hours
6263: loss=2.962, avg loss=2.741, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 400832 images, time remaining=2.1 hours
6264: loss=2.721, avg loss=2.739, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 400896 images, time remaining=2.1 hours
6265: loss=2.920, avg loss=2.757, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 400960 images, time remaining=2.1 hours
6266: loss=3.019, avg loss=2.783, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=1.5 seconds, 401024 images, time remaining=2.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6267: loss=2.413, avg loss=2.746, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=3.3 seconds, train=1.9 seconds, 401088 images, time remaining=2.1 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6268: loss=2.623, avg loss=2.734, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.0 seconds, train=1.9 seconds, 401152 images, time remaining=2.1 hours
6269: loss=3.194, avg loss=2.780, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 401216 images, time remaining=2 hours
6270: loss=3.096, avg loss=2.812, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 401280 images, time remaining=2 hours
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b693800000
6271: loss=3.489, avg loss=2.879, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.7 seconds, train=2.9 seconds, 401344 images, time remaining=2 hours
6272: loss=2.874, avg loss=2.879, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 401408 images, time remaining=2 hours
6273: loss=2.967, avg loss=2.888, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 401472 images, time remaining=2 hours
6274: loss=3.393, avg loss=2.938, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.0 seconds, train=2.9 seconds, 401536 images, time remaining=2 hours
6275: loss=2.758, avg loss=2.920, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 401600 images, time remaining=2 hours
6276: loss=2.485, avg loss=2.877, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 401664 images, time remaining=2 hours
6277: loss=3.027, avg loss=2.892, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=1.8 seconds, train=2.6 seconds, 401728 images, time remaining=2 hours
6278: loss=3.116, avg loss=2.914, last=96.02%, best=96.02%, next=6278, rate=0.00130000, load 64=2.3 seconds, train=2.9 seconds, 401792 images, time remaining=2 hours
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b688a00000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=102964, unique_truth_count=57264
rank=0 of ranks=102964rank=100 of ranks=102964rank=200 of ranks=102964rank=300 of ranks=102964rank=400 of ranks=102964rank=500 of ranks=102964rank=600 of ranks=102964rank=700 of ranks=102964rank=800 of ranks=102964rank=900 of ranks=102964rank=1000 of ranks=102964rank=1100 of ranks=102964rank=1200 of ranks=102964rank=1300 of ranks=102964rank=1400 of ranks=102964rank=1500 of ranks=102964rank=1600 of ranks=102964rank=1700 of ranks=102964rank=1800 of ranks=102964rank=1900 of ranks=102964rank=2000 of ranks=102964rank=2100 of ranks=102964rank=2200 of ranks=102964rank=2300 of ranks=102964rank=2400 of ranks=102964rank=2500 of ranks=102964rank=2600 of ranks=102964rank=2700 of ranks=102964rank=2800 of ranks=102964rank=2900 of ranks=102964rank=3000 of ranks=102964rank=3100 of ranks=102964rank=3200 of ranks=102964rank=3300 of ranks=102964rank=3400 of ranks=102964rank=3500 of ranks=102964rank=3600 of ranks=102964rank=3700 of ranks=102964rank=3800 of ranks=102964rank=3900 of ranks=102964rank=4000 of ranks=102964rank=4100 of ranks=102964rank=4200 of ranks=102964rank=4300 of ranks=102964rank=4400 of ranks=102964rank=4500 of ranks=102964rank=4600 of ranks=102964rank=4700 of ranks=102964rank=4800 of ranks=102964rank=4900 of ranks=102964rank=5000 of ranks=102964rank=5100 of ranks=102964rank=5200 of ranks=102964rank=5300 of ranks=102964rank=5400 of ranks=102964rank=5500 of ranks=102964rank=5600 of ranks=102964rank=5700 of ranks=102964rank=5800 of ranks=102964rank=5900 of ranks=102964rank=6000 of ranks=102964rank=6100 of ranks=102964rank=6200 of ranks=102964rank=6300 of ranks=102964rank=6400 of ranks=102964rank=6500 of ranks=102964rank=6600 of ranks=102964rank=6700 of ranks=102964rank=6800 of ranks=102964rank=6900 of ranks=102964rank=7000 of ranks=102964rank=7100 of ranks=102964rank=7200 of ranks=102964rank=7300 of ranks=102964rank=7400 of ranks=102964rank=7500 of ranks=102964rank=7600 of ranks=102964rank=7700 of ranks=102964rank=7800 of ranks=102964rank=7900 of ranks=102964rank=8000 of ranks=102964rank=8100 of ranks=102964rank=8200 of ranks=102964rank=8300 of ranks=102964rank=8400 of ranks=102964rank=8500 of ranks=102964rank=8600 of ranks=102964rank=8700 of ranks=102964rank=8800 of ranks=102964rank=8900 of ranks=102964rank=9000 of ranks=102964rank=9100 of ranks=102964rank=9200 of ranks=102964rank=9300 of ranks=102964rank=9400 of ranks=102964rank=9500 of ranks=102964rank=9600 of ranks=102964rank=9700 of ranks=102964rank=9800 of ranks=102964rank=9900 of ranks=102964rank=10000 of ranks=102964rank=10100 of ranks=102964rank=10200 of ranks=102964rank=10300 of ranks=102964rank=10400 of ranks=102964rank=10500 of ranks=102964rank=10600 of ranks=102964rank=10700 of ranks=102964rank=10800 of ranks=102964rank=10900 of ranks=102964rank=11000 of ranks=102964rank=11100 of ranks=102964rank=11200 of ranks=102964rank=11300 of ranks=102964rank=11400 of ranks=102964rank=11500 of ranks=102964rank=11600 of ranks=102964rank=11700 of ranks=102964rank=11800 of ranks=102964rank=11900 of ranks=102964rank=12000 of ranks=102964rank=12100 of ranks=102964rank=12200 of ranks=102964rank=12300 of ranks=102964rank=12400 of ranks=102964rank=12500 of ranks=102964rank=12600 of ranks=102964rank=12700 of ranks=102964rank=12800 of ranks=102964rank=12900 of ranks=102964rank=13000 of ranks=102964rank=13100 of ranks=102964rank=13200 of ranks=102964rank=13300 of ranks=102964rank=13400 of ranks=102964rank=13500 of ranks=102964rank=13600 of ranks=102964rank=13700 of ranks=102964rank=13800 of ranks=102964rank=13900 of ranks=102964rank=14000 of ranks=102964rank=14100 of ranks=102964rank=14200 of ranks=102964rank=14300 of ranks=102964rank=14400 of ranks=102964rank=14500 of ranks=102964rank=14600 of ranks=102964rank=14700 of ranks=102964rank=14800 of ranks=102964rank=14900 of ranks=102964rank=15000 of ranks=102964rank=15100 of ranks=102964rank=15200 of ranks=102964rank=15300 of ranks=102964rank=15400 of ranks=102964rank=15500 of ranks=102964rank=15600 of ranks=102964rank=15700 of ranks=102964rank=15800 of ranks=102964rank=15900 of ranks=102964rank=16000 of ranks=102964rank=16100 of ranks=102964rank=16200 of ranks=102964rank=16300 of ranks=102964rank=16400 of ranks=102964rank=16500 of ranks=102964rank=16600 of ranks=102964rank=16700 of ranks=102964rank=16800 of ranks=102964rank=16900 of ranks=102964rank=17000 of ranks=102964rank=17100 of ranks=102964rank=17200 of ranks=102964rank=17300 of ranks=102964rank=17400 of ranks=102964rank=17500 of ranks=102964rank=17600 of ranks=102964rank=17700 of ranks=102964rank=17800 of ranks=102964rank=17900 of ranks=102964rank=18000 of ranks=102964rank=18100 of ranks=102964rank=18200 of ranks=102964rank=18300 of ranks=102964rank=18400 of ranks=102964rank=18500 of ranks=102964rank=18600 of ranks=102964rank=18700 of ranks=102964rank=18800 of ranks=102964rank=18900 of ranks=102964rank=19000 of ranks=102964rank=19100 of ranks=102964rank=19200 of ranks=102964rank=19300 of ranks=102964rank=19400 of ranks=102964rank=19500 of ranks=102964rank=19600 of ranks=102964rank=19700 of ranks=102964rank=19800 of ranks=102964rank=19900 of ranks=102964rank=20000 of ranks=102964rank=20100 of ranks=102964rank=20200 of ranks=102964rank=20300 of ranks=102964rank=20400 of ranks=102964rank=20500 of ranks=102964rank=20600 of ranks=102964rank=20700 of ranks=102964rank=20800 of ranks=102964rank=20900 of ranks=102964rank=21000 of ranks=102964rank=21100 of ranks=102964rank=21200 of ranks=102964rank=21300 of ranks=102964rank=21400 of ranks=102964rank=21500 of ranks=102964rank=21600 of ranks=102964rank=21700 of ranks=102964rank=21800 of ranks=102964rank=21900 of ranks=102964rank=22000 of ranks=102964rank=22100 of ranks=102964rank=22200 of ranks=102964rank=22300 of ranks=102964rank=22400 of ranks=102964rank=22500 of ranks=102964rank=22600 of ranks=102964rank=22700 of ranks=102964rank=22800 of ranks=102964rank=22900 of ranks=102964rank=23000 of ranks=102964rank=23100 of ranks=102964rank=23200 of ranks=102964rank=23300 of ranks=102964rank=23400 of ranks=102964rank=23500 of ranks=102964rank=23600 of ranks=102964rank=23700 of ranks=102964rank=23800 of ranks=102964rank=23900 of ranks=102964rank=24000 of ranks=102964rank=24100 of ranks=102964rank=24200 of ranks=102964rank=24300 of ranks=102964rank=24400 of ranks=102964rank=24500 of ranks=102964rank=24600 of ranks=102964rank=24700 of ranks=102964rank=24800 of ranks=102964rank=24900 of ranks=102964rank=25000 of ranks=102964rank=25100 of ranks=102964rank=25200 of ranks=102964rank=25300 of ranks=102964rank=25400 of ranks=102964rank=25500 of ranks=102964rank=25600 of ranks=102964rank=25700 of ranks=102964rank=25800 of ranks=102964rank=25900 of ranks=102964rank=26000 of ranks=102964rank=26100 of ranks=102964rank=26200 of ranks=102964rank=26300 of ranks=102964rank=26400 of ranks=102964rank=26500 of ranks=102964rank=26600 of ranks=102964rank=26700 of ranks=102964rank=26800 of ranks=102964rank=26900 of ranks=102964rank=27000 of ranks=102964rank=27100 of ranks=102964rank=27200 of ranks=102964rank=27300 of ranks=102964rank=27400 of ranks=102964rank=27500 of ranks=102964rank=27600 of ranks=102964rank=27700 of ranks=102964rank=27800 of ranks=102964rank=27900 of ranks=102964rank=28000 of ranks=102964rank=28100 of ranks=102964rank=28200 of ranks=102964rank=28300 of ranks=102964rank=28400 of ranks=102964rank=28500 of ranks=102964rank=28600 of ranks=102964rank=28700 of ranks=102964rank=28800 of ranks=102964rank=28900 of ranks=102964rank=29000 of ranks=102964rank=29100 of ranks=102964rank=29200 of ranks=102964rank=29300 of ranks=102964rank=29400 of ranks=102964rank=29500 of ranks=102964rank=29600 of ranks=102964rank=29700 of ranks=102964rank=29800 of ranks=102964rank=29900 of ranks=102964rank=30000 of ranks=102964rank=30100 of ranks=102964rank=30200 of ranks=102964rank=30300 of ranks=102964rank=30400 of ranks=102964rank=30500 of ranks=102964rank=30600 of ranks=102964rank=30700 of ranks=102964rank=30800 of ranks=102964rank=30900 of ranks=102964rank=31000 of ranks=102964rank=31100 of ranks=102964rank=31200 of ranks=102964rank=31300 of ranks=102964rank=31400 of ranks=102964rank=31500 of ranks=102964rank=31600 of ranks=102964rank=31700 of ranks=102964rank=31800 of ranks=102964rank=31900 of ranks=102964rank=32000 of ranks=102964rank=32100 of ranks=102964rank=32200 of ranks=102964rank=32300 of ranks=102964rank=32400 of ranks=102964rank=32500 of ranks=102964rank=32600 of ranks=102964rank=32700 of ranks=102964rank=32800 of ranks=102964rank=32900 of ranks=102964rank=33000 of ranks=102964rank=33100 of ranks=102964rank=33200 of ranks=102964rank=33300 of ranks=102964rank=33400 of ranks=102964rank=33500 of ranks=102964rank=33600 of ranks=102964rank=33700 of ranks=102964rank=33800 of ranks=102964rank=33900 of ranks=102964rank=34000 of ranks=102964rank=34100 of ranks=102964rank=34200 of ranks=102964rank=34300 of ranks=102964rank=34400 of ranks=102964rank=34500 of ranks=102964rank=34600 of ranks=102964rank=34700 of ranks=102964rank=34800 of ranks=102964rank=34900 of ranks=102964rank=35000 of ranks=102964rank=35100 of ranks=102964rank=35200 of ranks=102964rank=35300 of ranks=102964rank=35400 of ranks=102964rank=35500 of ranks=102964rank=35600 of ranks=102964rank=35700 of ranks=102964rank=35800 of ranks=102964rank=35900 of ranks=102964rank=36000 of ranks=102964rank=36100 of ranks=102964rank=36200 of ranks=102964rank=36300 of ranks=102964rank=36400 of ranks=102964rank=36500 of ranks=102964rank=36600 of ranks=102964rank=36700 of ranks=102964rank=36800 of ranks=102964rank=36900 of ranks=102964rank=37000 of ranks=102964rank=37100 of ranks=102964rank=37200 of ranks=102964rank=37300 of ranks=102964rank=37400 of ranks=102964rank=37500 of ranks=102964rank=37600 of ranks=102964rank=37700 of ranks=102964rank=37800 of ranks=102964rank=37900 of ranks=102964rank=38000 of ranks=102964rank=38100 of ranks=102964rank=38200 of ranks=102964rank=38300 of ranks=102964rank=38400 of ranks=102964rank=38500 of ranks=102964rank=38600 of ranks=102964rank=38700 of ranks=102964rank=38800 of ranks=102964rank=38900 of ranks=102964rank=39000 of ranks=102964rank=39100 of ranks=102964rank=39200 of ranks=102964rank=39300 of ranks=102964rank=39400 of ranks=102964rank=39500 of ranks=102964rank=39600 of ranks=102964rank=39700 of ranks=102964rank=39800 of ranks=102964rank=39900 of ranks=102964rank=40000 of ranks=102964rank=40100 of ranks=102964rank=40200 of ranks=102964rank=40300 of ranks=102964rank=40400 of ranks=102964rank=40500 of ranks=102964rank=40600 of ranks=102964rank=40700 of ranks=102964rank=40800 of ranks=102964rank=40900 of ranks=102964rank=41000 of ranks=102964rank=41100 of ranks=102964rank=41200 of ranks=102964rank=41300 of ranks=102964rank=41400 of ranks=102964rank=41500 of ranks=102964rank=41600 of ranks=102964rank=41700 of ranks=102964rank=41800 of ranks=102964rank=41900 of ranks=102964rank=42000 of ranks=102964rank=42100 of ranks=102964rank=42200 of ranks=102964rank=42300 of ranks=102964rank=42400 of ranks=102964rank=42500 of ranks=102964rank=42600 of ranks=102964rank=42700 of ranks=102964rank=42800 of ranks=102964rank=42900 of ranks=102964rank=43000 of ranks=102964rank=43100 of ranks=102964rank=43200 of ranks=102964rank=43300 of ranks=102964rank=43400 of ranks=102964rank=43500 of ranks=102964rank=43600 of ranks=102964rank=43700 of ranks=102964rank=43800 of ranks=102964rank=43900 of ranks=102964rank=44000 of ranks=102964rank=44100 of ranks=102964rank=44200 of ranks=102964rank=44300 of ranks=102964rank=44400 of ranks=102964rank=44500 of ranks=102964rank=44600 of ranks=102964rank=44700 of ranks=102964rank=44800 of ranks=102964rank=44900 of ranks=102964rank=45000 of ranks=102964rank=45100 of ranks=102964rank=45200 of ranks=102964rank=45300 of ranks=102964rank=45400 of ranks=102964rank=45500 of ranks=102964rank=45600 of ranks=102964rank=45700 of ranks=102964rank=45800 of ranks=102964rank=45900 of ranks=102964rank=46000 of ranks=102964rank=46100 of ranks=102964rank=46200 of ranks=102964rank=46300 of ranks=102964rank=46400 of ranks=102964rank=46500 of ranks=102964rank=46600 of ranks=102964rank=46700 of ranks=102964rank=46800 of ranks=102964rank=46900 of ranks=102964rank=47000 of ranks=102964rank=47100 of ranks=102964rank=47200 of ranks=102964rank=47300 of ranks=102964rank=47400 of ranks=102964rank=47500 of ranks=102964rank=47600 of ranks=102964rank=47700 of ranks=102964rank=47800 of ranks=102964rank=47900 of ranks=102964rank=48000 of ranks=102964rank=48100 of ranks=102964rank=48200 of ranks=102964rank=48300 of ranks=102964rank=48400 of ranks=102964rank=48500 of ranks=102964rank=48600 of ranks=102964rank=48700 of ranks=102964rank=48800 of ranks=102964rank=48900 of ranks=102964rank=49000 of ranks=102964rank=49100 of ranks=102964rank=49200 of ranks=102964rank=49300 of ranks=102964rank=49400 of ranks=102964rank=49500 of ranks=102964rank=49600 of ranks=102964rank=49700 of ranks=102964rank=49800 of ranks=102964rank=49900 of ranks=102964rank=50000 of ranks=102964rank=50100 of ranks=102964rank=50200 of ranks=102964rank=50300 of ranks=102964rank=50400 of ranks=102964rank=50500 of ranks=102964rank=50600 of ranks=102964rank=50700 of ranks=102964rank=50800 of ranks=102964rank=50900 of ranks=102964rank=51000 of ranks=102964rank=51100 of ranks=102964rank=51200 of ranks=102964rank=51300 of ranks=102964rank=51400 of ranks=102964rank=51500 of ranks=102964rank=51600 of ranks=102964rank=51700 of ranks=102964rank=51800 of ranks=102964rank=51900 of ranks=102964rank=52000 of ranks=102964rank=52100 of ranks=102964rank=52200 of ranks=102964rank=52300 of ranks=102964rank=52400 of ranks=102964rank=52500 of ranks=102964rank=52600 of ranks=102964rank=52700 of ranks=102964rank=52800 of ranks=102964rank=52900 of ranks=102964rank=53000 of ranks=102964rank=53100 of ranks=102964rank=53200 of ranks=102964rank=53300 of ranks=102964rank=53400 of ranks=102964rank=53500 of ranks=102964rank=53600 of ranks=102964rank=53700 of ranks=102964rank=53800 of ranks=102964rank=53900 of ranks=102964rank=54000 of ranks=102964rank=54100 of ranks=102964rank=54200 of ranks=102964rank=54300 of ranks=102964rank=54400 of ranks=102964rank=54500 of ranks=102964rank=54600 of ranks=102964rank=54700 of ranks=102964rank=54800 of ranks=102964rank=54900 of ranks=102964rank=55000 of ranks=102964rank=55100 of ranks=102964rank=55200 of ranks=102964rank=55300 of ranks=102964rank=55400 of ranks=102964rank=55500 of ranks=102964rank=55600 of ranks=102964rank=55700 of ranks=102964rank=55800 of ranks=102964rank=55900 of ranks=102964rank=56000 of ranks=102964rank=56100 of ranks=102964rank=56200 of ranks=102964rank=56300 of ranks=102964rank=56400 of ranks=102964rank=56500 of ranks=102964rank=56600 of ranks=102964rank=56700 of ranks=102964rank=56800 of ranks=102964rank=56900 of ranks=102964rank=57000 of ranks=102964rank=57100 of ranks=102964rank=57200 of ranks=102964rank=57300 of ranks=102964rank=57400 of ranks=102964rank=57500 of ranks=102964rank=57600 of ranks=102964rank=57700 of ranks=102964rank=57800 of ranks=102964rank=57900 of ranks=102964rank=58000 of ranks=102964rank=58100 of ranks=102964rank=58200 of ranks=102964rank=58300 of ranks=102964rank=58400 of ranks=102964rank=58500 of ranks=102964rank=58600 of ranks=102964rank=58700 of ranks=102964rank=58800 of ranks=102964rank=58900 of ranks=102964rank=59000 of ranks=102964rank=59100 of ranks=102964rank=59200 of ranks=102964rank=59300 of ranks=102964rank=59400 of ranks=102964rank=59500 of ranks=102964rank=59600 of ranks=102964rank=59700 of ranks=102964rank=59800 of ranks=102964rank=59900 of ranks=102964rank=60000 of ranks=102964rank=60100 of ranks=102964rank=60200 of ranks=102964rank=60300 of ranks=102964rank=60400 of ranks=102964rank=60500 of ranks=102964rank=60600 of ranks=102964rank=60700 of ranks=102964rank=60800 of ranks=102964rank=60900 of ranks=102964rank=61000 of ranks=102964rank=61100 of ranks=102964rank=61200 of ranks=102964rank=61300 of ranks=102964rank=61400 of ranks=102964rank=61500 of ranks=102964rank=61600 of ranks=102964rank=61700 of ranks=102964rank=61800 of ranks=102964rank=61900 of ranks=102964rank=62000 of ranks=102964rank=62100 of ranks=102964rank=62200 of ranks=102964rank=62300 of ranks=102964rank=62400 of ranks=102964rank=62500 of ranks=102964rank=62600 of ranks=102964rank=62700 of ranks=102964rank=62800 of ranks=102964rank=62900 of ranks=102964rank=63000 of ranks=102964rank=63100 of ranks=102964rank=63200 of ranks=102964rank=63300 of ranks=102964rank=63400 of ranks=102964rank=63500 of ranks=102964rank=63600 of ranks=102964rank=63700 of ranks=102964rank=63800 of ranks=102964rank=63900 of ranks=102964rank=64000 of ranks=102964rank=64100 of ranks=102964rank=64200 of ranks=102964rank=64300 of ranks=102964rank=64400 of ranks=102964rank=64500 of ranks=102964rank=64600 of ranks=102964rank=64700 of ranks=102964rank=64800 of ranks=102964rank=64900 of ranks=102964rank=65000 of ranks=102964rank=65100 of ranks=102964rank=65200 of ranks=102964rank=65300 of ranks=102964rank=65400 of ranks=102964rank=65500 of ranks=102964rank=65600 of ranks=102964rank=65700 of ranks=102964rank=65800 of ranks=102964rank=65900 of ranks=102964rank=66000 of ranks=102964rank=66100 of ranks=102964rank=66200 of ranks=102964rank=66300 of ranks=102964rank=66400 of ranks=102964rank=66500 of ranks=102964rank=66600 of ranks=102964rank=66700 of ranks=102964rank=66800 of ranks=102964rank=66900 of ranks=102964rank=67000 of ranks=102964rank=67100 of ranks=102964rank=67200 of ranks=102964rank=67300 of ranks=102964rank=67400 of ranks=102964rank=67500 of ranks=102964rank=67600 of ranks=102964rank=67700 of ranks=102964rank=67800 of ranks=102964rank=67900 of ranks=102964rank=68000 of ranks=102964rank=68100 of ranks=102964rank=68200 of ranks=102964rank=68300 of ranks=102964rank=68400 of ranks=102964rank=68500 of ranks=102964rank=68600 of ranks=102964rank=68700 of ranks=102964rank=68800 of ranks=102964rank=68900 of ranks=102964rank=69000 of ranks=102964rank=69100 of ranks=102964rank=69200 of ranks=102964rank=69300 of ranks=102964rank=69400 of ranks=102964rank=69500 of ranks=102964rank=69600 of ranks=102964rank=69700 of ranks=102964rank=69800 of ranks=102964rank=69900 of ranks=102964rank=70000 of ranks=102964rank=70100 of ranks=102964rank=70200 of ranks=102964rank=70300 of ranks=102964rank=70400 of ranks=102964rank=70500 of ranks=102964rank=70600 of ranks=102964rank=70700 of ranks=102964rank=70800 of ranks=102964rank=70900 of ranks=102964rank=71000 of ranks=102964rank=71100 of ranks=102964rank=71200 of ranks=102964rank=71300 of ranks=102964rank=71400 of ranks=102964rank=71500 of ranks=102964rank=71600 of ranks=102964rank=71700 of ranks=102964rank=71800 of ranks=102964rank=71900 of ranks=102964rank=72000 of ranks=102964rank=72100 of ranks=102964rank=72200 of ranks=102964rank=72300 of ranks=102964rank=72400 of ranks=102964rank=72500 of ranks=102964rank=72600 of ranks=102964rank=72700 of ranks=102964rank=72800 of ranks=102964rank=72900 of ranks=102964rank=73000 of ranks=102964rank=73100 of ranks=102964rank=73200 of ranks=102964rank=73300 of ranks=102964rank=73400 of ranks=102964rank=73500 of ranks=102964rank=73600 of ranks=102964rank=73700 of ranks=102964rank=73800 of ranks=102964rank=73900 of ranks=102964rank=74000 of ranks=102964rank=74100 of ranks=102964rank=74200 of ranks=102964rank=74300 of ranks=102964rank=74400 of ranks=102964rank=74500 of ranks=102964rank=74600 of ranks=102964rank=74700 of ranks=102964rank=74800 of ranks=102964rank=74900 of ranks=102964rank=75000 of ranks=102964rank=75100 of ranks=102964rank=75200 of ranks=102964rank=75300 of ranks=102964rank=75400 of ranks=102964rank=75500 of ranks=102964rank=75600 of ranks=102964rank=75700 of ranks=102964rank=75800 of ranks=102964rank=75900 of ranks=102964rank=76000 of ranks=102964rank=76100 of ranks=102964rank=76200 of ranks=102964rank=76300 of ranks=102964rank=76400 of ranks=102964rank=76500 of ranks=102964rank=76600 of ranks=102964rank=76700 of ranks=102964rank=76800 of ranks=102964rank=76900 of ranks=102964rank=77000 of ranks=102964rank=77100 of ranks=102964rank=77200 of ranks=102964rank=77300 of ranks=102964rank=77400 of ranks=102964rank=77500 of ranks=102964rank=77600 of ranks=102964rank=77700 of ranks=102964rank=77800 of ranks=102964rank=77900 of ranks=102964rank=78000 of ranks=102964rank=78100 of ranks=102964rank=78200 of ranks=102964rank=78300 of ranks=102964rank=78400 of ranks=102964rank=78500 of ranks=102964rank=78600 of ranks=102964rank=78700 of ranks=102964rank=78800 of ranks=102964rank=78900 of ranks=102964rank=79000 of ranks=102964rank=79100 of ranks=102964rank=79200 of ranks=102964rank=79300 of ranks=102964rank=79400 of ranks=102964rank=79500 of ranks=102964rank=79600 of ranks=102964rank=79700 of ranks=102964rank=79800 of ranks=102964rank=79900 of ranks=102964rank=80000 of ranks=102964rank=80100 of ranks=102964rank=80200 of ranks=102964rank=80300 of ranks=102964rank=80400 of ranks=102964rank=80500 of ranks=102964rank=80600 of ranks=102964rank=80700 of ranks=102964rank=80800 of ranks=102964rank=80900 of ranks=102964rank=81000 of ranks=102964rank=81100 of ranks=102964rank=81200 of ranks=102964rank=81300 of ranks=102964rank=81400 of ranks=102964rank=81500 of ranks=102964rank=81600 of ranks=102964rank=81700 of ranks=102964rank=81800 of ranks=102964rank=81900 of ranks=102964rank=82000 of ranks=102964rank=82100 of ranks=102964rank=82200 of ranks=102964rank=82300 of ranks=102964rank=82400 of ranks=102964rank=82500 of ranks=102964rank=82600 of ranks=102964rank=82700 of ranks=102964rank=82800 of ranks=102964rank=82900 of ranks=102964rank=83000 of ranks=102964rank=83100 of ranks=102964rank=83200 of ranks=102964rank=83300 of ranks=102964rank=83400 of ranks=102964rank=83500 of ranks=102964rank=83600 of ranks=102964rank=83700 of ranks=102964rank=83800 of ranks=102964rank=83900 of ranks=102964rank=84000 of ranks=102964rank=84100 of ranks=102964rank=84200 of ranks=102964rank=84300 of ranks=102964rank=84400 of ranks=102964rank=84500 of ranks=102964rank=84600 of ranks=102964rank=84700 of ranks=102964rank=84800 of ranks=102964rank=84900 of ranks=102964rank=85000 of ranks=102964rank=85100 of ranks=102964rank=85200 of ranks=102964rank=85300 of ranks=102964rank=85400 of ranks=102964rank=85500 of ranks=102964rank=85600 of ranks=102964rank=85700 of ranks=102964rank=85800 of ranks=102964rank=85900 of ranks=102964rank=86000 of ranks=102964rank=86100 of ranks=102964rank=86200 of ranks=102964rank=86300 of ranks=102964rank=86400 of ranks=102964rank=86500 of ranks=102964rank=86600 of ranks=102964rank=86700 of ranks=102964rank=86800 of ranks=102964rank=86900 of ranks=102964rank=87000 of ranks=102964rank=87100 of ranks=102964rank=87200 of ranks=102964rank=87300 of ranks=102964rank=87400 of ranks=102964rank=87500 of ranks=102964rank=87600 of ranks=102964rank=87700 of ranks=102964rank=87800 of ranks=102964rank=87900 of ranks=102964rank=88000 of ranks=102964rank=88100 of ranks=102964rank=88200 of ranks=102964rank=88300 of ranks=102964rank=88400 of ranks=102964rank=88500 of ranks=102964rank=88600 of ranks=102964rank=88700 of ranks=102964rank=88800 of ranks=102964rank=88900 of ranks=102964rank=89000 of ranks=102964rank=89100 of ranks=102964rank=89200 of ranks=102964rank=89300 of ranks=102964rank=89400 of ranks=102964rank=89500 of ranks=102964rank=89600 of ranks=102964rank=89700 of ranks=102964rank=89800 of ranks=102964rank=89900 of ranks=102964rank=90000 of ranks=102964rank=90100 of ranks=102964rank=90200 of ranks=102964rank=90300 of ranks=102964rank=90400 of ranks=102964rank=90500 of ranks=102964rank=90600 of ranks=102964rank=90700 of ranks=102964rank=90800 of ranks=102964rank=90900 of ranks=102964rank=91000 of ranks=102964rank=91100 of ranks=102964rank=91200 of ranks=102964rank=91300 of ranks=102964rank=91400 of ranks=102964rank=91500 of ranks=102964rank=91600 of ranks=102964rank=91700 of ranks=102964rank=91800 of ranks=102964rank=91900 of ranks=102964rank=92000 of ranks=102964rank=92100 of ranks=102964rank=92200 of ranks=102964rank=92300 of ranks=102964rank=92400 of ranks=102964rank=92500 of ranks=102964rank=92600 of ranks=102964rank=92700 of ranks=102964rank=92800 of ranks=102964rank=92900 of ranks=102964rank=93000 of ranks=102964rank=93100 of ranks=102964rank=93200 of ranks=102964rank=93300 of ranks=102964rank=93400 of ranks=102964rank=93500 of ranks=102964rank=93600 of ranks=102964rank=93700 of ranks=102964rank=93800 of ranks=102964rank=93900 of ranks=102964rank=94000 of ranks=102964rank=94100 of ranks=102964rank=94200 of ranks=102964rank=94300 of ranks=102964rank=94400 of ranks=102964rank=94500 of ranks=102964rank=94600 of ranks=102964rank=94700 of ranks=102964rank=94800 of ranks=102964rank=94900 of ranks=102964rank=95000 of ranks=102964rank=95100 of ranks=102964rank=95200 of ranks=102964rank=95300 of ranks=102964rank=95400 of ranks=102964rank=95500 of ranks=102964rank=95600 of ranks=102964rank=95700 of ranks=102964rank=95800 of ranks=102964rank=95900 of ranks=102964rank=96000 of ranks=102964rank=96100 of ranks=102964rank=96200 of ranks=102964rank=96300 of ranks=102964rank=96400 of ranks=102964rank=96500 of ranks=102964rank=96600 of ranks=102964rank=96700 of ranks=102964rank=96800 of ranks=102964rank=96900 of ranks=102964rank=97000 of ranks=102964rank=97100 of ranks=102964rank=97200 of ranks=102964rank=97300 of ranks=102964rank=97400 of ranks=102964rank=97500 of ranks=102964rank=97600 of ranks=102964rank=97700 of ranks=102964rank=97800 of ranks=102964rank=97900 of ranks=102964rank=98000 of ranks=102964rank=98100 of ranks=102964rank=98200 of ranks=102964rank=98300 of ranks=102964rank=98400 of ranks=102964rank=98500 of ranks=102964rank=98600 of ranks=102964rank=98700 of ranks=102964rank=98800 of ranks=102964rank=98900 of ranks=102964rank=99000 of ranks=102964rank=99100 of ranks=102964rank=99200 of ranks=102964rank=99300 of ranks=102964rank=99400 of ranks=102964rank=99500 of ranks=102964rank=99600 of ranks=102964rank=99700 of ranks=102964rank=99800 of ranks=102964rank=99900 of ranks=102964rank=100000 of ranks=102964rank=100100 of ranks=102964rank=100200 of ranks=102964rank=100300 of ranks=102964rank=100400 of ranks=102964rank=100500 of ranks=102964rank=100600 of ranks=102964rank=100700 of ranks=102964rank=100800 of ranks=102964rank=100900 of ranks=102964rank=101000 of ranks=102964rank=101100 of ranks=102964rank=101200 of ranks=102964rank=101300 of ranks=102964rank=101400 of ranks=102964rank=101500 of ranks=102964rank=101600 of ranks=102964rank=101700 of ranks=102964rank=101800 of ranks=102964rank=101900 of ranks=102964rank=102000 of ranks=102964rank=102100 of ranks=102964rank=102200 of ranks=102964rank=102300 of ranks=102964rank=102400 of ranks=102964rank=102500 of ranks=102964rank=102600 of ranks=102964rank=102700 of ranks=102964rank=102800 of ranks=102964rank=102900 of ranks=102964

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              95.5106    485   2562     13    498           73.8633
   1 car                    98.5199  49988  26187    328  50316           82.8601
   2 truck                  97.6329   1810   5371     15   1825           71.8682
   3 bus                    95.0449    361   3595      5    366           64.3438
   4 pedestrian             96.0164   4153   8452    106   4259           70.3458

for conf_thresh=0.25, precision=0.92, recall=0.95, F1 score=0.93
for conf_thresh=0.25, TP=54638, FP=5070, FN=2626, average IoU=81.31%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=96.54%
Total detection time: 161 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
New best mAP, saving weights!
Saving weights to /workspace/.cache/splits/combined_best.weights
6279: loss=2.528, avg loss=2.875, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 401856 images, time remaining=2 hours
6280: loss=2.960, avg loss=2.884, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 401920 images, time remaining=2 hours
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6281: loss=3.693, avg loss=2.965, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=2.7 seconds, train=5.9 seconds, 401984 images, time remaining=2 hours
6282: loss=4.137, avg loss=3.082, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 402048 images, time remaining=2 hours
6283: loss=3.792, avg loss=3.153, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.9 seconds, train=6.0 seconds, 402112 images, time remaining=2 hours
6284: loss=3.761, avg loss=3.214, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.9 seconds, train=5.8 seconds, 402176 images, time remaining=2 hours
6285: loss=4.541, avg loss=3.347, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.7 seconds, train=6.0 seconds, 402240 images, time remaining=2 hours
6286: loss=3.687, avg loss=3.381, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=2.0 seconds, train=5.8 seconds, 402304 images, time remaining=2 hours
6287: loss=2.883, avg loss=3.331, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.7 seconds, train=5.8 seconds, 402368 images, time remaining=2 hours
6288: loss=3.790, avg loss=3.377, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 402432 images, time remaining=2 hours
6289: loss=4.272, avg loss=3.466, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.7 seconds, train=5.9 seconds, 402496 images, time remaining=2 hours
6290: loss=4.323, avg loss=3.552, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=2.0 seconds, train=6.0 seconds, 402560 images, time remaining=2 hours
Resizing, random_coef=1.40, batch=4, 896x672
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
6291: loss=3.118, avg loss=3.509, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.1 seconds, train=2.6 seconds, 402624 images, time remaining=2 hours
6292: loss=2.884, avg loss=3.446, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 402688 images, time remaining=2 hours
6293: loss=2.798, avg loss=3.381, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 402752 images, time remaining=2 hours
6294: loss=3.193, avg loss=3.362, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 402816 images, time remaining=2 hours
6295: loss=2.349, avg loss=3.261, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 402880 images, time remaining=2 hours
6296: loss=3.177, avg loss=3.253, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 402944 images, time remaining=2 hours
6297: loss=3.256, avg loss=3.253, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 403008 images, time remaining=2 hours
6298: loss=3.098, avg loss=3.238, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.5 seconds, 403072 images, time remaining=2 hours
6299: loss=2.394, avg loss=3.153, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.5 seconds, 403136 images, time remaining=2 hours
6300: loss=2.908, avg loss=3.129, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.7 seconds, train=2.6 seconds, 403200 images, time remaining=2 hours
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b7a0600000
6301: loss=2.962, avg loss=3.112, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 403264 images, time remaining=2 hours
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6302: loss=2.593, avg loss=3.060, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=3.9 seconds, train=2.1 seconds, 403328 images, time remaining=2 hours
6303: loss=2.496, avg loss=3.004, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 403392 images, time remaining=2 hours
6304: loss=3.278, avg loss=3.031, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.5 seconds, train=2.1 seconds, 403456 images, time remaining=2 hours
6305: loss=2.782, avg loss=3.006, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 403520 images, time remaining=2 hours
6306: loss=2.888, avg loss=2.994, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 403584 images, time remaining=2 hours
6307: loss=2.903, avg loss=2.985, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 403648 images, time remaining=2 hours
6308: loss=2.687, avg loss=2.955, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 403712 images, time remaining=2 hours
6309: loss=2.697, avg loss=2.930, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 403776 images, time remaining=2 hours
6310: loss=3.017, avg loss=2.938, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 403840 images, time remaining=2 hours
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b5e9a00000
6311: loss=2.890, avg loss=2.934, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.6 seconds, 403904 images, time remaining=2 hours
6312: loss=3.425, avg loss=2.983, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 403968 images, time remaining=2 hours
6313: loss=2.392, avg loss=2.924, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 404032 images, time remaining=2 hours
6314: loss=2.364, avg loss=2.868, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.7 seconds, 404096 images, time remaining=2 hours
6315: loss=2.763, avg loss=2.857, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.7 seconds, 404160 images, time remaining=2 hours
6316: loss=2.920, avg loss=2.864, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=2.6 seconds, 404224 images, time remaining=2 hours
6317: loss=2.414, avg loss=2.819, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.6 seconds, 404288 images, time remaining=2 hours
6318: loss=2.427, avg loss=2.779, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.6 seconds, 404352 images, time remaining=2 hours
6319: loss=2.232, avg loss=2.725, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 404416 images, time remaining=119.9 minutes
6320: loss=3.234, avg loss=2.776, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 404480 images, time remaining=119.9 minutes
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6321: loss=3.230, avg loss=2.821, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=4.9 seconds, 404544 images, time remaining=119.8 minutes
6322: loss=3.833, avg loss=2.922, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 404608 images, time remaining=119.8 minutes
6323: loss=2.994, avg loss=2.929, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 404672 images, time remaining=119.7 minutes
6324: loss=2.781, avg loss=2.915, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 404736 images, time remaining=119.6 minutes
6325: loss=3.039, avg loss=2.927, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.7 seconds, train=4.7 seconds, 404800 images, time remaining=119.5 minutes
6326: loss=2.724, avg loss=2.907, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 404864 images, time remaining=119.5 minutes
6327: loss=3.745, avg loss=2.991, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=4.7 seconds, 404928 images, time remaining=119.4 minutes
6328: loss=3.222, avg loss=3.014, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.8 seconds, train=4.8 seconds, 404992 images, time remaining=119.3 minutes
6329: loss=3.392, avg loss=3.051, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=2.5 seconds, train=4.8 seconds, 405056 images, time remaining=119.3 minutes
6330: loss=2.498, avg loss=2.996, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.5 seconds, train=4.7 seconds, 405120 images, time remaining=119.2 minutes
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b777a00000
6331: loss=3.157, avg loss=3.012, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 405184 images, time remaining=119.1 minutes
6332: loss=3.401, avg loss=3.051, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 405248 images, time remaining=119 minutes
6333: loss=2.808, avg loss=3.027, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.5 seconds, train=1.9 seconds, 405312 images, time remaining=118.9 minutes
6334: loss=2.887, avg loss=3.013, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 405376 images, time remaining=118.9 minutes
6335: loss=2.727, avg loss=2.984, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 405440 images, time remaining=118.8 minutes
6336: loss=3.764, avg loss=3.062, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 405504 images, time remaining=118.7 minutes
6337: loss=2.717, avg loss=3.028, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.0 seconds, 405568 images, time remaining=118.6 minutes
6338: loss=3.256, avg loss=3.051, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=1.9 seconds, 405632 images, time remaining=118.5 minutes
6339: loss=3.027, avg loss=3.048, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=1.9 seconds, 405696 images, time remaining=118.5 minutes
6340: loss=3.221, avg loss=3.066, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=1.9 seconds, 405760 images, time remaining=118.4 minutes
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6341: loss=4.599, avg loss=3.219, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=4.1 seconds, train=5.4 seconds, 405824 images, time remaining=118.3 minutes
6342: loss=3.522, avg loss=3.249, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.7 seconds, train=5.4 seconds, 405888 images, time remaining=118.3 minutes
6343: loss=3.330, avg loss=3.257, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 405952 images, time remaining=118.2 minutes
6344: loss=4.331, avg loss=3.365, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 406016 images, time remaining=118.1 minutes
6345: loss=3.538, avg loss=3.382, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=2.5 seconds, train=5.3 seconds, 406080 images, time remaining=118.1 minutes
6346: loss=3.949, avg loss=3.439, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 406144 images, time remaining=118 minutes
6347: loss=3.357, avg loss=3.431, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=5.3 seconds, 406208 images, time remaining=117.9 minutes
6348: loss=3.715, avg loss=3.459, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.8 seconds, train=5.3 seconds, 406272 images, time remaining=117.9 minutes
6349: loss=2.604, avg loss=3.373, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.7 seconds, train=5.3 seconds, 406336 images, time remaining=117.8 minutes
6350: loss=2.916, avg loss=3.328, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=5.2 seconds, 406400 images, time remaining=117.7 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6351: loss=3.688, avg loss=3.364, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=3.2 seconds, train=2.9 seconds, 406464 images, time remaining=117.7 minutes
6352: loss=3.931, avg loss=3.421, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.7 seconds, train=2.9 seconds, 406528 images, time remaining=117.6 minutes
6353: loss=2.241, avg loss=3.303, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 406592 images, time remaining=117.5 minutes
6354: loss=3.007, avg loss=3.273, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 406656 images, time remaining=117.4 minutes
6355: loss=2.950, avg loss=3.241, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 406720 images, time remaining=117.4 minutes
6356: loss=2.649, avg loss=3.181, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=2.8 seconds, 406784 images, time remaining=117.3 minutes
6357: loss=3.720, avg loss=3.235, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.5 seconds, train=2.9 seconds, 406848 images, time remaining=117.2 minutes
6358: loss=2.998, avg loss=3.212, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 406912 images, time remaining=117.1 minutes
6359: loss=3.007, avg loss=3.191, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 406976 images, time remaining=117 minutes
6360: loss=3.025, avg loss=3.175, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 407040 images, time remaining=117 minutes
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b721e00000
6361: loss=2.480, avg loss=3.105, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 407104 images, time remaining=116.9 minutes
6362: loss=2.270, avg loss=3.022, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.1 seconds, train=2.0 seconds, 407168 images, time remaining=116.8 minutes
6363: loss=2.902, avg loss=3.010, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.0 seconds, 407232 images, time remaining=116.7 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6364: loss=2.838, avg loss=2.992, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=4.0 seconds, train=2.1 seconds, 407296 images, time remaining=116.7 minutes
6365: loss=2.926, avg loss=2.986, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=2.0 seconds, 407360 images, time remaining=116.6 minutes
6366: loss=3.097, avg loss=2.997, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=2.1 seconds, 407424 images, time remaining=116.5 minutes
6367: loss=2.684, avg loss=2.966, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 407488 images, time remaining=116.4 minutes
6368: loss=2.947, avg loss=2.964, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 407552 images, time remaining=116.3 minutes
6369: loss=3.255, avg loss=2.993, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 407616 images, time remaining=116.3 minutes
6370: loss=2.846, avg loss=2.978, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 407680 images, time remaining=116.2 minutes
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b1fe000000
6371: loss=2.900, avg loss=2.970, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.1 seconds, 407744 images, time remaining=116.1 minutes
6372: loss=2.564, avg loss=2.930, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 407808 images, time remaining=116 minutes
6373: loss=2.608, avg loss=2.898, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.1 seconds, 407872 images, time remaining=115.9 minutes
6374: loss=2.252, avg loss=2.833, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 407936 images, time remaining=115.9 minutes
6375: loss=3.219, avg loss=2.872, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 408000 images, time remaining=115.8 minutes
6376: loss=3.314, avg loss=2.916, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.6 seconds, train=2.2 seconds, 408064 images, time remaining=115.7 minutes
6377: loss=3.027, avg loss=2.927, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.4 seconds, 408128 images, time remaining=115.6 minutes
6378: loss=2.732, avg loss=2.907, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 408192 images, time remaining=115.5 minutes
6379: loss=2.670, avg loss=2.884, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 408256 images, time remaining=115.5 minutes
6380: loss=2.883, avg loss=2.884, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.2 seconds, 408320 images, time remaining=115.4 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
6381: loss=2.770, avg loss=2.872, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.9 seconds, train=2.9 seconds, 408384 images, time remaining=115.3 minutes
6382: loss=2.562, avg loss=2.841, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.7 seconds, 408448 images, time remaining=115.2 minutes
6383: loss=3.285, avg loss=2.886, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.9 seconds, 408512 images, time remaining=115.2 minutes
6384: loss=2.610, avg loss=2.858, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.5 seconds, train=2.7 seconds, 408576 images, time remaining=115.1 minutes
6385: loss=3.016, avg loss=2.874, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=2.5 seconds, train=2.8 seconds, 408640 images, time remaining=115 minutes
6386: loss=2.916, avg loss=2.878, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.5 seconds, train=2.8 seconds, 408704 images, time remaining=115 minutes
6387: loss=2.741, avg loss=2.864, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.9 seconds, 408768 images, time remaining=114.9 minutes
6388: loss=2.753, avg loss=2.853, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.8 seconds, 408832 images, time remaining=114.8 minutes
6389: loss=3.027, avg loss=2.871, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.8 seconds, 408896 images, time remaining=114.7 minutes
6390: loss=2.954, avg loss=2.879, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=2.0 seconds, train=2.9 seconds, 408960 images, time remaining=114.6 minutes
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b4e7400000
6391: loss=2.627, avg loss=2.854, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.2 seconds, 409024 images, time remaining=114.6 minutes
6392: loss=2.434, avg loss=2.812, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.1 seconds, train=2.4 seconds, 409088 images, time remaining=114.5 minutes
6393: loss=3.429, avg loss=2.873, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.4 seconds, train=2.2 seconds, 409152 images, time remaining=114.4 minutes
6394: loss=2.627, avg loss=2.849, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.2 seconds, train=2.3 seconds, 409216 images, time remaining=114.3 minutes
6395: loss=2.579, avg loss=2.822, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 409280 images, time remaining=114.2 minutes
6396: loss=2.777, avg loss=2.817, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.1 seconds, 409344 images, time remaining=114.2 minutes
6397: loss=2.971, avg loss=2.833, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 409408 images, time remaining=114.1 minutes
6398: loss=3.236, avg loss=2.873, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 409472 images, time remaining=114 minutes
6399: loss=2.380, avg loss=2.824, last=96.54%, best=96.54%, next=6684, rate=0.00130000, load 64=1.3 seconds, train=2.3 seconds, 409536 images, time remaining=113.9 minutes
6400: loss=2.733, avg loss=2.815, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 409600 images, time remaining=113.8 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6401: loss=3.524, avg loss=2.886, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.8 seconds, train=5.9 seconds, 409664 images, time remaining=113.8 minutes
6402: loss=4.032, avg loss=3.000, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=2.0 seconds, train=5.8 seconds, 409728 images, time remaining=113.7 minutes
6403: loss=4.135, avg loss=3.114, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=5.7 seconds, 409792 images, time remaining=113.7 minutes
6404: loss=4.368, avg loss=3.239, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.9 seconds, train=5.8 seconds, 409856 images, time remaining=113.6 minutes
6405: loss=4.313, avg loss=3.347, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=5.7 seconds, 409920 images, time remaining=113.5 minutes
6406: loss=3.320, avg loss=3.344, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.8 seconds, train=5.8 seconds, 409984 images, time remaining=113.5 minutes
6407: loss=4.122, avg loss=3.422, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.9 seconds, train=5.7 seconds, 410048 images, time remaining=113.4 minutes
6408: loss=3.008, avg loss=3.380, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.9 seconds, train=5.5 seconds, 410112 images, time remaining=113.3 minutes
6409: loss=3.136, avg loss=3.356, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=2.6 seconds, train=5.8 seconds, 410176 images, time remaining=113.3 minutes
6410: loss=4.235, avg loss=3.444, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.8 seconds, train=5.8 seconds, 410240 images, time remaining=113.2 minutes
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b4fbc00000
6411: loss=2.659, avg loss=3.365, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 410304 images, time remaining=113.2 minutes
6412: loss=2.082, avg loss=3.237, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 410368 images, time remaining=113.1 minutes
6413: loss=2.601, avg loss=3.173, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.3 seconds, 410432 images, time remaining=113 minutes
6414: loss=2.882, avg loss=3.144, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 410496 images, time remaining=112.9 minutes
6415: loss=2.862, avg loss=3.116, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.8 seconds, train=2.2 seconds, 410560 images, time remaining=112.8 minutes
6416: loss=2.308, avg loss=3.035, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.2 seconds, 410624 images, time remaining=112.8 minutes
6417: loss=2.642, avg loss=2.996, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.2 seconds, 410688 images, time remaining=112.7 minutes
6418: loss=2.925, avg loss=2.989, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.9 seconds, train=2.2 seconds, 410752 images, time remaining=112.6 minutes
6419: loss=2.740, avg loss=2.964, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 410816 images, time remaining=112.5 minutes
6420: loss=2.630, avg loss=2.931, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.4 seconds, 410880 images, time remaining=112.4 minutes
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b84fa00000
6421: loss=2.371, avg loss=2.875, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.2 seconds, 410944 images, time remaining=112.3 minutes
6422: loss=2.705, avg loss=2.858, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.2 seconds, 411008 images, time remaining=112.3 minutes
6423: loss=2.727, avg loss=2.845, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.3 seconds, 411072 images, time remaining=112.2 minutes
6424: loss=2.521, avg loss=2.812, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.8 seconds, train=2.2 seconds, 411136 images, time remaining=112.1 minutes
6425: loss=2.826, avg loss=2.814, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.9 seconds, train=2.3 seconds, 411200 images, time remaining=112 minutes
6426: loss=2.480, avg loss=2.780, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.3 seconds, 411264 images, time remaining=112 minutes
6427: loss=2.581, avg loss=2.760, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.2 seconds, 411328 images, time remaining=111.9 minutes
6428: loss=2.348, avg loss=2.719, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 411392 images, time remaining=111.8 minutes
6429: loss=2.660, avg loss=2.713, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.2 seconds, 411456 images, time remaining=111.7 minutes
6430: loss=2.278, avg loss=2.670, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.4 seconds, 411520 images, time remaining=111.6 minutes
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b73c000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6431: loss=3.103, avg loss=2.713, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=2.0 seconds, train=1.9 seconds, 411584 images, time remaining=111.6 minutes
6432: loss=2.851, avg loss=2.727, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=1.9 seconds, 411648 images, time remaining=111.5 minutes
6433: loss=2.309, avg loss=2.685, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.0 seconds, 411712 images, time remaining=111.4 minutes
6434: loss=2.494, avg loss=2.666, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=1.9 seconds, 411776 images, time remaining=111.3 minutes
6435: loss=2.863, avg loss=2.686, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.0 seconds, 411840 images, time remaining=111.2 minutes
6436: loss=2.904, avg loss=2.708, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=1.9 seconds, 411904 images, time remaining=111.2 minutes
6437: loss=2.496, avg loss=2.686, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.0 seconds, 411968 images, time remaining=111.1 minutes
6438: loss=2.543, avg loss=2.672, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=1.9 seconds, 412032 images, time remaining=111 minutes
6439: loss=2.460, avg loss=2.651, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=1.9 seconds, 412096 images, time remaining=110.9 minutes
6440: loss=2.073, avg loss=2.593, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=1.9 seconds, 412160 images, time remaining=110.8 minutes
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6441: loss=3.175, avg loss=2.651, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.0 seconds, 412224 images, time remaining=110.8 minutes
6442: loss=3.061, avg loss=2.692, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 412288 images, time remaining=110.7 minutes
6443: loss=2.286, avg loss=2.652, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=4.0 seconds, 412352 images, time remaining=110.7 minutes
6444: loss=2.618, avg loss=2.648, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=3.9 seconds, 412416 images, time remaining=110.6 minutes
6445: loss=3.242, avg loss=2.708, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=4.0 seconds, 412480 images, time remaining=110.5 minutes
6446: loss=2.802, avg loss=2.717, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.0 seconds, 412544 images, time remaining=110.4 minutes
6447: loss=1.949, avg loss=2.640, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 412608 images, time remaining=110.3 minutes
6448: loss=2.392, avg loss=2.615, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 412672 images, time remaining=110.3 minutes
6449: loss=2.150, avg loss=2.569, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=4.0 seconds, 412736 images, time remaining=110.2 minutes
6450: loss=2.738, avg loss=2.586, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=4.0 seconds, 412800 images, time remaining=110.1 minutes
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b837e00000
6451: loss=2.174, avg loss=2.545, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.1 seconds, train=1.9 seconds, 412864 images, time remaining=110.1 minutes
6452: loss=2.629, avg loss=2.553, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.1 seconds, train=1.9 seconds, 412928 images, time remaining=110 minutes
6453: loss=2.883, avg loss=2.586, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=1.9 seconds, 412992 images, time remaining=109.9 minutes
6454: loss=2.934, avg loss=2.621, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=1.9 seconds, 413056 images, time remaining=109.8 minutes
6455: loss=2.905, avg loss=2.649, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.0 seconds, 413120 images, time remaining=109.7 minutes
6456: loss=1.875, avg loss=2.572, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=1.9 seconds, 413184 images, time remaining=109.7 minutes
6457: loss=2.233, avg loss=2.538, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.0 seconds, 413248 images, time remaining=109.6 minutes
6458: loss=2.865, avg loss=2.571, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.0 seconds, 413312 images, time remaining=109.5 minutes
6459: loss=2.225, avg loss=2.536, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.0 seconds, 413376 images, time remaining=109.4 minutes
6460: loss=2.110, avg loss=2.493, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=1.9 seconds, 413440 images, time remaining=109.3 minutes
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b3f4000000
6461: loss=2.431, avg loss=2.487, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.0 seconds, 413504 images, time remaining=109.3 minutes
6462: loss=2.493, avg loss=2.488, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.1 seconds, 413568 images, time remaining=109.2 minutes
6463: loss=2.584, avg loss=2.497, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.2 seconds, 413632 images, time remaining=109.1 minutes
6464: loss=2.515, avg loss=2.499, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 413696 images, time remaining=109 minutes
6465: loss=2.695, avg loss=2.519, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.1 seconds, 413760 images, time remaining=108.9 minutes
6466: loss=2.481, avg loss=2.515, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.1 seconds, 413824 images, time remaining=108.9 minutes
6467: loss=2.449, avg loss=2.508, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.2 seconds, 413888 images, time remaining=108.8 minutes
6468: loss=1.952, avg loss=2.453, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.1 seconds, 413952 images, time remaining=108.7 minutes
6469: loss=2.877, avg loss=2.495, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.1 seconds, 414016 images, time remaining=108.6 minutes
6470: loss=2.232, avg loss=2.469, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.2 seconds, 414080 images, time remaining=108.6 minutes
Resizing, random_coef=1.40, batch=4, 992x768
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6471: loss=2.701, avg loss=2.492, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=3.9 seconds, 414144 images, time remaining=108.5 minutes
6472: loss=2.687, avg loss=2.512, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=3.8 seconds, 414208 images, time remaining=108.4 minutes
6473: loss=3.031, avg loss=2.564, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=3.9 seconds, 414272 images, time remaining=108.3 minutes
6474: loss=3.079, avg loss=2.615, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=3.8 seconds, 414336 images, time remaining=108.3 minutes
6475: loss=2.164, avg loss=2.570, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=3.9 seconds, 414400 images, time remaining=108.2 minutes
6476: loss=2.361, avg loss=2.549, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=3.8 seconds, 414464 images, time remaining=108.1 minutes
6477: loss=2.401, avg loss=2.534, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=3.9 seconds, 414528 images, time remaining=108 minutes
6478: loss=2.822, avg loss=2.563, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=3.9 seconds, 414592 images, time remaining=108 minutes
6479: loss=2.395, avg loss=2.546, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=3.8 seconds, 414656 images, time remaining=107.9 minutes
6480: loss=2.760, avg loss=2.568, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=3.8 seconds, 414720 images, time remaining=107.8 minutes
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b6e9000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6481: loss=2.973, avg loss=2.608, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=3.2 seconds, train=2.4 seconds, 414784 images, time remaining=107.8 minutes
6482: loss=2.240, avg loss=2.571, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.4 seconds, 414848 images, time remaining=107.7 minutes
6483: loss=2.642, avg loss=2.578, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.4 seconds, 414912 images, time remaining=107.6 minutes
6484: loss=2.677, avg loss=2.588, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.4 seconds, 414976 images, time remaining=107.5 minutes
6485: loss=2.535, avg loss=2.583, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.4 seconds, 415040 images, time remaining=107.5 minutes
6486: loss=2.704, avg loss=2.595, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.3 seconds, 415104 images, time remaining=107.4 minutes
6487: loss=2.682, avg loss=2.604, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.5 seconds, 415168 images, time remaining=107.3 minutes
6488: loss=2.306, avg loss=2.574, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.4 seconds, 415232 images, time remaining=107.2 minutes
6489: loss=2.258, avg loss=2.542, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.4 seconds, 415296 images, time remaining=107.1 minutes
6490: loss=2.436, avg loss=2.532, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.4 seconds, 415360 images, time remaining=107.1 minutes
Resizing, random_coef=1.40, batch=4, 896x672
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b7b3e00000
6491: loss=2.636, avg loss=2.542, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.5 seconds, 415424 images, time remaining=107 minutes
6492: loss=2.402, avg loss=2.528, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.5 seconds, 415488 images, time remaining=106.9 minutes
6493: loss=2.654, avg loss=2.541, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.6 seconds, 415552 images, time remaining=106.8 minutes
6494: loss=2.744, avg loss=2.561, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.5 seconds, 415616 images, time remaining=106.8 minutes
6495: loss=2.253, avg loss=2.530, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.6 seconds, 415680 images, time remaining=106.7 minutes
6496: loss=2.147, avg loss=2.492, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.6 seconds, 415744 images, time remaining=106.6 minutes
6497: loss=2.032, avg loss=2.446, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.5 seconds, 415808 images, time remaining=106.5 minutes
6498: loss=2.326, avg loss=2.434, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.5 seconds, 415872 images, time remaining=106.5 minutes
6499: loss=2.137, avg loss=2.404, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.5 seconds, 415936 images, time remaining=106.4 minutes
6500: loss=2.232, avg loss=2.387, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.7 seconds, 416000 images, time remaining=106.3 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b694a00000
6501: loss=1.856, avg loss=2.334, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.1 seconds, 416064 images, time remaining=106.2 minutes
6502: loss=2.247, avg loss=2.325, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 416128 images, time remaining=106.1 minutes
6503: loss=2.131, avg loss=2.306, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.2 seconds, 416192 images, time remaining=106.1 minutes
6504: loss=2.717, avg loss=2.347, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.1 seconds, 416256 images, time remaining=106 minutes
6505: loss=2.657, avg loss=2.378, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.2 seconds, 416320 images, time remaining=105.9 minutes
6506: loss=1.779, avg loss=2.318, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.1 seconds, 416384 images, time remaining=105.8 minutes
6507: loss=2.497, avg loss=2.336, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.1 seconds, train=2.1 seconds, 416448 images, time remaining=105.8 minutes
6508: loss=1.760, avg loss=2.278, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.1 seconds, 416512 images, time remaining=105.7 minutes
6509: loss=2.037, avg loss=2.254, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.2 seconds, 416576 images, time remaining=105.6 minutes
6510: loss=1.989, avg loss=2.228, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.1 seconds, 416640 images, time remaining=105.5 minutes
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b706600000
6511: loss=2.092, avg loss=2.214, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.2 seconds, 416704 images, time remaining=105.4 minutes
6512: loss=2.243, avg loss=2.217, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.2 seconds, 416768 images, time remaining=105.4 minutes
6513: loss=2.231, avg loss=2.218, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.4 seconds, 416832 images, time remaining=105.3 minutes
6514: loss=2.138, avg loss=2.210, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.2 seconds, 416896 images, time remaining=105.2 minutes
6515: loss=2.503, avg loss=2.240, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 416960 images, time remaining=105.2 minutes
6516: loss=2.656, avg loss=2.281, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.2 seconds, 417024 images, time remaining=105.1 minutes
6517: loss=2.735, avg loss=2.327, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 417088 images, time remaining=105 minutes
6518: loss=2.103, avg loss=2.304, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.2 seconds, 417152 images, time remaining=104.9 minutes
6519: loss=2.105, avg loss=2.284, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.3 seconds, 417216 images, time remaining=104.8 minutes
6520: loss=2.317, avg loss=2.287, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.4 seconds, 417280 images, time remaining=104.8 minutes
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6521: loss=3.387, avg loss=2.397, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.8 seconds, train=6.3 seconds, 417344 images, time remaining=104.7 minutes
6522: loss=2.817, avg loss=2.439, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=2.3 seconds, train=6.0 seconds, 417408 images, time remaining=104.6 minutes
6523: loss=3.835, avg loss=2.579, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=6.2 seconds, 417472 images, time remaining=104.6 minutes
6524: loss=3.167, avg loss=2.638, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.9 seconds, train=6.1 seconds, 417536 images, time remaining=104.5 minutes
6525: loss=3.503, avg loss=2.724, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=6.1 seconds, 417600 images, time remaining=104.4 minutes
6526: loss=3.656, avg loss=2.817, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=2.1 seconds, train=6.0 seconds, 417664 images, time remaining=104.4 minutes
6527: loss=3.368, avg loss=2.872, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.8 seconds, train=6.1 seconds, 417728 images, time remaining=104.3 minutes
6528: loss=3.219, avg loss=2.907, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.9 seconds, train=6.0 seconds, 417792 images, time remaining=104.3 minutes
6529: loss=3.039, avg loss=2.920, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=6.1 seconds, 417856 images, time remaining=104.2 minutes
6530: loss=3.789, avg loss=3.007, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=2.0 seconds, train=6.1 seconds, 417920 images, time remaining=104.1 minutes
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6531: loss=2.359, avg loss=2.942, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.4 seconds, 417984 images, time remaining=104.1 minutes
6532: loss=2.639, avg loss=2.912, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=2.0 seconds, train=4.3 seconds, 418048 images, time remaining=104 minutes
6533: loss=2.904, avg loss=2.911, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=2.3 seconds, train=4.5 seconds, 418112 images, time remaining=103.9 minutes
6534: loss=2.220, avg loss=2.842, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.3 seconds, 418176 images, time remaining=103.9 minutes
6535: loss=2.646, avg loss=2.822, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=4.3 seconds, 418240 images, time remaining=103.8 minutes
6536: loss=2.995, avg loss=2.840, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=2.1 seconds, train=4.3 seconds, 418304 images, time remaining=103.7 minutes
6537: loss=2.360, avg loss=2.792, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.4 seconds, 418368 images, time remaining=103.6 minutes
6538: loss=1.916, avg loss=2.704, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.3 seconds, 418432 images, time remaining=103.6 minutes
6539: loss=2.525, avg loss=2.686, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=2.0 seconds, train=4.3 seconds, 418496 images, time remaining=103.5 minutes
6540: loss=2.460, avg loss=2.664, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.3 seconds, 418560 images, time remaining=103.4 minutes
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b1fe000000
6541: loss=2.273, avg loss=2.625, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=2.1 seconds, 418624 images, time remaining=103.4 minutes
6542: loss=2.199, avg loss=2.582, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.2 seconds, 418688 images, time remaining=103.3 minutes
6543: loss=2.640, avg loss=2.588, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.3 seconds, 418752 images, time remaining=103.2 minutes
6544: loss=2.407, avg loss=2.570, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.2 seconds, 418816 images, time remaining=103.1 minutes
6545: loss=2.815, avg loss=2.594, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.2 seconds, 418880 images, time remaining=103.1 minutes
6546: loss=2.667, avg loss=2.601, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.2 seconds, 418944 images, time remaining=103 minutes
6547: loss=2.180, avg loss=2.559, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 419008 images, time remaining=102.9 minutes
6548: loss=2.334, avg loss=2.537, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.1 seconds, 419072 images, time remaining=102.8 minutes
6549: loss=2.741, avg loss=2.557, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.3 seconds, 419136 images, time remaining=102.7 minutes
6550: loss=2.554, avg loss=2.557, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.1 seconds, 419200 images, time remaining=102.6 minutes
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b742200000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6551: loss=2.349, avg loss=2.536, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=2.8 seconds, train=2.8 seconds, 419264 images, time remaining=102.6 minutes
6552: loss=2.113, avg loss=2.494, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=2.7 seconds, 419328 images, time remaining=102.5 minutes
6553: loss=2.452, avg loss=2.490, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.7 seconds, 419392 images, time remaining=102.4 minutes
6554: loss=1.848, avg loss=2.425, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.7 seconds, 419456 images, time remaining=102.4 minutes
6555: loss=2.566, avg loss=2.439, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.6 seconds, 419520 images, time remaining=102.3 minutes
6556: loss=2.336, avg loss=2.429, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.7 seconds, 419584 images, time remaining=102.2 minutes
6557: loss=2.700, avg loss=2.456, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.7 seconds, 419648 images, time remaining=102.1 minutes
6558: loss=2.516, avg loss=2.462, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.7 seconds, 419712 images, time remaining=102.1 minutes
6559: loss=2.265, avg loss=2.442, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.7 seconds, 419776 images, time remaining=102 minutes
6560: loss=2.167, avg loss=2.415, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 419840 images, time remaining=101.9 minutes
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b6bea00000
6561: loss=2.055, avg loss=2.379, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.1 seconds, 419904 images, time remaining=101.8 minutes
6562: loss=2.280, avg loss=2.369, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.1 seconds, 419968 images, time remaining=101.7 minutes
6563: loss=2.580, avg loss=2.390, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.1 seconds, 420032 images, time remaining=101.7 minutes
6564: loss=2.086, avg loss=2.360, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=2.1 seconds, 420096 images, time remaining=101.6 minutes
6565: loss=2.413, avg loss=2.365, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.1 seconds, train=2.2 seconds, 420160 images, time remaining=101.5 minutes
6566: loss=2.189, avg loss=2.347, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.1 seconds, 420224 images, time remaining=101.4 minutes
6567: loss=2.344, avg loss=2.347, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.1 seconds, train=2.2 seconds, 420288 images, time remaining=101.4 minutes
6568: loss=2.057, avg loss=2.318, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 420352 images, time remaining=101.3 minutes
6569: loss=2.306, avg loss=2.317, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.1 seconds, 420416 images, time remaining=101.2 minutes
6570: loss=2.716, avg loss=2.357, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 420480 images, time remaining=101.1 minutes
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6571: loss=2.636, avg loss=2.385, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 420544 images, time remaining=101.1 minutes
6572: loss=2.646, avg loss=2.411, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=4.6 seconds, 420608 images, time remaining=101 minutes
6573: loss=2.347, avg loss=2.404, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=3.7 seconds, train=4.7 seconds, 420672 images, time remaining=100.9 minutes
6574: loss=2.943, avg loss=2.458, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.7 seconds, 420736 images, time remaining=100.9 minutes
6575: loss=2.569, avg loss=2.469, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 420800 images, time remaining=100.8 minutes
6576: loss=2.659, avg loss=2.488, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 420864 images, time remaining=100.7 minutes
6577: loss=3.106, avg loss=2.550, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.8 seconds, 420928 images, time remaining=100.7 minutes
6578: loss=3.061, avg loss=2.601, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 420992 images, time remaining=100.6 minutes
6579: loss=2.612, avg loss=2.602, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 421056 images, time remaining=100.5 minutes
6580: loss=2.489, avg loss=2.591, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.9 seconds, train=4.7 seconds, 421120 images, time remaining=100.4 minutes
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
6581: loss=2.094, avg loss=2.541, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.8 seconds, 421184 images, time remaining=100.4 minutes
6582: loss=2.444, avg loss=2.532, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 421248 images, time remaining=100.3 minutes
6583: loss=2.169, avg loss=2.495, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 421312 images, time remaining=100.2 minutes
6584: loss=2.031, avg loss=2.449, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.6 seconds, 421376 images, time remaining=100.2 minutes
6585: loss=2.433, avg loss=2.447, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 421440 images, time remaining=100.1 minutes
6586: loss=2.323, avg loss=2.435, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 421504 images, time remaining=100 minutes
6587: loss=2.172, avg loss=2.409, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.7 seconds, 421568 images, time remaining=99.9 minutes
6588: loss=2.163, avg loss=2.384, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 421632 images, time remaining=99.8 minutes
6589: loss=2.210, avg loss=2.367, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=2.7 seconds, 421696 images, time remaining=99.8 minutes
6590: loss=2.033, avg loss=2.333, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 421760 images, time remaining=99.7 minutes
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6591: loss=2.076, avg loss=2.308, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=4.5 seconds, 421824 images, time remaining=99.6 minutes
6592: loss=2.477, avg loss=2.325, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=4.4 seconds, 421888 images, time remaining=99.6 minutes
6593: loss=2.885, avg loss=2.381, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=4.5 seconds, 421952 images, time remaining=99.5 minutes
6594: loss=2.904, avg loss=2.433, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.3 seconds, 422016 images, time remaining=99.4 minutes
6595: loss=2.925, avg loss=2.482, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.3 seconds, 422080 images, time remaining=99.3 minutes
6596: loss=2.257, avg loss=2.460, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.5 seconds, 422144 images, time remaining=99.3 minutes
6597: loss=2.402, avg loss=2.454, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.4 seconds, 422208 images, time remaining=99.2 minutes
6598: loss=2.373, avg loss=2.446, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=4.4 seconds, 422272 images, time remaining=99.2 minutes
6599: loss=2.600, avg loss=2.461, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.5 seconds, 422336 images, time remaining=99.1 minutes
6600: loss=2.301, avg loss=2.445, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.4 seconds, 422400 images, time remaining=99 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6601: loss=2.399, avg loss=2.440, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.8 seconds, train=4.9 seconds, 422464 images, time remaining=98.9 minutes
6602: loss=2.155, avg loss=2.412, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.9 seconds, 422528 images, time remaining=98.9 minutes
6603: loss=2.758, avg loss=2.447, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=5.0 seconds, 422592 images, time remaining=98.8 minutes
6604: loss=2.643, avg loss=2.466, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.8 seconds, 422656 images, time remaining=98.8 minutes
6605: loss=2.276, avg loss=2.447, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.9 seconds, 422720 images, time remaining=98.7 minutes
6606: loss=2.303, avg loss=2.433, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.9 seconds, 422784 images, time remaining=98.6 minutes
6607: loss=2.543, avg loss=2.444, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.9 seconds, train=4.9 seconds, 422848 images, time remaining=98.5 minutes
6608: loss=2.229, avg loss=2.422, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.9 seconds, 422912 images, time remaining=98.5 minutes
6609: loss=2.415, avg loss=2.422, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=4.9 seconds, 422976 images, time remaining=98.4 minutes
6610: loss=2.441, avg loss=2.424, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.8 seconds, 423040 images, time remaining=98.3 minutes
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14b827600000
6611: loss=2.298, avg loss=2.411, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.2 seconds, 423104 images, time remaining=98.3 minutes
6612: loss=2.495, avg loss=2.420, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 423168 images, time remaining=98.2 minutes
6613: loss=2.037, avg loss=2.381, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.1 seconds, 423232 images, time remaining=98.1 minutes
6614: loss=2.140, avg loss=2.357, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.1 seconds, train=2.2 seconds, 423296 images, time remaining=98 minutes
6615: loss=1.852, avg loss=2.307, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.3 seconds, 423360 images, time remaining=97.9 minutes
6616: loss=2.525, avg loss=2.328, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 423424 images, time remaining=97.9 minutes
6617: loss=2.461, avg loss=2.342, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 423488 images, time remaining=97.8 minutes
6618: loss=2.427, avg loss=2.350, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 423552 images, time remaining=97.7 minutes
6619: loss=2.456, avg loss=2.361, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.1 seconds, 423616 images, time remaining=97.6 minutes
6620: loss=2.828, avg loss=2.407, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 423680 images, time remaining=97.6 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
6621: loss=2.301, avg loss=2.397, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 423744 images, time remaining=97.5 minutes
6622: loss=2.460, avg loss=2.403, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.8 seconds, 423808 images, time remaining=97.4 minutes
6623: loss=2.310, avg loss=2.394, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 423872 images, time remaining=97.3 minutes
6624: loss=2.566, avg loss=2.411, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 423936 images, time remaining=97.3 minutes
6625: loss=2.355, avg loss=2.405, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.9 seconds, 424000 images, time remaining=97.2 minutes
6626: loss=1.920, avg loss=2.357, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.8 seconds, 424064 images, time remaining=97.1 minutes
6627: loss=2.108, avg loss=2.332, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 424128 images, time remaining=97 minutes
6628: loss=2.226, avg loss=2.321, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.9 seconds, 424192 images, time remaining=97 minutes
6629: loss=2.276, avg loss=2.317, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.9 seconds, 424256 images, time remaining=96.9 minutes
6630: loss=2.264, avg loss=2.312, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 424320 images, time remaining=96.8 minutes
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6631: loss=2.635, avg loss=2.344, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.8 seconds, 424384 images, time remaining=96.8 minutes
6632: loss=3.029, avg loss=2.412, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 424448 images, time remaining=96.7 minutes
6633: loss=2.352, avg loss=2.406, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 424512 images, time remaining=96.6 minutes
6634: loss=3.398, avg loss=2.506, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=4.7 seconds, 424576 images, time remaining=96.6 minutes
6635: loss=2.924, avg loss=2.547, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=4.7 seconds, 424640 images, time remaining=96.5 minutes
6636: loss=3.342, avg loss=2.627, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 424704 images, time remaining=96.4 minutes
6637: loss=2.238, avg loss=2.588, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=4.7 seconds, 424768 images, time remaining=96.3 minutes
6638: loss=2.664, avg loss=2.595, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 424832 images, time remaining=96.3 minutes
6639: loss=2.654, avg loss=2.601, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 424896 images, time remaining=96.2 minutes
6640: loss=3.014, avg loss=2.642, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.8 seconds, train=4.8 seconds, 424960 images, time remaining=96.1 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
6641: loss=2.060, avg loss=2.584, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 425024 images, time remaining=96.1 minutes
6642: loss=2.364, avg loss=2.562, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 425088 images, time remaining=96 minutes
6643: loss=2.671, avg loss=2.573, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.9 seconds, 425152 images, time remaining=95.9 minutes
6644: loss=1.944, avg loss=2.510, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.8 seconds, 425216 images, time remaining=95.8 minutes
6645: loss=2.226, avg loss=2.482, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.9 seconds, 425280 images, time remaining=95.8 minutes
6646: loss=2.207, avg loss=2.454, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 425344 images, time remaining=95.7 minutes
6647: loss=2.007, avg loss=2.410, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.9 seconds, 425408 images, time remaining=95.6 minutes
6648: loss=1.975, avg loss=2.366, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.9 seconds, 425472 images, time remaining=95.6 minutes
6649: loss=2.034, avg loss=2.333, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 425536 images, time remaining=95.5 minutes
6650: loss=2.256, avg loss=2.325, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 425600 images, time remaining=95.4 minutes
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6651: loss=2.411, avg loss=2.334, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 425664 images, time remaining=95.3 minutes
6652: loss=2.187, avg loss=2.319, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.6 seconds, 425728 images, time remaining=95.3 minutes
6653: loss=2.716, avg loss=2.359, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.5 seconds, 425792 images, time remaining=95.2 minutes
6654: loss=1.964, avg loss=2.319, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=3.2 seconds, train=4.7 seconds, 425856 images, time remaining=95.1 minutes
6655: loss=3.398, avg loss=2.427, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 425920 images, time remaining=95.1 minutes
6656: loss=2.585, avg loss=2.443, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=4.7 seconds, 425984 images, time remaining=95 minutes
6657: loss=3.381, avg loss=2.537, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=4.7 seconds, 426048 images, time remaining=94.9 minutes
6658: loss=3.233, avg loss=2.606, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=4.8 seconds, 426112 images, time remaining=94.8 minutes
6659: loss=3.281, avg loss=2.674, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 426176 images, time remaining=94.8 minutes
6660: loss=3.045, avg loss=2.711, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 426240 images, time remaining=94.7 minutes
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6661: loss=3.336, avg loss=2.773, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=6.0 seconds, 426304 images, time remaining=94.7 minutes
6662: loss=3.089, avg loss=2.805, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.9 seconds, train=5.7 seconds, 426368 images, time remaining=94.6 minutes
6663: loss=3.731, avg loss=2.898, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=5.9 seconds, 426432 images, time remaining=94.5 minutes
6664: loss=3.094, avg loss=2.917, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.8 seconds, train=5.8 seconds, 426496 images, time remaining=94.5 minutes
6665: loss=3.545, avg loss=2.980, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.8 seconds, train=5.9 seconds, 426560 images, time remaining=94.4 minutes
6666: loss=2.839, avg loss=2.966, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=5.9 seconds, 426624 images, time remaining=94.3 minutes
6667: loss=2.846, avg loss=2.954, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.8 seconds, train=5.9 seconds, 426688 images, time remaining=94.3 minutes
6668: loss=3.171, avg loss=2.976, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.8 seconds, train=5.9 seconds, 426752 images, time remaining=94.2 minutes
6669: loss=2.309, avg loss=2.909, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.7 seconds, train=5.9 seconds, 426816 images, time remaining=94.1 minutes
6670: loss=2.704, avg loss=2.888, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.9 seconds, train=5.9 seconds, 426880 images, time remaining=94.1 minutes
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b792800000
6671: loss=2.455, avg loss=2.845, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.1 seconds, train=1.9 seconds, 426944 images, time remaining=94 minutes
6672: loss=2.558, avg loss=2.816, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.1 seconds, train=2.0 seconds, 427008 images, time remaining=93.9 minutes
6673: loss=2.511, avg loss=2.786, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=1.9 seconds, 427072 images, time remaining=93.8 minutes
6674: loss=2.618, avg loss=2.769, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.0 seconds, 427136 images, time remaining=93.8 minutes
6675: loss=2.389, avg loss=2.731, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.0 seconds, 427200 images, time remaining=93.7 minutes
6676: loss=2.366, avg loss=2.695, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=1.9 seconds, 427264 images, time remaining=93.6 minutes
6677: loss=2.570, avg loss=2.682, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=1.9 seconds, 427328 images, time remaining=93.5 minutes
6678: loss=2.313, avg loss=2.645, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.0 seconds, 427392 images, time remaining=93.4 minutes
6679: loss=3.070, avg loss=2.688, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.2 seconds, train=2.0 seconds, 427456 images, time remaining=93.4 minutes
6680: loss=2.189, avg loss=2.638, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.0 seconds, 427520 images, time remaining=93.3 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
6681: loss=2.078, avg loss=2.582, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.5 seconds, train=2.8 seconds, 427584 images, time remaining=93.2 minutes
6682: loss=1.840, avg loss=2.508, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 427648 images, time remaining=93.2 minutes
6683: loss=2.682, avg loss=2.525, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.4 seconds, train=2.9 seconds, 427712 images, time remaining=93.1 minutes
6684: loss=2.616, avg loss=2.534, last=96.54%, best=96.54%, next=6684, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 427776 images, time remaining=93 minutes
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=94884, unique_truth_count=57264
rank=0 of ranks=94884rank=100 of ranks=94884rank=200 of ranks=94884rank=300 of ranks=94884rank=400 of ranks=94884rank=500 of ranks=94884rank=600 of ranks=94884rank=700 of ranks=94884rank=800 of ranks=94884rank=900 of ranks=94884rank=1000 of ranks=94884rank=1100 of ranks=94884rank=1200 of ranks=94884rank=1300 of ranks=94884rank=1400 of ranks=94884rank=1500 of ranks=94884rank=1600 of ranks=94884rank=1700 of ranks=94884rank=1800 of ranks=94884rank=1900 of ranks=94884rank=2000 of ranks=94884rank=2100 of ranks=94884rank=2200 of ranks=94884rank=2300 of ranks=94884rank=2400 of ranks=94884rank=2500 of ranks=94884rank=2600 of ranks=94884rank=2700 of ranks=94884rank=2800 of ranks=94884rank=2900 of ranks=94884rank=3000 of ranks=94884rank=3100 of ranks=94884rank=3200 of ranks=94884rank=3300 of ranks=94884rank=3400 of ranks=94884rank=3500 of ranks=94884rank=3600 of ranks=94884rank=3700 of ranks=94884rank=3800 of ranks=94884rank=3900 of ranks=94884rank=4000 of ranks=94884rank=4100 of ranks=94884rank=4200 of ranks=94884rank=4300 of ranks=94884rank=4400 of ranks=94884rank=4500 of ranks=94884rank=4600 of ranks=94884rank=4700 of ranks=94884rank=4800 of ranks=94884rank=4900 of ranks=94884rank=5000 of ranks=94884rank=5100 of ranks=94884rank=5200 of ranks=94884rank=5300 of ranks=94884rank=5400 of ranks=94884rank=5500 of ranks=94884rank=5600 of ranks=94884rank=5700 of ranks=94884rank=5800 of ranks=94884rank=5900 of ranks=94884rank=6000 of ranks=94884rank=6100 of ranks=94884rank=6200 of ranks=94884rank=6300 of ranks=94884rank=6400 of ranks=94884rank=6500 of ranks=94884rank=6600 of ranks=94884rank=6700 of ranks=94884rank=6800 of ranks=94884rank=6900 of ranks=94884rank=7000 of ranks=94884rank=7100 of ranks=94884rank=7200 of ranks=94884rank=7300 of ranks=94884rank=7400 of ranks=94884rank=7500 of ranks=94884rank=7600 of ranks=94884rank=7700 of ranks=94884rank=7800 of ranks=94884rank=7900 of ranks=94884rank=8000 of ranks=94884rank=8100 of ranks=94884rank=8200 of ranks=94884rank=8300 of ranks=94884rank=8400 of ranks=94884rank=8500 of ranks=94884rank=8600 of ranks=94884rank=8700 of ranks=94884rank=8800 of ranks=94884rank=8900 of ranks=94884rank=9000 of ranks=94884rank=9100 of ranks=94884rank=9200 of ranks=94884rank=9300 of ranks=94884rank=9400 of ranks=94884rank=9500 of ranks=94884rank=9600 of ranks=94884rank=9700 of ranks=94884rank=9800 of ranks=94884rank=9900 of ranks=94884rank=10000 of ranks=94884rank=10100 of ranks=94884rank=10200 of ranks=94884rank=10300 of ranks=94884rank=10400 of ranks=94884rank=10500 of ranks=94884rank=10600 of ranks=94884rank=10700 of ranks=94884rank=10800 of ranks=94884rank=10900 of ranks=94884rank=11000 of ranks=94884rank=11100 of ranks=94884rank=11200 of ranks=94884rank=11300 of ranks=94884rank=11400 of ranks=94884rank=11500 of ranks=94884rank=11600 of ranks=94884rank=11700 of ranks=94884rank=11800 of ranks=94884rank=11900 of ranks=94884rank=12000 of ranks=94884rank=12100 of ranks=94884rank=12200 of ranks=94884rank=12300 of ranks=94884rank=12400 of ranks=94884rank=12500 of ranks=94884rank=12600 of ranks=94884rank=12700 of ranks=94884rank=12800 of ranks=94884rank=12900 of ranks=94884rank=13000 of ranks=94884rank=13100 of ranks=94884rank=13200 of ranks=94884rank=13300 of ranks=94884rank=13400 of ranks=94884rank=13500 of ranks=94884rank=13600 of ranks=94884rank=13700 of ranks=94884rank=13800 of ranks=94884rank=13900 of ranks=94884rank=14000 of ranks=94884rank=14100 of ranks=94884rank=14200 of ranks=94884rank=14300 of ranks=94884rank=14400 of ranks=94884rank=14500 of ranks=94884rank=14600 of ranks=94884rank=14700 of ranks=94884rank=14800 of ranks=94884rank=14900 of ranks=94884rank=15000 of ranks=94884rank=15100 of ranks=94884rank=15200 of ranks=94884rank=15300 of ranks=94884rank=15400 of ranks=94884rank=15500 of ranks=94884rank=15600 of ranks=94884rank=15700 of ranks=94884rank=15800 of ranks=94884rank=15900 of ranks=94884rank=16000 of ranks=94884rank=16100 of ranks=94884rank=16200 of ranks=94884rank=16300 of ranks=94884rank=16400 of ranks=94884rank=16500 of ranks=94884rank=16600 of ranks=94884rank=16700 of ranks=94884rank=16800 of ranks=94884rank=16900 of ranks=94884rank=17000 of ranks=94884rank=17100 of ranks=94884rank=17200 of ranks=94884rank=17300 of ranks=94884rank=17400 of ranks=94884rank=17500 of ranks=94884rank=17600 of ranks=94884rank=17700 of ranks=94884rank=17800 of ranks=94884rank=17900 of ranks=94884rank=18000 of ranks=94884rank=18100 of ranks=94884rank=18200 of ranks=94884rank=18300 of ranks=94884rank=18400 of ranks=94884rank=18500 of ranks=94884rank=18600 of ranks=94884rank=18700 of ranks=94884rank=18800 of ranks=94884rank=18900 of ranks=94884rank=19000 of ranks=94884rank=19100 of ranks=94884rank=19200 of ranks=94884rank=19300 of ranks=94884rank=19400 of ranks=94884rank=19500 of ranks=94884rank=19600 of ranks=94884rank=19700 of ranks=94884rank=19800 of ranks=94884rank=19900 of ranks=94884rank=20000 of ranks=94884rank=20100 of ranks=94884rank=20200 of ranks=94884rank=20300 of ranks=94884rank=20400 of ranks=94884rank=20500 of ranks=94884rank=20600 of ranks=94884rank=20700 of ranks=94884rank=20800 of ranks=94884rank=20900 of ranks=94884rank=21000 of ranks=94884rank=21100 of ranks=94884rank=21200 of ranks=94884rank=21300 of ranks=94884rank=21400 of ranks=94884rank=21500 of ranks=94884rank=21600 of ranks=94884rank=21700 of ranks=94884rank=21800 of ranks=94884rank=21900 of ranks=94884rank=22000 of ranks=94884rank=22100 of ranks=94884rank=22200 of ranks=94884rank=22300 of ranks=94884rank=22400 of ranks=94884rank=22500 of ranks=94884rank=22600 of ranks=94884rank=22700 of ranks=94884rank=22800 of ranks=94884rank=22900 of ranks=94884rank=23000 of ranks=94884rank=23100 of ranks=94884rank=23200 of ranks=94884rank=23300 of ranks=94884rank=23400 of ranks=94884rank=23500 of ranks=94884rank=23600 of ranks=94884rank=23700 of ranks=94884rank=23800 of ranks=94884rank=23900 of ranks=94884rank=24000 of ranks=94884rank=24100 of ranks=94884rank=24200 of ranks=94884rank=24300 of ranks=94884rank=24400 of ranks=94884rank=24500 of ranks=94884rank=24600 of ranks=94884rank=24700 of ranks=94884rank=24800 of ranks=94884rank=24900 of ranks=94884rank=25000 of ranks=94884rank=25100 of ranks=94884rank=25200 of ranks=94884rank=25300 of ranks=94884rank=25400 of ranks=94884rank=25500 of ranks=94884rank=25600 of ranks=94884rank=25700 of ranks=94884rank=25800 of ranks=94884rank=25900 of ranks=94884rank=26000 of ranks=94884rank=26100 of ranks=94884rank=26200 of ranks=94884rank=26300 of ranks=94884rank=26400 of ranks=94884rank=26500 of ranks=94884rank=26600 of ranks=94884rank=26700 of ranks=94884rank=26800 of ranks=94884rank=26900 of ranks=94884rank=27000 of ranks=94884rank=27100 of ranks=94884rank=27200 of ranks=94884rank=27300 of ranks=94884rank=27400 of ranks=94884rank=27500 of ranks=94884rank=27600 of ranks=94884rank=27700 of ranks=94884rank=27800 of ranks=94884rank=27900 of ranks=94884rank=28000 of ranks=94884rank=28100 of ranks=94884rank=28200 of ranks=94884rank=28300 of ranks=94884rank=28400 of ranks=94884rank=28500 of ranks=94884rank=28600 of ranks=94884rank=28700 of ranks=94884rank=28800 of ranks=94884rank=28900 of ranks=94884rank=29000 of ranks=94884rank=29100 of ranks=94884rank=29200 of ranks=94884rank=29300 of ranks=94884rank=29400 of ranks=94884rank=29500 of ranks=94884rank=29600 of ranks=94884rank=29700 of ranks=94884rank=29800 of ranks=94884rank=29900 of ranks=94884rank=30000 of ranks=94884rank=30100 of ranks=94884rank=30200 of ranks=94884rank=30300 of ranks=94884rank=30400 of ranks=94884rank=30500 of ranks=94884rank=30600 of ranks=94884rank=30700 of ranks=94884rank=30800 of ranks=94884rank=30900 of ranks=94884rank=31000 of ranks=94884rank=31100 of ranks=94884rank=31200 of ranks=94884rank=31300 of ranks=94884rank=31400 of ranks=94884rank=31500 of ranks=94884rank=31600 of ranks=94884rank=31700 of ranks=94884rank=31800 of ranks=94884rank=31900 of ranks=94884rank=32000 of ranks=94884rank=32100 of ranks=94884rank=32200 of ranks=94884rank=32300 of ranks=94884rank=32400 of ranks=94884rank=32500 of ranks=94884rank=32600 of ranks=94884rank=32700 of ranks=94884rank=32800 of ranks=94884rank=32900 of ranks=94884rank=33000 of ranks=94884rank=33100 of ranks=94884rank=33200 of ranks=94884rank=33300 of ranks=94884rank=33400 of ranks=94884rank=33500 of ranks=94884rank=33600 of ranks=94884rank=33700 of ranks=94884rank=33800 of ranks=94884rank=33900 of ranks=94884rank=34000 of ranks=94884rank=34100 of ranks=94884rank=34200 of ranks=94884rank=34300 of ranks=94884rank=34400 of ranks=94884rank=34500 of ranks=94884rank=34600 of ranks=94884rank=34700 of ranks=94884rank=34800 of ranks=94884rank=34900 of ranks=94884rank=35000 of ranks=94884rank=35100 of ranks=94884rank=35200 of ranks=94884rank=35300 of ranks=94884rank=35400 of ranks=94884rank=35500 of ranks=94884rank=35600 of ranks=94884rank=35700 of ranks=94884rank=35800 of ranks=94884rank=35900 of ranks=94884rank=36000 of ranks=94884rank=36100 of ranks=94884rank=36200 of ranks=94884rank=36300 of ranks=94884rank=36400 of ranks=94884rank=36500 of ranks=94884rank=36600 of ranks=94884rank=36700 of ranks=94884rank=36800 of ranks=94884rank=36900 of ranks=94884rank=37000 of ranks=94884rank=37100 of ranks=94884rank=37200 of ranks=94884rank=37300 of ranks=94884rank=37400 of ranks=94884rank=37500 of ranks=94884rank=37600 of ranks=94884rank=37700 of ranks=94884rank=37800 of ranks=94884rank=37900 of ranks=94884rank=38000 of ranks=94884rank=38100 of ranks=94884rank=38200 of ranks=94884rank=38300 of ranks=94884rank=38400 of ranks=94884rank=38500 of ranks=94884rank=38600 of ranks=94884rank=38700 of ranks=94884rank=38800 of ranks=94884rank=38900 of ranks=94884rank=39000 of ranks=94884rank=39100 of ranks=94884rank=39200 of ranks=94884rank=39300 of ranks=94884rank=39400 of ranks=94884rank=39500 of ranks=94884rank=39600 of ranks=94884rank=39700 of ranks=94884rank=39800 of ranks=94884rank=39900 of ranks=94884rank=40000 of ranks=94884rank=40100 of ranks=94884rank=40200 of ranks=94884rank=40300 of ranks=94884rank=40400 of ranks=94884rank=40500 of ranks=94884rank=40600 of ranks=94884rank=40700 of ranks=94884rank=40800 of ranks=94884rank=40900 of ranks=94884rank=41000 of ranks=94884rank=41100 of ranks=94884rank=41200 of ranks=94884rank=41300 of ranks=94884rank=41400 of ranks=94884rank=41500 of ranks=94884rank=41600 of ranks=94884rank=41700 of ranks=94884rank=41800 of ranks=94884rank=41900 of ranks=94884rank=42000 of ranks=94884rank=42100 of ranks=94884rank=42200 of ranks=94884rank=42300 of ranks=94884rank=42400 of ranks=94884rank=42500 of ranks=94884rank=42600 of ranks=94884rank=42700 of ranks=94884rank=42800 of ranks=94884rank=42900 of ranks=94884rank=43000 of ranks=94884rank=43100 of ranks=94884rank=43200 of ranks=94884rank=43300 of ranks=94884rank=43400 of ranks=94884rank=43500 of ranks=94884rank=43600 of ranks=94884rank=43700 of ranks=94884rank=43800 of ranks=94884rank=43900 of ranks=94884rank=44000 of ranks=94884rank=44100 of ranks=94884rank=44200 of ranks=94884rank=44300 of ranks=94884rank=44400 of ranks=94884rank=44500 of ranks=94884rank=44600 of ranks=94884rank=44700 of ranks=94884rank=44800 of ranks=94884rank=44900 of ranks=94884rank=45000 of ranks=94884rank=45100 of ranks=94884rank=45200 of ranks=94884rank=45300 of ranks=94884rank=45400 of ranks=94884rank=45500 of ranks=94884rank=45600 of ranks=94884rank=45700 of ranks=94884rank=45800 of ranks=94884rank=45900 of ranks=94884rank=46000 of ranks=94884rank=46100 of ranks=94884rank=46200 of ranks=94884rank=46300 of ranks=94884rank=46400 of ranks=94884rank=46500 of ranks=94884rank=46600 of ranks=94884rank=46700 of ranks=94884rank=46800 of ranks=94884rank=46900 of ranks=94884rank=47000 of ranks=94884rank=47100 of ranks=94884rank=47200 of ranks=94884rank=47300 of ranks=94884rank=47400 of ranks=94884rank=47500 of ranks=94884rank=47600 of ranks=94884rank=47700 of ranks=94884rank=47800 of ranks=94884rank=47900 of ranks=94884rank=48000 of ranks=94884rank=48100 of ranks=94884rank=48200 of ranks=94884rank=48300 of ranks=94884rank=48400 of ranks=94884rank=48500 of ranks=94884rank=48600 of ranks=94884rank=48700 of ranks=94884rank=48800 of ranks=94884rank=48900 of ranks=94884rank=49000 of ranks=94884rank=49100 of ranks=94884rank=49200 of ranks=94884rank=49300 of ranks=94884rank=49400 of ranks=94884rank=49500 of ranks=94884rank=49600 of ranks=94884rank=49700 of ranks=94884rank=49800 of ranks=94884rank=49900 of ranks=94884rank=50000 of ranks=94884rank=50100 of ranks=94884rank=50200 of ranks=94884rank=50300 of ranks=94884rank=50400 of ranks=94884rank=50500 of ranks=94884rank=50600 of ranks=94884rank=50700 of ranks=94884rank=50800 of ranks=94884rank=50900 of ranks=94884rank=51000 of ranks=94884rank=51100 of ranks=94884rank=51200 of ranks=94884rank=51300 of ranks=94884rank=51400 of ranks=94884rank=51500 of ranks=94884rank=51600 of ranks=94884rank=51700 of ranks=94884rank=51800 of ranks=94884rank=51900 of ranks=94884rank=52000 of ranks=94884rank=52100 of ranks=94884rank=52200 of ranks=94884rank=52300 of ranks=94884rank=52400 of ranks=94884rank=52500 of ranks=94884rank=52600 of ranks=94884rank=52700 of ranks=94884rank=52800 of ranks=94884rank=52900 of ranks=94884rank=53000 of ranks=94884rank=53100 of ranks=94884rank=53200 of ranks=94884rank=53300 of ranks=94884rank=53400 of ranks=94884rank=53500 of ranks=94884rank=53600 of ranks=94884rank=53700 of ranks=94884rank=53800 of ranks=94884rank=53900 of ranks=94884rank=54000 of ranks=94884rank=54100 of ranks=94884rank=54200 of ranks=94884rank=54300 of ranks=94884rank=54400 of ranks=94884rank=54500 of ranks=94884rank=54600 of ranks=94884rank=54700 of ranks=94884rank=54800 of ranks=94884rank=54900 of ranks=94884rank=55000 of ranks=94884rank=55100 of ranks=94884rank=55200 of ranks=94884rank=55300 of ranks=94884rank=55400 of ranks=94884rank=55500 of ranks=94884rank=55600 of ranks=94884rank=55700 of ranks=94884rank=55800 of ranks=94884rank=55900 of ranks=94884rank=56000 of ranks=94884rank=56100 of ranks=94884rank=56200 of ranks=94884rank=56300 of ranks=94884rank=56400 of ranks=94884rank=56500 of ranks=94884rank=56600 of ranks=94884rank=56700 of ranks=94884rank=56800 of ranks=94884rank=56900 of ranks=94884rank=57000 of ranks=94884rank=57100 of ranks=94884rank=57200 of ranks=94884rank=57300 of ranks=94884rank=57400 of ranks=94884rank=57500 of ranks=94884rank=57600 of ranks=94884rank=57700 of ranks=94884rank=57800 of ranks=94884rank=57900 of ranks=94884rank=58000 of ranks=94884rank=58100 of ranks=94884rank=58200 of ranks=94884rank=58300 of ranks=94884rank=58400 of ranks=94884rank=58500 of ranks=94884rank=58600 of ranks=94884rank=58700 of ranks=94884rank=58800 of ranks=94884rank=58900 of ranks=94884rank=59000 of ranks=94884rank=59100 of ranks=94884rank=59200 of ranks=94884rank=59300 of ranks=94884rank=59400 of ranks=94884rank=59500 of ranks=94884rank=59600 of ranks=94884rank=59700 of ranks=94884rank=59800 of ranks=94884rank=59900 of ranks=94884rank=60000 of ranks=94884rank=60100 of ranks=94884rank=60200 of ranks=94884rank=60300 of ranks=94884rank=60400 of ranks=94884rank=60500 of ranks=94884rank=60600 of ranks=94884rank=60700 of ranks=94884rank=60800 of ranks=94884rank=60900 of ranks=94884rank=61000 of ranks=94884rank=61100 of ranks=94884rank=61200 of ranks=94884rank=61300 of ranks=94884rank=61400 of ranks=94884rank=61500 of ranks=94884rank=61600 of ranks=94884rank=61700 of ranks=94884rank=61800 of ranks=94884rank=61900 of ranks=94884rank=62000 of ranks=94884rank=62100 of ranks=94884rank=62200 of ranks=94884rank=62300 of ranks=94884rank=62400 of ranks=94884rank=62500 of ranks=94884rank=62600 of ranks=94884rank=62700 of ranks=94884rank=62800 of ranks=94884rank=62900 of ranks=94884rank=63000 of ranks=94884rank=63100 of ranks=94884rank=63200 of ranks=94884rank=63300 of ranks=94884rank=63400 of ranks=94884rank=63500 of ranks=94884rank=63600 of ranks=94884rank=63700 of ranks=94884rank=63800 of ranks=94884rank=63900 of ranks=94884rank=64000 of ranks=94884rank=64100 of ranks=94884rank=64200 of ranks=94884rank=64300 of ranks=94884rank=64400 of ranks=94884rank=64500 of ranks=94884rank=64600 of ranks=94884rank=64700 of ranks=94884rank=64800 of ranks=94884rank=64900 of ranks=94884rank=65000 of ranks=94884rank=65100 of ranks=94884rank=65200 of ranks=94884rank=65300 of ranks=94884rank=65400 of ranks=94884rank=65500 of ranks=94884rank=65600 of ranks=94884rank=65700 of ranks=94884rank=65800 of ranks=94884rank=65900 of ranks=94884rank=66000 of ranks=94884rank=66100 of ranks=94884rank=66200 of ranks=94884rank=66300 of ranks=94884rank=66400 of ranks=94884rank=66500 of ranks=94884rank=66600 of ranks=94884rank=66700 of ranks=94884rank=66800 of ranks=94884rank=66900 of ranks=94884rank=67000 of ranks=94884rank=67100 of ranks=94884rank=67200 of ranks=94884rank=67300 of ranks=94884rank=67400 of ranks=94884rank=67500 of ranks=94884rank=67600 of ranks=94884rank=67700 of ranks=94884rank=67800 of ranks=94884rank=67900 of ranks=94884rank=68000 of ranks=94884rank=68100 of ranks=94884rank=68200 of ranks=94884rank=68300 of ranks=94884rank=68400 of ranks=94884rank=68500 of ranks=94884rank=68600 of ranks=94884rank=68700 of ranks=94884rank=68800 of ranks=94884rank=68900 of ranks=94884rank=69000 of ranks=94884rank=69100 of ranks=94884rank=69200 of ranks=94884rank=69300 of ranks=94884rank=69400 of ranks=94884rank=69500 of ranks=94884rank=69600 of ranks=94884rank=69700 of ranks=94884rank=69800 of ranks=94884rank=69900 of ranks=94884rank=70000 of ranks=94884rank=70100 of ranks=94884rank=70200 of ranks=94884rank=70300 of ranks=94884rank=70400 of ranks=94884rank=70500 of ranks=94884rank=70600 of ranks=94884rank=70700 of ranks=94884rank=70800 of ranks=94884rank=70900 of ranks=94884rank=71000 of ranks=94884rank=71100 of ranks=94884rank=71200 of ranks=94884rank=71300 of ranks=94884rank=71400 of ranks=94884rank=71500 of ranks=94884rank=71600 of ranks=94884rank=71700 of ranks=94884rank=71800 of ranks=94884rank=71900 of ranks=94884rank=72000 of ranks=94884rank=72100 of ranks=94884rank=72200 of ranks=94884rank=72300 of ranks=94884rank=72400 of ranks=94884rank=72500 of ranks=94884rank=72600 of ranks=94884rank=72700 of ranks=94884rank=72800 of ranks=94884rank=72900 of ranks=94884rank=73000 of ranks=94884rank=73100 of ranks=94884rank=73200 of ranks=94884rank=73300 of ranks=94884rank=73400 of ranks=94884rank=73500 of ranks=94884rank=73600 of ranks=94884rank=73700 of ranks=94884rank=73800 of ranks=94884rank=73900 of ranks=94884rank=74000 of ranks=94884rank=74100 of ranks=94884rank=74200 of ranks=94884rank=74300 of ranks=94884rank=74400 of ranks=94884rank=74500 of ranks=94884rank=74600 of ranks=94884rank=74700 of ranks=94884rank=74800 of ranks=94884rank=74900 of ranks=94884rank=75000 of ranks=94884rank=75100 of ranks=94884rank=75200 of ranks=94884rank=75300 of ranks=94884rank=75400 of ranks=94884rank=75500 of ranks=94884rank=75600 of ranks=94884rank=75700 of ranks=94884rank=75800 of ranks=94884rank=75900 of ranks=94884rank=76000 of ranks=94884rank=76100 of ranks=94884rank=76200 of ranks=94884rank=76300 of ranks=94884rank=76400 of ranks=94884rank=76500 of ranks=94884rank=76600 of ranks=94884rank=76700 of ranks=94884rank=76800 of ranks=94884rank=76900 of ranks=94884rank=77000 of ranks=94884rank=77100 of ranks=94884rank=77200 of ranks=94884rank=77300 of ranks=94884rank=77400 of ranks=94884rank=77500 of ranks=94884rank=77600 of ranks=94884rank=77700 of ranks=94884rank=77800 of ranks=94884rank=77900 of ranks=94884rank=78000 of ranks=94884rank=78100 of ranks=94884rank=78200 of ranks=94884rank=78300 of ranks=94884rank=78400 of ranks=94884rank=78500 of ranks=94884rank=78600 of ranks=94884rank=78700 of ranks=94884rank=78800 of ranks=94884rank=78900 of ranks=94884rank=79000 of ranks=94884rank=79100 of ranks=94884rank=79200 of ranks=94884rank=79300 of ranks=94884rank=79400 of ranks=94884rank=79500 of ranks=94884rank=79600 of ranks=94884rank=79700 of ranks=94884rank=79800 of ranks=94884rank=79900 of ranks=94884rank=80000 of ranks=94884rank=80100 of ranks=94884rank=80200 of ranks=94884rank=80300 of ranks=94884rank=80400 of ranks=94884rank=80500 of ranks=94884rank=80600 of ranks=94884rank=80700 of ranks=94884rank=80800 of ranks=94884rank=80900 of ranks=94884rank=81000 of ranks=94884rank=81100 of ranks=94884rank=81200 of ranks=94884rank=81300 of ranks=94884rank=81400 of ranks=94884rank=81500 of ranks=94884rank=81600 of ranks=94884rank=81700 of ranks=94884rank=81800 of ranks=94884rank=81900 of ranks=94884rank=82000 of ranks=94884rank=82100 of ranks=94884rank=82200 of ranks=94884rank=82300 of ranks=94884rank=82400 of ranks=94884rank=82500 of ranks=94884rank=82600 of ranks=94884rank=82700 of ranks=94884rank=82800 of ranks=94884rank=82900 of ranks=94884rank=83000 of ranks=94884rank=83100 of ranks=94884rank=83200 of ranks=94884rank=83300 of ranks=94884rank=83400 of ranks=94884rank=83500 of ranks=94884rank=83600 of ranks=94884rank=83700 of ranks=94884rank=83800 of ranks=94884rank=83900 of ranks=94884rank=84000 of ranks=94884rank=84100 of ranks=94884rank=84200 of ranks=94884rank=84300 of ranks=94884rank=84400 of ranks=94884rank=84500 of ranks=94884rank=84600 of ranks=94884rank=84700 of ranks=94884rank=84800 of ranks=94884rank=84900 of ranks=94884rank=85000 of ranks=94884rank=85100 of ranks=94884rank=85200 of ranks=94884rank=85300 of ranks=94884rank=85400 of ranks=94884rank=85500 of ranks=94884rank=85600 of ranks=94884rank=85700 of ranks=94884rank=85800 of ranks=94884rank=85900 of ranks=94884rank=86000 of ranks=94884rank=86100 of ranks=94884rank=86200 of ranks=94884rank=86300 of ranks=94884rank=86400 of ranks=94884rank=86500 of ranks=94884rank=86600 of ranks=94884rank=86700 of ranks=94884rank=86800 of ranks=94884rank=86900 of ranks=94884rank=87000 of ranks=94884rank=87100 of ranks=94884rank=87200 of ranks=94884rank=87300 of ranks=94884rank=87400 of ranks=94884rank=87500 of ranks=94884rank=87600 of ranks=94884rank=87700 of ranks=94884rank=87800 of ranks=94884rank=87900 of ranks=94884rank=88000 of ranks=94884rank=88100 of ranks=94884rank=88200 of ranks=94884rank=88300 of ranks=94884rank=88400 of ranks=94884rank=88500 of ranks=94884rank=88600 of ranks=94884rank=88700 of ranks=94884rank=88800 of ranks=94884rank=88900 of ranks=94884rank=89000 of ranks=94884rank=89100 of ranks=94884rank=89200 of ranks=94884rank=89300 of ranks=94884rank=89400 of ranks=94884rank=89500 of ranks=94884rank=89600 of ranks=94884rank=89700 of ranks=94884rank=89800 of ranks=94884rank=89900 of ranks=94884rank=90000 of ranks=94884rank=90100 of ranks=94884rank=90200 of ranks=94884rank=90300 of ranks=94884rank=90400 of ranks=94884rank=90500 of ranks=94884rank=90600 of ranks=94884rank=90700 of ranks=94884rank=90800 of ranks=94884rank=90900 of ranks=94884rank=91000 of ranks=94884rank=91100 of ranks=94884rank=91200 of ranks=94884rank=91300 of ranks=94884rank=91400 of ranks=94884rank=91500 of ranks=94884rank=91600 of ranks=94884rank=91700 of ranks=94884rank=91800 of ranks=94884rank=91900 of ranks=94884rank=92000 of ranks=94884rank=92100 of ranks=94884rank=92200 of ranks=94884rank=92300 of ranks=94884rank=92400 of ranks=94884rank=92500 of ranks=94884rank=92600 of ranks=94884rank=92700 of ranks=94884rank=92800 of ranks=94884rank=92900 of ranks=94884rank=93000 of ranks=94884rank=93100 of ranks=94884rank=93200 of ranks=94884rank=93300 of ranks=94884rank=93400 of ranks=94884rank=93500 of ranks=94884rank=93600 of ranks=94884rank=93700 of ranks=94884rank=93800 of ranks=94884rank=93900 of ranks=94884rank=94000 of ranks=94884rank=94100 of ranks=94884rank=94200 of ranks=94884rank=94300 of ranks=94884rank=94400 of ranks=94884rank=94500 of ranks=94884rank=94600 of ranks=94884rank=94700 of ranks=94884rank=94800 of ranks=94884

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              97.4289    490   1143      8    498           77.1510
   1 car                    98.7573  50039  27032    277  50316           82.9971
   2 truck                  98.4376   1813   3318     12   1825           74.7393
   3 bus                    96.4527    361   2119      5    366           69.5734
   4 pedestrian             96.8310   4171   4398     88   4259           75.6561

for conf_thresh=0.25, precision=0.91, recall=0.97, F1 score=0.93
for conf_thresh=0.25, TP=55266, FP=5758, FN=1998, average IoU=82.05%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=97.58%
Total detection time: 110 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
New best mAP, saving weights!
Saving weights to /workspace/.cache/splits/combined_best.weights
6685: loss=2.065, avg loss=2.487, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.9 seconds, 427840 images, time remaining=93.3 minutes
6686: loss=2.875, avg loss=2.526, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.9 seconds, 427904 images, time remaining=93.2 minutes
6687: loss=2.547, avg loss=2.528, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.8 seconds, 427968 images, time remaining=93.2 minutes
6688: loss=2.173, avg loss=2.493, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.9 seconds, 428032 images, time remaining=93.1 minutes
6689: loss=1.785, avg loss=2.422, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 428096 images, time remaining=93 minutes
6690: loss=2.720, avg loss=2.452, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.8 seconds, 428160 images, time remaining=92.9 minutes
Resizing, random_coef=1.40, batch=4, 1088x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6691: loss=2.715, avg loss=2.478, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.4 seconds, 428224 images, time remaining=92.9 minutes
6692: loss=1.750, avg loss=2.405, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=4.3 seconds, 428288 images, time remaining=92.8 minutes
6693: loss=2.040, avg loss=2.369, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.4 seconds, 428352 images, time remaining=92.7 minutes
6694: loss=2.182, avg loss=2.350, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.3 seconds, 428416 images, time remaining=92.6 minutes
6695: loss=2.422, avg loss=2.357, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.3 seconds, 428480 images, time remaining=92.6 minutes
6696: loss=2.879, avg loss=2.409, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.3 seconds, 428544 images, time remaining=92.5 minutes
6697: loss=2.516, avg loss=2.420, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=4.2 seconds, 428608 images, time remaining=92.4 minutes
6698: loss=2.482, avg loss=2.426, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=3.9 seconds, train=4.3 seconds, 428672 images, time remaining=92.4 minutes
6699: loss=2.222, avg loss=2.406, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.2 seconds, 428736 images, time remaining=92.3 minutes
6700: loss=2.470, avg loss=2.412, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.3 seconds, 428800 images, time remaining=92.2 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6701: loss=2.442, avg loss=2.415, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.0 seconds, 428864 images, time remaining=92.2 minutes
6702: loss=2.134, avg loss=2.387, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 428928 images, time remaining=92.1 minutes
6703: loss=1.982, avg loss=2.347, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 428992 images, time remaining=92 minutes
6704: loss=2.273, avg loss=2.339, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=3.9 seconds, 429056 images, time remaining=91.9 minutes
6705: loss=2.046, avg loss=2.310, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 429120 images, time remaining=91.9 minutes
6706: loss=2.465, avg loss=2.325, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=3.9 seconds, 429184 images, time remaining=91.8 minutes
6707: loss=1.684, avg loss=2.261, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.0 seconds, 429248 images, time remaining=91.7 minutes
6708: loss=2.244, avg loss=2.260, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=4.0 seconds, 429312 images, time remaining=91.7 minutes
6709: loss=2.158, avg loss=2.249, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=4.0 seconds, 429376 images, time remaining=91.6 minutes
6710: loss=1.881, avg loss=2.213, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.0 seconds, 429440 images, time remaining=91.5 minutes
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6711: loss=2.977, avg loss=2.289, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=6.0 seconds, 429504 images, time remaining=91.5 minutes
6712: loss=2.582, avg loss=2.318, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.0 seconds, train=5.8 seconds, 429568 images, time remaining=91.4 minutes
6713: loss=2.896, avg loss=2.376, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=5.9 seconds, 429632 images, time remaining=91.3 minutes
6714: loss=2.728, avg loss=2.411, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=6.1 seconds, 429696 images, time remaining=91.3 minutes
6715: loss=2.520, avg loss=2.422, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=5.9 seconds, 429760 images, time remaining=91.2 minutes
6716: loss=2.437, avg loss=2.424, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.9 seconds, 429824 images, time remaining=91.1 minutes
6717: loss=2.803, avg loss=2.462, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=6.0 seconds, 429888 images, time remaining=91.1 minutes
6718: loss=3.342, avg loss=2.550, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.0 seconds, train=5.8 seconds, 429952 images, time remaining=91 minutes
6719: loss=3.054, avg loss=2.600, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=5.8 seconds, 430016 images, time remaining=90.9 minutes
6720: loss=2.749, avg loss=2.615, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.0 seconds, train=5.9 seconds, 430080 images, time remaining=90.9 minutes
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6721: loss=1.865, avg loss=2.540, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=3.9 seconds, 430144 images, time remaining=90.8 minutes
6722: loss=2.335, avg loss=2.519, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 430208 images, time remaining=90.7 minutes
6723: loss=3.068, avg loss=2.574, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.0 seconds, 430272 images, time remaining=90.7 minutes
6724: loss=1.937, avg loss=2.511, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=4.0 seconds, 430336 images, time remaining=90.6 minutes
6725: loss=2.121, avg loss=2.472, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.0 seconds, 430400 images, time remaining=90.5 minutes
6726: loss=1.887, avg loss=2.413, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=3.9 seconds, 430464 images, time remaining=90.4 minutes
6727: loss=1.674, avg loss=2.339, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 430528 images, time remaining=90.4 minutes
6728: loss=2.662, avg loss=2.372, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=4.0 seconds, 430592 images, time remaining=90.3 minutes
6729: loss=2.104, avg loss=2.345, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 430656 images, time remaining=90.2 minutes
6730: loss=2.237, avg loss=2.334, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=3.9 seconds, 430720 images, time remaining=90.2 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
6731: loss=2.483, avg loss=2.349, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.8 seconds, 430784 images, time remaining=90.1 minutes
6732: loss=2.104, avg loss=2.324, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=2.8 seconds, 430848 images, time remaining=90 minutes
6733: loss=2.578, avg loss=2.350, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 430912 images, time remaining=89.9 minutes
6734: loss=2.058, avg loss=2.321, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.9 seconds, 430976 images, time remaining=89.9 minutes
6735: loss=1.833, avg loss=2.272, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 431040 images, time remaining=89.8 minutes
6736: loss=2.226, avg loss=2.267, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 431104 images, time remaining=89.7 minutes
6737: loss=2.567, avg loss=2.297, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.9 seconds, 431168 images, time remaining=89.6 minutes
6738: loss=1.853, avg loss=2.253, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=2.8 seconds, 431232 images, time remaining=89.6 minutes
6739: loss=2.199, avg loss=2.247, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.9 seconds, 431296 images, time remaining=89.5 minutes
6740: loss=1.750, avg loss=2.198, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 431360 images, time remaining=89.4 minutes
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b825e00000
6741: loss=1.732, avg loss=2.151, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.2 seconds, 431424 images, time remaining=89.3 minutes
6742: loss=2.815, avg loss=2.217, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.4 seconds, 431488 images, time remaining=89.3 minutes
6743: loss=2.032, avg loss=2.199, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 431552 images, time remaining=89.2 minutes
6744: loss=2.522, avg loss=2.231, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 431616 images, time remaining=89.1 minutes
6745: loss=1.902, avg loss=2.198, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=2.2 seconds, 431680 images, time remaining=89 minutes
6746: loss=1.954, avg loss=2.174, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.1 seconds, train=2.3 seconds, 431744 images, time remaining=89 minutes
6747: loss=2.011, avg loss=2.158, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 431808 images, time remaining=88.9 minutes
6748: loss=2.427, avg loss=2.185, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=2.3 seconds, 431872 images, time remaining=88.8 minutes
6749: loss=2.532, avg loss=2.219, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.3 seconds, 431936 images, time remaining=88.7 minutes
6750: loss=2.557, avg loss=2.253, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 432000 images, time remaining=88.6 minutes
Resizing, random_coef=1.40, batch=4, 1024x768
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6751: loss=1.864, avg loss=2.214, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=3.9 seconds, 432064 images, time remaining=88.6 minutes
6752: loss=2.626, avg loss=2.255, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 432128 images, time remaining=88.5 minutes
6753: loss=2.363, avg loss=2.266, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 432192 images, time remaining=88.4 minutes
6754: loss=2.423, avg loss=2.282, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=3.9 seconds, 432256 images, time remaining=88.4 minutes
6755: loss=1.897, avg loss=2.243, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=3.8 seconds, 432320 images, time remaining=88.3 minutes
6756: loss=2.726, avg loss=2.292, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=3.9 seconds, 432384 images, time remaining=88.2 minutes
6757: loss=2.502, avg loss=2.313, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=3.9 seconds, 432448 images, time remaining=88.2 minutes
6758: loss=2.659, avg loss=2.347, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=3.9 seconds, 432512 images, time remaining=88.1 minutes
6759: loss=2.110, avg loss=2.324, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 432576 images, time remaining=88 minutes
6760: loss=2.590, avg loss=2.350, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.8 seconds, 432640 images, time remaining=87.9 minutes
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6761: loss=2.630, avg loss=2.378, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=5.5 seconds, 432704 images, time remaining=87.9 minutes
6762: loss=3.549, avg loss=2.495, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=5.4 seconds, 432768 images, time remaining=87.8 minutes
6763: loss=2.827, avg loss=2.528, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=5.5 seconds, 432832 images, time remaining=87.8 minutes
6764: loss=3.502, avg loss=2.626, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=5.6 seconds, 432896 images, time remaining=87.7 minutes
6765: loss=3.137, avg loss=2.677, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.5 seconds, 432960 images, time remaining=87.6 minutes
6766: loss=2.522, avg loss=2.661, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.5 seconds, 433024 images, time remaining=87.5 minutes
6767: loss=2.986, avg loss=2.694, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.4 seconds, 433088 images, time remaining=87.5 minutes
6768: loss=2.791, avg loss=2.704, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=5.5 seconds, 433152 images, time remaining=87.4 minutes
6769: loss=3.046, avg loss=2.738, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=5.6 seconds, 433216 images, time remaining=87.3 minutes
6770: loss=2.728, avg loss=2.737, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.5 seconds, 433280 images, time remaining=87.3 minutes
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6771: loss=2.729, avg loss=2.736, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.7 seconds, 433344 images, time remaining=87.2 minutes
6772: loss=2.343, avg loss=2.697, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=4.7 seconds, 433408 images, time remaining=87.2 minutes
6773: loss=2.754, avg loss=2.703, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=4.8 seconds, 433472 images, time remaining=87.1 minutes
6774: loss=1.998, avg loss=2.632, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=4.6 seconds, 433536 images, time remaining=87 minutes
6775: loss=2.692, avg loss=2.638, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.6 seconds, 433600 images, time remaining=86.9 minutes
6776: loss=2.009, avg loss=2.575, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=4.6 seconds, 433664 images, time remaining=86.9 minutes
6777: loss=2.729, avg loss=2.591, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 433728 images, time remaining=86.8 minutes
6778: loss=2.588, avg loss=2.590, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.7 seconds, 433792 images, time remaining=86.7 minutes
6779: loss=2.866, avg loss=2.618, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.7 seconds, 433856 images, time remaining=86.7 minutes
6780: loss=3.145, avg loss=2.671, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=4.6 seconds, 433920 images, time remaining=86.6 minutes
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b75c200000
6781: loss=2.186, avg loss=2.622, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.2 seconds, 433984 images, time remaining=86.5 minutes
6782: loss=1.865, avg loss=2.546, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=2.3 seconds, 434048 images, time remaining=86.4 minutes
6783: loss=2.582, avg loss=2.550, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=2.1 seconds, 434112 images, time remaining=86.3 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6784: loss=2.431, avg loss=2.538, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.3 seconds, train=2.2 seconds, 434176 images, time remaining=86.3 minutes
6785: loss=2.542, avg loss=2.539, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 434240 images, time remaining=86.2 minutes
6786: loss=2.968, avg loss=2.582, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.1 seconds, train=2.2 seconds, 434304 images, time remaining=86.1 minutes
6787: loss=2.296, avg loss=2.553, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.3 seconds, 434368 images, time remaining=86 minutes
6788: loss=2.273, avg loss=2.525, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.2 seconds, 434432 images, time remaining=86 minutes
6789: loss=1.885, avg loss=2.461, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.2 seconds, 434496 images, time remaining=85.9 minutes
6790: loss=2.277, avg loss=2.443, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=2.3 seconds, 434560 images, time remaining=85.8 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
6791: loss=2.538, avg loss=2.452, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 434624 images, time remaining=85.8 minutes
6792: loss=2.684, avg loss=2.475, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=2.8 seconds, 434688 images, time remaining=85.7 minutes
6793: loss=2.309, avg loss=2.459, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=2.8 seconds, 434752 images, time remaining=85.6 minutes
6794: loss=1.923, avg loss=2.405, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=2.7 seconds, 434816 images, time remaining=85.5 minutes
6795: loss=2.417, avg loss=2.406, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.9 seconds, 434880 images, time remaining=85.4 minutes
6796: loss=1.596, avg loss=2.325, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 434944 images, time remaining=85.4 minutes
6797: loss=2.853, avg loss=2.378, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.9 seconds, 435008 images, time remaining=85.3 minutes
6798: loss=2.352, avg loss=2.375, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 435072 images, time remaining=85.2 minutes
6799: loss=1.654, avg loss=2.303, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=2.7 seconds, 435136 images, time remaining=85.1 minutes
6800: loss=2.456, avg loss=2.319, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=2.7 seconds, 435200 images, time remaining=85.1 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6801: loss=2.885, avg loss=2.375, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=4.7 seconds, 435264 images, time remaining=85 minutes
6802: loss=1.942, avg loss=2.332, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=4.9 seconds, 435328 images, time remaining=84.9 minutes
6803: loss=1.993, avg loss=2.298, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.8 seconds, 435392 images, time remaining=84.9 minutes
6804: loss=2.611, avg loss=2.329, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=5.0 seconds, 435456 images, time remaining=84.8 minutes
6805: loss=2.382, avg loss=2.335, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.9 seconds, 435520 images, time remaining=84.8 minutes
6806: loss=2.503, avg loss=2.351, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.0 seconds, train=4.8 seconds, 435584 images, time remaining=84.7 minutes
6807: loss=1.975, avg loss=2.314, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 435648 images, time remaining=84.6 minutes
6808: loss=2.035, avg loss=2.286, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=4.8 seconds, 435712 images, time remaining=84.5 minutes
6809: loss=1.843, avg loss=2.242, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=4.8 seconds, 435776 images, time remaining=84.5 minutes
6810: loss=2.105, avg loss=2.228, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.9 seconds, 435840 images, time remaining=84.4 minutes
Resizing, random_coef=1.40, batch=4, 992x768
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6811: loss=2.222, avg loss=2.227, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.8 seconds, 435904 images, time remaining=84.3 minutes
6812: loss=2.026, avg loss=2.207, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=3.8 seconds, 435968 images, time remaining=84.2 minutes
6813: loss=1.713, avg loss=2.158, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=3.9 seconds, 436032 images, time remaining=84.2 minutes
6814: loss=2.001, avg loss=2.142, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=3.8 seconds, 436096 images, time remaining=84.1 minutes
6815: loss=2.182, avg loss=2.146, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.8 seconds, 436160 images, time remaining=84 minutes
6816: loss=2.373, avg loss=2.169, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.8 seconds, 436224 images, time remaining=84 minutes
6817: loss=1.904, avg loss=2.142, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 436288 images, time remaining=83.9 minutes
6818: loss=2.051, avg loss=2.133, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=3.8 seconds, 436352 images, time remaining=83.8 minutes
6819: loss=1.996, avg loss=2.119, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=3.6 seconds, train=3.8 seconds, 436416 images, time remaining=83.8 minutes
6820: loss=1.785, avg loss=2.086, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=3.6 seconds, 436480 images, time remaining=83.7 minutes
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b664600000
6821: loss=2.472, avg loss=2.125, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.4 seconds, 436544 images, time remaining=83.6 minutes
6822: loss=2.350, avg loss=2.147, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=2.3 seconds, 436608 images, time remaining=83.5 minutes
6823: loss=2.145, avg loss=2.147, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=2.5 seconds, 436672 images, time remaining=83.5 minutes
6824: loss=2.357, avg loss=2.168, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=2.2 seconds, 436736 images, time remaining=83.4 minutes
6825: loss=2.153, avg loss=2.166, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.4 seconds, 436800 images, time remaining=83.3 minutes
6826: loss=2.311, avg loss=2.181, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=2.3 seconds, 436864 images, time remaining=83.2 minutes
6827: loss=3.199, avg loss=2.283, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.4 seconds, 436928 images, time remaining=83.1 minutes
6828: loss=2.071, avg loss=2.261, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.3 seconds, 436992 images, time remaining=83.1 minutes
6829: loss=2.158, avg loss=2.251, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.3 seconds, 437056 images, time remaining=83 minutes
6830: loss=2.115, avg loss=2.237, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=2.3 seconds, 437120 images, time remaining=82.9 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b736a00000
6831: loss=2.039, avg loss=2.218, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.8 seconds, 437184 images, time remaining=82.8 minutes
6832: loss=2.134, avg loss=2.209, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.9 seconds, 437248 images, time remaining=82.8 minutes
6833: loss=2.229, avg loss=2.211, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 437312 images, time remaining=82.7 minutes
6834: loss=2.325, avg loss=2.223, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 437376 images, time remaining=82.6 minutes
6835: loss=2.440, avg loss=2.244, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 437440 images, time remaining=82.6 minutes
6836: loss=2.254, avg loss=2.245, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.9 seconds, 437504 images, time remaining=82.5 minutes
6837: loss=2.396, avg loss=2.260, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=2.8 seconds, 437568 images, time remaining=82.4 minutes
6838: loss=2.165, avg loss=2.251, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.9 seconds, 437632 images, time remaining=82.3 minutes
6839: loss=2.090, avg loss=2.235, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 437696 images, time remaining=82.2 minutes
6840: loss=2.523, avg loss=2.264, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.8 seconds, 437760 images, time remaining=82.2 minutes
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6841: loss=3.669, avg loss=2.404, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=6.1 seconds, 437824 images, time remaining=82.1 minutes
6842: loss=2.576, avg loss=2.421, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.8 seconds, train=6.1 seconds, 437888 images, time remaining=82.1 minutes
6843: loss=3.111, avg loss=2.490, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.0 seconds, train=6.0 seconds, 437952 images, time remaining=82 minutes
6844: loss=3.041, avg loss=2.545, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=6.1 seconds, 438016 images, time remaining=81.9 minutes
6845: loss=2.577, avg loss=2.549, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=6.1 seconds, 438080 images, time remaining=81.9 minutes
6846: loss=2.600, avg loss=2.554, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=6.0 seconds, 438144 images, time remaining=81.8 minutes
6847: loss=3.014, avg loss=2.600, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=6.1 seconds, 438208 images, time remaining=81.7 minutes
6848: loss=3.238, avg loss=2.664, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=6.2 seconds, 438272 images, time remaining=81.7 minutes
6849: loss=3.040, avg loss=2.701, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=6.1 seconds, 438336 images, time remaining=81.6 minutes
6850: loss=2.884, avg loss=2.720, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=6.1 seconds, 438400 images, time remaining=81.5 minutes
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6851: loss=2.593, avg loss=2.707, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 438464 images, time remaining=81.5 minutes
6852: loss=2.713, avg loss=2.707, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 438528 images, time remaining=81.4 minutes
6853: loss=2.546, avg loss=2.691, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 438592 images, time remaining=81.3 minutes
6854: loss=2.218, avg loss=2.644, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.7 seconds, 438656 images, time remaining=81.3 minutes
6855: loss=2.503, avg loss=2.630, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=4.8 seconds, 438720 images, time remaining=81.2 minutes
6856: loss=2.616, avg loss=2.629, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 438784 images, time remaining=81.1 minutes
6857: loss=2.948, avg loss=2.661, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.8 seconds, 438848 images, time remaining=81.1 minutes
6858: loss=2.236, avg loss=2.618, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.7 seconds, 438912 images, time remaining=81 minutes
6859: loss=2.511, avg loss=2.607, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=4.7 seconds, 438976 images, time remaining=80.9 minutes
6860: loss=2.296, avg loss=2.576, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=3.2 seconds, train=4.7 seconds, 439040 images, time remaining=80.8 minutes
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6861: loss=2.507, avg loss=2.569, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.9 seconds, 439104 images, time remaining=80.8 minutes
6862: loss=2.329, avg loss=2.545, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=5.8 seconds, 439168 images, time remaining=80.7 minutes
6863: loss=2.577, avg loss=2.549, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.8 seconds, 439232 images, time remaining=80.7 minutes
6864: loss=3.082, avg loss=2.602, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=5.8 seconds, 439296 images, time remaining=80.6 minutes
6865: loss=2.223, avg loss=2.564, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.6 seconds, 439360 images, time remaining=80.5 minutes
6866: loss=2.695, avg loss=2.577, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.7 seconds, 439424 images, time remaining=80.5 minutes
6867: loss=2.528, avg loss=2.572, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.8 seconds, 439488 images, time remaining=80.4 minutes
6868: loss=2.882, avg loss=2.603, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=5.8 seconds, 439552 images, time remaining=80.3 minutes
6869: loss=3.003, avg loss=2.643, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.7 seconds, 439616 images, time remaining=80.3 minutes
6870: loss=3.172, avg loss=2.696, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.6 seconds, 439680 images, time remaining=80.2 minutes
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b8a4000000
6871: loss=1.897, avg loss=2.616, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.3 seconds, 439744 images, time remaining=80.1 minutes
6872: loss=2.297, avg loss=2.584, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.5 seconds, 439808 images, time remaining=80 minutes
6873: loss=2.378, avg loss=2.564, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.3 seconds, 439872 images, time remaining=80 minutes
6874: loss=2.404, avg loss=2.548, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.4 seconds, 439936 images, time remaining=79.9 minutes
6875: loss=2.396, avg loss=2.532, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.4 seconds, 440000 images, time remaining=79.8 minutes
6876: loss=2.010, avg loss=2.480, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.5 seconds, 440064 images, time remaining=79.7 minutes
6877: loss=2.443, avg loss=2.476, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.3 seconds, 440128 images, time remaining=79.7 minutes
6878: loss=1.837, avg loss=2.413, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.4 seconds, 440192 images, time remaining=79.6 minutes
6879: loss=2.163, avg loss=2.388, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.3 seconds, 440256 images, time remaining=79.5 minutes
6880: loss=1.928, avg loss=2.342, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.3 seconds, 440320 images, time remaining=79.4 minutes
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6881: loss=2.264, avg loss=2.334, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 440384 images, time remaining=79.4 minutes
6882: loss=2.233, avg loss=2.324, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=4.8 seconds, 440448 images, time remaining=79.3 minutes
6883: loss=2.029, avg loss=2.294, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 440512 images, time remaining=79.2 minutes
6884: loss=3.306, avg loss=2.395, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 440576 images, time remaining=79.2 minutes
6885: loss=3.079, avg loss=2.464, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=4.8 seconds, 440640 images, time remaining=79.1 minutes
6886: loss=2.828, avg loss=2.500, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=4.8 seconds, 440704 images, time remaining=79 minutes
6887: loss=2.539, avg loss=2.504, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=4.9 seconds, 440768 images, time remaining=79 minutes
6888: loss=2.930, avg loss=2.547, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.7 seconds, 440832 images, time remaining=78.9 minutes
6889: loss=2.479, avg loss=2.540, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.7 seconds, 440896 images, time remaining=78.8 minutes
6890: loss=2.067, avg loss=2.493, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 440960 images, time remaining=78.7 minutes
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b6c1200000
6891: loss=2.319, avg loss=2.475, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.3 seconds, 441024 images, time remaining=78.7 minutes
6892: loss=2.211, avg loss=2.449, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.3 seconds, 441088 images, time remaining=78.6 minutes
6893: loss=2.176, avg loss=2.421, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.2 seconds, 441152 images, time remaining=78.5 minutes
6894: loss=1.935, avg loss=2.373, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.3 seconds, 441216 images, time remaining=78.4 minutes
6895: loss=1.831, avg loss=2.319, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.2 seconds, 441280 images, time remaining=78.4 minutes
6896: loss=2.388, avg loss=2.326, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.3 seconds, 441344 images, time remaining=78.3 minutes
6897: loss=1.972, avg loss=2.290, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 441408 images, time remaining=78.2 minutes
6898: loss=2.074, avg loss=2.269, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.2 seconds, 441472 images, time remaining=78.2 minutes
6899: loss=2.352, avg loss=2.277, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.3 seconds, 441536 images, time remaining=78.1 minutes
6900: loss=2.311, avg loss=2.280, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 441600 images, time remaining=78 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 832x672
GPU #0: allocating workspace: 418.6 MiB begins at 0x14be64a00000
6901: loss=2.417, avg loss=2.294, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.4 seconds, 441664 images, time remaining=77.9 minutes
6902: loss=2.079, avg loss=2.273, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 441728 images, time remaining=77.8 minutes
6903: loss=2.029, avg loss=2.248, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 441792 images, time remaining=77.8 minutes
6904: loss=1.889, avg loss=2.212, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.3 seconds, 441856 images, time remaining=77.7 minutes
6905: loss=2.154, avg loss=2.207, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.4 seconds, 441920 images, time remaining=77.6 minutes
6906: loss=2.738, avg loss=2.260, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=2.3 seconds, 441984 images, time remaining=77.5 minutes
6907: loss=2.449, avg loss=2.279, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.3 seconds, 442048 images, time remaining=77.5 minutes
6908: loss=1.678, avg loss=2.219, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.3 seconds, 442112 images, time remaining=77.4 minutes
6909: loss=1.648, avg loss=2.161, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=2.4 seconds, 442176 images, time remaining=77.3 minutes
6910: loss=2.041, avg loss=2.149, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.4 seconds, 442240 images, time remaining=77.2 minutes
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6911: loss=2.377, avg loss=2.172, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.4 seconds, 442304 images, time remaining=77.2 minutes
6912: loss=2.912, avg loss=2.246, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.3 seconds, 442368 images, time remaining=77.1 minutes
6913: loss=2.855, avg loss=2.307, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.4 seconds, 442432 images, time remaining=77 minutes
6914: loss=2.921, avg loss=2.368, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.4 seconds, 442496 images, time remaining=77 minutes
6915: loss=2.407, avg loss=2.372, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.4 seconds, 442560 images, time remaining=76.9 minutes
6916: loss=2.898, avg loss=2.425, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.4 seconds, 442624 images, time remaining=76.8 minutes
6917: loss=2.349, avg loss=2.417, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=4.4 seconds, 442688 images, time remaining=76.7 minutes
6918: loss=2.070, avg loss=2.383, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.4 seconds, 442752 images, time remaining=76.7 minutes
6919: loss=2.297, avg loss=2.374, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.4 seconds, 442816 images, time remaining=76.6 minutes
6920: loss=2.943, avg loss=2.431, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.4 seconds, 442880 images, time remaining=76.5 minutes
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6921: loss=2.364, avg loss=2.424, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=3.9 seconds, 442944 images, time remaining=76.5 minutes
6922: loss=2.441, avg loss=2.426, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 443008 images, time remaining=76.4 minutes
6923: loss=2.048, avg loss=2.388, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=3.9 seconds, 443072 images, time remaining=76.3 minutes
6924: loss=2.152, avg loss=2.365, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=4.0 seconds, 443136 images, time remaining=76.3 minutes
6925: loss=2.096, avg loss=2.338, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.1 seconds, 443200 images, time remaining=76.2 minutes
6926: loss=1.793, avg loss=2.283, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.0 seconds, 443264 images, time remaining=76.1 minutes
6927: loss=1.919, avg loss=2.247, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 443328 images, time remaining=76.1 minutes
6928: loss=2.436, avg loss=2.266, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=3.9 seconds, 443392 images, time remaining=76 minutes
6929: loss=2.050, avg loss=2.244, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 443456 images, time remaining=75.9 minutes
6930: loss=2.275, avg loss=2.247, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 443520 images, time remaining=75.8 minutes
Resizing, random_coef=1.40, batch=4, 1344x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6931: loss=2.845, avg loss=2.307, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.9 seconds, 443584 images, time remaining=75.8 minutes
6932: loss=4.069, avg loss=2.483, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=5.8 seconds, 443648 images, time remaining=75.7 minutes
6933: loss=2.667, avg loss=2.501, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.8 seconds, 443712 images, time remaining=75.6 minutes
6934: loss=3.323, avg loss=2.584, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=5.9 seconds, 443776 images, time remaining=75.6 minutes
6935: loss=2.699, avg loss=2.595, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=5.9 seconds, 443840 images, time remaining=75.5 minutes
6936: loss=3.252, avg loss=2.661, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=6.0 seconds, 443904 images, time remaining=75.4 minutes
6937: loss=3.530, avg loss=2.748, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=6.1 seconds, 443968 images, time remaining=75.4 minutes
6938: loss=2.964, avg loss=2.769, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=5.9 seconds, 444032 images, time remaining=75.3 minutes
6939: loss=3.196, avg loss=2.812, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.9 seconds, 444096 images, time remaining=75.2 minutes
6940: loss=2.859, avg loss=2.817, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.1 seconds, train=5.8 seconds, 444160 images, time remaining=75.2 minutes
Resizing, random_coef=1.40, batch=4, 1312x1024
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6941: loss=2.757, avg loss=2.811, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.7 seconds, 444224 images, time remaining=75.1 minutes
6942: loss=2.620, avg loss=2.792, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=5.8 seconds, 444288 images, time remaining=75.1 minutes
6943: loss=3.233, avg loss=2.836, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=5.8 seconds, 444352 images, time remaining=75 minutes
6944: loss=2.775, avg loss=2.830, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.0 seconds, train=5.7 seconds, 444416 images, time remaining=74.9 minutes
6945: loss=2.823, avg loss=2.829, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=5.8 seconds, 444480 images, time remaining=74.8 minutes
6946: loss=3.264, avg loss=2.873, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.4 seconds, train=5.8 seconds, 444544 images, time remaining=74.8 minutes
6947: loss=2.503, avg loss=2.836, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.0 seconds, train=5.8 seconds, 444608 images, time remaining=74.7 minutes
6948: loss=2.008, avg loss=2.753, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=5.6 seconds, 444672 images, time remaining=74.7 minutes
6949: loss=2.527, avg loss=2.730, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.5 seconds, train=5.8 seconds, 444736 images, time remaining=74.6 minutes
6950: loss=2.795, avg loss=2.737, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=5.8 seconds, 444800 images, time remaining=74.5 minutes
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6951: loss=2.965, avg loss=2.759, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=5.6 seconds, 444864 images, time remaining=74.4 minutes
6952: loss=3.018, avg loss=2.785, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.6 seconds, 444928 images, time remaining=74.4 minutes
6953: loss=2.943, avg loss=2.801, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.7 seconds, 444992 images, time remaining=74.3 minutes
6954: loss=2.520, avg loss=2.773, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.6 seconds, 445056 images, time remaining=74.2 minutes
6955: loss=2.778, avg loss=2.774, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=4.3 seconds, train=5.6 seconds, 445120 images, time remaining=74.2 minutes
6956: loss=2.189, avg loss=2.715, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.1 seconds, train=5.6 seconds, 445184 images, time remaining=74.1 minutes
6957: loss=2.450, avg loss=2.689, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=5.7 seconds, 445248 images, time remaining=74 minutes
6958: loss=3.050, avg loss=2.725, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.0 seconds, train=5.6 seconds, 445312 images, time remaining=74 minutes
6959: loss=3.513, avg loss=2.804, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.7 seconds, 445376 images, time remaining=73.9 minutes
6960: loss=2.761, avg loss=2.799, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=5.5 seconds, 445440 images, time remaining=73.8 minutes
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6961: loss=2.863, avg loss=2.806, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.6 seconds, 445504 images, time remaining=73.8 minutes
6962: loss=2.469, avg loss=2.772, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.2 seconds, train=5.5 seconds, 445568 images, time remaining=73.7 minutes
6963: loss=2.827, avg loss=2.778, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.1 seconds, train=5.6 seconds, 445632 images, time remaining=73.7 minutes
6964: loss=2.782, avg loss=2.778, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.0 seconds, train=5.6 seconds, 445696 images, time remaining=73.6 minutes
6965: loss=2.412, avg loss=2.741, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=5.5 seconds, 445760 images, time remaining=73.5 minutes
6966: loss=2.869, avg loss=2.754, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=5.5 seconds, 445824 images, time remaining=73.4 minutes
6967: loss=3.234, avg loss=2.802, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.5 seconds, 445888 images, time remaining=73.4 minutes
6968: loss=2.652, avg loss=2.787, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.5 seconds, 445952 images, time remaining=73.3 minutes
6969: loss=2.648, avg loss=2.773, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.5 seconds, train=5.5 seconds, 446016 images, time remaining=73.2 minutes
6970: loss=2.859, avg loss=2.782, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=5.4 seconds, 446080 images, time remaining=73.2 minutes
Resizing, random_coef=1.40, batch=4, 1024x768
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6971: loss=2.002, avg loss=2.704, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=3.9 seconds, 446144 images, time remaining=73.1 minutes
6972: loss=2.690, avg loss=2.702, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=3.9 seconds, 446208 images, time remaining=73 minutes
6973: loss=2.579, avg loss=2.690, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 446272 images, time remaining=72.9 minutes
6974: loss=2.794, avg loss=2.700, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=3.9 seconds, 446336 images, time remaining=72.9 minutes
6975: loss=2.603, avg loss=2.691, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=3.9 seconds, 446400 images, time remaining=72.8 minutes
6976: loss=2.560, avg loss=2.678, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=3.9 seconds, 446464 images, time remaining=72.7 minutes
6977: loss=2.253, avg loss=2.635, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=3.8 seconds, 446528 images, time remaining=72.7 minutes
6978: loss=2.734, avg loss=2.645, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.2 seconds, train=3.9 seconds, 446592 images, time remaining=72.6 minutes
6979: loss=2.212, avg loss=2.602, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.0 seconds, 446656 images, time remaining=72.5 minutes
6980: loss=2.106, avg loss=2.552, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=3.9 seconds, 446720 images, time remaining=72.4 minutes
Resizing, random_coef=1.40, batch=4, 1024x768
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
6981: loss=2.162, avg loss=2.513, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=4.0 seconds, 446784 images, time remaining=72.4 minutes
6982: loss=2.491, avg loss=2.511, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 446848 images, time remaining=72.3 minutes
6983: loss=2.557, avg loss=2.516, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=3.9 seconds, 446912 images, time remaining=72.2 minutes
6984: loss=1.892, avg loss=2.453, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 446976 images, time remaining=72.2 minutes
6985: loss=2.447, avg loss=2.453, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=3.9 seconds, 447040 images, time remaining=72.1 minutes
6986: loss=2.397, avg loss=2.447, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=3.9 seconds, 447104 images, time remaining=72 minutes
6987: loss=2.326, avg loss=2.435, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=3.9 seconds, 447168 images, time remaining=71.9 minutes
6988: loss=2.150, avg loss=2.406, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 447232 images, time remaining=71.9 minutes
6989: loss=2.391, avg loss=2.405, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=3.9 seconds, 447296 images, time remaining=71.8 minutes
6990: loss=1.740, avg loss=2.338, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 447360 images, time remaining=71.7 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
6991: loss=1.706, avg loss=2.275, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 447424 images, time remaining=71.7 minutes
6992: loss=1.814, avg loss=2.229, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=2.8 seconds, 447488 images, time remaining=71.6 minutes
6993: loss=2.041, avg loss=2.210, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.9 seconds, 447552 images, time remaining=71.5 minutes
6994: loss=1.954, avg loss=2.185, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.8 seconds, 447616 images, time remaining=71.4 minutes
6995: loss=2.117, avg loss=2.178, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 447680 images, time remaining=71.4 minutes
6996: loss=2.244, avg loss=2.184, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.9 seconds, 447744 images, time remaining=71.3 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
6997: loss=2.174, avg loss=2.183, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.7 seconds, train=2.6 seconds, 447808 images, time remaining=71.2 minutes
6998: loss=2.669, avg loss=2.232, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.9 seconds, train=2.8 seconds, 447872 images, time remaining=71.2 minutes
6999: loss=2.263, avg loss=2.235, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 447936 images, time remaining=71.1 minutes
7000: loss=2.035, avg loss=2.215, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 448000 images, time remaining=71 minutes
Saving weights to /workspace/.cache/splits/combined_7000.weights
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14b842000000
7001: loss=1.692, avg loss=2.163, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.2 seconds, 448064 images, time remaining=70.9 minutes
7002: loss=2.081, avg loss=2.154, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 448128 images, time remaining=70.8 minutes
7003: loss=2.574, avg loss=2.196, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 448192 images, time remaining=70.8 minutes
7004: loss=2.058, avg loss=2.183, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.3 seconds, 448256 images, time remaining=70.7 minutes
7005: loss=2.221, avg loss=2.186, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.3 seconds, 448320 images, time remaining=70.6 minutes
7006: loss=1.815, avg loss=2.149, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 448384 images, time remaining=70.6 minutes
7007: loss=1.833, avg loss=2.118, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.1 seconds, 448448 images, time remaining=70.5 minutes
7008: loss=2.214, avg loss=2.127, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.3 seconds, 448512 images, time remaining=70.4 minutes
7009: loss=2.632, avg loss=2.178, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.2 seconds, 448576 images, time remaining=70.3 minutes
7010: loss=1.510, avg loss=2.111, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 448640 images, time remaining=70.2 minutes
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b561e00000
7011: loss=2.194, avg loss=2.119, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.2 seconds, 448704 images, time remaining=70.2 minutes
7012: loss=2.237, avg loss=2.131, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 448768 images, time remaining=70.1 minutes
7013: loss=1.841, avg loss=2.102, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.2 seconds, 448832 images, time remaining=70 minutes
7014: loss=2.321, avg loss=2.124, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.1 seconds, 448896 images, time remaining=69.9 minutes
7015: loss=2.199, avg loss=2.131, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.2 seconds, 448960 images, time remaining=69.9 minutes
7016: loss=1.852, avg loss=2.104, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 449024 images, time remaining=69.8 minutes
7017: loss=2.360, avg loss=2.129, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.1 seconds, 449088 images, time remaining=69.7 minutes
7018: loss=2.338, avg loss=2.150, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 449152 images, time remaining=69.6 minutes
7019: loss=1.606, avg loss=2.096, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.1 seconds, 449216 images, time remaining=69.6 minutes
7020: loss=2.558, avg loss=2.142, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 449280 images, time remaining=69.5 minutes
Resizing, random_coef=1.40, batch=4, 1184x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7021: loss=2.719, avg loss=2.200, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 449344 images, time remaining=69.4 minutes
7022: loss=3.490, avg loss=2.329, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.5 seconds, 449408 images, time remaining=69.4 minutes
7023: loss=2.883, avg loss=2.384, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.6 seconds, 449472 images, time remaining=69.3 minutes
7024: loss=2.510, avg loss=2.397, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.6 seconds, 449536 images, time remaining=69.2 minutes
7025: loss=2.682, avg loss=2.425, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=4.5 seconds, 449600 images, time remaining=69.2 minutes
7026: loss=2.557, avg loss=2.438, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.6 seconds, 449664 images, time remaining=69.1 minutes
7027: loss=2.663, avg loss=2.461, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.6 seconds, 449728 images, time remaining=69 minutes
7028: loss=2.657, avg loss=2.480, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.6 seconds, 449792 images, time remaining=68.9 minutes
7029: loss=2.218, avg loss=2.454, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 449856 images, time remaining=68.9 minutes
7030: loss=2.568, avg loss=2.466, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.6 seconds, 449920 images, time remaining=68.8 minutes
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7031: loss=2.243, avg loss=2.443, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 449984 images, time remaining=68.7 minutes
7032: loss=2.325, avg loss=2.432, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.1 seconds, 450048 images, time remaining=68.7 minutes
7033: loss=2.804, avg loss=2.469, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.0 seconds, 450112 images, time remaining=68.6 minutes
7034: loss=1.935, avg loss=2.415, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 450176 images, time remaining=68.5 minutes
7035: loss=2.033, avg loss=2.377, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 450240 images, time remaining=68.4 minutes
7036: loss=2.123, avg loss=2.352, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.1 seconds, 450304 images, time remaining=68.4 minutes
7037: loss=2.047, avg loss=2.321, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.1 seconds, 450368 images, time remaining=68.3 minutes
7038: loss=2.254, avg loss=2.315, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=4.1 seconds, 450432 images, time remaining=68.2 minutes
7039: loss=2.724, avg loss=2.356, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 450496 images, time remaining=68.2 minutes
7040: loss=1.464, avg loss=2.266, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=4.1 seconds, 450560 images, time remaining=68.1 minutes
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
7041: loss=2.166, avg loss=2.256, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.8 seconds, 450624 images, time remaining=68 minutes
7042: loss=1.805, avg loss=2.211, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.7 seconds, 450688 images, time remaining=67.9 minutes
7043: loss=2.647, avg loss=2.255, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 450752 images, time remaining=67.9 minutes
7044: loss=1.852, avg loss=2.214, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.7 seconds, 450816 images, time remaining=67.8 minutes
7045: loss=2.328, avg loss=2.226, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 450880 images, time remaining=67.7 minutes
7046: loss=1.812, avg loss=2.184, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.7 seconds, 450944 images, time remaining=67.6 minutes
7047: loss=2.221, avg loss=2.188, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.7 seconds, 451008 images, time remaining=67.6 minutes
7048: loss=2.251, avg loss=2.194, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.7 seconds, 451072 images, time remaining=67.5 minutes
7049: loss=2.425, avg loss=2.217, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=2.7 seconds, 451136 images, time remaining=67.4 minutes
7050: loss=2.068, avg loss=2.203, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.7 seconds, 451200 images, time remaining=67.3 minutes
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b539400000
7051: loss=2.360, avg loss=2.218, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.2 seconds, 451264 images, time remaining=67.3 minutes
7052: loss=2.143, avg loss=2.211, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.3 seconds, train=2.3 seconds, 451328 images, time remaining=67.2 minutes
7053: loss=2.260, avg loss=2.216, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=2.0 seconds, train=2.3 seconds, 451392 images, time remaining=67.1 minutes
7054: loss=2.506, avg loss=2.245, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.3 seconds, 451456 images, time remaining=67 minutes
7055: loss=2.100, avg loss=2.230, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 451520 images, time remaining=67 minutes
7056: loss=2.277, avg loss=2.235, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.4 seconds, 451584 images, time remaining=66.9 minutes
7057: loss=2.371, avg loss=2.249, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.3 seconds, 451648 images, time remaining=66.8 minutes
7058: loss=2.009, avg loss=2.225, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 451712 images, time remaining=66.8 minutes
7059: loss=2.004, avg loss=2.202, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.2 seconds, 451776 images, time remaining=66.7 minutes
7060: loss=2.085, avg loss=2.191, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.1 seconds, train=2.4 seconds, 451840 images, time remaining=66.6 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b6b3400000
7061: loss=2.326, avg loss=2.204, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.9 seconds, 451904 images, time remaining=66.5 minutes
7062: loss=2.150, avg loss=2.199, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 451968 images, time remaining=66.4 minutes
7063: loss=2.464, avg loss=2.225, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 452032 images, time remaining=66.4 minutes
7064: loss=2.035, avg loss=2.206, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=2.8 seconds, 452096 images, time remaining=66.3 minutes
7065: loss=2.136, avg loss=2.199, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 452160 images, time remaining=66.2 minutes
7066: loss=1.963, avg loss=2.176, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=2.7 seconds, 452224 images, time remaining=66.2 minutes
7067: loss=1.829, avg loss=2.141, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.7 seconds, 452288 images, time remaining=66.1 minutes
7068: loss=2.135, avg loss=2.140, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 452352 images, time remaining=66 minutes
7069: loss=2.024, avg loss=2.129, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 452416 images, time remaining=65.9 minutes
7070: loss=2.036, avg loss=2.119, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 452480 images, time remaining=65.9 minutes
Resizing, random_coef=1.40, batch=4, 1184x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7071: loss=2.506, avg loss=2.158, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=4.7 seconds, 452544 images, time remaining=65.8 minutes
7072: loss=2.744, avg loss=2.217, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 452608 images, time remaining=65.7 minutes
7073: loss=2.522, avg loss=2.247, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=4.7 seconds, 452672 images, time remaining=65.7 minutes
7074: loss=2.426, avg loss=2.265, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.6 seconds, 452736 images, time remaining=65.6 minutes
7075: loss=2.306, avg loss=2.269, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.8 seconds, train=4.7 seconds, 452800 images, time remaining=65.5 minutes
7076: loss=2.202, avg loss=2.263, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 452864 images, time remaining=65.4 minutes
7077: loss=2.217, avg loss=2.258, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.7 seconds, 452928 images, time remaining=65.4 minutes
7078: loss=2.602, avg loss=2.292, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=4.7 seconds, 452992 images, time remaining=65.3 minutes
7079: loss=2.185, avg loss=2.282, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.6 seconds, train=4.8 seconds, 453056 images, time remaining=65.2 minutes
7080: loss=2.331, avg loss=2.287, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.7 seconds, train=4.6 seconds, 453120 images, time remaining=65.2 minutes
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14b58b400000
7081: loss=2.312, avg loss=2.289, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.1 seconds, 453184 images, time remaining=65.1 minutes
7082: loss=2.073, avg loss=2.268, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.1 seconds, 453248 images, time remaining=65 minutes
7083: loss=1.945, avg loss=2.235, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.2 seconds, train=2.1 seconds, 453312 images, time remaining=64.9 minutes
7084: loss=2.193, avg loss=2.231, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.0 seconds, 453376 images, time remaining=64.9 minutes
7085: loss=2.073, avg loss=2.215, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.2 seconds, 453440 images, time remaining=64.8 minutes
7086: loss=2.275, avg loss=2.221, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.1 seconds, 453504 images, time remaining=64.7 minutes
7087: loss=2.659, avg loss=2.265, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.1 seconds, 453568 images, time remaining=64.7 minutes
7088: loss=2.254, avg loss=2.264, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.5 seconds, train=2.1 seconds, 453632 images, time remaining=64.6 minutes
7089: loss=2.174, avg loss=2.255, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.3 seconds, train=2.1 seconds, 453696 images, time remaining=64.5 minutes
7090: loss=2.892, avg loss=2.319, last=97.58%, best=97.58%, next=7090, rate=0.00013000, load 64=1.4 seconds, train=2.1 seconds, 453760 images, time remaining=64.4 minutes
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b733200000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=87621, unique_truth_count=57264
rank=0 of ranks=87621rank=100 of ranks=87621rank=200 of ranks=87621rank=300 of ranks=87621rank=400 of ranks=87621rank=500 of ranks=87621rank=600 of ranks=87621rank=700 of ranks=87621rank=800 of ranks=87621rank=900 of ranks=87621rank=1000 of ranks=87621rank=1100 of ranks=87621rank=1200 of ranks=87621rank=1300 of ranks=87621rank=1400 of ranks=87621rank=1500 of ranks=87621rank=1600 of ranks=87621rank=1700 of ranks=87621rank=1800 of ranks=87621rank=1900 of ranks=87621rank=2000 of ranks=87621rank=2100 of ranks=87621rank=2200 of ranks=87621rank=2300 of ranks=87621rank=2400 of ranks=87621rank=2500 of ranks=87621rank=2600 of ranks=87621rank=2700 of ranks=87621rank=2800 of ranks=87621rank=2900 of ranks=87621rank=3000 of ranks=87621rank=3100 of ranks=87621rank=3200 of ranks=87621rank=3300 of ranks=87621rank=3400 of ranks=87621rank=3500 of ranks=87621rank=3600 of ranks=87621rank=3700 of ranks=87621rank=3800 of ranks=87621rank=3900 of ranks=87621rank=4000 of ranks=87621rank=4100 of ranks=87621rank=4200 of ranks=87621rank=4300 of ranks=87621rank=4400 of ranks=87621rank=4500 of ranks=87621rank=4600 of ranks=87621rank=4700 of ranks=87621rank=4800 of ranks=87621rank=4900 of ranks=87621rank=5000 of ranks=87621rank=5100 of ranks=87621rank=5200 of ranks=87621rank=5300 of ranks=87621rank=5400 of ranks=87621rank=5500 of ranks=87621rank=5600 of ranks=87621rank=5700 of ranks=87621rank=5800 of ranks=87621rank=5900 of ranks=87621rank=6000 of ranks=87621rank=6100 of ranks=87621rank=6200 of ranks=87621rank=6300 of ranks=87621rank=6400 of ranks=87621rank=6500 of ranks=87621rank=6600 of ranks=87621rank=6700 of ranks=87621rank=6800 of ranks=87621rank=6900 of ranks=87621rank=7000 of ranks=87621rank=7100 of ranks=87621rank=7200 of ranks=87621rank=7300 of ranks=87621rank=7400 of ranks=87621rank=7500 of ranks=87621rank=7600 of ranks=87621rank=7700 of ranks=87621rank=7800 of ranks=87621rank=7900 of ranks=87621rank=8000 of ranks=87621rank=8100 of ranks=87621rank=8200 of ranks=87621rank=8300 of ranks=87621rank=8400 of ranks=87621rank=8500 of ranks=87621rank=8600 of ranks=87621rank=8700 of ranks=87621rank=8800 of ranks=87621rank=8900 of ranks=87621rank=9000 of ranks=87621rank=9100 of ranks=87621rank=9200 of ranks=87621rank=9300 of ranks=87621rank=9400 of ranks=87621rank=9500 of ranks=87621rank=9600 of ranks=87621rank=9700 of ranks=87621rank=9800 of ranks=87621rank=9900 of ranks=87621rank=10000 of ranks=87621rank=10100 of ranks=87621rank=10200 of ranks=87621rank=10300 of ranks=87621rank=10400 of ranks=87621rank=10500 of ranks=87621rank=10600 of ranks=87621rank=10700 of ranks=87621rank=10800 of ranks=87621rank=10900 of ranks=87621rank=11000 of ranks=87621rank=11100 of ranks=87621rank=11200 of ranks=87621rank=11300 of ranks=87621rank=11400 of ranks=87621rank=11500 of ranks=87621rank=11600 of ranks=87621rank=11700 of ranks=87621rank=11800 of ranks=87621rank=11900 of ranks=87621rank=12000 of ranks=87621rank=12100 of ranks=87621rank=12200 of ranks=87621rank=12300 of ranks=87621rank=12400 of ranks=87621rank=12500 of ranks=87621rank=12600 of ranks=87621rank=12700 of ranks=87621rank=12800 of ranks=87621rank=12900 of ranks=87621rank=13000 of ranks=87621rank=13100 of ranks=87621rank=13200 of ranks=87621rank=13300 of ranks=87621rank=13400 of ranks=87621rank=13500 of ranks=87621rank=13600 of ranks=87621rank=13700 of ranks=87621rank=13800 of ranks=87621rank=13900 of ranks=87621rank=14000 of ranks=87621rank=14100 of ranks=87621rank=14200 of ranks=87621rank=14300 of ranks=87621rank=14400 of ranks=87621rank=14500 of ranks=87621rank=14600 of ranks=87621rank=14700 of ranks=87621rank=14800 of ranks=87621rank=14900 of ranks=87621rank=15000 of ranks=87621rank=15100 of ranks=87621rank=15200 of ranks=87621rank=15300 of ranks=87621rank=15400 of ranks=87621rank=15500 of ranks=87621rank=15600 of ranks=87621rank=15700 of ranks=87621rank=15800 of ranks=87621rank=15900 of ranks=87621rank=16000 of ranks=87621rank=16100 of ranks=87621rank=16200 of ranks=87621rank=16300 of ranks=87621rank=16400 of ranks=87621rank=16500 of ranks=87621rank=16600 of ranks=87621rank=16700 of ranks=87621rank=16800 of ranks=87621rank=16900 of ranks=87621rank=17000 of ranks=87621rank=17100 of ranks=87621rank=17200 of ranks=87621rank=17300 of ranks=87621rank=17400 of ranks=87621rank=17500 of ranks=87621rank=17600 of ranks=87621rank=17700 of ranks=87621rank=17800 of ranks=87621rank=17900 of ranks=87621rank=18000 of ranks=87621rank=18100 of ranks=87621rank=18200 of ranks=87621rank=18300 of ranks=87621rank=18400 of ranks=87621rank=18500 of ranks=87621rank=18600 of ranks=87621rank=18700 of ranks=87621rank=18800 of ranks=87621rank=18900 of ranks=87621rank=19000 of ranks=87621rank=19100 of ranks=87621rank=19200 of ranks=87621rank=19300 of ranks=87621rank=19400 of ranks=87621rank=19500 of ranks=87621rank=19600 of ranks=87621rank=19700 of ranks=87621rank=19800 of ranks=87621rank=19900 of ranks=87621rank=20000 of ranks=87621rank=20100 of ranks=87621rank=20200 of ranks=87621rank=20300 of ranks=87621rank=20400 of ranks=87621rank=20500 of ranks=87621rank=20600 of ranks=87621rank=20700 of ranks=87621rank=20800 of ranks=87621rank=20900 of ranks=87621rank=21000 of ranks=87621rank=21100 of ranks=87621rank=21200 of ranks=87621rank=21300 of ranks=87621rank=21400 of ranks=87621rank=21500 of ranks=87621rank=21600 of ranks=87621rank=21700 of ranks=87621rank=21800 of ranks=87621rank=21900 of ranks=87621rank=22000 of ranks=87621rank=22100 of ranks=87621rank=22200 of ranks=87621rank=22300 of ranks=87621rank=22400 of ranks=87621rank=22500 of ranks=87621rank=22600 of ranks=87621rank=22700 of ranks=87621rank=22800 of ranks=87621rank=22900 of ranks=87621rank=23000 of ranks=87621rank=23100 of ranks=87621rank=23200 of ranks=87621rank=23300 of ranks=87621rank=23400 of ranks=87621rank=23500 of ranks=87621rank=23600 of ranks=87621rank=23700 of ranks=87621rank=23800 of ranks=87621rank=23900 of ranks=87621rank=24000 of ranks=87621rank=24100 of ranks=87621rank=24200 of ranks=87621rank=24300 of ranks=87621rank=24400 of ranks=87621rank=24500 of ranks=87621rank=24600 of ranks=87621rank=24700 of ranks=87621rank=24800 of ranks=87621rank=24900 of ranks=87621rank=25000 of ranks=87621rank=25100 of ranks=87621rank=25200 of ranks=87621rank=25300 of ranks=87621rank=25400 of ranks=87621rank=25500 of ranks=87621rank=25600 of ranks=87621rank=25700 of ranks=87621rank=25800 of ranks=87621rank=25900 of ranks=87621rank=26000 of ranks=87621rank=26100 of ranks=87621rank=26200 of ranks=87621rank=26300 of ranks=87621rank=26400 of ranks=87621rank=26500 of ranks=87621rank=26600 of ranks=87621rank=26700 of ranks=87621rank=26800 of ranks=87621rank=26900 of ranks=87621rank=27000 of ranks=87621rank=27100 of ranks=87621rank=27200 of ranks=87621rank=27300 of ranks=87621rank=27400 of ranks=87621rank=27500 of ranks=87621rank=27600 of ranks=87621rank=27700 of ranks=87621rank=27800 of ranks=87621rank=27900 of ranks=87621rank=28000 of ranks=87621rank=28100 of ranks=87621rank=28200 of ranks=87621rank=28300 of ranks=87621rank=28400 of ranks=87621rank=28500 of ranks=87621rank=28600 of ranks=87621rank=28700 of ranks=87621rank=28800 of ranks=87621rank=28900 of ranks=87621rank=29000 of ranks=87621rank=29100 of ranks=87621rank=29200 of ranks=87621rank=29300 of ranks=87621rank=29400 of ranks=87621rank=29500 of ranks=87621rank=29600 of ranks=87621rank=29700 of ranks=87621rank=29800 of ranks=87621rank=29900 of ranks=87621rank=30000 of ranks=87621rank=30100 of ranks=87621rank=30200 of ranks=87621rank=30300 of ranks=87621rank=30400 of ranks=87621rank=30500 of ranks=87621rank=30600 of ranks=87621rank=30700 of ranks=87621rank=30800 of ranks=87621rank=30900 of ranks=87621rank=31000 of ranks=87621rank=31100 of ranks=87621rank=31200 of ranks=87621rank=31300 of ranks=87621rank=31400 of ranks=87621rank=31500 of ranks=87621rank=31600 of ranks=87621rank=31700 of ranks=87621rank=31800 of ranks=87621rank=31900 of ranks=87621rank=32000 of ranks=87621rank=32100 of ranks=87621rank=32200 of ranks=87621rank=32300 of ranks=87621rank=32400 of ranks=87621rank=32500 of ranks=87621rank=32600 of ranks=87621rank=32700 of ranks=87621rank=32800 of ranks=87621rank=32900 of ranks=87621rank=33000 of ranks=87621rank=33100 of ranks=87621rank=33200 of ranks=87621rank=33300 of ranks=87621rank=33400 of ranks=87621rank=33500 of ranks=87621rank=33600 of ranks=87621rank=33700 of ranks=87621rank=33800 of ranks=87621rank=33900 of ranks=87621rank=34000 of ranks=87621rank=34100 of ranks=87621rank=34200 of ranks=87621rank=34300 of ranks=87621rank=34400 of ranks=87621rank=34500 of ranks=87621rank=34600 of ranks=87621rank=34700 of ranks=87621rank=34800 of ranks=87621rank=34900 of ranks=87621rank=35000 of ranks=87621rank=35100 of ranks=87621rank=35200 of ranks=87621rank=35300 of ranks=87621rank=35400 of ranks=87621rank=35500 of ranks=87621rank=35600 of ranks=87621rank=35700 of ranks=87621rank=35800 of ranks=87621rank=35900 of ranks=87621rank=36000 of ranks=87621rank=36100 of ranks=87621rank=36200 of ranks=87621rank=36300 of ranks=87621rank=36400 of ranks=87621rank=36500 of ranks=87621rank=36600 of ranks=87621rank=36700 of ranks=87621rank=36800 of ranks=87621rank=36900 of ranks=87621rank=37000 of ranks=87621rank=37100 of ranks=87621rank=37200 of ranks=87621rank=37300 of ranks=87621rank=37400 of ranks=87621rank=37500 of ranks=87621rank=37600 of ranks=87621rank=37700 of ranks=87621rank=37800 of ranks=87621rank=37900 of ranks=87621rank=38000 of ranks=87621rank=38100 of ranks=87621rank=38200 of ranks=87621rank=38300 of ranks=87621rank=38400 of ranks=87621rank=38500 of ranks=87621rank=38600 of ranks=87621rank=38700 of ranks=87621rank=38800 of ranks=87621rank=38900 of ranks=87621rank=39000 of ranks=87621rank=39100 of ranks=87621rank=39200 of ranks=87621rank=39300 of ranks=87621rank=39400 of ranks=87621rank=39500 of ranks=87621rank=39600 of ranks=87621rank=39700 of ranks=87621rank=39800 of ranks=87621rank=39900 of ranks=87621rank=40000 of ranks=87621rank=40100 of ranks=87621rank=40200 of ranks=87621rank=40300 of ranks=87621rank=40400 of ranks=87621rank=40500 of ranks=87621rank=40600 of ranks=87621rank=40700 of ranks=87621rank=40800 of ranks=87621rank=40900 of ranks=87621rank=41000 of ranks=87621rank=41100 of ranks=87621rank=41200 of ranks=87621rank=41300 of ranks=87621rank=41400 of ranks=87621rank=41500 of ranks=87621rank=41600 of ranks=87621rank=41700 of ranks=87621rank=41800 of ranks=87621rank=41900 of ranks=87621rank=42000 of ranks=87621rank=42100 of ranks=87621rank=42200 of ranks=87621rank=42300 of ranks=87621rank=42400 of ranks=87621rank=42500 of ranks=87621rank=42600 of ranks=87621rank=42700 of ranks=87621rank=42800 of ranks=87621rank=42900 of ranks=87621rank=43000 of ranks=87621rank=43100 of ranks=87621rank=43200 of ranks=87621rank=43300 of ranks=87621rank=43400 of ranks=87621rank=43500 of ranks=87621rank=43600 of ranks=87621rank=43700 of ranks=87621rank=43800 of ranks=87621rank=43900 of ranks=87621rank=44000 of ranks=87621rank=44100 of ranks=87621rank=44200 of ranks=87621rank=44300 of ranks=87621rank=44400 of ranks=87621rank=44500 of ranks=87621rank=44600 of ranks=87621rank=44700 of ranks=87621rank=44800 of ranks=87621rank=44900 of ranks=87621rank=45000 of ranks=87621rank=45100 of ranks=87621rank=45200 of ranks=87621rank=45300 of ranks=87621rank=45400 of ranks=87621rank=45500 of ranks=87621rank=45600 of ranks=87621rank=45700 of ranks=87621rank=45800 of ranks=87621rank=45900 of ranks=87621rank=46000 of ranks=87621rank=46100 of ranks=87621rank=46200 of ranks=87621rank=46300 of ranks=87621rank=46400 of ranks=87621rank=46500 of ranks=87621rank=46600 of ranks=87621rank=46700 of ranks=87621rank=46800 of ranks=87621rank=46900 of ranks=87621rank=47000 of ranks=87621rank=47100 of ranks=87621rank=47200 of ranks=87621rank=47300 of ranks=87621rank=47400 of ranks=87621rank=47500 of ranks=87621rank=47600 of ranks=87621rank=47700 of ranks=87621rank=47800 of ranks=87621rank=47900 of ranks=87621rank=48000 of ranks=87621rank=48100 of ranks=87621rank=48200 of ranks=87621rank=48300 of ranks=87621rank=48400 of ranks=87621rank=48500 of ranks=87621rank=48600 of ranks=87621rank=48700 of ranks=87621rank=48800 of ranks=87621rank=48900 of ranks=87621rank=49000 of ranks=87621rank=49100 of ranks=87621rank=49200 of ranks=87621rank=49300 of ranks=87621rank=49400 of ranks=87621rank=49500 of ranks=87621rank=49600 of ranks=87621rank=49700 of ranks=87621rank=49800 of ranks=87621rank=49900 of ranks=87621rank=50000 of ranks=87621rank=50100 of ranks=87621rank=50200 of ranks=87621rank=50300 of ranks=87621rank=50400 of ranks=87621rank=50500 of ranks=87621rank=50600 of ranks=87621rank=50700 of ranks=87621rank=50800 of ranks=87621rank=50900 of ranks=87621rank=51000 of ranks=87621rank=51100 of ranks=87621rank=51200 of ranks=87621rank=51300 of ranks=87621rank=51400 of ranks=87621rank=51500 of ranks=87621rank=51600 of ranks=87621rank=51700 of ranks=87621rank=51800 of ranks=87621rank=51900 of ranks=87621rank=52000 of ranks=87621rank=52100 of ranks=87621rank=52200 of ranks=87621rank=52300 of ranks=87621rank=52400 of ranks=87621rank=52500 of ranks=87621rank=52600 of ranks=87621rank=52700 of ranks=87621rank=52800 of ranks=87621rank=52900 of ranks=87621rank=53000 of ranks=87621rank=53100 of ranks=87621rank=53200 of ranks=87621rank=53300 of ranks=87621rank=53400 of ranks=87621rank=53500 of ranks=87621rank=53600 of ranks=87621rank=53700 of ranks=87621rank=53800 of ranks=87621rank=53900 of ranks=87621rank=54000 of ranks=87621rank=54100 of ranks=87621rank=54200 of ranks=87621rank=54300 of ranks=87621rank=54400 of ranks=87621rank=54500 of ranks=87621rank=54600 of ranks=87621rank=54700 of ranks=87621rank=54800 of ranks=87621rank=54900 of ranks=87621rank=55000 of ranks=87621rank=55100 of ranks=87621rank=55200 of ranks=87621rank=55300 of ranks=87621rank=55400 of ranks=87621rank=55500 of ranks=87621rank=55600 of ranks=87621rank=55700 of ranks=87621rank=55800 of ranks=87621rank=55900 of ranks=87621rank=56000 of ranks=87621rank=56100 of ranks=87621rank=56200 of ranks=87621rank=56300 of ranks=87621rank=56400 of ranks=87621rank=56500 of ranks=87621rank=56600 of ranks=87621rank=56700 of ranks=87621rank=56800 of ranks=87621rank=56900 of ranks=87621rank=57000 of ranks=87621rank=57100 of ranks=87621rank=57200 of ranks=87621rank=57300 of ranks=87621rank=57400 of ranks=87621rank=57500 of ranks=87621rank=57600 of ranks=87621rank=57700 of ranks=87621rank=57800 of ranks=87621rank=57900 of ranks=87621rank=58000 of ranks=87621rank=58100 of ranks=87621rank=58200 of ranks=87621rank=58300 of ranks=87621rank=58400 of ranks=87621rank=58500 of ranks=87621rank=58600 of ranks=87621rank=58700 of ranks=87621rank=58800 of ranks=87621rank=58900 of ranks=87621rank=59000 of ranks=87621rank=59100 of ranks=87621rank=59200 of ranks=87621rank=59300 of ranks=87621rank=59400 of ranks=87621rank=59500 of ranks=87621rank=59600 of ranks=87621rank=59700 of ranks=87621rank=59800 of ranks=87621rank=59900 of ranks=87621rank=60000 of ranks=87621rank=60100 of ranks=87621rank=60200 of ranks=87621rank=60300 of ranks=87621rank=60400 of ranks=87621rank=60500 of ranks=87621rank=60600 of ranks=87621rank=60700 of ranks=87621rank=60800 of ranks=87621rank=60900 of ranks=87621rank=61000 of ranks=87621rank=61100 of ranks=87621rank=61200 of ranks=87621rank=61300 of ranks=87621rank=61400 of ranks=87621rank=61500 of ranks=87621rank=61600 of ranks=87621rank=61700 of ranks=87621rank=61800 of ranks=87621rank=61900 of ranks=87621rank=62000 of ranks=87621rank=62100 of ranks=87621rank=62200 of ranks=87621rank=62300 of ranks=87621rank=62400 of ranks=87621rank=62500 of ranks=87621rank=62600 of ranks=87621rank=62700 of ranks=87621rank=62800 of ranks=87621rank=62900 of ranks=87621rank=63000 of ranks=87621rank=63100 of ranks=87621rank=63200 of ranks=87621rank=63300 of ranks=87621rank=63400 of ranks=87621rank=63500 of ranks=87621rank=63600 of ranks=87621rank=63700 of ranks=87621rank=63800 of ranks=87621rank=63900 of ranks=87621rank=64000 of ranks=87621rank=64100 of ranks=87621rank=64200 of ranks=87621rank=64300 of ranks=87621rank=64400 of ranks=87621rank=64500 of ranks=87621rank=64600 of ranks=87621rank=64700 of ranks=87621rank=64800 of ranks=87621rank=64900 of ranks=87621rank=65000 of ranks=87621rank=65100 of ranks=87621rank=65200 of ranks=87621rank=65300 of ranks=87621rank=65400 of ranks=87621rank=65500 of ranks=87621rank=65600 of ranks=87621rank=65700 of ranks=87621rank=65800 of ranks=87621rank=65900 of ranks=87621rank=66000 of ranks=87621rank=66100 of ranks=87621rank=66200 of ranks=87621rank=66300 of ranks=87621rank=66400 of ranks=87621rank=66500 of ranks=87621rank=66600 of ranks=87621rank=66700 of ranks=87621rank=66800 of ranks=87621rank=66900 of ranks=87621rank=67000 of ranks=87621rank=67100 of ranks=87621rank=67200 of ranks=87621rank=67300 of ranks=87621rank=67400 of ranks=87621rank=67500 of ranks=87621rank=67600 of ranks=87621rank=67700 of ranks=87621rank=67800 of ranks=87621rank=67900 of ranks=87621rank=68000 of ranks=87621rank=68100 of ranks=87621rank=68200 of ranks=87621rank=68300 of ranks=87621rank=68400 of ranks=87621rank=68500 of ranks=87621rank=68600 of ranks=87621rank=68700 of ranks=87621rank=68800 of ranks=87621rank=68900 of ranks=87621rank=69000 of ranks=87621rank=69100 of ranks=87621rank=69200 of ranks=87621rank=69300 of ranks=87621rank=69400 of ranks=87621rank=69500 of ranks=87621rank=69600 of ranks=87621rank=69700 of ranks=87621rank=69800 of ranks=87621rank=69900 of ranks=87621rank=70000 of ranks=87621rank=70100 of ranks=87621rank=70200 of ranks=87621rank=70300 of ranks=87621rank=70400 of ranks=87621rank=70500 of ranks=87621rank=70600 of ranks=87621rank=70700 of ranks=87621rank=70800 of ranks=87621rank=70900 of ranks=87621rank=71000 of ranks=87621rank=71100 of ranks=87621rank=71200 of ranks=87621rank=71300 of ranks=87621rank=71400 of ranks=87621rank=71500 of ranks=87621rank=71600 of ranks=87621rank=71700 of ranks=87621rank=71800 of ranks=87621rank=71900 of ranks=87621rank=72000 of ranks=87621rank=72100 of ranks=87621rank=72200 of ranks=87621rank=72300 of ranks=87621rank=72400 of ranks=87621rank=72500 of ranks=87621rank=72600 of ranks=87621rank=72700 of ranks=87621rank=72800 of ranks=87621rank=72900 of ranks=87621rank=73000 of ranks=87621rank=73100 of ranks=87621rank=73200 of ranks=87621rank=73300 of ranks=87621rank=73400 of ranks=87621rank=73500 of ranks=87621rank=73600 of ranks=87621rank=73700 of ranks=87621rank=73800 of ranks=87621rank=73900 of ranks=87621rank=74000 of ranks=87621rank=74100 of ranks=87621rank=74200 of ranks=87621rank=74300 of ranks=87621rank=74400 of ranks=87621rank=74500 of ranks=87621rank=74600 of ranks=87621rank=74700 of ranks=87621rank=74800 of ranks=87621rank=74900 of ranks=87621rank=75000 of ranks=87621rank=75100 of ranks=87621rank=75200 of ranks=87621rank=75300 of ranks=87621rank=75400 of ranks=87621rank=75500 of ranks=87621rank=75600 of ranks=87621rank=75700 of ranks=87621rank=75800 of ranks=87621rank=75900 of ranks=87621rank=76000 of ranks=87621rank=76100 of ranks=87621rank=76200 of ranks=87621rank=76300 of ranks=87621rank=76400 of ranks=87621rank=76500 of ranks=87621rank=76600 of ranks=87621rank=76700 of ranks=87621rank=76800 of ranks=87621rank=76900 of ranks=87621rank=77000 of ranks=87621rank=77100 of ranks=87621rank=77200 of ranks=87621rank=77300 of ranks=87621rank=77400 of ranks=87621rank=77500 of ranks=87621rank=77600 of ranks=87621rank=77700 of ranks=87621rank=77800 of ranks=87621rank=77900 of ranks=87621rank=78000 of ranks=87621rank=78100 of ranks=87621rank=78200 of ranks=87621rank=78300 of ranks=87621rank=78400 of ranks=87621rank=78500 of ranks=87621rank=78600 of ranks=87621rank=78700 of ranks=87621rank=78800 of ranks=87621rank=78900 of ranks=87621rank=79000 of ranks=87621rank=79100 of ranks=87621rank=79200 of ranks=87621rank=79300 of ranks=87621rank=79400 of ranks=87621rank=79500 of ranks=87621rank=79600 of ranks=87621rank=79700 of ranks=87621rank=79800 of ranks=87621rank=79900 of ranks=87621rank=80000 of ranks=87621rank=80100 of ranks=87621rank=80200 of ranks=87621rank=80300 of ranks=87621rank=80400 of ranks=87621rank=80500 of ranks=87621rank=80600 of ranks=87621rank=80700 of ranks=87621rank=80800 of ranks=87621rank=80900 of ranks=87621rank=81000 of ranks=87621rank=81100 of ranks=87621rank=81200 of ranks=87621rank=81300 of ranks=87621rank=81400 of ranks=87621rank=81500 of ranks=87621rank=81600 of ranks=87621rank=81700 of ranks=87621rank=81800 of ranks=87621rank=81900 of ranks=87621rank=82000 of ranks=87621rank=82100 of ranks=87621rank=82200 of ranks=87621rank=82300 of ranks=87621rank=82400 of ranks=87621rank=82500 of ranks=87621rank=82600 of ranks=87621rank=82700 of ranks=87621rank=82800 of ranks=87621rank=82900 of ranks=87621rank=83000 of ranks=87621rank=83100 of ranks=87621rank=83200 of ranks=87621rank=83300 of ranks=87621rank=83400 of ranks=87621rank=83500 of ranks=87621rank=83600 of ranks=87621rank=83700 of ranks=87621rank=83800 of ranks=87621rank=83900 of ranks=87621rank=84000 of ranks=87621rank=84100 of ranks=87621rank=84200 of ranks=87621rank=84300 of ranks=87621rank=84400 of ranks=87621rank=84500 of ranks=87621rank=84600 of ranks=87621rank=84700 of ranks=87621rank=84800 of ranks=87621rank=84900 of ranks=87621rank=85000 of ranks=87621rank=85100 of ranks=87621rank=85200 of ranks=87621rank=85300 of ranks=87621rank=85400 of ranks=87621rank=85500 of ranks=87621rank=85600 of ranks=87621rank=85700 of ranks=87621rank=85800 of ranks=87621rank=85900 of ranks=87621rank=86000 of ranks=87621rank=86100 of ranks=87621rank=86200 of ranks=87621rank=86300 of ranks=87621rank=86400 of ranks=87621rank=86500 of ranks=87621rank=86600 of ranks=87621rank=86700 of ranks=87621rank=86800 of ranks=87621rank=86900 of ranks=87621rank=87000 of ranks=87621rank=87100 of ranks=87621rank=87200 of ranks=87621rank=87300 of ranks=87621rank=87400 of ranks=87621rank=87500 of ranks=87621rank=87600 of ranks=87621

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              97.9390    493   1027      5    498           77.0369
   1 car                    98.7852  50024  20799    292  50316           84.7965
   2 truck                  98.6233   1813   2540     12   1825           77.4211
   3 bus                    96.9486    362   1801      4    366           69.1612
   4 pedestrian             97.1906   4180   4582     79   4259           75.8164

for conf_thresh=0.25, precision=0.92, recall=0.96, F1 score=0.94
for conf_thresh=0.25, TP=55223, FP=4701, FN=2041, average IoU=83.71%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=97.90%
Total detection time: 122 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
New best mAP, saving weights!
Saving weights to /workspace/.cache/splits/combined_best.weights
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b4bee00000
7091: loss=2.347, avg loss=2.322, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=2.3 seconds, 453824 images, time remaining=64.6 minutes
7092: loss=2.613, avg loss=2.351, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.4 seconds, 453888 images, time remaining=64.6 minutes
7093: loss=2.273, avg loss=2.343, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.7 seconds, train=2.3 seconds, 453952 images, time remaining=64.5 minutes
7094: loss=2.220, avg loss=2.331, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.2 seconds, train=2.4 seconds, 454016 images, time remaining=64.4 minutes
7095: loss=2.317, avg loss=2.329, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 454080 images, time remaining=64.3 minutes
7096: loss=2.211, avg loss=2.317, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 454144 images, time remaining=64.2 minutes
7097: loss=2.153, avg loss=2.301, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.2 seconds, train=2.3 seconds, 454208 images, time remaining=64.2 minutes
7098: loss=1.864, avg loss=2.257, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.3 seconds, 454272 images, time remaining=64.1 minutes
7099: loss=2.452, avg loss=2.277, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.2 seconds, train=2.4 seconds, 454336 images, time remaining=64 minutes
7100: loss=2.128, avg loss=2.262, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.4 seconds, 454400 images, time remaining=63.9 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7101: loss=1.836, avg loss=2.219, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=4.9 seconds, 454464 images, time remaining=63.9 minutes
7102: loss=2.348, avg loss=2.232, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.9 seconds, train=5.0 seconds, 454528 images, time remaining=63.8 minutes
7103: loss=2.099, avg loss=2.219, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.8 seconds, 454592 images, time remaining=63.8 minutes
7104: loss=2.186, avg loss=2.215, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.9 seconds, 454656 images, time remaining=63.7 minutes
7105: loss=2.708, avg loss=2.265, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=4.9 seconds, 454720 images, time remaining=63.6 minutes
7106: loss=2.492, avg loss=2.287, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.9 seconds, 454784 images, time remaining=63.5 minutes
7107: loss=2.355, avg loss=2.294, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.9 seconds, 454848 images, time remaining=63.5 minutes
7108: loss=2.208, avg loss=2.286, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.0 seconds, 454912 images, time remaining=63.4 minutes
7109: loss=2.282, avg loss=2.285, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.9 seconds, 454976 images, time remaining=63.3 minutes
7110: loss=2.013, avg loss=2.258, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.9 seconds, 455040 images, time remaining=63.2 minutes
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7111: loss=2.537, avg loss=2.286, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.7 seconds, train=5.4 seconds, 455104 images, time remaining=63.2 minutes
7112: loss=2.417, avg loss=2.299, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.8 seconds, train=5.3 seconds, 455168 images, time remaining=63.1 minutes
7113: loss=2.800, avg loss=2.349, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=2.7 seconds, train=5.5 seconds, 455232 images, time remaining=63.1 minutes
7114: loss=3.015, avg loss=2.416, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.7 seconds, train=5.4 seconds, 455296 images, time remaining=63 minutes
7115: loss=3.046, avg loss=2.479, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.7 seconds, train=5.4 seconds, 455360 images, time remaining=62.9 minutes
7116: loss=1.969, avg loss=2.428, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.4 seconds, 455424 images, time remaining=62.8 minutes
7117: loss=2.506, avg loss=2.436, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.3 seconds, 455488 images, time remaining=62.8 minutes
7118: loss=1.989, avg loss=2.391, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.3 seconds, 455552 images, time remaining=62.7 minutes
7119: loss=2.499, avg loss=2.402, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.7 seconds, train=5.4 seconds, 455616 images, time remaining=62.6 minutes
7120: loss=2.749, avg loss=2.436, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.7 seconds, train=5.3 seconds, 455680 images, time remaining=62.6 minutes
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7121: loss=2.786, avg loss=2.471, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 455744 images, time remaining=62.5 minutes
7122: loss=2.546, avg loss=2.479, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=4.0 seconds, 455808 images, time remaining=62.4 minutes
7123: loss=2.933, avg loss=2.524, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.0 seconds, 455872 images, time remaining=62.4 minutes
7124: loss=2.114, avg loss=2.483, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.2 seconds, train=4.0 seconds, 455936 images, time remaining=62.3 minutes
7125: loss=2.454, avg loss=2.480, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=3.9 seconds, 456000 images, time remaining=62.2 minutes
7126: loss=2.284, avg loss=2.461, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.2 seconds, train=3.9 seconds, 456064 images, time remaining=62.1 minutes
7127: loss=2.042, avg loss=2.419, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=4.0 seconds, 456128 images, time remaining=62.1 minutes
7128: loss=2.048, avg loss=2.382, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=3.9 seconds, 456192 images, time remaining=62 minutes
7129: loss=2.145, avg loss=2.358, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 456256 images, time remaining=61.9 minutes
7130: loss=1.944, avg loss=2.317, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 456320 images, time remaining=61.9 minutes
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7131: loss=2.222, avg loss=2.307, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.1 seconds, 456384 images, time remaining=61.8 minutes
7132: loss=2.151, avg loss=2.292, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=3.9 seconds, 456448 images, time remaining=61.7 minutes
7133: loss=1.978, avg loss=2.260, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.8 seconds, train=4.1 seconds, 456512 images, time remaining=61.6 minutes
7134: loss=2.594, avg loss=2.294, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 456576 images, time remaining=61.6 minutes
7135: loss=2.274, avg loss=2.292, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 456640 images, time remaining=61.5 minutes
7136: loss=2.322, avg loss=2.295, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.2 seconds, train=4.0 seconds, 456704 images, time remaining=61.4 minutes
7137: loss=3.035, avg loss=2.369, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=4.1 seconds, 456768 images, time remaining=61.4 minutes
7138: loss=1.819, avg loss=2.314, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=4.0 seconds, 456832 images, time remaining=61.3 minutes
7139: loss=2.283, avg loss=2.311, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.0 seconds, 456896 images, time remaining=61.2 minutes
7140: loss=1.959, avg loss=2.276, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.8 seconds, train=3.9 seconds, 456960 images, time remaining=61.1 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
7141: loss=1.793, avg loss=2.227, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.9 seconds, train=2.9 seconds, 457024 images, time remaining=61.1 minutes
7142: loss=1.609, avg loss=2.165, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=2.9 seconds, 457088 images, time remaining=61 minutes
7143: loss=2.122, avg loss=2.161, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 457152 images, time remaining=60.9 minutes
7144: loss=2.264, avg loss=2.171, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.9 seconds, 457216 images, time remaining=60.9 minutes
7145: loss=1.749, avg loss=2.129, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 457280 images, time remaining=60.8 minutes
7146: loss=1.950, avg loss=2.111, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 457344 images, time remaining=60.7 minutes
7147: loss=2.536, avg loss=2.154, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 457408 images, time remaining=60.6 minutes
7148: loss=1.796, avg loss=2.118, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.2 seconds, train=2.8 seconds, 457472 images, time remaining=60.6 minutes
7149: loss=1.912, avg loss=2.097, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.8 seconds, 457536 images, time remaining=60.5 minutes
7150: loss=2.387, avg loss=2.126, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 457600 images, time remaining=60.4 minutes
Resizing, random_coef=1.40, batch=4, 928x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
7151: loss=2.393, avg loss=2.153, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.9 seconds, train=2.7 seconds, 457664 images, time remaining=60.3 minutes
7152: loss=2.038, avg loss=2.141, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 457728 images, time remaining=60.3 minutes
7153: loss=2.247, avg loss=2.152, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 457792 images, time remaining=60.2 minutes
7154: loss=2.177, avg loss=2.155, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.7 seconds, 457856 images, time remaining=60.1 minutes
7155: loss=1.926, avg loss=2.132, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.2 seconds, train=2.7 seconds, 457920 images, time remaining=60 minutes
7156: loss=1.888, avg loss=2.107, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 457984 images, time remaining=60 minutes
7157: loss=2.144, avg loss=2.111, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.2 seconds, train=2.7 seconds, 458048 images, time remaining=59.9 minutes
7158: loss=2.357, avg loss=2.136, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 458112 images, time remaining=59.8 minutes
7159: loss=2.139, avg loss=2.136, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=2.8 seconds, 458176 images, time remaining=59.8 minutes
7160: loss=2.001, avg loss=2.122, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.7 seconds, 458240 images, time remaining=59.7 minutes
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7161: loss=2.271, avg loss=2.137, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.8 seconds, train=5.4 seconds, 458304 images, time remaining=59.6 minutes
7162: loss=2.263, avg loss=2.150, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.7 seconds, train=5.2 seconds, 458368 images, time remaining=59.5 minutes
7163: loss=2.662, avg loss=2.201, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=2.1 seconds, train=5.3 seconds, 458432 images, time remaining=59.5 minutes
7164: loss=3.160, avg loss=2.297, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.4 seconds, 458496 images, time remaining=59.4 minutes
7165: loss=3.084, avg loss=2.376, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.7 seconds, train=5.4 seconds, 458560 images, time remaining=59.3 minutes
7166: loss=2.635, avg loss=2.402, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.3 seconds, 458624 images, time remaining=59.3 minutes
7167: loss=2.111, avg loss=2.373, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.4 seconds, 458688 images, time remaining=59.2 minutes
7168: loss=2.868, avg loss=2.422, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.3 seconds, 458752 images, time remaining=59.1 minutes
7169: loss=2.937, avg loss=2.474, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.7 seconds, train=5.4 seconds, 458816 images, time remaining=59.1 minutes
7170: loss=2.491, avg loss=2.475, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.3 seconds, 458880 images, time remaining=59 minutes
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
7171: loss=1.863, avg loss=2.414, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=2.6 seconds, 458944 images, time remaining=58.9 minutes
7172: loss=1.933, avg loss=2.366, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=2.6 seconds, 459008 images, time remaining=58.8 minutes
7173: loss=1.683, avg loss=2.298, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.6 seconds, 459072 images, time remaining=58.8 minutes
7174: loss=2.191, avg loss=2.287, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.7 seconds, 459136 images, time remaining=58.7 minutes
7175: loss=2.405, avg loss=2.299, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.6 seconds, 459200 images, time remaining=58.6 minutes
7176: loss=1.906, avg loss=2.260, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.3 seconds, train=2.7 seconds, 459264 images, time remaining=58.6 minutes
7177: loss=1.830, avg loss=2.217, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 459328 images, time remaining=58.5 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7178: loss=2.262, avg loss=2.221, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=5.4 seconds, train=2.7 seconds, 459392 images, time remaining=58.4 minutes
7179: loss=2.015, avg loss=2.201, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=2.7 seconds, 459456 images, time remaining=58.3 minutes
7180: loss=1.927, avg loss=2.173, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=2.0 seconds, train=2.6 seconds, 459520 images, time remaining=58.3 minutes
Resizing, random_coef=1.40, batch=4, 1088x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7181: loss=1.931, avg loss=2.149, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.2 seconds, 459584 images, time remaining=58.2 minutes
7182: loss=2.293, avg loss=2.163, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.7 seconds, train=4.1 seconds, 459648 images, time remaining=58.1 minutes
7183: loss=2.762, avg loss=2.223, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.2 seconds, 459712 images, time remaining=58.1 minutes
7184: loss=2.575, avg loss=2.258, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=4.0 seconds, 459776 images, time remaining=58 minutes
7185: loss=2.172, avg loss=2.250, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.8 seconds, train=4.2 seconds, 459840 images, time remaining=57.9 minutes
7186: loss=2.076, avg loss=2.232, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.7 seconds, train=4.1 seconds, 459904 images, time remaining=57.8 minutes
7187: loss=2.069, avg loss=2.216, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.1 seconds, 459968 images, time remaining=57.8 minutes
7188: loss=2.342, avg loss=2.229, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.4 seconds, train=4.1 seconds, 460032 images, time remaining=57.7 minutes
7189: loss=2.129, avg loss=2.219, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.1 seconds, 460096 images, time remaining=57.6 minutes
7190: loss=1.986, avg loss=2.195, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.5 seconds, train=4.1 seconds, 460160 images, time remaining=57.6 minutes
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7191: loss=2.185, avg loss=2.194, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.3 seconds, 460224 images, time remaining=57.5 minutes
7192: loss=2.216, avg loss=2.197, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.3 seconds, 460288 images, time remaining=57.4 minutes
7193: loss=2.762, avg loss=2.253, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.3 seconds, 460352 images, time remaining=57.4 minutes
7194: loss=2.168, avg loss=2.245, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.7 seconds, train=5.4 seconds, 460416 images, time remaining=57.3 minutes
7195: loss=2.885, avg loss=2.309, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.4 seconds, 460480 images, time remaining=57.2 minutes
7196: loss=2.313, avg loss=2.309, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.1 seconds, 460544 images, time remaining=57.1 minutes
7197: loss=2.176, avg loss=2.296, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=2.4 seconds, train=5.4 seconds, 460608 images, time remaining=57.1 minutes
7198: loss=2.552, avg loss=2.321, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.7 seconds, train=5.3 seconds, 460672 images, time remaining=57 minutes
7199: loss=2.241, avg loss=2.313, last=97.90%, best=97.90%, next=7496, rate=0.00013000, load 64=1.6 seconds, train=5.4 seconds, 460736 images, time remaining=57 minutes
7200: loss=2.464, avg loss=2.328, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.3 seconds, 460800 images, time remaining=56.9 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7201: loss=1.897, avg loss=2.285, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=3.5 seconds, train=4.0 seconds, 460864 images, time remaining=56.8 minutes
7202: loss=2.386, avg loss=2.295, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.2 seconds, train=4.0 seconds, 460928 images, time remaining=56.7 minutes
7203: loss=2.264, avg loss=2.292, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=4.1 seconds, 460992 images, time remaining=56.7 minutes
7204: loss=2.513, avg loss=2.314, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 461056 images, time remaining=56.6 minutes
7205: loss=2.061, avg loss=2.289, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 461120 images, time remaining=56.5 minutes
7206: loss=2.399, avg loss=2.300, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.1 seconds, 461184 images, time remaining=56.5 minutes
7207: loss=2.587, avg loss=2.329, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.1 seconds, 461248 images, time remaining=56.4 minutes
7208: loss=2.577, avg loss=2.353, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=4.1 seconds, 461312 images, time remaining=56.3 minutes
7209: loss=2.334, avg loss=2.351, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.1 seconds, 461376 images, time remaining=56.2 minutes
7210: loss=2.601, avg loss=2.376, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.1 seconds, 461440 images, time remaining=56.2 minutes
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b6c9a00000
7211: loss=2.392, avg loss=2.378, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=2.2 seconds, 461504 images, time remaining=56.1 minutes
7212: loss=2.129, avg loss=2.353, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.3 seconds, 461568 images, time remaining=56 minutes
7213: loss=2.581, avg loss=2.376, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 461632 images, time remaining=56 minutes
7214: loss=1.785, avg loss=2.317, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.1 seconds, 461696 images, time remaining=55.9 minutes
7215: loss=2.241, avg loss=2.309, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.2 seconds, 461760 images, time remaining=55.8 minutes
7216: loss=2.381, avg loss=2.316, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 461824 images, time remaining=55.7 minutes
7217: loss=2.435, avg loss=2.328, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.2 seconds, 461888 images, time remaining=55.6 minutes
7218: loss=2.160, avg loss=2.311, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.1 seconds, 461952 images, time remaining=55.6 minutes
7219: loss=2.175, avg loss=2.298, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.2 seconds, 462016 images, time remaining=55.5 minutes
7220: loss=2.560, avg loss=2.324, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 462080 images, time remaining=55.4 minutes
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b4c5c00000
7221: loss=2.223, avg loss=2.314, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=2.4 seconds, 462144 images, time remaining=55.4 minutes
7222: loss=2.072, avg loss=2.290, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.3 seconds, 462208 images, time remaining=55.3 minutes
7223: loss=2.141, avg loss=2.275, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.4 seconds, 462272 images, time remaining=55.2 minutes
7224: loss=1.944, avg loss=2.242, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.4 seconds, 462336 images, time remaining=55.1 minutes
7225: loss=2.233, avg loss=2.241, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.4 seconds, 462400 images, time remaining=55 minutes
7226: loss=2.276, avg loss=2.244, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.4 seconds, 462464 images, time remaining=55 minutes
7227: loss=2.170, avg loss=2.237, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.5 seconds, 462528 images, time remaining=54.9 minutes
7228: loss=1.550, avg loss=2.168, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.3 seconds, 462592 images, time remaining=54.8 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7229: loss=2.058, avg loss=2.157, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=3.1 seconds, train=2.2 seconds, 462656 images, time remaining=54.8 minutes
7230: loss=2.443, avg loss=2.186, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.8 seconds, train=2.3 seconds, 462720 images, time remaining=54.7 minutes
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7231: loss=1.988, avg loss=2.166, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.3 seconds, 462784 images, time remaining=54.6 minutes
7232: loss=2.203, avg loss=2.170, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.4 seconds, 462848 images, time remaining=54.5 minutes
7233: loss=2.251, avg loss=2.178, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=4.3 seconds, 462912 images, time remaining=54.5 minutes
7234: loss=2.363, avg loss=2.196, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.8 seconds, train=4.3 seconds, 462976 images, time remaining=54.4 minutes
7235: loss=2.227, avg loss=2.199, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.3 seconds, 463040 images, time remaining=54.3 minutes
7236: loss=2.564, avg loss=2.236, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.9 seconds, train=4.5 seconds, 463104 images, time remaining=54.3 minutes
7237: loss=2.452, avg loss=2.257, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.5 seconds, 463168 images, time remaining=54.2 minutes
7238: loss=2.384, avg loss=2.270, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=4.4 seconds, 463232 images, time remaining=54.1 minutes
7239: loss=2.859, avg loss=2.329, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.9 seconds, train=4.3 seconds, 463296 images, time remaining=54 minutes
7240: loss=2.693, avg loss=2.365, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.4 seconds, 463360 images, time remaining=54 minutes
Resizing, random_coef=1.40, batch=4, 1152x896
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7241: loss=2.509, avg loss=2.380, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=5.0 seconds, 463424 images, time remaining=53.9 minutes
7242: loss=3.014, avg loss=2.443, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=5.0 seconds, 463488 images, time remaining=53.8 minutes
7243: loss=2.339, avg loss=2.433, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.8 seconds, 463552 images, time remaining=53.8 minutes
7244: loss=2.258, avg loss=2.415, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=4.8 seconds, 463616 images, time remaining=53.7 minutes
7245: loss=2.268, avg loss=2.400, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=3.4 seconds, train=4.8 seconds, 463680 images, time remaining=53.6 minutes
7246: loss=2.030, avg loss=2.363, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.9 seconds, 463744 images, time remaining=53.6 minutes
7247: loss=2.235, avg loss=2.351, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.8 seconds, train=5.0 seconds, 463808 images, time remaining=53.5 minutes
7248: loss=2.636, avg loss=2.379, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.1 seconds, train=4.9 seconds, 463872 images, time remaining=53.4 minutes
7249: loss=2.005, avg loss=2.342, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.8 seconds, 463936 images, time remaining=53.4 minutes
7250: loss=2.057, avg loss=2.313, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.0 seconds, 464000 images, time remaining=53.3 minutes
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b864e00000
7251: loss=2.050, avg loss=2.287, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.1 seconds, train=1.9 seconds, 464064 images, time remaining=53.2 minutes
7252: loss=2.013, avg loss=2.259, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 464128 images, time remaining=53.2 minutes
7253: loss=2.327, avg loss=2.266, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=2.0 seconds, 464192 images, time remaining=53.1 minutes
7254: loss=2.539, avg loss=2.294, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 464256 images, time remaining=53 minutes
7255: loss=2.496, avg loss=2.314, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.0 seconds, 464320 images, time remaining=52.9 minutes
7256: loss=1.919, avg loss=2.274, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.8 seconds, train=1.9 seconds, 464384 images, time remaining=52.8 minutes
7257: loss=2.496, avg loss=2.296, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=1.9 seconds, 464448 images, time remaining=52.8 minutes
7258: loss=2.162, avg loss=2.283, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=1.9 seconds, 464512 images, time remaining=52.7 minutes
7259: loss=2.442, avg loss=2.299, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=1.9 seconds, 464576 images, time remaining=52.6 minutes
7260: loss=2.239, avg loss=2.293, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=1.9 seconds, 464640 images, time remaining=52.5 minutes
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14c3d5800000
7261: loss=2.518, avg loss=2.315, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.1 seconds, 464704 images, time remaining=52.5 minutes
7262: loss=1.791, avg loss=2.263, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.2 seconds, 464768 images, time remaining=52.4 minutes
7263: loss=2.069, avg loss=2.244, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 464832 images, time remaining=52.3 minutes
7264: loss=1.632, avg loss=2.182, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=2.1 seconds, 464896 images, time remaining=52.2 minutes
7265: loss=1.920, avg loss=2.156, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.1 seconds, 464960 images, time remaining=52.2 minutes
7266: loss=2.500, avg loss=2.191, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 465024 images, time remaining=52.1 minutes
7267: loss=2.610, avg loss=2.233, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 465088 images, time remaining=52 minutes
7268: loss=1.693, avg loss=2.179, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.1 seconds, 465152 images, time remaining=51.9 minutes
7269: loss=2.730, avg loss=2.234, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.1 seconds, 465216 images, time remaining=51.9 minutes
7270: loss=2.169, avg loss=2.227, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=2.0 seconds, 465280 images, time remaining=51.8 minutes
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b55fc00000
7271: loss=2.220, avg loss=2.227, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.2 seconds, 465344 images, time remaining=51.7 minutes
7272: loss=1.995, avg loss=2.203, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.2 seconds, 465408 images, time remaining=51.7 minutes
7273: loss=2.222, avg loss=2.205, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=2.1 seconds, 465472 images, time remaining=51.6 minutes
7274: loss=2.382, avg loss=2.223, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=2.2 seconds, 465536 images, time remaining=51.5 minutes
7275: loss=2.641, avg loss=2.265, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.8 seconds, train=2.2 seconds, 465600 images, time remaining=51.4 minutes
7276: loss=2.205, avg loss=2.259, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.3 seconds, 465664 images, time remaining=51.3 minutes
7277: loss=2.633, avg loss=2.296, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=2.2 seconds, 465728 images, time remaining=51.3 minutes
7278: loss=1.906, avg loss=2.257, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=2.2 seconds, 465792 images, time remaining=51.2 minutes
7279: loss=2.596, avg loss=2.291, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.9 seconds, train=2.3 seconds, 465856 images, time remaining=51.1 minutes
7280: loss=1.701, avg loss=2.232, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=2.1 seconds, 465920 images, time remaining=51.1 minutes
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b549800000
7281: loss=2.052, avg loss=2.214, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.0 seconds, train=2.6 seconds, 465984 images, time remaining=51 minutes
7282: loss=2.004, avg loss=2.193, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.5 seconds, 466048 images, time remaining=50.9 minutes
7283: loss=2.188, avg loss=2.193, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.7 seconds, 466112 images, time remaining=50.8 minutes
7284: loss=1.812, avg loss=2.155, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.6 seconds, 466176 images, time remaining=50.8 minutes
7285: loss=1.803, avg loss=2.119, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.7 seconds, 466240 images, time remaining=50.7 minutes
7286: loss=1.928, avg loss=2.100, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.6 seconds, 466304 images, time remaining=50.6 minutes
7287: loss=1.651, avg loss=2.055, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.6 seconds, 466368 images, time remaining=50.5 minutes
7288: loss=2.223, avg loss=2.072, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.7 seconds, 466432 images, time remaining=50.5 minutes
7289: loss=2.147, avg loss=2.080, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.6 seconds, 466496 images, time remaining=50.4 minutes
7290: loss=2.104, avg loss=2.082, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=2.5 seconds, 466560 images, time remaining=50.3 minutes
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b867000000
7291: loss=2.265, avg loss=2.100, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 466624 images, time remaining=50.2 minutes
7292: loss=2.004, avg loss=2.091, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 466688 images, time remaining=50.2 minutes
7293: loss=2.300, avg loss=2.112, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 466752 images, time remaining=50.1 minutes
7294: loss=1.978, avg loss=2.098, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 466816 images, time remaining=50 minutes
7295: loss=1.992, avg loss=2.088, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 466880 images, time remaining=50 minutes
7296: loss=2.549, avg loss=2.134, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=1.9 seconds, 466944 images, time remaining=49.9 minutes
7297: loss=2.562, avg loss=2.176, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=1.9 seconds, 467008 images, time remaining=49.8 minutes
7298: loss=2.272, avg loss=2.186, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=1.9 seconds, 467072 images, time remaining=49.7 minutes
7299: loss=2.800, avg loss=2.247, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=1.9 seconds, 467136 images, time remaining=49.7 minutes
7300: loss=2.276, avg loss=2.250, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=1.9 seconds, 467200 images, time remaining=49.6 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b867000000
7301: loss=1.952, avg loss=2.220, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 467264 images, time remaining=49.5 minutes
7302: loss=2.139, avg loss=2.212, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.1 seconds, train=1.9 seconds, 467328 images, time remaining=49.4 minutes
7303: loss=1.898, avg loss=2.181, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 467392 images, time remaining=49.4 minutes
7304: loss=2.738, avg loss=2.237, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.0 seconds, 467456 images, time remaining=49.3 minutes
7305: loss=1.997, avg loss=2.213, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=1.9 seconds, 467520 images, time remaining=49.2 minutes
7306: loss=2.563, avg loss=2.248, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=1.9 seconds, 467584 images, time remaining=49.1 minutes
7307: loss=2.592, avg loss=2.282, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.1 seconds, train=2.0 seconds, 467648 images, time remaining=49.1 minutes
7308: loss=2.357, avg loss=2.290, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=2.0 seconds, 467712 images, time remaining=49 minutes
7309: loss=2.435, avg loss=2.304, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.0 seconds, 467776 images, time remaining=48.9 minutes
7310: loss=2.176, avg loss=2.291, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.0 seconds, 467840 images, time remaining=48.8 minutes
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7311: loss=2.808, avg loss=2.343, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.5 seconds, 467904 images, time remaining=48.8 minutes
7312: loss=2.180, avg loss=2.327, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.8 seconds, train=5.3 seconds, 467968 images, time remaining=48.7 minutes
7313: loss=2.543, avg loss=2.348, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.9 seconds, train=5.4 seconds, 468032 images, time remaining=48.6 minutes
7314: loss=2.617, avg loss=2.375, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.3 seconds, 468096 images, time remaining=48.6 minutes
7315: loss=1.916, avg loss=2.329, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.3 seconds, 468160 images, time remaining=48.5 minutes
7316: loss=2.359, avg loss=2.332, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=5.4 seconds, 468224 images, time remaining=48.4 minutes
7317: loss=2.556, avg loss=2.354, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.3 seconds, 468288 images, time remaining=48.4 minutes
7318: loss=2.728, avg loss=2.392, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=5.4 seconds, 468352 images, time remaining=48.3 minutes
7319: loss=2.074, avg loss=2.360, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.4 seconds, 468416 images, time remaining=48.2 minutes
7320: loss=3.058, avg loss=2.430, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.2 seconds, 468480 images, time remaining=48.2 minutes
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7321: loss=2.363, avg loss=2.423, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.4 seconds, train=5.5 seconds, 468544 images, time remaining=48.1 minutes
7322: loss=2.375, avg loss=2.418, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=5.6 seconds, 468608 images, time remaining=48 minutes
7323: loss=2.284, avg loss=2.405, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=5.5 seconds, 468672 images, time remaining=48 minutes
7324: loss=3.060, avg loss=2.470, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.5 seconds, 468736 images, time remaining=47.9 minutes
7325: loss=2.836, avg loss=2.507, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.5 seconds, train=5.5 seconds, 468800 images, time remaining=47.8 minutes
7326: loss=2.612, avg loss=2.517, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=5.5 seconds, 468864 images, time remaining=47.8 minutes
7327: loss=2.557, avg loss=2.521, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.4 seconds, 468928 images, time remaining=47.7 minutes
7328: loss=2.920, avg loss=2.561, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.9 seconds, train=5.4 seconds, 468992 images, time remaining=47.6 minutes
7329: loss=2.084, avg loss=2.513, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.4 seconds, 469056 images, time remaining=47.5 minutes
7330: loss=2.520, avg loss=2.514, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.5 seconds, 469120 images, time remaining=47.5 minutes
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b5de200000
7331: loss=2.220, avg loss=2.485, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 469184 images, time remaining=47.4 minutes
7332: loss=2.568, avg loss=2.493, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.0 seconds, 469248 images, time remaining=47.3 minutes
7333: loss=2.807, avg loss=2.524, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.0 seconds, 469312 images, time remaining=47.2 minutes
7334: loss=2.195, avg loss=2.491, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.0 seconds, 469376 images, time remaining=47.2 minutes
7335: loss=2.218, avg loss=2.464, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 469440 images, time remaining=47.1 minutes
7336: loss=2.314, avg loss=2.449, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.1 seconds, train=1.9 seconds, 469504 images, time remaining=47 minutes
7337: loss=1.977, avg loss=2.402, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 469568 images, time remaining=46.9 minutes
7338: loss=2.407, avg loss=2.402, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=2.0 seconds, 469632 images, time remaining=46.9 minutes
7339: loss=2.060, avg loss=2.368, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.0 seconds, 469696 images, time remaining=46.8 minutes
7340: loss=2.574, avg loss=2.389, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 469760 images, time remaining=46.7 minutes
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7341: loss=2.442, avg loss=2.394, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.8 seconds, 469824 images, time remaining=46.7 minutes
7342: loss=2.976, avg loss=2.452, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.8 seconds, 469888 images, time remaining=46.6 minutes
7343: loss=1.984, avg loss=2.405, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.6 seconds, 469952 images, time remaining=46.5 minutes
7344: loss=2.172, avg loss=2.382, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.8 seconds, train=4.8 seconds, 470016 images, time remaining=46.5 minutes
7345: loss=1.973, avg loss=2.341, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.8 seconds, train=4.7 seconds, 470080 images, time remaining=46.4 minutes
7346: loss=2.383, avg loss=2.345, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=4.8 seconds, 470144 images, time remaining=46.3 minutes
7347: loss=3.046, avg loss=2.415, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.8 seconds, 470208 images, time remaining=46.2 minutes
7348: loss=3.015, avg loss=2.475, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=4.8 seconds, 470272 images, time remaining=46.2 minutes
7349: loss=2.643, avg loss=2.492, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.0 seconds, train=4.9 seconds, 470336 images, time remaining=46.1 minutes
7350: loss=2.424, avg loss=2.485, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.5 seconds, train=4.7 seconds, 470400 images, time remaining=46 minutes
Resizing, random_coef=1.40, batch=4, 1216x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7351: loss=2.621, avg loss=2.499, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=5.3 seconds, 470464 images, time remaining=46 minutes
7352: loss=3.162, avg loss=2.565, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.3 seconds, 470528 images, time remaining=45.9 minutes
7353: loss=2.540, avg loss=2.563, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=5.3 seconds, 470592 images, time remaining=45.8 minutes
7354: loss=2.589, avg loss=2.565, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=5.1 seconds, 470656 images, time remaining=45.8 minutes
7355: loss=2.318, avg loss=2.541, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.2 seconds, train=5.2 seconds, 470720 images, time remaining=45.7 minutes
7356: loss=2.490, avg loss=2.536, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=5.3 seconds, 470784 images, time remaining=45.6 minutes
7357: loss=2.136, avg loss=2.496, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.9 seconds, train=5.3 seconds, 470848 images, time remaining=45.6 minutes
7358: loss=1.817, avg loss=2.428, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=5.2 seconds, 470912 images, time remaining=45.5 minutes
7359: loss=1.956, avg loss=2.381, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=5.3 seconds, 470976 images, time remaining=45.4 minutes
7360: loss=2.620, avg loss=2.405, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.9 seconds, train=5.2 seconds, 471040 images, time remaining=45.3 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
7361: loss=1.951, avg loss=2.359, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.3 seconds, train=2.9 seconds, 471104 images, time remaining=45.3 minutes
7362: loss=2.226, avg loss=2.346, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.9 seconds, 471168 images, time remaining=45.2 minutes
7363: loss=2.241, avg loss=2.335, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 471232 images, time remaining=45.1 minutes
7364: loss=2.279, avg loss=2.330, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.9 seconds, 471296 images, time remaining=45.1 minutes
7365: loss=2.073, avg loss=2.304, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=2.8 seconds, 471360 images, time remaining=45 minutes
7366: loss=1.961, avg loss=2.270, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=2.8 seconds, 471424 images, time remaining=44.9 minutes
7367: loss=2.137, avg loss=2.256, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=2.7 seconds, 471488 images, time remaining=44.8 minutes
7368: loss=2.105, avg loss=2.241, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.9 seconds, train=2.8 seconds, 471552 images, time remaining=44.8 minutes
7369: loss=1.831, avg loss=2.200, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 471616 images, time remaining=44.7 minutes
7370: loss=2.371, avg loss=2.217, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 471680 images, time remaining=44.6 minutes
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b8aa400000
7371: loss=2.368, avg loss=2.232, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.4 seconds, 471744 images, time remaining=44.5 minutes
7372: loss=1.982, avg loss=2.207, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=2.4 seconds, 471808 images, time remaining=44.5 minutes
7373: loss=2.121, avg loss=2.199, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=2.4 seconds, 471872 images, time remaining=44.4 minutes
7374: loss=2.049, avg loss=2.184, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=2.5 seconds, 471936 images, time remaining=44.3 minutes
7375: loss=2.011, avg loss=2.166, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=2.3 seconds, 472000 images, time remaining=44.3 minutes
7376: loss=2.335, avg loss=2.183, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.4 seconds, 472064 images, time remaining=44.2 minutes
7377: loss=1.765, avg loss=2.141, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.4 seconds, 472128 images, time remaining=44.1 minutes
7378: loss=2.518, avg loss=2.179, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.5 seconds, 472192 images, time remaining=44 minutes
7379: loss=1.937, avg loss=2.155, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=2.2 seconds, 472256 images, time remaining=44 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7380: loss=2.450, avg loss=2.184, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.3 seconds, train=2.3 seconds, 472320 images, time remaining=43.9 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b518c00000
7381: loss=2.241, avg loss=2.190, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 472384 images, time remaining=43.8 minutes
7382: loss=2.005, avg loss=2.172, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=2.8 seconds, 472448 images, time remaining=43.7 minutes
7383: loss=1.902, avg loss=2.145, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 472512 images, time remaining=43.7 minutes
7384: loss=2.171, avg loss=2.147, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=2.9 seconds, 472576 images, time remaining=43.6 minutes
7385: loss=1.723, avg loss=2.105, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.9 seconds, 472640 images, time remaining=43.5 minutes
7386: loss=2.182, avg loss=2.113, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 472704 images, time remaining=43.5 minutes
7387: loss=2.084, avg loss=2.110, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.9 seconds, 472768 images, time remaining=43.4 minutes
7388: loss=2.425, avg loss=2.141, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.9 seconds, 472832 images, time remaining=43.3 minutes
7389: loss=1.954, avg loss=2.123, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 472896 images, time remaining=43.2 minutes
7390: loss=1.798, avg loss=2.090, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=2.8 seconds, 472960 images, time remaining=43.2 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b518c00000
7391: loss=2.093, avg loss=2.090, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.7 seconds, 473024 images, time remaining=43.1 minutes
7392: loss=2.058, avg loss=2.087, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 473088 images, time remaining=43 minutes
7393: loss=2.105, avg loss=2.089, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 473152 images, time remaining=43 minutes
7394: loss=1.909, avg loss=2.071, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=2.8 seconds, 473216 images, time remaining=42.9 minutes
7395: loss=2.343, avg loss=2.098, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.6 seconds, 473280 images, time remaining=42.8 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7396: loss=2.037, avg loss=2.092, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=4.2 seconds, train=2.8 seconds, 473344 images, time remaining=42.7 minutes
7397: loss=2.486, avg loss=2.131, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 473408 images, time remaining=42.7 minutes
7398: loss=1.865, avg loss=2.105, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 473472 images, time remaining=42.6 minutes
7399: loss=2.001, avg loss=2.094, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 473536 images, time remaining=42.5 minutes
7400: loss=1.695, avg loss=2.054, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 473600 images, time remaining=42.5 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7401: loss=2.376, avg loss=2.087, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.9 seconds, 473664 images, time remaining=42.4 minutes
7402: loss=2.547, avg loss=2.133, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.7 seconds, 473728 images, time remaining=42.3 minutes
7403: loss=2.145, avg loss=2.134, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.7 seconds, 473792 images, time remaining=42.2 minutes
7404: loss=2.071, avg loss=2.128, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.8 seconds, 473856 images, time remaining=42.2 minutes
7405: loss=2.586, avg loss=2.173, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.8 seconds, 473920 images, time remaining=42.1 minutes
7406: loss=2.345, avg loss=2.191, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.7 seconds, 473984 images, time remaining=42 minutes
7407: loss=2.066, avg loss=2.178, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.0 seconds, train=4.8 seconds, 474048 images, time remaining=42 minutes
7408: loss=2.006, avg loss=2.161, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.8 seconds, 474112 images, time remaining=41.9 minutes
7409: loss=2.725, avg loss=2.217, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.9 seconds, 474176 images, time remaining=41.8 minutes
7410: loss=2.623, avg loss=2.258, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=4.8 seconds, 474240 images, time remaining=41.8 minutes
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7411: loss=2.159, avg loss=2.248, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=5.0 seconds, train=3.9 seconds, 474304 images, time remaining=41.7 minutes
7412: loss=2.599, avg loss=2.283, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 474368 images, time remaining=41.6 minutes
7413: loss=1.750, avg loss=2.230, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.8 seconds, train=4.0 seconds, 474432 images, time remaining=41.5 minutes
7414: loss=2.493, avg loss=2.256, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.1 seconds, 474496 images, time remaining=41.5 minutes
7415: loss=1.940, avg loss=2.225, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.0 seconds, 474560 images, time remaining=41.4 minutes
7416: loss=2.363, avg loss=2.238, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.0 seconds, 474624 images, time remaining=41.3 minutes
7417: loss=2.082, avg loss=2.223, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.8 seconds, train=3.9 seconds, 474688 images, time remaining=41.3 minutes
7418: loss=2.465, avg loss=2.247, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.9 seconds, train=3.9 seconds, 474752 images, time remaining=41.2 minutes
7419: loss=2.159, avg loss=2.238, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.3 seconds, train=4.0 seconds, 474816 images, time remaining=41.1 minutes
7420: loss=2.289, avg loss=2.243, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.0 seconds, 474880 images, time remaining=41 minutes
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14b719000000
7421: loss=2.000, avg loss=2.219, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.1 seconds, train=2.2 seconds, 474944 images, time remaining=41 minutes
7422: loss=1.646, avg loss=2.162, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=2.2 seconds, 475008 images, time remaining=40.9 minutes
7423: loss=1.541, avg loss=2.100, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=2.3 seconds, 475072 images, time remaining=40.8 minutes
7424: loss=2.065, avg loss=2.096, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=2.1 seconds, 475136 images, time remaining=40.8 minutes
7425: loss=1.837, avg loss=2.070, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=2.2 seconds, 475200 images, time remaining=40.7 minutes
7426: loss=2.216, avg loss=2.085, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.2 seconds, 475264 images, time remaining=40.6 minutes
7427: loss=2.268, avg loss=2.103, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.2 seconds, 475328 images, time remaining=40.5 minutes
7428: loss=2.410, avg loss=2.134, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.2 seconds, 475392 images, time remaining=40.5 minutes
7429: loss=1.828, avg loss=2.103, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=2.1 seconds, 475456 images, time remaining=40.4 minutes
7430: loss=2.122, avg loss=2.105, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.1 seconds, train=2.2 seconds, 475520 images, time remaining=40.3 minutes
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7431: loss=1.800, avg loss=2.075, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.9 seconds, train=4.0 seconds, 475584 images, time remaining=40.2 minutes
7432: loss=2.327, avg loss=2.100, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.0 seconds, 475648 images, time remaining=40.2 minutes
7433: loss=2.225, avg loss=2.112, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.8 seconds, train=3.9 seconds, 475712 images, time remaining=40.1 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7434: loss=1.763, avg loss=2.077, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=5.7 seconds, train=3.9 seconds, 475776 images, time remaining=40 minutes
7435: loss=2.324, avg loss=2.102, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.9 seconds, train=4.0 seconds, 475840 images, time remaining=40 minutes
7436: loss=2.110, avg loss=2.103, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=3.9 seconds, 475904 images, time remaining=39.9 minutes
7437: loss=2.116, avg loss=2.104, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.0 seconds, 475968 images, time remaining=39.8 minutes
7438: loss=1.682, avg loss=2.062, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.0 seconds, 476032 images, time remaining=39.8 minutes
7439: loss=2.543, avg loss=2.110, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.0 seconds, 476096 images, time remaining=39.7 minutes
7440: loss=2.205, avg loss=2.119, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 476160 images, time remaining=39.6 minutes
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
7441: loss=1.996, avg loss=2.107, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.6 seconds, 476224 images, time remaining=39.5 minutes
7442: loss=2.019, avg loss=2.098, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.6 seconds, 476288 images, time remaining=39.5 minutes
7443: loss=1.824, avg loss=2.071, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.6 seconds, 476352 images, time remaining=39.4 minutes
7444: loss=1.984, avg loss=2.062, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.5 seconds, 476416 images, time remaining=39.3 minutes
7445: loss=1.942, avg loss=2.050, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=2.7 seconds, 476480 images, time remaining=39.2 minutes
7446: loss=2.312, avg loss=2.076, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.5 seconds, 476544 images, time remaining=39.2 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7447: loss=2.092, avg loss=2.078, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=4.0 seconds, train=2.5 seconds, 476608 images, time remaining=39.1 minutes
7448: loss=1.853, avg loss=2.055, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.6 seconds, 476672 images, time remaining=39 minutes
7449: loss=1.847, avg loss=2.035, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.6 seconds, 476736 images, time remaining=39 minutes
7450: loss=2.072, avg loss=2.038, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.6 seconds, 476800 images, time remaining=38.9 minutes
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
7451: loss=1.496, avg loss=1.984, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.6 seconds, 476864 images, time remaining=38.8 minutes
7452: loss=1.671, avg loss=1.953, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.6 seconds, 476928 images, time remaining=38.8 minutes
7453: loss=1.945, avg loss=1.952, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.6 seconds, 476992 images, time remaining=38.7 minutes
7454: loss=1.999, avg loss=1.957, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.7 seconds, 477056 images, time remaining=38.6 minutes
7455: loss=2.019, avg loss=1.963, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=2.7 seconds, 477120 images, time remaining=38.5 minutes
7456: loss=2.516, avg loss=2.018, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=2.7 seconds, 477184 images, time remaining=38.5 minutes
7457: loss=1.595, avg loss=1.976, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=2.7 seconds, 477248 images, time remaining=38.4 minutes
7458: loss=1.948, avg loss=1.973, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.4 seconds, 477312 images, time remaining=38.3 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7459: loss=2.412, avg loss=2.017, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.6 seconds, train=2.5 seconds, 477376 images, time remaining=38.2 minutes
7460: loss=2.120, avg loss=2.027, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.3 seconds, train=2.6 seconds, 477440 images, time remaining=38.2 minutes
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7461: loss=2.130, avg loss=2.038, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.8 seconds, train=4.7 seconds, 477504 images, time remaining=38.1 minutes
7462: loss=2.564, avg loss=2.090, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=4.8 seconds, 477568 images, time remaining=38 minutes
7463: loss=2.066, avg loss=2.088, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.8 seconds, 477632 images, time remaining=38 minutes
7464: loss=2.063, avg loss=2.085, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=4.7 seconds, 477696 images, time remaining=37.9 minutes
7465: loss=2.567, avg loss=2.133, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.7 seconds, train=4.8 seconds, 477760 images, time remaining=37.8 minutes
7466: loss=2.193, avg loss=2.139, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.7 seconds, 477824 images, time remaining=37.7 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7467: loss=2.605, avg loss=2.186, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=5.3 seconds, train=4.7 seconds, 477888 images, time remaining=37.7 minutes
7468: loss=2.407, avg loss=2.208, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.8 seconds, train=4.7 seconds, 477952 images, time remaining=37.6 minutes
7469: loss=2.184, avg loss=2.206, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.7 seconds, 478016 images, time remaining=37.5 minutes
7470: loss=2.377, avg loss=2.223, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=3.1 seconds, train=4.8 seconds, 478080 images, time remaining=37.5 minutes
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7471: loss=2.028, avg loss=2.203, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.3 seconds, 478144 images, time remaining=37.4 minutes
7472: loss=2.869, avg loss=2.270, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.4 seconds, 478208 images, time remaining=37.3 minutes
7473: loss=1.909, avg loss=2.234, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.3 seconds, 478272 images, time remaining=37.2 minutes
7474: loss=1.887, avg loss=2.199, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=4.2 seconds, 478336 images, time remaining=37.2 minutes
7475: loss=2.537, avg loss=2.233, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=3.4 seconds, train=4.4 seconds, 478400 images, time remaining=37.1 minutes
7476: loss=1.999, avg loss=2.209, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.3 seconds, 478464 images, time remaining=37 minutes
7477: loss=1.899, avg loss=2.178, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.3 seconds, 478528 images, time remaining=37 minutes
7478: loss=2.658, avg loss=2.226, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.8 seconds, train=4.3 seconds, 478592 images, time remaining=36.9 minutes
7479: loss=2.320, avg loss=2.236, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.8 seconds, train=4.3 seconds, 478656 images, time remaining=36.8 minutes
7480: loss=2.115, avg loss=2.224, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.5 seconds, train=4.3 seconds, 478720 images, time remaining=36.8 minutes
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b50fe00000
7481: loss=2.257, avg loss=2.227, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.6 seconds, train=1.9 seconds, 478784 images, time remaining=36.7 minutes
7482: loss=2.490, avg loss=2.253, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 478848 images, time remaining=36.6 minutes
7483: loss=2.340, avg loss=2.262, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 478912 images, time remaining=36.5 minutes
7484: loss=2.404, avg loss=2.276, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.7 seconds, train=1.9 seconds, 478976 images, time remaining=36.5 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7485: loss=1.898, avg loss=2.238, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.3 seconds, train=1.9 seconds, 479040 images, time remaining=36.4 minutes
7486: loss=2.404, avg loss=2.255, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=2.0 seconds, 479104 images, time remaining=36.3 minutes
7487: loss=2.358, avg loss=2.265, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.0 seconds, 479168 images, time remaining=36.2 minutes
7488: loss=2.672, avg loss=2.306, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=2.0 seconds, 479232 images, time remaining=36.2 minutes
7489: loss=2.441, avg loss=2.319, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.0 seconds, 479296 images, time remaining=36.1 minutes
7490: loss=1.936, avg loss=2.281, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.4 seconds, train=1.9 seconds, 479360 images, time remaining=36 minutes
Resizing, random_coef=1.40, batch=4, 768x608
GPU #0: allocating workspace: 351.1 MiB begins at 0x14bf3de00000
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7491: loss=2.206, avg loss=2.274, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=2.6 seconds, train=2.1 seconds, 479424 images, time remaining=36 minutes
7492: loss=2.325, avg loss=2.279, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.1 seconds, 479488 images, time remaining=35.9 minutes
7493: loss=2.262, avg loss=2.277, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 479552 images, time remaining=35.8 minutes
7494: loss=1.851, avg loss=2.234, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 479616 images, time remaining=35.8 minutes
7495: loss=2.054, avg loss=2.216, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.2 seconds, train=2.1 seconds, 479680 images, time remaining=35.7 minutes
7496: loss=2.561, avg loss=2.251, last=97.90%, best=97.90%, next=7496, rate=0.00001300, load 64=1.1 seconds, train=2.1 seconds, 479744 images, time remaining=35.6 minutes
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b5d9c00000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=87445, unique_truth_count=57264
rank=0 of ranks=87445rank=100 of ranks=87445rank=200 of ranks=87445rank=300 of ranks=87445rank=400 of ranks=87445rank=500 of ranks=87445rank=600 of ranks=87445rank=700 of ranks=87445rank=800 of ranks=87445rank=900 of ranks=87445rank=1000 of ranks=87445rank=1100 of ranks=87445rank=1200 of ranks=87445rank=1300 of ranks=87445rank=1400 of ranks=87445rank=1500 of ranks=87445rank=1600 of ranks=87445rank=1700 of ranks=87445rank=1800 of ranks=87445rank=1900 of ranks=87445rank=2000 of ranks=87445rank=2100 of ranks=87445rank=2200 of ranks=87445rank=2300 of ranks=87445rank=2400 of ranks=87445rank=2500 of ranks=87445rank=2600 of ranks=87445rank=2700 of ranks=87445rank=2800 of ranks=87445rank=2900 of ranks=87445rank=3000 of ranks=87445rank=3100 of ranks=87445rank=3200 of ranks=87445rank=3300 of ranks=87445rank=3400 of ranks=87445rank=3500 of ranks=87445rank=3600 of ranks=87445rank=3700 of ranks=87445rank=3800 of ranks=87445rank=3900 of ranks=87445rank=4000 of ranks=87445rank=4100 of ranks=87445rank=4200 of ranks=87445rank=4300 of ranks=87445rank=4400 of ranks=87445rank=4500 of ranks=87445rank=4600 of ranks=87445rank=4700 of ranks=87445rank=4800 of ranks=87445rank=4900 of ranks=87445rank=5000 of ranks=87445rank=5100 of ranks=87445rank=5200 of ranks=87445rank=5300 of ranks=87445rank=5400 of ranks=87445rank=5500 of ranks=87445rank=5600 of ranks=87445rank=5700 of ranks=87445rank=5800 of ranks=87445rank=5900 of ranks=87445rank=6000 of ranks=87445rank=6100 of ranks=87445rank=6200 of ranks=87445rank=6300 of ranks=87445rank=6400 of ranks=87445rank=6500 of ranks=87445rank=6600 of ranks=87445rank=6700 of ranks=87445rank=6800 of ranks=87445rank=6900 of ranks=87445rank=7000 of ranks=87445rank=7100 of ranks=87445rank=7200 of ranks=87445rank=7300 of ranks=87445rank=7400 of ranks=87445rank=7500 of ranks=87445rank=7600 of ranks=87445rank=7700 of ranks=87445rank=7800 of ranks=87445rank=7900 of ranks=87445rank=8000 of ranks=87445rank=8100 of ranks=87445rank=8200 of ranks=87445rank=8300 of ranks=87445rank=8400 of ranks=87445rank=8500 of ranks=87445rank=8600 of ranks=87445rank=8700 of ranks=87445rank=8800 of ranks=87445rank=8900 of ranks=87445rank=9000 of ranks=87445rank=9100 of ranks=87445rank=9200 of ranks=87445rank=9300 of ranks=87445rank=9400 of ranks=87445rank=9500 of ranks=87445rank=9600 of ranks=87445rank=9700 of ranks=87445rank=9800 of ranks=87445rank=9900 of ranks=87445rank=10000 of ranks=87445rank=10100 of ranks=87445rank=10200 of ranks=87445rank=10300 of ranks=87445rank=10400 of ranks=87445rank=10500 of ranks=87445rank=10600 of ranks=87445rank=10700 of ranks=87445rank=10800 of ranks=87445rank=10900 of ranks=87445rank=11000 of ranks=87445rank=11100 of ranks=87445rank=11200 of ranks=87445rank=11300 of ranks=87445rank=11400 of ranks=87445rank=11500 of ranks=87445rank=11600 of ranks=87445rank=11700 of ranks=87445rank=11800 of ranks=87445rank=11900 of ranks=87445rank=12000 of ranks=87445rank=12100 of ranks=87445rank=12200 of ranks=87445rank=12300 of ranks=87445rank=12400 of ranks=87445rank=12500 of ranks=87445rank=12600 of ranks=87445rank=12700 of ranks=87445rank=12800 of ranks=87445rank=12900 of ranks=87445rank=13000 of ranks=87445rank=13100 of ranks=87445rank=13200 of ranks=87445rank=13300 of ranks=87445rank=13400 of ranks=87445rank=13500 of ranks=87445rank=13600 of ranks=87445rank=13700 of ranks=87445rank=13800 of ranks=87445rank=13900 of ranks=87445rank=14000 of ranks=87445rank=14100 of ranks=87445rank=14200 of ranks=87445rank=14300 of ranks=87445rank=14400 of ranks=87445rank=14500 of ranks=87445rank=14600 of ranks=87445rank=14700 of ranks=87445rank=14800 of ranks=87445rank=14900 of ranks=87445rank=15000 of ranks=87445rank=15100 of ranks=87445rank=15200 of ranks=87445rank=15300 of ranks=87445rank=15400 of ranks=87445rank=15500 of ranks=87445rank=15600 of ranks=87445rank=15700 of ranks=87445rank=15800 of ranks=87445rank=15900 of ranks=87445rank=16000 of ranks=87445rank=16100 of ranks=87445rank=16200 of ranks=87445rank=16300 of ranks=87445rank=16400 of ranks=87445rank=16500 of ranks=87445rank=16600 of ranks=87445rank=16700 of ranks=87445rank=16800 of ranks=87445rank=16900 of ranks=87445rank=17000 of ranks=87445rank=17100 of ranks=87445rank=17200 of ranks=87445rank=17300 of ranks=87445rank=17400 of ranks=87445rank=17500 of ranks=87445rank=17600 of ranks=87445rank=17700 of ranks=87445rank=17800 of ranks=87445rank=17900 of ranks=87445rank=18000 of ranks=87445rank=18100 of ranks=87445rank=18200 of ranks=87445rank=18300 of ranks=87445rank=18400 of ranks=87445rank=18500 of ranks=87445rank=18600 of ranks=87445rank=18700 of ranks=87445rank=18800 of ranks=87445rank=18900 of ranks=87445rank=19000 of ranks=87445rank=19100 of ranks=87445rank=19200 of ranks=87445rank=19300 of ranks=87445rank=19400 of ranks=87445rank=19500 of ranks=87445rank=19600 of ranks=87445rank=19700 of ranks=87445rank=19800 of ranks=87445rank=19900 of ranks=87445rank=20000 of ranks=87445rank=20100 of ranks=87445rank=20200 of ranks=87445rank=20300 of ranks=87445rank=20400 of ranks=87445rank=20500 of ranks=87445rank=20600 of ranks=87445rank=20700 of ranks=87445rank=20800 of ranks=87445rank=20900 of ranks=87445rank=21000 of ranks=87445rank=21100 of ranks=87445rank=21200 of ranks=87445rank=21300 of ranks=87445rank=21400 of ranks=87445rank=21500 of ranks=87445rank=21600 of ranks=87445rank=21700 of ranks=87445rank=21800 of ranks=87445rank=21900 of ranks=87445rank=22000 of ranks=87445rank=22100 of ranks=87445rank=22200 of ranks=87445rank=22300 of ranks=87445rank=22400 of ranks=87445rank=22500 of ranks=87445rank=22600 of ranks=87445rank=22700 of ranks=87445rank=22800 of ranks=87445rank=22900 of ranks=87445rank=23000 of ranks=87445rank=23100 of ranks=87445rank=23200 of ranks=87445rank=23300 of ranks=87445rank=23400 of ranks=87445rank=23500 of ranks=87445rank=23600 of ranks=87445rank=23700 of ranks=87445rank=23800 of ranks=87445rank=23900 of ranks=87445rank=24000 of ranks=87445rank=24100 of ranks=87445rank=24200 of ranks=87445rank=24300 of ranks=87445rank=24400 of ranks=87445rank=24500 of ranks=87445rank=24600 of ranks=87445rank=24700 of ranks=87445rank=24800 of ranks=87445rank=24900 of ranks=87445rank=25000 of ranks=87445rank=25100 of ranks=87445rank=25200 of ranks=87445rank=25300 of ranks=87445rank=25400 of ranks=87445rank=25500 of ranks=87445rank=25600 of ranks=87445rank=25700 of ranks=87445rank=25800 of ranks=87445rank=25900 of ranks=87445rank=26000 of ranks=87445rank=26100 of ranks=87445rank=26200 of ranks=87445rank=26300 of ranks=87445rank=26400 of ranks=87445rank=26500 of ranks=87445rank=26600 of ranks=87445rank=26700 of ranks=87445rank=26800 of ranks=87445rank=26900 of ranks=87445rank=27000 of ranks=87445rank=27100 of ranks=87445rank=27200 of ranks=87445rank=27300 of ranks=87445rank=27400 of ranks=87445rank=27500 of ranks=87445rank=27600 of ranks=87445rank=27700 of ranks=87445rank=27800 of ranks=87445rank=27900 of ranks=87445rank=28000 of ranks=87445rank=28100 of ranks=87445rank=28200 of ranks=87445rank=28300 of ranks=87445rank=28400 of ranks=87445rank=28500 of ranks=87445rank=28600 of ranks=87445rank=28700 of ranks=87445rank=28800 of ranks=87445rank=28900 of ranks=87445rank=29000 of ranks=87445rank=29100 of ranks=87445rank=29200 of ranks=87445rank=29300 of ranks=87445rank=29400 of ranks=87445rank=29500 of ranks=87445rank=29600 of ranks=87445rank=29700 of ranks=87445rank=29800 of ranks=87445rank=29900 of ranks=87445rank=30000 of ranks=87445rank=30100 of ranks=87445rank=30200 of ranks=87445rank=30300 of ranks=87445rank=30400 of ranks=87445rank=30500 of ranks=87445rank=30600 of ranks=87445rank=30700 of ranks=87445rank=30800 of ranks=87445rank=30900 of ranks=87445rank=31000 of ranks=87445rank=31100 of ranks=87445rank=31200 of ranks=87445rank=31300 of ranks=87445rank=31400 of ranks=87445rank=31500 of ranks=87445rank=31600 of ranks=87445rank=31700 of ranks=87445rank=31800 of ranks=87445rank=31900 of ranks=87445rank=32000 of ranks=87445rank=32100 of ranks=87445rank=32200 of ranks=87445rank=32300 of ranks=87445rank=32400 of ranks=87445rank=32500 of ranks=87445rank=32600 of ranks=87445rank=32700 of ranks=87445rank=32800 of ranks=87445rank=32900 of ranks=87445rank=33000 of ranks=87445rank=33100 of ranks=87445rank=33200 of ranks=87445rank=33300 of ranks=87445rank=33400 of ranks=87445rank=33500 of ranks=87445rank=33600 of ranks=87445rank=33700 of ranks=87445rank=33800 of ranks=87445rank=33900 of ranks=87445rank=34000 of ranks=87445rank=34100 of ranks=87445rank=34200 of ranks=87445rank=34300 of ranks=87445rank=34400 of ranks=87445rank=34500 of ranks=87445rank=34600 of ranks=87445rank=34700 of ranks=87445rank=34800 of ranks=87445rank=34900 of ranks=87445rank=35000 of ranks=87445rank=35100 of ranks=87445rank=35200 of ranks=87445rank=35300 of ranks=87445rank=35400 of ranks=87445rank=35500 of ranks=87445rank=35600 of ranks=87445rank=35700 of ranks=87445rank=35800 of ranks=87445rank=35900 of ranks=87445rank=36000 of ranks=87445rank=36100 of ranks=87445rank=36200 of ranks=87445rank=36300 of ranks=87445rank=36400 of ranks=87445rank=36500 of ranks=87445rank=36600 of ranks=87445rank=36700 of ranks=87445rank=36800 of ranks=87445rank=36900 of ranks=87445rank=37000 of ranks=87445rank=37100 of ranks=87445rank=37200 of ranks=87445rank=37300 of ranks=87445rank=37400 of ranks=87445rank=37500 of ranks=87445rank=37600 of ranks=87445rank=37700 of ranks=87445rank=37800 of ranks=87445rank=37900 of ranks=87445rank=38000 of ranks=87445rank=38100 of ranks=87445rank=38200 of ranks=87445rank=38300 of ranks=87445rank=38400 of ranks=87445rank=38500 of ranks=87445rank=38600 of ranks=87445rank=38700 of ranks=87445rank=38800 of ranks=87445rank=38900 of ranks=87445rank=39000 of ranks=87445rank=39100 of ranks=87445rank=39200 of ranks=87445rank=39300 of ranks=87445rank=39400 of ranks=87445rank=39500 of ranks=87445rank=39600 of ranks=87445rank=39700 of ranks=87445rank=39800 of ranks=87445rank=39900 of ranks=87445rank=40000 of ranks=87445rank=40100 of ranks=87445rank=40200 of ranks=87445rank=40300 of ranks=87445rank=40400 of ranks=87445rank=40500 of ranks=87445rank=40600 of ranks=87445rank=40700 of ranks=87445rank=40800 of ranks=87445rank=40900 of ranks=87445rank=41000 of ranks=87445rank=41100 of ranks=87445rank=41200 of ranks=87445rank=41300 of ranks=87445rank=41400 of ranks=87445rank=41500 of ranks=87445rank=41600 of ranks=87445rank=41700 of ranks=87445rank=41800 of ranks=87445rank=41900 of ranks=87445rank=42000 of ranks=87445rank=42100 of ranks=87445rank=42200 of ranks=87445rank=42300 of ranks=87445rank=42400 of ranks=87445rank=42500 of ranks=87445rank=42600 of ranks=87445rank=42700 of ranks=87445rank=42800 of ranks=87445rank=42900 of ranks=87445rank=43000 of ranks=87445rank=43100 of ranks=87445rank=43200 of ranks=87445rank=43300 of ranks=87445rank=43400 of ranks=87445rank=43500 of ranks=87445rank=43600 of ranks=87445rank=43700 of ranks=87445rank=43800 of ranks=87445rank=43900 of ranks=87445rank=44000 of ranks=87445rank=44100 of ranks=87445rank=44200 of ranks=87445rank=44300 of ranks=87445rank=44400 of ranks=87445rank=44500 of ranks=87445rank=44600 of ranks=87445rank=44700 of ranks=87445rank=44800 of ranks=87445rank=44900 of ranks=87445rank=45000 of ranks=87445rank=45100 of ranks=87445rank=45200 of ranks=87445rank=45300 of ranks=87445rank=45400 of ranks=87445rank=45500 of ranks=87445rank=45600 of ranks=87445rank=45700 of ranks=87445rank=45800 of ranks=87445rank=45900 of ranks=87445rank=46000 of ranks=87445rank=46100 of ranks=87445rank=46200 of ranks=87445rank=46300 of ranks=87445rank=46400 of ranks=87445rank=46500 of ranks=87445rank=46600 of ranks=87445rank=46700 of ranks=87445rank=46800 of ranks=87445rank=46900 of ranks=87445rank=47000 of ranks=87445rank=47100 of ranks=87445rank=47200 of ranks=87445rank=47300 of ranks=87445rank=47400 of ranks=87445rank=47500 of ranks=87445rank=47600 of ranks=87445rank=47700 of ranks=87445rank=47800 of ranks=87445rank=47900 of ranks=87445rank=48000 of ranks=87445rank=48100 of ranks=87445rank=48200 of ranks=87445rank=48300 of ranks=87445rank=48400 of ranks=87445rank=48500 of ranks=87445rank=48600 of ranks=87445rank=48700 of ranks=87445rank=48800 of ranks=87445rank=48900 of ranks=87445rank=49000 of ranks=87445rank=49100 of ranks=87445rank=49200 of ranks=87445rank=49300 of ranks=87445rank=49400 of ranks=87445rank=49500 of ranks=87445rank=49600 of ranks=87445rank=49700 of ranks=87445rank=49800 of ranks=87445rank=49900 of ranks=87445rank=50000 of ranks=87445rank=50100 of ranks=87445rank=50200 of ranks=87445rank=50300 of ranks=87445rank=50400 of ranks=87445rank=50500 of ranks=87445rank=50600 of ranks=87445rank=50700 of ranks=87445rank=50800 of ranks=87445rank=50900 of ranks=87445rank=51000 of ranks=87445rank=51100 of ranks=87445rank=51200 of ranks=87445rank=51300 of ranks=87445rank=51400 of ranks=87445rank=51500 of ranks=87445rank=51600 of ranks=87445rank=51700 of ranks=87445rank=51800 of ranks=87445rank=51900 of ranks=87445rank=52000 of ranks=87445rank=52100 of ranks=87445rank=52200 of ranks=87445rank=52300 of ranks=87445rank=52400 of ranks=87445rank=52500 of ranks=87445rank=52600 of ranks=87445rank=52700 of ranks=87445rank=52800 of ranks=87445rank=52900 of ranks=87445rank=53000 of ranks=87445rank=53100 of ranks=87445rank=53200 of ranks=87445rank=53300 of ranks=87445rank=53400 of ranks=87445rank=53500 of ranks=87445rank=53600 of ranks=87445rank=53700 of ranks=87445rank=53800 of ranks=87445rank=53900 of ranks=87445rank=54000 of ranks=87445rank=54100 of ranks=87445rank=54200 of ranks=87445rank=54300 of ranks=87445rank=54400 of ranks=87445rank=54500 of ranks=87445rank=54600 of ranks=87445rank=54700 of ranks=87445rank=54800 of ranks=87445rank=54900 of ranks=87445rank=55000 of ranks=87445rank=55100 of ranks=87445rank=55200 of ranks=87445rank=55300 of ranks=87445rank=55400 of ranks=87445rank=55500 of ranks=87445rank=55600 of ranks=87445rank=55700 of ranks=87445rank=55800 of ranks=87445rank=55900 of ranks=87445rank=56000 of ranks=87445rank=56100 of ranks=87445rank=56200 of ranks=87445rank=56300 of ranks=87445rank=56400 of ranks=87445rank=56500 of ranks=87445rank=56600 of ranks=87445rank=56700 of ranks=87445rank=56800 of ranks=87445rank=56900 of ranks=87445rank=57000 of ranks=87445rank=57100 of ranks=87445rank=57200 of ranks=87445rank=57300 of ranks=87445rank=57400 of ranks=87445rank=57500 of ranks=87445rank=57600 of ranks=87445rank=57700 of ranks=87445rank=57800 of ranks=87445rank=57900 of ranks=87445rank=58000 of ranks=87445rank=58100 of ranks=87445rank=58200 of ranks=87445rank=58300 of ranks=87445rank=58400 of ranks=87445rank=58500 of ranks=87445rank=58600 of ranks=87445rank=58700 of ranks=87445rank=58800 of ranks=87445rank=58900 of ranks=87445rank=59000 of ranks=87445rank=59100 of ranks=87445rank=59200 of ranks=87445rank=59300 of ranks=87445rank=59400 of ranks=87445rank=59500 of ranks=87445rank=59600 of ranks=87445rank=59700 of ranks=87445rank=59800 of ranks=87445rank=59900 of ranks=87445rank=60000 of ranks=87445rank=60100 of ranks=87445rank=60200 of ranks=87445rank=60300 of ranks=87445rank=60400 of ranks=87445rank=60500 of ranks=87445rank=60600 of ranks=87445rank=60700 of ranks=87445rank=60800 of ranks=87445rank=60900 of ranks=87445rank=61000 of ranks=87445rank=61100 of ranks=87445rank=61200 of ranks=87445rank=61300 of ranks=87445rank=61400 of ranks=87445rank=61500 of ranks=87445rank=61600 of ranks=87445rank=61700 of ranks=87445rank=61800 of ranks=87445rank=61900 of ranks=87445rank=62000 of ranks=87445rank=62100 of ranks=87445rank=62200 of ranks=87445rank=62300 of ranks=87445rank=62400 of ranks=87445rank=62500 of ranks=87445rank=62600 of ranks=87445rank=62700 of ranks=87445rank=62800 of ranks=87445rank=62900 of ranks=87445rank=63000 of ranks=87445rank=63100 of ranks=87445rank=63200 of ranks=87445rank=63300 of ranks=87445rank=63400 of ranks=87445rank=63500 of ranks=87445rank=63600 of ranks=87445rank=63700 of ranks=87445rank=63800 of ranks=87445rank=63900 of ranks=87445rank=64000 of ranks=87445rank=64100 of ranks=87445rank=64200 of ranks=87445rank=64300 of ranks=87445rank=64400 of ranks=87445rank=64500 of ranks=87445rank=64600 of ranks=87445rank=64700 of ranks=87445rank=64800 of ranks=87445rank=64900 of ranks=87445rank=65000 of ranks=87445rank=65100 of ranks=87445rank=65200 of ranks=87445rank=65300 of ranks=87445rank=65400 of ranks=87445rank=65500 of ranks=87445rank=65600 of ranks=87445rank=65700 of ranks=87445rank=65800 of ranks=87445rank=65900 of ranks=87445rank=66000 of ranks=87445rank=66100 of ranks=87445rank=66200 of ranks=87445rank=66300 of ranks=87445rank=66400 of ranks=87445rank=66500 of ranks=87445rank=66600 of ranks=87445rank=66700 of ranks=87445rank=66800 of ranks=87445rank=66900 of ranks=87445rank=67000 of ranks=87445rank=67100 of ranks=87445rank=67200 of ranks=87445rank=67300 of ranks=87445rank=67400 of ranks=87445rank=67500 of ranks=87445rank=67600 of ranks=87445rank=67700 of ranks=87445rank=67800 of ranks=87445rank=67900 of ranks=87445rank=68000 of ranks=87445rank=68100 of ranks=87445rank=68200 of ranks=87445rank=68300 of ranks=87445rank=68400 of ranks=87445rank=68500 of ranks=87445rank=68600 of ranks=87445rank=68700 of ranks=87445rank=68800 of ranks=87445rank=68900 of ranks=87445rank=69000 of ranks=87445rank=69100 of ranks=87445rank=69200 of ranks=87445rank=69300 of ranks=87445rank=69400 of ranks=87445rank=69500 of ranks=87445rank=69600 of ranks=87445rank=69700 of ranks=87445rank=69800 of ranks=87445rank=69900 of ranks=87445rank=70000 of ranks=87445rank=70100 of ranks=87445rank=70200 of ranks=87445rank=70300 of ranks=87445rank=70400 of ranks=87445rank=70500 of ranks=87445rank=70600 of ranks=87445rank=70700 of ranks=87445rank=70800 of ranks=87445rank=70900 of ranks=87445rank=71000 of ranks=87445rank=71100 of ranks=87445rank=71200 of ranks=87445rank=71300 of ranks=87445rank=71400 of ranks=87445rank=71500 of ranks=87445rank=71600 of ranks=87445rank=71700 of ranks=87445rank=71800 of ranks=87445rank=71900 of ranks=87445rank=72000 of ranks=87445rank=72100 of ranks=87445rank=72200 of ranks=87445rank=72300 of ranks=87445rank=72400 of ranks=87445rank=72500 of ranks=87445rank=72600 of ranks=87445rank=72700 of ranks=87445rank=72800 of ranks=87445rank=72900 of ranks=87445rank=73000 of ranks=87445rank=73100 of ranks=87445rank=73200 of ranks=87445rank=73300 of ranks=87445rank=73400 of ranks=87445rank=73500 of ranks=87445rank=73600 of ranks=87445rank=73700 of ranks=87445rank=73800 of ranks=87445rank=73900 of ranks=87445rank=74000 of ranks=87445rank=74100 of ranks=87445rank=74200 of ranks=87445rank=74300 of ranks=87445rank=74400 of ranks=87445rank=74500 of ranks=87445rank=74600 of ranks=87445rank=74700 of ranks=87445rank=74800 of ranks=87445rank=74900 of ranks=87445rank=75000 of ranks=87445rank=75100 of ranks=87445rank=75200 of ranks=87445rank=75300 of ranks=87445rank=75400 of ranks=87445rank=75500 of ranks=87445rank=75600 of ranks=87445rank=75700 of ranks=87445rank=75800 of ranks=87445rank=75900 of ranks=87445rank=76000 of ranks=87445rank=76100 of ranks=87445rank=76200 of ranks=87445rank=76300 of ranks=87445rank=76400 of ranks=87445rank=76500 of ranks=87445rank=76600 of ranks=87445rank=76700 of ranks=87445rank=76800 of ranks=87445rank=76900 of ranks=87445rank=77000 of ranks=87445rank=77100 of ranks=87445rank=77200 of ranks=87445rank=77300 of ranks=87445rank=77400 of ranks=87445rank=77500 of ranks=87445rank=77600 of ranks=87445rank=77700 of ranks=87445rank=77800 of ranks=87445rank=77900 of ranks=87445rank=78000 of ranks=87445rank=78100 of ranks=87445rank=78200 of ranks=87445rank=78300 of ranks=87445rank=78400 of ranks=87445rank=78500 of ranks=87445rank=78600 of ranks=87445rank=78700 of ranks=87445rank=78800 of ranks=87445rank=78900 of ranks=87445rank=79000 of ranks=87445rank=79100 of ranks=87445rank=79200 of ranks=87445rank=79300 of ranks=87445rank=79400 of ranks=87445rank=79500 of ranks=87445rank=79600 of ranks=87445rank=79700 of ranks=87445rank=79800 of ranks=87445rank=79900 of ranks=87445rank=80000 of ranks=87445rank=80100 of ranks=87445rank=80200 of ranks=87445rank=80300 of ranks=87445rank=80400 of ranks=87445rank=80500 of ranks=87445rank=80600 of ranks=87445rank=80700 of ranks=87445rank=80800 of ranks=87445rank=80900 of ranks=87445rank=81000 of ranks=87445rank=81100 of ranks=87445rank=81200 of ranks=87445rank=81300 of ranks=87445rank=81400 of ranks=87445rank=81500 of ranks=87445rank=81600 of ranks=87445rank=81700 of ranks=87445rank=81800 of ranks=87445rank=81900 of ranks=87445rank=82000 of ranks=87445rank=82100 of ranks=87445rank=82200 of ranks=87445rank=82300 of ranks=87445rank=82400 of ranks=87445rank=82500 of ranks=87445rank=82600 of ranks=87445rank=82700 of ranks=87445rank=82800 of ranks=87445rank=82900 of ranks=87445rank=83000 of ranks=87445rank=83100 of ranks=87445rank=83200 of ranks=87445rank=83300 of ranks=87445rank=83400 of ranks=87445rank=83500 of ranks=87445rank=83600 of ranks=87445rank=83700 of ranks=87445rank=83800 of ranks=87445rank=83900 of ranks=87445rank=84000 of ranks=87445rank=84100 of ranks=87445rank=84200 of ranks=87445rank=84300 of ranks=87445rank=84400 of ranks=87445rank=84500 of ranks=87445rank=84600 of ranks=87445rank=84700 of ranks=87445rank=84800 of ranks=87445rank=84900 of ranks=87445rank=85000 of ranks=87445rank=85100 of ranks=87445rank=85200 of ranks=87445rank=85300 of ranks=87445rank=85400 of ranks=87445rank=85500 of ranks=87445rank=85600 of ranks=87445rank=85700 of ranks=87445rank=85800 of ranks=87445rank=85900 of ranks=87445rank=86000 of ranks=87445rank=86100 of ranks=87445rank=86200 of ranks=87445rank=86300 of ranks=87445rank=86400 of ranks=87445rank=86500 of ranks=87445rank=86600 of ranks=87445rank=86700 of ranks=87445rank=86800 of ranks=87445rank=86900 of ranks=87445rank=87000 of ranks=87445rank=87100 of ranks=87445rank=87200 of ranks=87445rank=87300 of ranks=87445rank=87400 of ranks=87445

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              97.2814    489    841      9    498           79.3710
   1 car                    98.8057  50031  21277    285  50316           84.9326
   2 truck                  98.7251   1813   2566     12   1825           77.6482
   3 bus                    96.8130    361   1769      5    366           71.3175
   4 pedestrian             97.2252   4177   4121     82   4259           77.4738

for conf_thresh=0.25, precision=0.92, recall=0.96, F1 score=0.94
for conf_thresh=0.25, TP=55200, FP=4658, FN=2064, average IoU=84.00%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=97.77%
Total detection time: 119 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
7497: loss=2.144, avg loss=2.240, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.9 seconds, 479808 images, time remaining=35.7 minutes
7498: loss=2.362, avg loss=2.252, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 479872 images, time remaining=35.6 minutes
7499: loss=2.144, avg loss=2.241, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 479936 images, time remaining=35.5 minutes
7500: loss=2.024, avg loss=2.220, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.9 seconds, 480000 images, time remaining=35.5 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 896x704
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b5d9c00000
7501: loss=2.105, avg loss=2.208, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.7 seconds, 480064 images, time remaining=35.4 minutes
7502: loss=2.282, avg loss=2.216, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.7 seconds, 480128 images, time remaining=35.3 minutes
7503: loss=1.449, avg loss=2.139, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.7 seconds, 480192 images, time remaining=35.2 minutes
7504: loss=1.489, avg loss=2.074, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.6 seconds, 480256 images, time remaining=35.1 minutes
7505: loss=2.300, avg loss=2.097, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.6 seconds, 480320 images, time remaining=35.1 minutes
7506: loss=2.138, avg loss=2.101, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.6 seconds, 480384 images, time remaining=35 minutes
7507: loss=1.961, avg loss=2.087, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.7 seconds, 480448 images, time remaining=34.9 minutes
7508: loss=1.872, avg loss=2.065, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.6 seconds, 480512 images, time remaining=34.9 minutes
7509: loss=2.337, avg loss=2.092, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=2.7 seconds, 480576 images, time remaining=34.8 minutes
7510: loss=2.514, avg loss=2.135, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.5 seconds, 480640 images, time remaining=34.7 minutes
Resizing, random_coef=1.40, batch=4, 768x576
GPU #0: allocating workspace: 4.2 GiB begins at 0x14b5d9c00000
7511: loss=2.316, avg loss=2.153, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.1 seconds, 480704 images, time remaining=34.6 minutes
7512: loss=2.185, avg loss=2.156, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=2.2 seconds, 480768 images, time remaining=34.6 minutes
7513: loss=2.158, avg loss=2.156, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 480832 images, time remaining=34.5 minutes
7514: loss=2.583, avg loss=2.199, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.1 seconds, 480896 images, time remaining=34.4 minutes
7515: loss=2.459, avg loss=2.225, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.3 seconds, 480960 images, time remaining=34.3 minutes
7516: loss=2.303, avg loss=2.233, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 481024 images, time remaining=34.3 minutes
7517: loss=2.742, avg loss=2.284, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.1 seconds, 481088 images, time remaining=34.2 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7518: loss=1.683, avg loss=2.224, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=3.9 seconds, train=2.3 seconds, 481152 images, time remaining=34.1 minutes
7519: loss=2.555, avg loss=2.257, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.3 seconds, 481216 images, time remaining=34.1 minutes
7520: loss=2.385, avg loss=2.270, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.2 seconds, 481280 images, time remaining=34 minutes
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b50a000000
7521: loss=2.275, avg loss=2.270, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.1 seconds, 481344 images, time remaining=33.9 minutes
7522: loss=2.168, avg loss=2.260, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.2 seconds, 481408 images, time remaining=33.8 minutes
7523: loss=2.323, avg loss=2.266, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 481472 images, time remaining=33.8 minutes
7524: loss=2.208, avg loss=2.260, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.2 seconds, 481536 images, time remaining=33.7 minutes
7525: loss=1.874, avg loss=2.222, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.1 seconds, 481600 images, time remaining=33.6 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7526: loss=1.965, avg loss=2.196, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=4.1 seconds, train=2.1 seconds, 481664 images, time remaining=33.6 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7527: loss=1.971, avg loss=2.174, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=2.1 seconds, train=2.1 seconds, 481728 images, time remaining=33.5 minutes
7528: loss=2.337, avg loss=2.190, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.2 seconds, 481792 images, time remaining=33.4 minutes
7529: loss=2.107, avg loss=2.182, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 481856 images, time remaining=33.3 minutes
7530: loss=2.510, avg loss=2.215, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.1 seconds, 481920 images, time remaining=33.3 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b648e00000
7531: loss=2.308, avg loss=2.224, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 481984 images, time remaining=33.2 minutes
7532: loss=2.446, avg loss=2.246, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 482048 images, time remaining=33.1 minutes
7533: loss=2.161, avg loss=2.238, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 482112 images, time remaining=33 minutes
7534: loss=2.212, avg loss=2.235, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 482176 images, time remaining=33 minutes
7535: loss=2.241, avg loss=2.236, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.6 seconds, 482240 images, time remaining=32.9 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7536: loss=2.044, avg loss=2.217, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=3.2 seconds, train=2.8 seconds, 482304 images, time remaining=32.8 minutes
7537: loss=2.369, avg loss=2.232, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 482368 images, time remaining=32.8 minutes
7538: loss=2.057, avg loss=2.214, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=2.8 seconds, 482432 images, time remaining=32.7 minutes
7539: loss=1.966, avg loss=2.190, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.7 seconds, 482496 images, time remaining=32.6 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7540: loss=2.000, avg loss=2.171, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=4.6 seconds, train=2.8 seconds, 482560 images, time remaining=32.5 minutes
Resizing, random_coef=1.40, batch=4, 1216x928
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7541: loss=2.248, avg loss=2.178, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.9 seconds, train=4.7 seconds, 482624 images, time remaining=32.5 minutes
7542: loss=2.393, avg loss=2.200, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=4.8 seconds, 482688 images, time remaining=32.4 minutes
7543: loss=2.264, avg loss=2.206, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=4.8 seconds, 482752 images, time remaining=32.3 minutes
7544: loss=2.782, avg loss=2.264, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.9 seconds, 482816 images, time remaining=32.3 minutes
7545: loss=2.525, avg loss=2.290, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=4.8 seconds, 482880 images, time remaining=32.2 minutes
7546: loss=2.596, avg loss=2.321, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=4.7 seconds, 482944 images, time remaining=32.1 minutes
7547: loss=2.231, avg loss=2.312, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=4.8 seconds, 483008 images, time remaining=32.1 minutes
7548: loss=2.271, avg loss=2.308, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=4.8 seconds, 483072 images, time remaining=32 minutes
7549: loss=2.056, avg loss=2.282, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=4.7 seconds, 483136 images, time remaining=31.9 minutes
7550: loss=2.018, avg loss=2.256, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.7 seconds, 483200 images, time remaining=31.9 minutes
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7551: loss=2.091, avg loss=2.239, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=4.3 seconds, 483264 images, time remaining=31.8 minutes
7552: loss=2.411, avg loss=2.256, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=4.4 seconds, 483328 images, time remaining=31.7 minutes
7553: loss=2.037, avg loss=2.235, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=4.2 seconds, 483392 images, time remaining=31.6 minutes
7554: loss=1.938, avg loss=2.205, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=2.1 seconds, train=4.3 seconds, 483456 images, time remaining=31.6 minutes
7555: loss=2.497, avg loss=2.234, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.3 seconds, 483520 images, time remaining=31.5 minutes
7556: loss=2.150, avg loss=2.226, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=4.4 seconds, 483584 images, time remaining=31.4 minutes
7557: loss=2.420, avg loss=2.245, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=4.4 seconds, 483648 images, time remaining=31.3 minutes
7558: loss=2.388, avg loss=2.259, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=4.3 seconds, 483712 images, time remaining=31.3 minutes
7559: loss=2.339, avg loss=2.267, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=4.4 seconds, 483776 images, time remaining=31.2 minutes
7560: loss=2.365, avg loss=2.277, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=4.4 seconds, 483840 images, time remaining=31.1 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
7561: loss=2.253, avg loss=2.275, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 483904 images, time remaining=31.1 minutes
7562: loss=1.904, avg loss=2.238, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.7 seconds, 483968 images, time remaining=31 minutes
7563: loss=2.212, avg loss=2.235, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=2.6 seconds, train=2.8 seconds, 484032 images, time remaining=30.9 minutes
7564: loss=2.198, avg loss=2.231, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=2.7 seconds, 484096 images, time remaining=30.9 minutes
7565: loss=1.974, avg loss=2.206, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=2.7 seconds, 484160 images, time remaining=30.8 minutes
7566: loss=2.165, avg loss=2.202, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=2.9 seconds, 484224 images, time remaining=30.7 minutes
7567: loss=2.699, avg loss=2.251, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=2.9 seconds, 484288 images, time remaining=30.6 minutes
7568: loss=2.470, avg loss=2.273, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.9 seconds, 484352 images, time remaining=30.6 minutes
7569: loss=2.138, avg loss=2.260, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 484416 images, time remaining=30.5 minutes
7570: loss=2.044, avg loss=2.238, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 484480 images, time remaining=30.4 minutes
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b8b9a00000
7571: loss=1.989, avg loss=2.213, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.1 seconds, train=1.9 seconds, 484544 images, time remaining=30.3 minutes
7572: loss=2.493, avg loss=2.241, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.1 seconds, train=1.9 seconds, 484608 images, time remaining=30.3 minutes
7573: loss=1.945, avg loss=2.211, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 484672 images, time remaining=30.2 minutes
7574: loss=2.439, avg loss=2.234, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 484736 images, time remaining=30.1 minutes
7575: loss=2.492, avg loss=2.260, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 484800 images, time remaining=30.1 minutes
7576: loss=2.282, avg loss=2.262, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=1.9 seconds, 484864 images, time remaining=30 minutes
7577: loss=1.644, avg loss=2.200, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 484928 images, time remaining=29.9 minutes
7578: loss=2.142, avg loss=2.195, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=1.9 seconds, 484992 images, time remaining=29.9 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7579: loss=1.787, avg loss=2.154, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=2.8 seconds, train=1.9 seconds, 485056 images, time remaining=29.8 minutes
7580: loss=1.858, avg loss=2.124, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=2.0 seconds, 485120 images, time remaining=29.7 minutes
Resizing, random_coef=1.40, batch=4, 1056x832
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7581: loss=2.210, avg loss=2.133, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.0 seconds, 485184 images, time remaining=29.6 minutes
7582: loss=1.860, avg loss=2.106, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=4.0 seconds, 485248 images, time remaining=29.6 minutes
7583: loss=2.073, avg loss=2.102, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.0 seconds, 485312 images, time remaining=29.5 minutes
7584: loss=2.053, avg loss=2.097, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=4.1 seconds, 485376 images, time remaining=29.4 minutes
7585: loss=2.163, avg loss=2.104, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=4.0 seconds, 485440 images, time remaining=29.4 minutes
7586: loss=2.011, avg loss=2.095, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=4.0 seconds, 485504 images, time remaining=29.3 minutes
7587: loss=2.105, avg loss=2.096, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 485568 images, time remaining=29.2 minutes
7588: loss=2.205, avg loss=2.107, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 485632 images, time remaining=29.1 minutes
7589: loss=1.936, avg loss=2.090, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.0 seconds, 485696 images, time remaining=29.1 minutes
7590: loss=2.395, avg loss=2.120, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=4.0 seconds, 485760 images, time remaining=29 minutes
Resizing, random_coef=1.40, batch=4, 704x544
GPU #0: allocating workspace: 289.6 MiB begins at 0x14b56fe00000
7591: loss=2.661, avg loss=2.174, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=972.7 milliseconds, train=1.8 seconds, 485824 images, time remaining=28.9 minutes
7592: loss=2.034, avg loss=2.160, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 485888 images, time remaining=28.9 minutes
7593: loss=2.255, avg loss=2.170, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 485952 images, time remaining=28.8 minutes
7594: loss=2.053, avg loss=2.158, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 486016 images, time remaining=28.7 minutes
7595: loss=2.183, avg loss=2.161, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 486080 images, time remaining=28.6 minutes
7596: loss=2.195, avg loss=2.164, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.8 seconds, 486144 images, time remaining=28.5 minutes
7597: loss=2.043, avg loss=2.152, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 486208 images, time remaining=28.5 minutes
7598: loss=2.265, avg loss=2.163, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.8 seconds, 486272 images, time remaining=28.4 minutes
7599: loss=2.826, avg loss=2.229, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 486336 images, time remaining=28.3 minutes
7600: loss=2.941, avg loss=2.301, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=1.9 seconds, 486400 images, time remaining=28.3 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b659a00000
7601: loss=2.567, avg loss=2.327, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 486464 images, time remaining=28.2 minutes
7602: loss=2.076, avg loss=2.302, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 486528 images, time remaining=28.1 minutes
7603: loss=1.977, avg loss=2.270, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 486592 images, time remaining=28 minutes
7604: loss=2.545, avg loss=2.297, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 486656 images, time remaining=28 minutes
7605: loss=2.236, avg loss=2.291, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 486720 images, time remaining=27.9 minutes
7606: loss=1.790, avg loss=2.241, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 486784 images, time remaining=27.8 minutes
7607: loss=2.175, avg loss=2.234, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 486848 images, time remaining=27.8 minutes
7608: loss=2.265, avg loss=2.237, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 486912 images, time remaining=27.7 minutes
7609: loss=2.315, avg loss=2.245, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.9 seconds, 486976 images, time remaining=27.6 minutes
7610: loss=1.874, avg loss=2.208, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 487040 images, time remaining=27.5 minutes
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b84a600000
7611: loss=2.003, avg loss=2.188, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.1 seconds, train=2.3 seconds, 487104 images, time remaining=27.5 minutes
7612: loss=2.350, avg loss=2.204, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.4 seconds, 487168 images, time remaining=27.4 minutes
7613: loss=2.224, avg loss=2.206, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.2 seconds, 487232 images, time remaining=27.3 minutes
7614: loss=2.424, avg loss=2.228, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.3 seconds, 487296 images, time remaining=27.3 minutes
7615: loss=1.855, avg loss=2.190, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.3 seconds, 487360 images, time remaining=27.2 minutes
7616: loss=3.003, avg loss=2.272, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.3 seconds, 487424 images, time remaining=27.1 minutes
7617: loss=1.585, avg loss=2.203, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.3 seconds, 487488 images, time remaining=27 minutes
7618: loss=1.704, avg loss=2.153, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 487552 images, time remaining=27 minutes
7619: loss=1.719, avg loss=2.110, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.3 seconds, 487616 images, time remaining=26.9 minutes
7620: loss=2.132, avg loss=2.112, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.2 seconds, 487680 images, time remaining=26.8 minutes
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7621: loss=2.139, avg loss=2.115, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.2 seconds, 487744 images, time remaining=26.8 minutes
7622: loss=2.270, avg loss=2.130, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.9 seconds, train=4.4 seconds, 487808 images, time remaining=26.7 minutes
7623: loss=2.488, avg loss=2.166, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=4.4 seconds, 487872 images, time remaining=26.6 minutes
7624: loss=2.524, avg loss=2.202, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.3 seconds, 487936 images, time remaining=26.5 minutes
7625: loss=2.020, avg loss=2.184, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=4.4 seconds, 488000 images, time remaining=26.5 minutes
7626: loss=2.253, avg loss=2.191, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.9 seconds, train=4.4 seconds, 488064 images, time remaining=26.4 minutes
7627: loss=2.341, avg loss=2.206, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=4.3 seconds, 488128 images, time remaining=26.3 minutes
7628: loss=2.341, avg loss=2.219, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=4.4 seconds, 488192 images, time remaining=26.3 minutes
7629: loss=2.408, avg loss=2.238, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.4 seconds, 488256 images, time remaining=26.2 minutes
7630: loss=2.134, avg loss=2.228, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=4.4 seconds, 488320 images, time remaining=26.1 minutes
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b620a00000
7631: loss=2.134, avg loss=2.218, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 488384 images, time remaining=26.1 minutes
7632: loss=2.465, avg loss=2.243, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.1 seconds, train=1.9 seconds, 488448 images, time remaining=26 minutes
7633: loss=2.564, avg loss=2.275, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.0 seconds, 488512 images, time remaining=25.9 minutes
7634: loss=2.578, avg loss=2.305, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.0 seconds, 488576 images, time remaining=25.8 minutes
7635: loss=2.310, avg loss=2.306, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.0 seconds, 488640 images, time remaining=25.8 minutes
7636: loss=2.226, avg loss=2.298, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 488704 images, time remaining=25.7 minutes
7637: loss=2.383, avg loss=2.306, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 488768 images, time remaining=25.6 minutes
7638: loss=2.145, avg loss=2.290, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.1 seconds, train=2.0 seconds, 488832 images, time remaining=25.5 minutes
7639: loss=1.853, avg loss=2.247, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 488896 images, time remaining=25.5 minutes
7640: loss=1.896, avg loss=2.212, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.1 seconds, train=2.1 seconds, 488960 images, time remaining=25.4 minutes
Resizing, random_coef=1.40, batch=4, 704x544
GPU #0: allocating workspace: 289.6 MiB begins at 0x14b67a000000
7641: loss=2.569, avg loss=2.247, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.8 seconds, 489024 images, time remaining=25.3 minutes
7642: loss=1.968, avg loss=2.219, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 489088 images, time remaining=25.3 minutes
7643: loss=2.394, avg loss=2.237, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.8 seconds, 489152 images, time remaining=25.2 minutes
7644: loss=2.275, avg loss=2.241, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.1 seconds, train=1.8 seconds, 489216 images, time remaining=25.1 minutes
7645: loss=3.151, avg loss=2.332, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=1.8 seconds, 489280 images, time remaining=25 minutes
7646: loss=1.828, avg loss=2.281, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.1 seconds, train=1.9 seconds, 489344 images, time remaining=25 minutes
7647: loss=2.450, avg loss=2.298, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 489408 images, time remaining=24.9 minutes
7648: loss=2.452, avg loss=2.314, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=1.8 seconds, 489472 images, time remaining=24.8 minutes
7649: loss=2.926, avg loss=2.375, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 489536 images, time remaining=24.8 minutes
7650: loss=2.141, avg loss=2.351, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.1 seconds, train=1.8 seconds, 489600 images, time remaining=24.7 minutes
Resizing, random_coef=1.40, batch=4, 992x768
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7651: loss=1.864, avg loss=2.303, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=3.9 seconds, 489664 images, time remaining=24.6 minutes
7652: loss=1.687, avg loss=2.241, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=3.8 seconds, 489728 images, time remaining=24.5 minutes
7653: loss=2.467, avg loss=2.264, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=3.8 seconds, 489792 images, time remaining=24.5 minutes
7654: loss=2.331, avg loss=2.270, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=3.9 seconds, 489856 images, time remaining=24.4 minutes
7655: loss=1.888, avg loss=2.232, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=3.8 seconds, 489920 images, time remaining=24.3 minutes
7656: loss=2.023, avg loss=2.211, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=3.8 seconds, 489984 images, time remaining=24.2 minutes
7657: loss=2.052, avg loss=2.195, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=3.9 seconds, 490048 images, time remaining=24.2 minutes
7658: loss=2.351, avg loss=2.211, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=3.8 seconds, 490112 images, time remaining=24.1 minutes
7659: loss=1.949, avg loss=2.185, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=3.9 seconds, 490176 images, time remaining=24 minutes
7660: loss=2.132, avg loss=2.179, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=3.7 seconds, 490240 images, time remaining=24 minutes
Resizing, random_coef=1.40, batch=4, 992x768
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7661: loss=2.004, avg loss=2.162, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=3.8 seconds, 490304 images, time remaining=23.9 minutes
7662: loss=2.018, avg loss=2.147, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 490368 images, time remaining=23.8 minutes
7663: loss=1.931, avg loss=2.126, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=3.9 seconds, 490432 images, time remaining=23.8 minutes
7664: loss=2.104, avg loss=2.124, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=3.8 seconds, 490496 images, time remaining=23.7 minutes
7665: loss=2.011, avg loss=2.112, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=3.8 seconds, 490560 images, time remaining=23.6 minutes
7666: loss=2.129, avg loss=2.114, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=3.8 seconds, 490624 images, time remaining=23.5 minutes
7667: loss=2.541, avg loss=2.157, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=3.8 seconds, 490688 images, time remaining=23.5 minutes
7668: loss=1.858, avg loss=2.127, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=3.9 seconds, 490752 images, time remaining=23.4 minutes
7669: loss=2.454, avg loss=2.160, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=3.8 seconds, 490816 images, time remaining=23.3 minutes
7670: loss=2.049, avg loss=2.149, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=3.7 seconds, 490880 images, time remaining=23.3 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b68b800000
7671: loss=1.922, avg loss=2.126, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=2.2 seconds, train=2.6 seconds, 490944 images, time remaining=23.2 minutes
7672: loss=1.843, avg loss=2.098, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.9 seconds, train=2.7 seconds, 491008 images, time remaining=23.1 minutes
7673: loss=1.772, avg loss=2.065, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=2.8 seconds, 491072 images, time remaining=23.1 minutes
7674: loss=2.110, avg loss=2.070, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 491136 images, time remaining=23 minutes
7675: loss=2.013, avg loss=2.064, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=2.8 seconds, 491200 images, time remaining=22.9 minutes
7676: loss=2.030, avg loss=2.060, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 491264 images, time remaining=22.8 minutes
7677: loss=1.921, avg loss=2.047, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 491328 images, time remaining=22.8 minutes
7678: loss=1.709, avg loss=2.013, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 491392 images, time remaining=22.7 minutes
7679: loss=2.149, avg loss=2.026, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.9 seconds, 491456 images, time remaining=22.6 minutes
7680: loss=2.014, avg loss=2.025, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=2.9 seconds, 491520 images, time remaining=22.5 minutes
Resizing, random_coef=1.40, batch=4, 800x640
GPU #0: allocating workspace: 384.1 MiB begins at 0x14b5a6200000
7681: loss=1.788, avg loss=2.002, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.1 seconds, 491584 images, time remaining=22.5 minutes
7682: loss=2.191, avg loss=2.020, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.3 seconds, 491648 images, time remaining=22.4 minutes
7683: loss=1.863, avg loss=2.005, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=2.2 seconds, 491712 images, time remaining=22.3 minutes
7684: loss=1.704, avg loss=1.975, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.2 seconds, 491776 images, time remaining=22.3 minutes
7685: loss=1.685, avg loss=1.946, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.2 seconds, 491840 images, time remaining=22.2 minutes
7686: loss=1.981, avg loss=1.949, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=1.9 seconds, 491904 images, time remaining=22.1 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7687: loss=1.697, avg loss=1.924, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=2.9 seconds, train=2.1 seconds, 491968 images, time remaining=22 minutes
7688: loss=2.189, avg loss=1.951, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.9 seconds, train=2.2 seconds, 492032 images, time remaining=22 minutes
7689: loss=2.413, avg loss=1.997, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.2 seconds, 492096 images, time remaining=21.9 minutes
7690: loss=1.779, avg loss=1.975, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.3 seconds, 492160 images, time remaining=21.8 minutes
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14b7fc200000
7691: loss=2.325, avg loss=2.010, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=2.4 seconds, 492224 images, time remaining=21.8 minutes
7692: loss=2.153, avg loss=2.024, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.2 seconds, 492288 images, time remaining=21.7 minutes
7693: loss=2.802, avg loss=2.102, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=2.1 seconds, train=2.3 seconds, 492352 images, time remaining=21.6 minutes
7694: loss=2.191, avg loss=2.111, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.2 seconds, 492416 images, time remaining=21.5 minutes
7695: loss=2.278, avg loss=2.128, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=2.3 seconds, 492480 images, time remaining=21.5 minutes
7696: loss=2.362, avg loss=2.151, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=2.2 seconds, 492544 images, time remaining=21.4 minutes
7697: loss=2.342, avg loss=2.170, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.3 seconds, 492608 images, time remaining=21.3 minutes
7698: loss=1.794, avg loss=2.133, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=2.3 seconds, 492672 images, time remaining=21.3 minutes
7699: loss=1.804, avg loss=2.100, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=2.2 seconds, 492736 images, time remaining=21.2 minutes
7700: loss=2.133, avg loss=2.103, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 492800 images, time remaining=21.1 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14c4d2e00000
7701: loss=2.409, avg loss=2.134, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 492864 images, time remaining=21 minutes
7702: loss=2.227, avg loss=2.143, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 492928 images, time remaining=21 minutes
7703: loss=2.554, avg loss=2.184, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 492992 images, time remaining=20.9 minutes
7704: loss=2.146, avg loss=2.180, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 493056 images, time remaining=20.8 minutes
7705: loss=1.924, avg loss=2.155, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 493120 images, time remaining=20.8 minutes
7706: loss=2.386, avg loss=2.178, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 493184 images, time remaining=20.7 minutes
7707: loss=2.092, avg loss=2.169, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 493248 images, time remaining=20.6 minutes
7708: loss=2.498, avg loss=2.202, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 493312 images, time remaining=20.5 minutes
7709: loss=2.739, avg loss=2.256, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.1 seconds, train=2.0 seconds, 493376 images, time remaining=20.5 minutes
7710: loss=2.042, avg loss=2.234, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 493440 images, time remaining=20.4 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b5e2e00000
7711: loss=2.259, avg loss=2.237, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 493504 images, time remaining=20.3 minutes
7712: loss=2.175, avg loss=2.231, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 493568 images, time remaining=20.3 minutes
7713: loss=2.058, avg loss=2.213, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 493632 images, time remaining=20.2 minutes
7714: loss=1.662, avg loss=2.158, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 493696 images, time remaining=20.1 minutes
7715: loss=1.915, avg loss=2.134, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 493760 images, time remaining=20.1 minutes
7716: loss=2.103, avg loss=2.131, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 493824 images, time remaining=20 minutes
7717: loss=1.851, avg loss=2.103, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 493888 images, time remaining=19.9 minutes
7718: loss=2.211, avg loss=2.114, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 493952 images, time remaining=19.8 minutes
7719: loss=2.031, avg loss=2.105, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 494016 images, time remaining=19.8 minutes
7720: loss=2.087, avg loss=2.104, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=2.8 seconds, 494080 images, time remaining=19.7 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b5e2e00000
7721: loss=2.596, avg loss=2.153, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 494144 images, time remaining=19.6 minutes
7722: loss=1.855, avg loss=2.123, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=2.7 seconds, 494208 images, time remaining=19.5 minutes
7723: loss=2.545, avg loss=2.165, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.9 seconds, 494272 images, time remaining=19.5 minutes
7724: loss=2.142, avg loss=2.163, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 494336 images, time remaining=19.4 minutes
7725: loss=2.701, avg loss=2.217, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 494400 images, time remaining=19.3 minutes
7726: loss=1.966, avg loss=2.192, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.9 seconds, 494464 images, time remaining=19.3 minutes
7727: loss=1.562, avg loss=2.129, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 494528 images, time remaining=19.2 minutes
7728: loss=2.017, avg loss=2.118, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=2.8 seconds, 494592 images, time remaining=19.1 minutes
7729: loss=2.298, avg loss=2.136, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 494656 images, time remaining=19 minutes
7730: loss=1.774, avg loss=2.099, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 494720 images, time remaining=19 minutes
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7731: loss=2.146, avg loss=2.104, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=3.9 seconds, 494784 images, time remaining=18.9 minutes
7732: loss=2.120, avg loss=2.106, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 494848 images, time remaining=18.8 minutes
7733: loss=2.613, avg loss=2.156, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=3.9 seconds, 494912 images, time remaining=18.8 minutes
7734: loss=2.088, avg loss=2.150, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=3.9 seconds, 494976 images, time remaining=18.7 minutes
7735: loss=1.895, avg loss=2.124, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=3.9 seconds, 495040 images, time remaining=18.6 minutes
7736: loss=2.282, avg loss=2.140, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=3.9 seconds, 495104 images, time remaining=18.6 minutes
7737: loss=2.280, avg loss=2.154, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=3.9 seconds, 495168 images, time remaining=18.5 minutes
7738: loss=2.117, avg loss=2.150, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=4.0 seconds, 495232 images, time remaining=18.4 minutes
7739: loss=1.926, avg loss=2.128, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=3.9 seconds, 495296 images, time remaining=18.3 minutes
7740: loss=2.211, avg loss=2.136, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 495360 images, time remaining=18.3 minutes
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7741: loss=3.184, avg loss=2.241, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=6.2 seconds, 495424 images, time remaining=18.2 minutes
7742: loss=3.050, avg loss=2.322, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=2.0 seconds, train=6.1 seconds, 495488 images, time remaining=18.1 minutes
7743: loss=2.063, avg loss=2.296, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=6.0 seconds, 495552 images, time remaining=18.1 minutes
7744: loss=2.539, avg loss=2.320, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=6.1 seconds, 495616 images, time remaining=18 minutes
7745: loss=2.979, avg loss=2.386, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 495680 images, time remaining=17.9 minutes
7746: loss=2.551, avg loss=2.403, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=6.0 seconds, 495744 images, time remaining=17.9 minutes
7747: loss=2.915, avg loss=2.454, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 495808 images, time remaining=17.8 minutes
7748: loss=3.066, avg loss=2.515, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 495872 images, time remaining=17.7 minutes
7749: loss=2.612, avg loss=2.525, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 495936 images, time remaining=17.6 minutes
7750: loss=3.360, avg loss=2.608, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=6.0 seconds, 496000 images, time remaining=17.6 minutes
Resizing, random_coef=1.40, batch=4, 1120x864
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7751: loss=2.958, avg loss=2.643, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.4 seconds, 496064 images, time remaining=17.5 minutes
7752: loss=2.534, avg loss=2.632, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.3 seconds, 496128 images, time remaining=17.4 minutes
7753: loss=2.226, avg loss=2.592, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.3 seconds, 496192 images, time remaining=17.4 minutes
7754: loss=2.326, avg loss=2.565, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.4 seconds, 496256 images, time remaining=17.3 minutes
7755: loss=2.005, avg loss=2.509, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=4.3 seconds, 496320 images, time remaining=17.2 minutes
7756: loss=2.125, avg loss=2.471, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=4.3 seconds, 496384 images, time remaining=17.2 minutes
7757: loss=2.183, avg loss=2.442, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.4 seconds, 496448 images, time remaining=17.1 minutes
7758: loss=2.358, avg loss=2.434, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.4 seconds, 496512 images, time remaining=17 minutes
7759: loss=2.054, avg loss=2.396, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=4.4 seconds, 496576 images, time remaining=16.9 minutes
7760: loss=2.561, avg loss=2.412, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.3 seconds, 496640 images, time remaining=16.9 minutes
Resizing, random_coef=1.40, batch=4, 1056x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7761: loss=2.929, avg loss=2.464, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.2 seconds, 496704 images, time remaining=16.8 minutes
7762: loss=1.858, avg loss=2.403, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.1 seconds, 496768 images, time remaining=16.8 minutes
7763: loss=2.595, avg loss=2.422, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=3.9 seconds, 496832 images, time remaining=16.7 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7764: loss=1.759, avg loss=2.356, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=4.9 seconds, train=3.9 seconds, 496896 images, time remaining=16.6 minutes
7765: loss=1.940, avg loss=2.314, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=4.0 seconds, 496960 images, time remaining=16.5 minutes
7766: loss=2.127, avg loss=2.296, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=4.0 seconds, 497024 images, time remaining=16.5 minutes
7767: loss=2.427, avg loss=2.309, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 497088 images, time remaining=16.4 minutes
7768: loss=2.523, avg loss=2.330, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 497152 images, time remaining=16.3 minutes
7769: loss=2.277, avg loss=2.325, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.1 seconds, 497216 images, time remaining=16.2 minutes
7770: loss=2.280, avg loss=2.320, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.1 seconds, 497280 images, time remaining=16.2 minutes
Resizing, random_coef=1.40, batch=4, 928x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
7771: loss=1.916, avg loss=2.280, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.5 seconds, 497344 images, time remaining=16.1 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7772: loss=2.081, avg loss=2.260, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=3.9 seconds, train=2.7 seconds, 497408 images, time remaining=16 minutes
7773: loss=2.308, avg loss=2.265, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 497472 images, time remaining=16 minutes
7774: loss=2.160, avg loss=2.254, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 497536 images, time remaining=15.9 minutes
7775: loss=1.870, avg loss=2.216, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 497600 images, time remaining=15.8 minutes
7776: loss=2.019, avg loss=2.196, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 497664 images, time remaining=15.8 minutes
7777: loss=1.735, avg loss=2.150, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 497728 images, time remaining=15.7 minutes
7778: loss=1.996, avg loss=2.135, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 497792 images, time remaining=15.6 minutes
7779: loss=1.778, avg loss=2.099, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 497856 images, time remaining=15.5 minutes
7780: loss=1.903, avg loss=2.079, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 497920 images, time remaining=15.5 minutes
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7781: loss=3.543, avg loss=2.226, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=5.4 seconds, 497984 images, time remaining=15.4 minutes
7782: loss=2.354, avg loss=2.239, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=2.3 seconds, train=5.5 seconds, 498048 images, time remaining=15.3 minutes
7783: loss=2.788, avg loss=2.293, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.6 seconds, 498112 images, time remaining=15.3 minutes
7784: loss=2.339, avg loss=2.298, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.5 seconds, 498176 images, time remaining=15.2 minutes
7785: loss=2.870, avg loss=2.355, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.5 seconds, 498240 images, time remaining=15.1 minutes
7786: loss=2.283, avg loss=2.348, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=5.4 seconds, 498304 images, time remaining=15.1 minutes
7787: loss=2.134, avg loss=2.327, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.5 seconds, 498368 images, time remaining=15 minutes
7788: loss=3.833, avg loss=2.477, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=5.6 seconds, 498432 images, time remaining=14.9 minutes
7789: loss=2.203, avg loss=2.450, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.4 seconds, 498496 images, time remaining=14.8 minutes
7790: loss=2.335, avg loss=2.438, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=5.5 seconds, 498560 images, time remaining=14.8 minutes
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7791: loss=2.841, avg loss=2.479, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=5.7 seconds, 498624 images, time remaining=14.7 minutes
7792: loss=2.128, avg loss=2.444, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.7 seconds, 498688 images, time remaining=14.6 minutes
7793: loss=2.227, avg loss=2.422, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.6 seconds, 498752 images, time remaining=14.6 minutes
7794: loss=3.297, avg loss=2.509, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.7 seconds, 498816 images, time remaining=14.5 minutes
7795: loss=2.510, avg loss=2.509, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.6 seconds, 498880 images, time remaining=14.4 minutes
7796: loss=3.072, avg loss=2.566, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.7 seconds, 498944 images, time remaining=14.4 minutes
7797: loss=2.451, avg loss=2.554, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.6 seconds, 499008 images, time remaining=14.3 minutes
7798: loss=2.579, avg loss=2.557, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.6 seconds, 499072 images, time remaining=14.2 minutes
7799: loss=2.497, avg loss=2.551, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=5.6 seconds, 499136 images, time remaining=14.1 minutes
7800: loss=2.796, avg loss=2.575, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.7 seconds, 499200 images, time remaining=14.1 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 864x672
GPU #0: allocating workspace: 434.4 MiB begins at 0x14b69f400000
7801: loss=1.823, avg loss=2.500, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.4 seconds, 499264 images, time remaining=14 minutes
7802: loss=1.800, avg loss=2.430, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.4 seconds, 499328 images, time remaining=13.9 minutes
7803: loss=1.767, avg loss=2.364, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.5 seconds, 499392 images, time remaining=13.9 minutes
7804: loss=2.163, avg loss=2.344, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.4 seconds, 499456 images, time remaining=13.8 minutes
7805: loss=2.110, avg loss=2.320, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.4 seconds, 499520 images, time remaining=13.7 minutes
7806: loss=1.538, avg loss=2.242, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.4 seconds, 499584 images, time remaining=13.6 minutes
7807: loss=2.317, avg loss=2.250, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.4 seconds, 499648 images, time remaining=13.6 minutes
7808: loss=1.986, avg loss=2.223, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=2.3 seconds, 499712 images, time remaining=13.5 minutes
7809: loss=2.302, avg loss=2.231, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.5 seconds, 499776 images, time remaining=13.4 minutes
7810: loss=1.892, avg loss=2.197, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.3 seconds, 499840 images, time remaining=13.4 minutes
Resizing, random_coef=1.40, batch=4, 736x576
GPU #0: allocating workspace: 319.6 MiB begins at 0x14b68c600000
7811: loss=1.913, avg loss=2.169, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 499904 images, time remaining=13.3 minutes
7812: loss=1.757, avg loss=2.128, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.9 seconds, 499968 images, time remaining=13.2 minutes
7813: loss=2.103, avg loss=2.125, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.0 seconds, 500032 images, time remaining=13.2 minutes
7814: loss=2.478, avg loss=2.160, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.0 seconds, 500096 images, time remaining=13.1 minutes
7815: loss=1.872, avg loss=2.132, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=1.9 seconds, 500160 images, time remaining=13 minutes
7816: loss=2.414, avg loss=2.160, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.0 seconds, 500224 images, time remaining=12.9 minutes
7817: loss=2.217, avg loss=2.166, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=1.9 seconds, 500288 images, time remaining=12.9 minutes
7818: loss=3.126, avg loss=2.262, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.0 seconds, 500352 images, time remaining=12.8 minutes
7819: loss=2.021, avg loss=2.238, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.0 seconds, 500416 images, time remaining=12.7 minutes
7820: loss=2.582, avg loss=2.272, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=1.8 seconds, 500480 images, time remaining=12.6 minutes
Resizing, random_coef=1.40, batch=4, 1280x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7821: loss=1.758, avg loss=2.221, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=5.5 seconds, 500544 images, time remaining=12.6 minutes
7822: loss=2.633, avg loss=2.262, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.6 seconds, 500608 images, time remaining=12.5 minutes
7823: loss=2.369, avg loss=2.273, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.9 seconds, train=5.6 seconds, 500672 images, time remaining=12.4 minutes
7824: loss=3.071, avg loss=2.352, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=5.5 seconds, 500736 images, time remaining=12.4 minutes
7825: loss=2.851, avg loss=2.402, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.5 seconds, 500800 images, time remaining=12.3 minutes
7826: loss=3.319, avg loss=2.494, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=5.5 seconds, 500864 images, time remaining=12.2 minutes
7827: loss=2.487, avg loss=2.493, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=2.0 seconds, train=5.6 seconds, 500928 images, time remaining=12.2 minutes
7828: loss=2.638, avg loss=2.508, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=5.5 seconds, 500992 images, time remaining=12.1 minutes
7829: loss=2.764, avg loss=2.533, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=5.4 seconds, 501056 images, time remaining=12 minutes
7830: loss=2.388, avg loss=2.519, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=5.4 seconds, 501120 images, time remaining=12 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
7831: loss=2.402, avg loss=2.507, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.9 seconds, 501184 images, time remaining=11.9 minutes
7832: loss=1.655, avg loss=2.422, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.7 seconds, 501248 images, time remaining=11.8 minutes
7833: loss=1.799, avg loss=2.360, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 501312 images, time remaining=11.7 minutes
7834: loss=2.268, avg loss=2.350, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 501376 images, time remaining=11.7 minutes
7835: loss=2.500, avg loss=2.365, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 501440 images, time remaining=11.6 minutes
7836: loss=1.914, avg loss=2.320, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 501504 images, time remaining=11.5 minutes
7837: loss=2.316, avg loss=2.320, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 501568 images, time remaining=11.5 minutes
7838: loss=1.852, avg loss=2.273, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 501632 images, time remaining=11.4 minutes
7839: loss=2.397, avg loss=2.285, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 501696 images, time remaining=11.3 minutes
7840: loss=2.327, avg loss=2.289, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=2.8 seconds, 501760 images, time remaining=11.2 minutes
Resizing, random_coef=1.40, batch=4, 1024x800
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7841: loss=2.301, avg loss=2.291, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 501824 images, time remaining=11.2 minutes
7842: loss=2.148, avg loss=2.276, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 501888 images, time remaining=11.1 minutes
7843: loss=2.166, avg loss=2.265, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=3.9 seconds, 501952 images, time remaining=11 minutes
7844: loss=2.534, avg loss=2.292, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=3.9 seconds, 502016 images, time remaining=11 minutes
7845: loss=2.156, avg loss=2.279, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=4.0 seconds, 502080 images, time remaining=10.9 minutes
7846: loss=2.128, avg loss=2.263, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=3.9 seconds, 502144 images, time remaining=10.8 minutes
7847: loss=2.378, avg loss=2.275, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=3.9 seconds, 502208 images, time remaining=10.8 minutes
7848: loss=2.265, avg loss=2.274, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=3.9 seconds, 502272 images, time remaining=10.7 minutes
7849: loss=2.104, avg loss=2.257, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=3.9 seconds, 502336 images, time remaining=10.6 minutes
7850: loss=2.040, avg loss=2.235, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=4.1 seconds, 502400 images, time remaining=10.5 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
7851: loss=1.768, avg loss=2.189, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 502464 images, time remaining=10.5 minutes
7852: loss=2.266, avg loss=2.196, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.9 seconds, 502528 images, time remaining=10.4 minutes
7853: loss=1.852, avg loss=2.162, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.8 seconds, 502592 images, time remaining=10.3 minutes
7854: loss=1.900, avg loss=2.136, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 502656 images, time remaining=10.3 minutes
7855: loss=1.940, avg loss=2.116, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.9 seconds, 502720 images, time remaining=10.2 minutes
7856: loss=1.880, avg loss=2.092, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.7 seconds, 502784 images, time remaining=10.1 minutes
7857: loss=2.022, avg loss=2.085, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=2.2 seconds, train=2.9 seconds, 502848 images, time remaining=10.1 minutes
7858: loss=2.399, avg loss=2.117, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.9 seconds, 502912 images, time remaining=10 minutes
7859: loss=2.143, avg loss=2.119, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 502976 images, time remaining=9.9 minutes
7860: loss=2.107, avg loss=2.118, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 503040 images, time remaining=9.8 minutes
Resizing, random_coef=1.40, batch=4, 960x736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
7861: loss=1.963, avg loss=2.103, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 503104 images, time remaining=9.8 minutes
7862: loss=2.095, avg loss=2.102, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 503168 images, time remaining=9.7 minutes
7863: loss=2.221, avg loss=2.114, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 503232 images, time remaining=9.6 minutes
7864: loss=2.770, avg loss=2.179, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 503296 images, time remaining=9.6 minutes
7865: loss=2.148, avg loss=2.176, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 503360 images, time remaining=9.5 minutes
7866: loss=1.904, avg loss=2.149, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.9 seconds, 503424 images, time remaining=9.4 minutes
7867: loss=2.133, avg loss=2.147, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 503488 images, time remaining=9.4 minutes
7868: loss=2.299, avg loss=2.163, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 503552 images, time remaining=9.3 minutes
7869: loss=1.561, avg loss=2.102, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 503616 images, time remaining=9.2 minutes
7870: loss=1.756, avg loss=2.068, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.8 seconds, 503680 images, time remaining=9.1 minutes
Resizing, random_coef=1.40, batch=4, 1248x960
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7871: loss=2.230, avg loss=2.084, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=2.0 seconds, train=5.4 seconds, 503744 images, time remaining=9.1 minutes
7872: loss=2.849, avg loss=2.160, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.9 seconds, train=5.4 seconds, 503808 images, time remaining=9 minutes
7873: loss=1.909, avg loss=2.135, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.3 seconds, 503872 images, time remaining=8.9 minutes
7874: loss=3.612, avg loss=2.283, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=5.3 seconds, 503936 images, time remaining=8.8 minutes
7875: loss=2.386, avg loss=2.293, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=5.4 seconds, 504000 images, time remaining=8.8 minutes
7876: loss=2.052, avg loss=2.269, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.7 seconds, train=5.3 seconds, 504064 images, time remaining=8.7 minutes
7877: loss=2.588, avg loss=2.301, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=5.3 seconds, 504128 images, time remaining=8.6 minutes
7878: loss=1.813, avg loss=2.252, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=5.4 seconds, 504192 images, time remaining=8.6 minutes
7879: loss=2.749, avg loss=2.302, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=5.3 seconds, 504256 images, time remaining=8.5 minutes
7880: loss=2.646, avg loss=2.336, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=5.3 seconds, 504320 images, time remaining=8.4 minutes
Resizing, random_coef=1.40, batch=4, 800x608
GPU #0: allocating workspace: 365.4 MiB begins at 0x14b6fc600000
7881: loss=2.472, avg loss=2.350, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.2 seconds, 504384 images, time remaining=8.4 minutes
7882: loss=2.163, avg loss=2.331, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 504448 images, time remaining=8.3 minutes
7883: loss=1.880, avg loss=2.286, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.1 seconds, 504512 images, time remaining=8.2 minutes
7884: loss=2.170, avg loss=2.274, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 504576 images, time remaining=8.1 minutes
7885: loss=2.178, avg loss=2.265, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.2 seconds, 504640 images, time remaining=8.1 minutes
7886: loss=1.726, avg loss=2.211, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 504704 images, time remaining=8 minutes
7887: loss=2.512, avg loss=2.241, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 504768 images, time remaining=7.9 minutes
7888: loss=2.121, avg loss=2.229, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.1 seconds, 504832 images, time remaining=7.9 minutes
7889: loss=1.836, avg loss=2.190, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.2 seconds, 504896 images, time remaining=7.8 minutes
7890: loss=2.032, avg loss=2.174, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.1 seconds, 504960 images, time remaining=7.7 minutes
Resizing, random_coef=1.40, batch=4, 832x640
GPU #0: allocating workspace: 399.1 MiB begins at 0x14bf3a000000
7891: loss=1.795, avg loss=2.136, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.3 seconds, 505024 images, time remaining=7.6 minutes
7892: loss=1.860, avg loss=2.108, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=2.3 seconds, 505088 images, time remaining=7.6 minutes
7893: loss=2.103, avg loss=2.108, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.4 seconds, 505152 images, time remaining=7.5 minutes
7894: loss=2.245, avg loss=2.122, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.4 seconds, train=2.2 seconds, 505216 images, time remaining=7.4 minutes
7895: loss=2.229, avg loss=2.132, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.3 seconds, 505280 images, time remaining=7.4 minutes
7896: loss=1.829, avg loss=2.102, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.5 seconds, train=2.2 seconds, 505344 images, time remaining=7.3 minutes
7897: loss=1.909, avg loss=2.083, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.6 seconds, train=2.2 seconds, 505408 images, time remaining=7.2 minutes
Performance bottleneck:  loading 64 images took longer than it takes to train.  Slow CPU or hard drive?  Loading images from a network share?
7898: loss=2.313, avg loss=2.106, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=3.7 seconds, train=2.2 seconds, 505472 images, time remaining=7.2 minutes
7899: loss=2.083, avg loss=2.103, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.2 seconds, train=2.4 seconds, 505536 images, time remaining=7.1 minutes
7900: loss=2.244, avg loss=2.118, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.3 seconds, train=2.3 seconds, 505600 images, time remaining=7 minutes
Saving weights to /workspace/.cache/splits/combined_last.weights
Resizing, random_coef=1.40, batch=4, 1312x992
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7901: loss=2.061, avg loss=2.112, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=1.8 seconds, train=5.7 seconds, 505664 images, time remaining=6.9 minutes
7902: loss=2.204, avg loss=2.121, last=97.77%, best=97.90%, next=7902, rate=0.00001300, load 64=2.3 seconds, train=5.6 seconds, 505728 images, time remaining=6.9 minutes
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=88174, unique_truth_count=57264
rank=0 of ranks=88174rank=100 of ranks=88174rank=200 of ranks=88174rank=300 of ranks=88174rank=400 of ranks=88174rank=500 of ranks=88174rank=600 of ranks=88174rank=700 of ranks=88174rank=800 of ranks=88174rank=900 of ranks=88174rank=1000 of ranks=88174rank=1100 of ranks=88174rank=1200 of ranks=88174rank=1300 of ranks=88174rank=1400 of ranks=88174rank=1500 of ranks=88174rank=1600 of ranks=88174rank=1700 of ranks=88174rank=1800 of ranks=88174rank=1900 of ranks=88174rank=2000 of ranks=88174rank=2100 of ranks=88174rank=2200 of ranks=88174rank=2300 of ranks=88174rank=2400 of ranks=88174rank=2500 of ranks=88174rank=2600 of ranks=88174rank=2700 of ranks=88174rank=2800 of ranks=88174rank=2900 of ranks=88174rank=3000 of ranks=88174rank=3100 of ranks=88174rank=3200 of ranks=88174rank=3300 of ranks=88174rank=3400 of ranks=88174rank=3500 of ranks=88174rank=3600 of ranks=88174rank=3700 of ranks=88174rank=3800 of ranks=88174rank=3900 of ranks=88174rank=4000 of ranks=88174rank=4100 of ranks=88174rank=4200 of ranks=88174rank=4300 of ranks=88174rank=4400 of ranks=88174rank=4500 of ranks=88174rank=4600 of ranks=88174rank=4700 of ranks=88174rank=4800 of ranks=88174rank=4900 of ranks=88174rank=5000 of ranks=88174rank=5100 of ranks=88174rank=5200 of ranks=88174rank=5300 of ranks=88174rank=5400 of ranks=88174rank=5500 of ranks=88174rank=5600 of ranks=88174rank=5700 of ranks=88174rank=5800 of ranks=88174rank=5900 of ranks=88174rank=6000 of ranks=88174rank=6100 of ranks=88174rank=6200 of ranks=88174rank=6300 of ranks=88174rank=6400 of ranks=88174rank=6500 of ranks=88174rank=6600 of ranks=88174rank=6700 of ranks=88174rank=6800 of ranks=88174rank=6900 of ranks=88174rank=7000 of ranks=88174rank=7100 of ranks=88174rank=7200 of ranks=88174rank=7300 of ranks=88174rank=7400 of ranks=88174rank=7500 of ranks=88174rank=7600 of ranks=88174rank=7700 of ranks=88174rank=7800 of ranks=88174rank=7900 of ranks=88174rank=8000 of ranks=88174rank=8100 of ranks=88174rank=8200 of ranks=88174rank=8300 of ranks=88174rank=8400 of ranks=88174rank=8500 of ranks=88174rank=8600 of ranks=88174rank=8700 of ranks=88174rank=8800 of ranks=88174rank=8900 of ranks=88174rank=9000 of ranks=88174rank=9100 of ranks=88174rank=9200 of ranks=88174rank=9300 of ranks=88174rank=9400 of ranks=88174rank=9500 of ranks=88174rank=9600 of ranks=88174rank=9700 of ranks=88174rank=9800 of ranks=88174rank=9900 of ranks=88174rank=10000 of ranks=88174rank=10100 of ranks=88174rank=10200 of ranks=88174rank=10300 of ranks=88174rank=10400 of ranks=88174rank=10500 of ranks=88174rank=10600 of ranks=88174rank=10700 of ranks=88174rank=10800 of ranks=88174rank=10900 of ranks=88174rank=11000 of ranks=88174rank=11100 of ranks=88174rank=11200 of ranks=88174rank=11300 of ranks=88174rank=11400 of ranks=88174rank=11500 of ranks=88174rank=11600 of ranks=88174rank=11700 of ranks=88174rank=11800 of ranks=88174rank=11900 of ranks=88174rank=12000 of ranks=88174rank=12100 of ranks=88174rank=12200 of ranks=88174rank=12300 of ranks=88174rank=12400 of ranks=88174rank=12500 of ranks=88174rank=12600 of ranks=88174rank=12700 of ranks=88174rank=12800 of ranks=88174rank=12900 of ranks=88174rank=13000 of ranks=88174rank=13100 of ranks=88174rank=13200 of ranks=88174rank=13300 of ranks=88174rank=13400 of ranks=88174rank=13500 of ranks=88174rank=13600 of ranks=88174rank=13700 of ranks=88174rank=13800 of ranks=88174rank=13900 of ranks=88174rank=14000 of ranks=88174rank=14100 of ranks=88174rank=14200 of ranks=88174rank=14300 of ranks=88174rank=14400 of ranks=88174rank=14500 of ranks=88174rank=14600 of ranks=88174rank=14700 of ranks=88174rank=14800 of ranks=88174rank=14900 of ranks=88174rank=15000 of ranks=88174rank=15100 of ranks=88174rank=15200 of ranks=88174rank=15300 of ranks=88174rank=15400 of ranks=88174rank=15500 of ranks=88174rank=15600 of ranks=88174rank=15700 of ranks=88174rank=15800 of ranks=88174rank=15900 of ranks=88174rank=16000 of ranks=88174rank=16100 of ranks=88174rank=16200 of ranks=88174rank=16300 of ranks=88174rank=16400 of ranks=88174rank=16500 of ranks=88174rank=16600 of ranks=88174rank=16700 of ranks=88174rank=16800 of ranks=88174rank=16900 of ranks=88174rank=17000 of ranks=88174rank=17100 of ranks=88174rank=17200 of ranks=88174rank=17300 of ranks=88174rank=17400 of ranks=88174rank=17500 of ranks=88174rank=17600 of ranks=88174rank=17700 of ranks=88174rank=17800 of ranks=88174rank=17900 of ranks=88174rank=18000 of ranks=88174rank=18100 of ranks=88174rank=18200 of ranks=88174rank=18300 of ranks=88174rank=18400 of ranks=88174rank=18500 of ranks=88174rank=18600 of ranks=88174rank=18700 of ranks=88174rank=18800 of ranks=88174rank=18900 of ranks=88174rank=19000 of ranks=88174rank=19100 of ranks=88174rank=19200 of ranks=88174rank=19300 of ranks=88174rank=19400 of ranks=88174rank=19500 of ranks=88174rank=19600 of ranks=88174rank=19700 of ranks=88174rank=19800 of ranks=88174rank=19900 of ranks=88174rank=20000 of ranks=88174rank=20100 of ranks=88174rank=20200 of ranks=88174rank=20300 of ranks=88174rank=20400 of ranks=88174rank=20500 of ranks=88174rank=20600 of ranks=88174rank=20700 of ranks=88174rank=20800 of ranks=88174rank=20900 of ranks=88174rank=21000 of ranks=88174rank=21100 of ranks=88174rank=21200 of ranks=88174rank=21300 of ranks=88174rank=21400 of ranks=88174rank=21500 of ranks=88174rank=21600 of ranks=88174rank=21700 of ranks=88174rank=21800 of ranks=88174rank=21900 of ranks=88174rank=22000 of ranks=88174rank=22100 of ranks=88174rank=22200 of ranks=88174rank=22300 of ranks=88174rank=22400 of ranks=88174rank=22500 of ranks=88174rank=22600 of ranks=88174rank=22700 of ranks=88174rank=22800 of ranks=88174rank=22900 of ranks=88174rank=23000 of ranks=88174rank=23100 of ranks=88174rank=23200 of ranks=88174rank=23300 of ranks=88174rank=23400 of ranks=88174rank=23500 of ranks=88174rank=23600 of ranks=88174rank=23700 of ranks=88174rank=23800 of ranks=88174rank=23900 of ranks=88174rank=24000 of ranks=88174rank=24100 of ranks=88174rank=24200 of ranks=88174rank=24300 of ranks=88174rank=24400 of ranks=88174rank=24500 of ranks=88174rank=24600 of ranks=88174rank=24700 of ranks=88174rank=24800 of ranks=88174rank=24900 of ranks=88174rank=25000 of ranks=88174rank=25100 of ranks=88174rank=25200 of ranks=88174rank=25300 of ranks=88174rank=25400 of ranks=88174rank=25500 of ranks=88174rank=25600 of ranks=88174rank=25700 of ranks=88174rank=25800 of ranks=88174rank=25900 of ranks=88174rank=26000 of ranks=88174rank=26100 of ranks=88174rank=26200 of ranks=88174rank=26300 of ranks=88174rank=26400 of ranks=88174rank=26500 of ranks=88174rank=26600 of ranks=88174rank=26700 of ranks=88174rank=26800 of ranks=88174rank=26900 of ranks=88174rank=27000 of ranks=88174rank=27100 of ranks=88174rank=27200 of ranks=88174rank=27300 of ranks=88174rank=27400 of ranks=88174rank=27500 of ranks=88174rank=27600 of ranks=88174rank=27700 of ranks=88174rank=27800 of ranks=88174rank=27900 of ranks=88174rank=28000 of ranks=88174rank=28100 of ranks=88174rank=28200 of ranks=88174rank=28300 of ranks=88174rank=28400 of ranks=88174rank=28500 of ranks=88174rank=28600 of ranks=88174rank=28700 of ranks=88174rank=28800 of ranks=88174rank=28900 of ranks=88174rank=29000 of ranks=88174rank=29100 of ranks=88174rank=29200 of ranks=88174rank=29300 of ranks=88174rank=29400 of ranks=88174rank=29500 of ranks=88174rank=29600 of ranks=88174rank=29700 of ranks=88174rank=29800 of ranks=88174rank=29900 of ranks=88174rank=30000 of ranks=88174rank=30100 of ranks=88174rank=30200 of ranks=88174rank=30300 of ranks=88174rank=30400 of ranks=88174rank=30500 of ranks=88174rank=30600 of ranks=88174rank=30700 of ranks=88174rank=30800 of ranks=88174rank=30900 of ranks=88174rank=31000 of ranks=88174rank=31100 of ranks=88174rank=31200 of ranks=88174rank=31300 of ranks=88174rank=31400 of ranks=88174rank=31500 of ranks=88174rank=31600 of ranks=88174rank=31700 of ranks=88174rank=31800 of ranks=88174rank=31900 of ranks=88174rank=32000 of ranks=88174rank=32100 of ranks=88174rank=32200 of ranks=88174rank=32300 of ranks=88174rank=32400 of ranks=88174rank=32500 of ranks=88174rank=32600 of ranks=88174rank=32700 of ranks=88174rank=32800 of ranks=88174rank=32900 of ranks=88174rank=33000 of ranks=88174rank=33100 of ranks=88174rank=33200 of ranks=88174rank=33300 of ranks=88174rank=33400 of ranks=88174rank=33500 of ranks=88174rank=33600 of ranks=88174rank=33700 of ranks=88174rank=33800 of ranks=88174rank=33900 of ranks=88174rank=34000 of ranks=88174rank=34100 of ranks=88174rank=34200 of ranks=88174rank=34300 of ranks=88174rank=34400 of ranks=88174rank=34500 of ranks=88174rank=34600 of ranks=88174rank=34700 of ranks=88174rank=34800 of ranks=88174rank=34900 of ranks=88174rank=35000 of ranks=88174rank=35100 of ranks=88174rank=35200 of ranks=88174rank=35300 of ranks=88174rank=35400 of ranks=88174rank=35500 of ranks=88174rank=35600 of ranks=88174rank=35700 of ranks=88174rank=35800 of ranks=88174rank=35900 of ranks=88174rank=36000 of ranks=88174rank=36100 of ranks=88174rank=36200 of ranks=88174rank=36300 of ranks=88174rank=36400 of ranks=88174rank=36500 of ranks=88174rank=36600 of ranks=88174rank=36700 of ranks=88174rank=36800 of ranks=88174rank=36900 of ranks=88174rank=37000 of ranks=88174rank=37100 of ranks=88174rank=37200 of ranks=88174rank=37300 of ranks=88174rank=37400 of ranks=88174rank=37500 of ranks=88174rank=37600 of ranks=88174rank=37700 of ranks=88174rank=37800 of ranks=88174rank=37900 of ranks=88174rank=38000 of ranks=88174rank=38100 of ranks=88174rank=38200 of ranks=88174rank=38300 of ranks=88174rank=38400 of ranks=88174rank=38500 of ranks=88174rank=38600 of ranks=88174rank=38700 of ranks=88174rank=38800 of ranks=88174rank=38900 of ranks=88174rank=39000 of ranks=88174rank=39100 of ranks=88174rank=39200 of ranks=88174rank=39300 of ranks=88174rank=39400 of ranks=88174rank=39500 of ranks=88174rank=39600 of ranks=88174rank=39700 of ranks=88174rank=39800 of ranks=88174rank=39900 of ranks=88174rank=40000 of ranks=88174rank=40100 of ranks=88174rank=40200 of ranks=88174rank=40300 of ranks=88174rank=40400 of ranks=88174rank=40500 of ranks=88174rank=40600 of ranks=88174rank=40700 of ranks=88174rank=40800 of ranks=88174rank=40900 of ranks=88174rank=41000 of ranks=88174rank=41100 of ranks=88174rank=41200 of ranks=88174rank=41300 of ranks=88174rank=41400 of ranks=88174rank=41500 of ranks=88174rank=41600 of ranks=88174rank=41700 of ranks=88174rank=41800 of ranks=88174rank=41900 of ranks=88174rank=42000 of ranks=88174rank=42100 of ranks=88174rank=42200 of ranks=88174rank=42300 of ranks=88174rank=42400 of ranks=88174rank=42500 of ranks=88174rank=42600 of ranks=88174rank=42700 of ranks=88174rank=42800 of ranks=88174rank=42900 of ranks=88174rank=43000 of ranks=88174rank=43100 of ranks=88174rank=43200 of ranks=88174rank=43300 of ranks=88174rank=43400 of ranks=88174rank=43500 of ranks=88174rank=43600 of ranks=88174rank=43700 of ranks=88174rank=43800 of ranks=88174rank=43900 of ranks=88174rank=44000 of ranks=88174rank=44100 of ranks=88174rank=44200 of ranks=88174rank=44300 of ranks=88174rank=44400 of ranks=88174rank=44500 of ranks=88174rank=44600 of ranks=88174rank=44700 of ranks=88174rank=44800 of ranks=88174rank=44900 of ranks=88174rank=45000 of ranks=88174rank=45100 of ranks=88174rank=45200 of ranks=88174rank=45300 of ranks=88174rank=45400 of ranks=88174rank=45500 of ranks=88174rank=45600 of ranks=88174rank=45700 of ranks=88174rank=45800 of ranks=88174rank=45900 of ranks=88174rank=46000 of ranks=88174rank=46100 of ranks=88174rank=46200 of ranks=88174rank=46300 of ranks=88174rank=46400 of ranks=88174rank=46500 of ranks=88174rank=46600 of ranks=88174rank=46700 of ranks=88174rank=46800 of ranks=88174rank=46900 of ranks=88174rank=47000 of ranks=88174rank=47100 of ranks=88174rank=47200 of ranks=88174rank=47300 of ranks=88174rank=47400 of ranks=88174rank=47500 of ranks=88174rank=47600 of ranks=88174rank=47700 of ranks=88174rank=47800 of ranks=88174rank=47900 of ranks=88174rank=48000 of ranks=88174rank=48100 of ranks=88174rank=48200 of ranks=88174rank=48300 of ranks=88174rank=48400 of ranks=88174rank=48500 of ranks=88174rank=48600 of ranks=88174rank=48700 of ranks=88174rank=48800 of ranks=88174rank=48900 of ranks=88174rank=49000 of ranks=88174rank=49100 of ranks=88174rank=49200 of ranks=88174rank=49300 of ranks=88174rank=49400 of ranks=88174rank=49500 of ranks=88174rank=49600 of ranks=88174rank=49700 of ranks=88174rank=49800 of ranks=88174rank=49900 of ranks=88174rank=50000 of ranks=88174rank=50100 of ranks=88174rank=50200 of ranks=88174rank=50300 of ranks=88174rank=50400 of ranks=88174rank=50500 of ranks=88174rank=50600 of ranks=88174rank=50700 of ranks=88174rank=50800 of ranks=88174rank=50900 of ranks=88174rank=51000 of ranks=88174rank=51100 of ranks=88174rank=51200 of ranks=88174rank=51300 of ranks=88174rank=51400 of ranks=88174rank=51500 of ranks=88174rank=51600 of ranks=88174rank=51700 of ranks=88174rank=51800 of ranks=88174rank=51900 of ranks=88174rank=52000 of ranks=88174rank=52100 of ranks=88174rank=52200 of ranks=88174rank=52300 of ranks=88174rank=52400 of ranks=88174rank=52500 of ranks=88174rank=52600 of ranks=88174rank=52700 of ranks=88174rank=52800 of ranks=88174rank=52900 of ranks=88174rank=53000 of ranks=88174rank=53100 of ranks=88174rank=53200 of ranks=88174rank=53300 of ranks=88174rank=53400 of ranks=88174rank=53500 of ranks=88174rank=53600 of ranks=88174rank=53700 of ranks=88174rank=53800 of ranks=88174rank=53900 of ranks=88174rank=54000 of ranks=88174rank=54100 of ranks=88174rank=54200 of ranks=88174rank=54300 of ranks=88174rank=54400 of ranks=88174rank=54500 of ranks=88174rank=54600 of ranks=88174rank=54700 of ranks=88174rank=54800 of ranks=88174rank=54900 of ranks=88174rank=55000 of ranks=88174rank=55100 of ranks=88174rank=55200 of ranks=88174rank=55300 of ranks=88174rank=55400 of ranks=88174rank=55500 of ranks=88174rank=55600 of ranks=88174rank=55700 of ranks=88174rank=55800 of ranks=88174rank=55900 of ranks=88174rank=56000 of ranks=88174rank=56100 of ranks=88174rank=56200 of ranks=88174rank=56300 of ranks=88174rank=56400 of ranks=88174rank=56500 of ranks=88174rank=56600 of ranks=88174rank=56700 of ranks=88174rank=56800 of ranks=88174rank=56900 of ranks=88174rank=57000 of ranks=88174rank=57100 of ranks=88174rank=57200 of ranks=88174rank=57300 of ranks=88174rank=57400 of ranks=88174rank=57500 of ranks=88174rank=57600 of ranks=88174rank=57700 of ranks=88174rank=57800 of ranks=88174rank=57900 of ranks=88174rank=58000 of ranks=88174rank=58100 of ranks=88174rank=58200 of ranks=88174rank=58300 of ranks=88174rank=58400 of ranks=88174rank=58500 of ranks=88174rank=58600 of ranks=88174rank=58700 of ranks=88174rank=58800 of ranks=88174rank=58900 of ranks=88174rank=59000 of ranks=88174rank=59100 of ranks=88174rank=59200 of ranks=88174rank=59300 of ranks=88174rank=59400 of ranks=88174rank=59500 of ranks=88174rank=59600 of ranks=88174rank=59700 of ranks=88174rank=59800 of ranks=88174rank=59900 of ranks=88174rank=60000 of ranks=88174rank=60100 of ranks=88174rank=60200 of ranks=88174rank=60300 of ranks=88174rank=60400 of ranks=88174rank=60500 of ranks=88174rank=60600 of ranks=88174rank=60700 of ranks=88174rank=60800 of ranks=88174rank=60900 of ranks=88174rank=61000 of ranks=88174rank=61100 of ranks=88174rank=61200 of ranks=88174rank=61300 of ranks=88174rank=61400 of ranks=88174rank=61500 of ranks=88174rank=61600 of ranks=88174rank=61700 of ranks=88174rank=61800 of ranks=88174rank=61900 of ranks=88174rank=62000 of ranks=88174rank=62100 of ranks=88174rank=62200 of ranks=88174rank=62300 of ranks=88174rank=62400 of ranks=88174rank=62500 of ranks=88174rank=62600 of ranks=88174rank=62700 of ranks=88174rank=62800 of ranks=88174rank=62900 of ranks=88174rank=63000 of ranks=88174rank=63100 of ranks=88174rank=63200 of ranks=88174rank=63300 of ranks=88174rank=63400 of ranks=88174rank=63500 of ranks=88174rank=63600 of ranks=88174rank=63700 of ranks=88174rank=63800 of ranks=88174rank=63900 of ranks=88174rank=64000 of ranks=88174rank=64100 of ranks=88174rank=64200 of ranks=88174rank=64300 of ranks=88174rank=64400 of ranks=88174rank=64500 of ranks=88174rank=64600 of ranks=88174rank=64700 of ranks=88174rank=64800 of ranks=88174rank=64900 of ranks=88174rank=65000 of ranks=88174rank=65100 of ranks=88174rank=65200 of ranks=88174rank=65300 of ranks=88174rank=65400 of ranks=88174rank=65500 of ranks=88174rank=65600 of ranks=88174rank=65700 of ranks=88174rank=65800 of ranks=88174rank=65900 of ranks=88174rank=66000 of ranks=88174rank=66100 of ranks=88174rank=66200 of ranks=88174rank=66300 of ranks=88174rank=66400 of ranks=88174rank=66500 of ranks=88174rank=66600 of ranks=88174rank=66700 of ranks=88174rank=66800 of ranks=88174rank=66900 of ranks=88174rank=67000 of ranks=88174rank=67100 of ranks=88174rank=67200 of ranks=88174rank=67300 of ranks=88174rank=67400 of ranks=88174rank=67500 of ranks=88174rank=67600 of ranks=88174rank=67700 of ranks=88174rank=67800 of ranks=88174rank=67900 of ranks=88174rank=68000 of ranks=88174rank=68100 of ranks=88174rank=68200 of ranks=88174rank=68300 of ranks=88174rank=68400 of ranks=88174rank=68500 of ranks=88174rank=68600 of ranks=88174rank=68700 of ranks=88174rank=68800 of ranks=88174rank=68900 of ranks=88174rank=69000 of ranks=88174rank=69100 of ranks=88174rank=69200 of ranks=88174rank=69300 of ranks=88174rank=69400 of ranks=88174rank=69500 of ranks=88174rank=69600 of ranks=88174rank=69700 of ranks=88174rank=69800 of ranks=88174rank=69900 of ranks=88174rank=70000 of ranks=88174rank=70100 of ranks=88174rank=70200 of ranks=88174rank=70300 of ranks=88174rank=70400 of ranks=88174rank=70500 of ranks=88174rank=70600 of ranks=88174rank=70700 of ranks=88174rank=70800 of ranks=88174rank=70900 of ranks=88174rank=71000 of ranks=88174rank=71100 of ranks=88174rank=71200 of ranks=88174rank=71300 of ranks=88174rank=71400 of ranks=88174rank=71500 of ranks=88174rank=71600 of ranks=88174rank=71700 of ranks=88174rank=71800 of ranks=88174rank=71900 of ranks=88174rank=72000 of ranks=88174rank=72100 of ranks=88174rank=72200 of ranks=88174rank=72300 of ranks=88174rank=72400 of ranks=88174rank=72500 of ranks=88174rank=72600 of ranks=88174rank=72700 of ranks=88174rank=72800 of ranks=88174rank=72900 of ranks=88174rank=73000 of ranks=88174rank=73100 of ranks=88174rank=73200 of ranks=88174rank=73300 of ranks=88174rank=73400 of ranks=88174rank=73500 of ranks=88174rank=73600 of ranks=88174rank=73700 of ranks=88174rank=73800 of ranks=88174rank=73900 of ranks=88174rank=74000 of ranks=88174rank=74100 of ranks=88174rank=74200 of ranks=88174rank=74300 of ranks=88174rank=74400 of ranks=88174rank=74500 of ranks=88174rank=74600 of ranks=88174rank=74700 of ranks=88174rank=74800 of ranks=88174rank=74900 of ranks=88174rank=75000 of ranks=88174rank=75100 of ranks=88174rank=75200 of ranks=88174rank=75300 of ranks=88174rank=75400 of ranks=88174rank=75500 of ranks=88174rank=75600 of ranks=88174rank=75700 of ranks=88174rank=75800 of ranks=88174rank=75900 of ranks=88174rank=76000 of ranks=88174rank=76100 of ranks=88174rank=76200 of ranks=88174rank=76300 of ranks=88174rank=76400 of ranks=88174rank=76500 of ranks=88174rank=76600 of ranks=88174rank=76700 of ranks=88174rank=76800 of ranks=88174rank=76900 of ranks=88174rank=77000 of ranks=88174rank=77100 of ranks=88174rank=77200 of ranks=88174rank=77300 of ranks=88174rank=77400 of ranks=88174rank=77500 of ranks=88174rank=77600 of ranks=88174rank=77700 of ranks=88174rank=77800 of ranks=88174rank=77900 of ranks=88174rank=78000 of ranks=88174rank=78100 of ranks=88174rank=78200 of ranks=88174rank=78300 of ranks=88174rank=78400 of ranks=88174rank=78500 of ranks=88174rank=78600 of ranks=88174rank=78700 of ranks=88174rank=78800 of ranks=88174rank=78900 of ranks=88174rank=79000 of ranks=88174rank=79100 of ranks=88174rank=79200 of ranks=88174rank=79300 of ranks=88174rank=79400 of ranks=88174rank=79500 of ranks=88174rank=79600 of ranks=88174rank=79700 of ranks=88174rank=79800 of ranks=88174rank=79900 of ranks=88174rank=80000 of ranks=88174rank=80100 of ranks=88174rank=80200 of ranks=88174rank=80300 of ranks=88174rank=80400 of ranks=88174rank=80500 of ranks=88174rank=80600 of ranks=88174rank=80700 of ranks=88174rank=80800 of ranks=88174rank=80900 of ranks=88174rank=81000 of ranks=88174rank=81100 of ranks=88174rank=81200 of ranks=88174rank=81300 of ranks=88174rank=81400 of ranks=88174rank=81500 of ranks=88174rank=81600 of ranks=88174rank=81700 of ranks=88174rank=81800 of ranks=88174rank=81900 of ranks=88174rank=82000 of ranks=88174rank=82100 of ranks=88174rank=82200 of ranks=88174rank=82300 of ranks=88174rank=82400 of ranks=88174rank=82500 of ranks=88174rank=82600 of ranks=88174rank=82700 of ranks=88174rank=82800 of ranks=88174rank=82900 of ranks=88174rank=83000 of ranks=88174rank=83100 of ranks=88174rank=83200 of ranks=88174rank=83300 of ranks=88174rank=83400 of ranks=88174rank=83500 of ranks=88174rank=83600 of ranks=88174rank=83700 of ranks=88174rank=83800 of ranks=88174rank=83900 of ranks=88174rank=84000 of ranks=88174rank=84100 of ranks=88174rank=84200 of ranks=88174rank=84300 of ranks=88174rank=84400 of ranks=88174rank=84500 of ranks=88174rank=84600 of ranks=88174rank=84700 of ranks=88174rank=84800 of ranks=88174rank=84900 of ranks=88174rank=85000 of ranks=88174rank=85100 of ranks=88174rank=85200 of ranks=88174rank=85300 of ranks=88174rank=85400 of ranks=88174rank=85500 of ranks=88174rank=85600 of ranks=88174rank=85700 of ranks=88174rank=85800 of ranks=88174rank=85900 of ranks=88174rank=86000 of ranks=88174rank=86100 of ranks=88174rank=86200 of ranks=88174rank=86300 of ranks=88174rank=86400 of ranks=88174rank=86500 of ranks=88174rank=86600 of ranks=88174rank=86700 of ranks=88174rank=86800 of ranks=88174rank=86900 of ranks=88174rank=87000 of ranks=88174rank=87100 of ranks=88174rank=87200 of ranks=88174rank=87300 of ranks=88174rank=87400 of ranks=88174rank=87500 of ranks=88174rank=87600 of ranks=88174rank=87700 of ranks=88174rank=87800 of ranks=88174rank=87900 of ranks=88174rank=88000 of ranks=88174rank=88100 of ranks=88174

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              97.6068    491    902      7    498           79.1069
   1 car                    98.8260  50037  22256    279  50316           84.3582
   2 truck                  98.7238   1812   2484     13   1825           77.8842
   3 bus                    96.9403    360   1732      6    366           70.6444
   4 pedestrian             97.1961   4172   3928     87   4259           77.5814

for conf_thresh=0.25, precision=0.92, recall=0.97, F1 score=0.94
for conf_thresh=0.25, TP=55368, FP=5092, FN=1896, average IoU=83.51%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=97.86%
Total detection time: 119 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
7903: loss=2.249, avg loss=2.134, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.3 seconds, train=3.0 seconds, 505792 images, time remaining=6.8 minutes
7904: loss=2.351, avg loss=2.156, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.5 seconds, train=2.9 seconds, 505856 images, time remaining=6.8 minutes
7905: loss=1.456, avg loss=2.086, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 505920 images, time remaining=6.7 minutes
7906: loss=1.990, avg loss=2.076, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.4 seconds, train=2.9 seconds, 505984 images, time remaining=6.6 minutes
7907: loss=1.819, avg loss=2.050, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 506048 images, time remaining=6.5 minutes
7908: loss=1.894, avg loss=2.035, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.5 seconds, train=2.9 seconds, 506112 images, time remaining=6.5 minutes
7909: loss=2.370, avg loss=2.068, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 506176 images, time remaining=6.4 minutes
7910: loss=1.954, avg loss=2.057, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.4 seconds, train=2.8 seconds, 506240 images, time remaining=6.3 minutes
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7911: loss=2.976, avg loss=2.149, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.0 seconds, train=6.1 seconds, 506304 images, time remaining=6.3 minutes
7912: loss=3.097, avg loss=2.244, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 506368 images, time remaining=6.2 minutes
7913: loss=2.663, avg loss=2.286, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.0 seconds, 506432 images, time remaining=6.1 minutes
7914: loss=3.395, avg loss=2.397, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 506496 images, time remaining=6.1 minutes
7915: loss=2.281, avg loss=2.385, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.0 seconds, 506560 images, time remaining=6 minutes
7916: loss=3.699, avg loss=2.516, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.4 seconds, train=6.2 seconds, 506624 images, time remaining=5.9 minutes
7917: loss=3.038, avg loss=2.569, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 506688 images, time remaining=5.8 minutes
7918: loss=3.084, avg loss=2.620, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.0 seconds, train=6.0 seconds, 506752 images, time remaining=5.8 minutes
7919: loss=3.167, avg loss=2.675, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 506816 images, time remaining=5.7 minutes
7920: loss=2.767, avg loss=2.684, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 506880 images, time remaining=5.6 minutes
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7921: loss=3.951, avg loss=2.811, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.2 seconds, 506944 images, time remaining=5.6 minutes
7922: loss=3.415, avg loss=2.871, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.0 seconds, 507008 images, time remaining=5.5 minutes
7923: loss=2.561, avg loss=2.840, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 507072 images, time remaining=5.4 minutes
7924: loss=3.048, avg loss=2.861, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.0 seconds, train=6.0 seconds, 507136 images, time remaining=5.3 minutes
7925: loss=3.064, avg loss=2.881, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 507200 images, time remaining=5.3 minutes
7926: loss=2.717, avg loss=2.865, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.0 seconds, 507264 images, time remaining=5.2 minutes
7927: loss=2.476, avg loss=2.826, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.1 seconds, 507328 images, time remaining=5.2 minutes
7928: loss=2.301, avg loss=2.773, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.2 seconds, 507392 images, time remaining=5.1 minutes
7929: loss=2.255, avg loss=2.722, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 507456 images, time remaining=5 minutes
7930: loss=2.463, avg loss=2.696, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 507520 images, time remaining=4.9 minutes
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7931: loss=2.613, avg loss=2.688, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.0 seconds, train=6.1 seconds, 507584 images, time remaining=4.9 minutes
7932: loss=2.837, avg loss=2.702, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.0 seconds, 507648 images, time remaining=4.8 minutes
7933: loss=2.676, avg loss=2.700, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 507712 images, time remaining=4.7 minutes
7934: loss=2.778, avg loss=2.708, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 507776 images, time remaining=4.6 minutes
7935: loss=2.933, avg loss=2.730, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.1 seconds, 507840 images, time remaining=4.6 minutes
7936: loss=3.503, avg loss=2.808, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 507904 images, time remaining=4.5 minutes
7937: loss=2.964, avg loss=2.823, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.1 seconds, 507968 images, time remaining=4.4 minutes
7938: loss=3.607, avg loss=2.902, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 508032 images, time remaining=4.4 minutes
7939: loss=2.631, avg loss=2.874, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.1 seconds, 508096 images, time remaining=4.3 minutes
7940: loss=3.202, avg loss=2.907, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 508160 images, time remaining=4.2 minutes
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7941: loss=2.830, avg loss=2.899, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.1 seconds, 508224 images, time remaining=4.2 minutes
7942: loss=2.599, avg loss=2.869, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 508288 images, time remaining=4.1 minutes
7943: loss=2.818, avg loss=2.864, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 508352 images, time remaining=4 minutes
7944: loss=3.092, avg loss=2.887, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.2 seconds, 508416 images, time remaining=3.9 minutes
7945: loss=3.181, avg loss=2.916, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 508480 images, time remaining=3.9 minutes
7946: loss=3.165, avg loss=2.941, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.0 seconds, 508544 images, time remaining=3.8 minutes
7947: loss=2.309, avg loss=2.878, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 508608 images, time remaining=3.7 minutes
7948: loss=2.784, avg loss=2.869, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.0 seconds, 508672 images, time remaining=3.7 minutes
7949: loss=3.457, avg loss=2.928, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.0 seconds, 508736 images, time remaining=3.6 minutes
7950: loss=2.386, avg loss=2.873, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.0 seconds, 508800 images, time remaining=3.5 minutes
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7951: loss=2.855, avg loss=2.872, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 508864 images, time remaining=3.4 minutes
7952: loss=2.552, avg loss=2.840, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.0 seconds, train=6.0 seconds, 508928 images, time remaining=3.4 minutes
7953: loss=2.515, avg loss=2.807, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 508992 images, time remaining=3.3 minutes
7954: loss=3.075, avg loss=2.834, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.1 seconds, train=6.0 seconds, 509056 images, time remaining=3.2 minutes
7955: loss=2.331, avg loss=2.784, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 509120 images, time remaining=3.2 minutes
7956: loss=2.772, avg loss=2.782, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.2 seconds, 509184 images, time remaining=3.1 minutes
7957: loss=2.957, avg loss=2.800, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.0 seconds, train=6.0 seconds, 509248 images, time remaining=3 minutes
7958: loss=2.997, avg loss=2.820, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 509312 images, time remaining=3 minutes
7959: loss=3.028, avg loss=2.841, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 509376 images, time remaining=2.9 minutes
7960: loss=3.010, avg loss=2.857, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.4 seconds, train=6.0 seconds, 509440 images, time remaining=2.8 minutes
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7961: loss=3.272, avg loss=2.899, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.0 seconds, 509504 images, time remaining=2.8 minutes
7962: loss=2.244, avg loss=2.833, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.1 seconds, train=6.1 seconds, 509568 images, time remaining=2.7 minutes
7963: loss=2.178, avg loss=2.768, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 509632 images, time remaining=2.6 minutes
7964: loss=3.446, avg loss=2.836, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 509696 images, time remaining=2.5 minutes
7965: loss=2.502, avg loss=2.802, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 509760 images, time remaining=2.5 minutes
7966: loss=2.763, avg loss=2.798, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.1 seconds, train=6.0 seconds, 509824 images, time remaining=2.4 minutes
7967: loss=2.349, avg loss=2.753, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 509888 images, time remaining=2.3 minutes
7968: loss=2.544, avg loss=2.733, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.0 seconds, train=6.1 seconds, 509952 images, time remaining=2.2 minutes
7969: loss=2.378, avg loss=2.697, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.0 seconds, 510016 images, time remaining=2.2 minutes
7970: loss=3.193, avg loss=2.747, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 510080 images, time remaining=2.1 minutes
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7971: loss=2.895, avg loss=2.762, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 510144 images, time remaining=2 minutes
7972: loss=3.053, avg loss=2.791, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.0 seconds, train=6.0 seconds, 510208 images, time remaining=118 seconds
7973: loss=3.764, avg loss=2.888, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=3.8 seconds, train=6.1 seconds, 510272 images, time remaining=114 seconds
7974: loss=2.745, avg loss=2.874, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 510336 images, time remaining=110 seconds
7975: loss=2.531, avg loss=2.839, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.1 seconds, 510400 images, time remaining=106 seconds
7976: loss=2.782, avg loss=2.834, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 510464 images, time remaining=101 seconds
7977: loss=2.527, avg loss=2.803, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.1 seconds, 510528 images, time remaining=97 seconds
7978: loss=2.237, avg loss=2.746, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.0 seconds, train=6.0 seconds, 510592 images, time remaining=93 seconds
7979: loss=3.294, avg loss=2.801, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.0 seconds, 510656 images, time remaining=89 seconds
7980: loss=2.416, avg loss=2.763, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.1 seconds, train=6.1 seconds, 510720 images, time remaining=85 seconds
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7981: loss=3.482, avg loss=2.835, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.1 seconds, 510784 images, time remaining=80 seconds
7982: loss=2.967, avg loss=2.848, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.0 seconds, 510848 images, time remaining=76 seconds
7983: loss=3.010, avg loss=2.864, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=5.9 seconds, 510912 images, time remaining=72 seconds
7984: loss=2.661, avg loss=2.844, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.0 seconds, train=6.1 seconds, 510976 images, time remaining=68 seconds
7985: loss=3.635, avg loss=2.923, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 511040 images, time remaining=63 seconds
7986: loss=2.367, avg loss=2.867, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.0 seconds, 511104 images, time remaining=59 seconds
7987: loss=3.406, avg loss=2.921, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.1 seconds, 511168 images, time remaining=55 seconds
7988: loss=2.439, avg loss=2.873, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 511232 images, time remaining=51 seconds
7989: loss=2.393, avg loss=2.825, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.0 seconds, train=6.0 seconds, 511296 images, time remaining=46 seconds
7990: loss=3.131, avg loss=2.856, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 511360 images, time remaining=42 seconds
Resizing, random_coef=1.40, batch=4, 1376x1056
GPU #0: allocating workspace: 16.6 GiB begins at 0x14aee4000000
7991: loss=2.692, avg loss=2.839, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.0 seconds, 511424 images, time remaining=38 seconds
7992: loss=2.249, avg loss=2.780, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=2.0 seconds, train=6.0 seconds, 511488 images, time remaining=34 seconds
7993: loss=2.756, avg loss=2.778, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.1 seconds, 511552 images, time remaining=29 seconds
7994: loss=3.581, avg loss=2.858, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.0 seconds, 511616 images, time remaining=25 seconds
7995: loss=2.695, avg loss=2.842, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.2 seconds, 511680 images, time remaining=21 seconds
7996: loss=2.695, avg loss=2.827, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.0 seconds, 511744 images, time remaining=17 seconds
7997: loss=2.598, avg loss=2.804, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 511808 images, time remaining=12 seconds
7998: loss=2.891, avg loss=2.813, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.8 seconds, train=6.1 seconds, 511872 images, time remaining=8 seconds
7999: loss=2.868, avg loss=2.818, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.7 seconds, train=6.1 seconds, 511936 images, time remaining=4 seconds
8000: loss=2.378, avg loss=2.774, last=97.86%, best=97.90%, next=8308, rate=0.00001300, load 64=1.9 seconds, train=6.1 seconds, 512000 images, time remaining=unknown
Resizing to initial size: 960 x 736
GPU #0: allocating workspace: 4.3 GiB begins at 0x14b1f6000000
Calculating mAP (mean average precision)...
Detection layer #139 is type 17 (yolo)
Detection layer #150 is type 17 (yolo)
Detection layer #161 is type 17 (yolo)
using 4 threads to load 2887 validation images for mAP% calculations
processing #0 (0%) processing #4 (0%) processing #8 (0%) processing #12 (0%) processing #16 (1%) processing #20 (1%) processing #24 (1%) processing #28 (1%) processing #32 (1%) processing #36 (1%) processing #40 (1%) processing #44 (2%) processing #48 (2%) processing #52 (2%) processing #56 (2%) processing #60 (2%) processing #64 (2%) processing #68 (2%) processing #72 (2%) processing #76 (3%) processing #80 (3%) processing #84 (3%) processing #88 (3%) processing #92 (3%) processing #96 (3%) processing #100 (3%) processing #104 (4%) processing #108 (4%) processing #112 (4%) processing #116 (4%) processing #120 (4%) processing #124 (4%) processing #128 (4%) processing #132 (5%) processing #136 (5%) processing #140 (5%) processing #144 (5%) processing #148 (5%) processing #152 (5%) processing #156 (5%) processing #160 (6%) processing #164 (6%) processing #168 (6%) processing #172 (6%) processing #176 (6%) processing #180 (6%) processing #184 (6%) processing #188 (7%) processing #192 (7%) processing #196 (7%) processing #200 (7%) processing #204 (7%) processing #208 (7%) processing #212 (7%) processing #216 (7%) processing #220 (8%) processing #224 (8%) processing #228 (8%) processing #232 (8%) processing #236 (8%) processing #240 (8%) processing #244 (8%) processing #248 (9%) processing #252 (9%) processing #256 (9%) processing #260 (9%) processing #264 (9%) processing #268 (9%) processing #272 (9%) processing #276 (10%) processing #280 (10%) processing #284 (10%) processing #288 (10%) processing #292 (10%) processing #296 (10%) processing #300 (10%) processing #304 (11%) processing #308 (11%) processing #312 (11%) processing #316 (11%) processing #320 (11%) processing #324 (11%) processing #328 (11%) processing #332 (11%) processing #336 (12%) processing #340 (12%) processing #344 (12%) processing #348 (12%) processing #352 (12%) processing #356 (12%) processing #360 (12%) processing #364 (13%) processing #368 (13%) processing #372 (13%) processing #376 (13%) processing #380 (13%) processing #384 (13%) processing #388 (13%) processing #392 (14%) processing #396 (14%) processing #400 (14%) processing #404 (14%) processing #408 (14%) processing #412 (14%) processing #416 (14%) processing #420 (15%) processing #424 (15%) processing #428 (15%) processing #432 (15%) processing #436 (15%) processing #440 (15%) processing #444 (15%) processing #448 (16%) processing #452 (16%) processing #456 (16%) processing #460 (16%) processing #464 (16%) processing #468 (16%) processing #472 (16%) processing #476 (16%) processing #480 (17%) processing #484 (17%) processing #488 (17%) processing #492 (17%) processing #496 (17%) processing #500 (17%) processing #504 (17%) processing #508 (18%) processing #512 (18%) processing #516 (18%) processing #520 (18%) processing #524 (18%) processing #528 (18%) processing #532 (18%) processing #536 (19%) processing #540 (19%) processing #544 (19%) processing #548 (19%) processing #552 (19%) processing #556 (19%) processing #560 (19%) processing #564 (20%) processing #568 (20%) processing #572 (20%) processing #576 (20%) processing #580 (20%) processing #584 (20%) processing #588 (20%) processing #592 (21%) processing #596 (21%) processing #600 (21%) processing #604 (21%) processing #608 (21%) processing #612 (21%) processing #616 (21%) processing #620 (21%) processing #624 (22%) processing #628 (22%) processing #632 (22%) processing #636 (22%) processing #640 (22%) processing #644 (22%) processing #648 (22%) processing #652 (23%) processing #656 (23%) processing #660 (23%) processing #664 (23%) processing #668 (23%) processing #672 (23%) processing #676 (23%) processing #680 (24%) processing #684 (24%) processing #688 (24%) processing #692 (24%) processing #696 (24%) processing #700 (24%) processing #704 (24%) processing #708 (25%) processing #712 (25%) processing #716 (25%) processing #720 (25%) processing #724 (25%) processing #728 (25%) processing #732 (25%) processing #736 (25%) processing #740 (26%) processing #744 (26%) processing #748 (26%) processing #752 (26%) processing #756 (26%) processing #760 (26%) processing #764 (26%) processing #768 (27%) processing #772 (27%) processing #776 (27%) processing #780 (27%) processing #784 (27%) processing #788 (27%) processing #792 (27%) processing #796 (28%) processing #800 (28%) processing #804 (28%) processing #808 (28%) processing #812 (28%) processing #816 (28%) processing #820 (28%) processing #824 (29%) processing #828 (29%) processing #832 (29%) processing #836 (29%) processing #840 (29%) processing #844 (29%) processing #848 (29%) processing #852 (30%) processing #856 (30%) processing #860 (30%) processing #864 (30%) processing #868 (30%) processing #872 (30%) processing #876 (30%) processing #880 (30%) processing #884 (31%) processing #888 (31%) processing #892 (31%) processing #896 (31%) processing #900 (31%) processing #904 (31%) processing #908 (31%) processing #912 (32%) processing #916 (32%) processing #920 (32%) processing #924 (32%) processing #928 (32%) processing #932 (32%) processing #936 (32%) processing #940 (33%) processing #944 (33%) processing #948 (33%) processing #952 (33%) processing #956 (33%) processing #960 (33%) processing #964 (33%) processing #968 (34%) processing #972 (34%) processing #976 (34%) processing #980 (34%) processing #984 (34%) processing #988 (34%) processing #992 (34%) processing #996 (34%) processing #1000 (35%) processing #1004 (35%) processing #1008 (35%) processing #1012 (35%) processing #1016 (35%) processing #1020 (35%) processing #1024 (35%) processing #1028 (36%) processing #1032 (36%) processing #1036 (36%) processing #1040 (36%) processing #1044 (36%) processing #1048 (36%) processing #1052 (36%) processing #1056 (37%) processing #1060 (37%) processing #1064 (37%) processing #1068 (37%) processing #1072 (37%) processing #1076 (37%) processing #1080 (37%) processing #1084 (38%) processing #1088 (38%) processing #1092 (38%) processing #1096 (38%) processing #1100 (38%) processing #1104 (38%) processing #1108 (38%) processing #1112 (39%) processing #1116 (39%) processing #1120 (39%) processing #1124 (39%) processing #1128 (39%) processing #1132 (39%) processing #1136 (39%) processing #1140 (39%) processing #1144 (40%) processing #1148 (40%) processing #1152 (40%) processing #1156 (40%) processing #1160 (40%) processing #1164 (40%) processing #1168 (40%) processing #1172 (41%) processing #1176 (41%) processing #1180 (41%) processing #1184 (41%) processing #1188 (41%) processing #1192 (41%) processing #1196 (41%) processing #1200 (42%) processing #1204 (42%) processing #1208 (42%) processing #1212 (42%) processing #1216 (42%) processing #1220 (42%) processing #1224 (42%) processing #1228 (43%) processing #1232 (43%) processing #1236 (43%) processing #1240 (43%) processing #1244 (43%) processing #1248 (43%) processing #1252 (43%) processing #1256 (44%) processing #1260 (44%) processing #1264 (44%) processing #1268 (44%) processing #1272 (44%) processing #1276 (44%) processing #1280 (44%) processing #1284 (44%) processing #1288 (45%) processing #1292 (45%) processing #1296 (45%) processing #1300 (45%) processing #1304 (45%) processing #1308 (45%) processing #1312 (45%) processing #1316 (46%) processing #1320 (46%) processing #1324 (46%) processing #1328 (46%) processing #1332 (46%) processing #1336 (46%) processing #1340 (46%) processing #1344 (47%) processing #1348 (47%) processing #1352 (47%) processing #1356 (47%) processing #1360 (47%) processing #1364 (47%) processing #1368 (47%) processing #1372 (48%) processing #1376 (48%) processing #1380 (48%) processing #1384 (48%) processing #1388 (48%) processing #1392 (48%) processing #1396 (48%) processing #1400 (48%) processing #1404 (49%) processing #1408 (49%) processing #1412 (49%) processing #1416 (49%) processing #1420 (49%) processing #1424 (49%) processing #1428 (49%) processing #1432 (50%) processing #1436 (50%) processing #1440 (50%) processing #1444 (50%) processing #1448 (50%) processing #1452 (50%) processing #1456 (50%) processing #1460 (51%) processing #1464 (51%) processing #1468 (51%) processing #1472 (51%) processing #1476 (51%) processing #1480 (51%) processing #1484 (51%) processing #1488 (52%) processing #1492 (52%) processing #1496 (52%) processing #1500 (52%) processing #1504 (52%) processing #1508 (52%) processing #1512 (52%) processing #1516 (53%) processing #1520 (53%) processing #1524 (53%) processing #1528 (53%) processing #1532 (53%) processing #1536 (53%) processing #1540 (53%) processing #1544 (53%) processing #1548 (54%) processing #1552 (54%) processing #1556 (54%) processing #1560 (54%) processing #1564 (54%) processing #1568 (54%) processing #1572 (54%) processing #1576 (55%) processing #1580 (55%) processing #1584 (55%) processing #1588 (55%) processing #1592 (55%) processing #1596 (55%) processing #1600 (55%) processing #1604 (56%) processing #1608 (56%) processing #1612 (56%) processing #1616 (56%) processing #1620 (56%) processing #1624 (56%) processing #1628 (56%) processing #1632 (57%) processing #1636 (57%) processing #1640 (57%) processing #1644 (57%) processing #1648 (57%) processing #1652 (57%) processing #1656 (57%) processing #1660 (57%) processing #1664 (58%) processing #1668 (58%) processing #1672 (58%) processing #1676 (58%) processing #1680 (58%) processing #1684 (58%) processing #1688 (58%) processing #1692 (59%) processing #1696 (59%) processing #1700 (59%) processing #1704 (59%) processing #1708 (59%) processing #1712 (59%) processing #1716 (59%) processing #1720 (60%) processing #1724 (60%) processing #1728 (60%) processing #1732 (60%) processing #1736 (60%) processing #1740 (60%) processing #1744 (60%) processing #1748 (61%) processing #1752 (61%) processing #1756 (61%) processing #1760 (61%) processing #1764 (61%) processing #1768 (61%) processing #1772 (61%) processing #1776 (62%) processing #1780 (62%) processing #1784 (62%) processing #1788 (62%) processing #1792 (62%) processing #1796 (62%) processing #1800 (62%) processing #1804 (62%) processing #1808 (63%) processing #1812 (63%) processing #1816 (63%) processing #1820 (63%) processing #1824 (63%) processing #1828 (63%) processing #1832 (63%) processing #1836 (64%) processing #1840 (64%) processing #1844 (64%) processing #1848 (64%) processing #1852 (64%) processing #1856 (64%) processing #1860 (64%) processing #1864 (65%) processing #1868 (65%) processing #1872 (65%) processing #1876 (65%) processing #1880 (65%) processing #1884 (65%) processing #1888 (65%) processing #1892 (66%) processing #1896 (66%) processing #1900 (66%) processing #1904 (66%) processing #1908 (66%) processing #1912 (66%) processing #1916 (66%) processing #1920 (67%) processing #1924 (67%) processing #1928 (67%) processing #1932 (67%) processing #1936 (67%) processing #1940 (67%) processing #1944 (67%) processing #1948 (67%) processing #1952 (68%) processing #1956 (68%) processing #1960 (68%) processing #1964 (68%) processing #1968 (68%) processing #1972 (68%) processing #1976 (68%) processing #1980 (69%) processing #1984 (69%) processing #1988 (69%) processing #1992 (69%) processing #1996 (69%) processing #2000 (69%) processing #2004 (69%) processing #2008 (70%) processing #2012 (70%) processing #2016 (70%) processing #2020 (70%) processing #2024 (70%) processing #2028 (70%) processing #2032 (70%) processing #2036 (71%) processing #2040 (71%) processing #2044 (71%) processing #2048 (71%) processing #2052 (71%) processing #2056 (71%) processing #2060 (71%) processing #2064 (71%) processing #2068 (72%) processing #2072 (72%) processing #2076 (72%) processing #2080 (72%) processing #2084 (72%) processing #2088 (72%) processing #2092 (72%) processing #2096 (73%) processing #2100 (73%) processing #2104 (73%) processing #2108 (73%) processing #2112 (73%) processing #2116 (73%) processing #2120 (73%) processing #2124 (74%) processing #2128 (74%) processing #2132 (74%) processing #2136 (74%) processing #2140 (74%) processing #2144 (74%) processing #2148 (74%) processing #2152 (75%) processing #2156 (75%) processing #2160 (75%) processing #2164 (75%) processing #2168 (75%) processing #2172 (75%) processing #2176 (75%) processing #2180 (76%) processing #2184 (76%) processing #2188 (76%) processing #2192 (76%) processing #2196 (76%) processing #2200 (76%) processing #2204 (76%) processing #2208 (76%) processing #2212 (77%) processing #2216 (77%) processing #2220 (77%) processing #2224 (77%) processing #2228 (77%) processing #2232 (77%) processing #2236 (77%) processing #2240 (78%) processing #2244 (78%) processing #2248 (78%) processing #2252 (78%) processing #2256 (78%) processing #2260 (78%) processing #2264 (78%) processing #2268 (79%) processing #2272 (79%) processing #2276 (79%) processing #2280 (79%) processing #2284 (79%) processing #2288 (79%) processing #2292 (79%) processing #2296 (80%) processing #2300 (80%) processing #2304 (80%) processing #2308 (80%) processing #2312 (80%) processing #2316 (80%) processing #2320 (80%) processing #2324 (80%) processing #2328 (81%) processing #2332 (81%) processing #2336 (81%) processing #2340 (81%) processing #2344 (81%) processing #2348 (81%) processing #2352 (81%) processing #2356 (82%) processing #2360 (82%) processing #2364 (82%) processing #2368 (82%) processing #2372 (82%) processing #2376 (82%) processing #2380 (82%) processing #2384 (83%) processing #2388 (83%) processing #2392 (83%) processing #2396 (83%) processing #2400 (83%) processing #2404 (83%) processing #2408 (83%) processing #2412 (84%) processing #2416 (84%) processing #2420 (84%) processing #2424 (84%) processing #2428 (84%) processing #2432 (84%) processing #2436 (84%) processing #2440 (85%) processing #2444 (85%) processing #2448 (85%) processing #2452 (85%) processing #2456 (85%) processing #2460 (85%) processing #2464 (85%) processing #2468 (85%) processing #2472 (86%) processing #2476 (86%) processing #2480 (86%) processing #2484 (86%) processing #2488 (86%) processing #2492 (86%) processing #2496 (86%) processing #2500 (87%) processing #2504 (87%) processing #2508 (87%) processing #2512 (87%) processing #2516 (87%) processing #2520 (87%) processing #2524 (87%) processing #2528 (88%) processing #2532 (88%) processing #2536 (88%) processing #2540 (88%) processing #2544 (88%) processing #2548 (88%) processing #2552 (88%) processing #2556 (89%) processing #2560 (89%) processing #2564 (89%) processing #2568 (89%) processing #2572 (89%) processing #2576 (89%) processing #2580 (89%) processing #2584 (90%) processing #2588 (90%) processing #2592 (90%) processing #2596 (90%) processing #2600 (90%) processing #2604 (90%) processing #2608 (90%) processing #2612 (90%) processing #2616 (91%) processing #2620 (91%) processing #2624 (91%) processing #2628 (91%) processing #2632 (91%) processing #2636 (91%) processing #2640 (91%) processing #2644 (92%) processing #2648 (92%) processing #2652 (92%) processing #2656 (92%) processing #2660 (92%) processing #2664 (92%) processing #2668 (92%) processing #2672 (93%) processing #2676 (93%) processing #2680 (93%) processing #2684 (93%) processing #2688 (93%) processing #2692 (93%) processing #2696 (93%) processing #2700 (94%) processing #2704 (94%) processing #2708 (94%) processing #2712 (94%) processing #2716 (94%) processing #2720 (94%) processing #2724 (94%) processing #2728 (94%) processing #2732 (95%) processing #2736 (95%) processing #2740 (95%) processing #2744 (95%) processing #2748 (95%) processing #2752 (95%) processing #2756 (95%) processing #2760 (96%) processing #2764 (96%) processing #2768 (96%) processing #2772 (96%) processing #2776 (96%) processing #2780 (96%) processing #2784 (96%) processing #2788 (97%) processing #2792 (97%) processing #2796 (97%) processing #2800 (97%) processing #2804 (97%) processing #2808 (97%) processing #2812 (97%) processing #2816 (98%) processing #2820 (98%) processing #2824 (98%) processing #2828 (98%) processing #2832 (98%) processing #2836 (98%) processing #2840 (98%) processing #2844 (99%) processing #2848 (99%) processing #2852 (99%) processing #2856 (99%) processing #2860 (99%) processing #2864 (99%) processing #2868 (99%) processing #2872 (99%) processing #2876 (100%) processing #2880 (100%) processing #2884 (100%) detections_count=88730, unique_truth_count=57264
rank=0 of ranks=88730rank=100 of ranks=88730rank=200 of ranks=88730rank=300 of ranks=88730rank=400 of ranks=88730rank=500 of ranks=88730rank=600 of ranks=88730rank=700 of ranks=88730rank=800 of ranks=88730rank=900 of ranks=88730rank=1000 of ranks=88730rank=1100 of ranks=88730rank=1200 of ranks=88730rank=1300 of ranks=88730rank=1400 of ranks=88730rank=1500 of ranks=88730rank=1600 of ranks=88730rank=1700 of ranks=88730rank=1800 of ranks=88730rank=1900 of ranks=88730rank=2000 of ranks=88730rank=2100 of ranks=88730rank=2200 of ranks=88730rank=2300 of ranks=88730rank=2400 of ranks=88730rank=2500 of ranks=88730rank=2600 of ranks=88730rank=2700 of ranks=88730rank=2800 of ranks=88730rank=2900 of ranks=88730rank=3000 of ranks=88730rank=3100 of ranks=88730rank=3200 of ranks=88730rank=3300 of ranks=88730rank=3400 of ranks=88730rank=3500 of ranks=88730rank=3600 of ranks=88730rank=3700 of ranks=88730rank=3800 of ranks=88730rank=3900 of ranks=88730rank=4000 of ranks=88730rank=4100 of ranks=88730rank=4200 of ranks=88730rank=4300 of ranks=88730rank=4400 of ranks=88730rank=4500 of ranks=88730rank=4600 of ranks=88730rank=4700 of ranks=88730rank=4800 of ranks=88730rank=4900 of ranks=88730rank=5000 of ranks=88730rank=5100 of ranks=88730rank=5200 of ranks=88730rank=5300 of ranks=88730rank=5400 of ranks=88730rank=5500 of ranks=88730rank=5600 of ranks=88730rank=5700 of ranks=88730rank=5800 of ranks=88730rank=5900 of ranks=88730rank=6000 of ranks=88730rank=6100 of ranks=88730rank=6200 of ranks=88730rank=6300 of ranks=88730rank=6400 of ranks=88730rank=6500 of ranks=88730rank=6600 of ranks=88730rank=6700 of ranks=88730rank=6800 of ranks=88730rank=6900 of ranks=88730rank=7000 of ranks=88730rank=7100 of ranks=88730rank=7200 of ranks=88730rank=7300 of ranks=88730rank=7400 of ranks=88730rank=7500 of ranks=88730rank=7600 of ranks=88730rank=7700 of ranks=88730rank=7800 of ranks=88730rank=7900 of ranks=88730rank=8000 of ranks=88730rank=8100 of ranks=88730rank=8200 of ranks=88730rank=8300 of ranks=88730rank=8400 of ranks=88730rank=8500 of ranks=88730rank=8600 of ranks=88730rank=8700 of ranks=88730rank=8800 of ranks=88730rank=8900 of ranks=88730rank=9000 of ranks=88730rank=9100 of ranks=88730rank=9200 of ranks=88730rank=9300 of ranks=88730rank=9400 of ranks=88730rank=9500 of ranks=88730rank=9600 of ranks=88730rank=9700 of ranks=88730rank=9800 of ranks=88730rank=9900 of ranks=88730rank=10000 of ranks=88730rank=10100 of ranks=88730rank=10200 of ranks=88730rank=10300 of ranks=88730rank=10400 of ranks=88730rank=10500 of ranks=88730rank=10600 of ranks=88730rank=10700 of ranks=88730rank=10800 of ranks=88730rank=10900 of ranks=88730rank=11000 of ranks=88730rank=11100 of ranks=88730rank=11200 of ranks=88730rank=11300 of ranks=88730rank=11400 of ranks=88730rank=11500 of ranks=88730rank=11600 of ranks=88730rank=11700 of ranks=88730rank=11800 of ranks=88730rank=11900 of ranks=88730rank=12000 of ranks=88730rank=12100 of ranks=88730rank=12200 of ranks=88730rank=12300 of ranks=88730rank=12400 of ranks=88730rank=12500 of ranks=88730rank=12600 of ranks=88730rank=12700 of ranks=88730rank=12800 of ranks=88730rank=12900 of ranks=88730rank=13000 of ranks=88730rank=13100 of ranks=88730rank=13200 of ranks=88730rank=13300 of ranks=88730rank=13400 of ranks=88730rank=13500 of ranks=88730rank=13600 of ranks=88730rank=13700 of ranks=88730rank=13800 of ranks=88730rank=13900 of ranks=88730rank=14000 of ranks=88730rank=14100 of ranks=88730rank=14200 of ranks=88730rank=14300 of ranks=88730rank=14400 of ranks=88730rank=14500 of ranks=88730rank=14600 of ranks=88730rank=14700 of ranks=88730rank=14800 of ranks=88730rank=14900 of ranks=88730rank=15000 of ranks=88730rank=15100 of ranks=88730rank=15200 of ranks=88730rank=15300 of ranks=88730rank=15400 of ranks=88730rank=15500 of ranks=88730rank=15600 of ranks=88730rank=15700 of ranks=88730rank=15800 of ranks=88730rank=15900 of ranks=88730rank=16000 of ranks=88730rank=16100 of ranks=88730rank=16200 of ranks=88730rank=16300 of ranks=88730rank=16400 of ranks=88730rank=16500 of ranks=88730rank=16600 of ranks=88730rank=16700 of ranks=88730rank=16800 of ranks=88730rank=16900 of ranks=88730rank=17000 of ranks=88730rank=17100 of ranks=88730rank=17200 of ranks=88730rank=17300 of ranks=88730rank=17400 of ranks=88730rank=17500 of ranks=88730rank=17600 of ranks=88730rank=17700 of ranks=88730rank=17800 of ranks=88730rank=17900 of ranks=88730rank=18000 of ranks=88730rank=18100 of ranks=88730rank=18200 of ranks=88730rank=18300 of ranks=88730rank=18400 of ranks=88730rank=18500 of ranks=88730rank=18600 of ranks=88730rank=18700 of ranks=88730rank=18800 of ranks=88730rank=18900 of ranks=88730rank=19000 of ranks=88730rank=19100 of ranks=88730rank=19200 of ranks=88730rank=19300 of ranks=88730rank=19400 of ranks=88730rank=19500 of ranks=88730rank=19600 of ranks=88730rank=19700 of ranks=88730rank=19800 of ranks=88730rank=19900 of ranks=88730rank=20000 of ranks=88730rank=20100 of ranks=88730rank=20200 of ranks=88730rank=20300 of ranks=88730rank=20400 of ranks=88730rank=20500 of ranks=88730rank=20600 of ranks=88730rank=20700 of ranks=88730rank=20800 of ranks=88730rank=20900 of ranks=88730rank=21000 of ranks=88730rank=21100 of ranks=88730rank=21200 of ranks=88730rank=21300 of ranks=88730rank=21400 of ranks=88730rank=21500 of ranks=88730rank=21600 of ranks=88730rank=21700 of ranks=88730rank=21800 of ranks=88730rank=21900 of ranks=88730rank=22000 of ranks=88730rank=22100 of ranks=88730rank=22200 of ranks=88730rank=22300 of ranks=88730rank=22400 of ranks=88730rank=22500 of ranks=88730rank=22600 of ranks=88730rank=22700 of ranks=88730rank=22800 of ranks=88730rank=22900 of ranks=88730rank=23000 of ranks=88730rank=23100 of ranks=88730rank=23200 of ranks=88730rank=23300 of ranks=88730rank=23400 of ranks=88730rank=23500 of ranks=88730rank=23600 of ranks=88730rank=23700 of ranks=88730rank=23800 of ranks=88730rank=23900 of ranks=88730rank=24000 of ranks=88730rank=24100 of ranks=88730rank=24200 of ranks=88730rank=24300 of ranks=88730rank=24400 of ranks=88730rank=24500 of ranks=88730rank=24600 of ranks=88730rank=24700 of ranks=88730rank=24800 of ranks=88730rank=24900 of ranks=88730rank=25000 of ranks=88730rank=25100 of ranks=88730rank=25200 of ranks=88730rank=25300 of ranks=88730rank=25400 of ranks=88730rank=25500 of ranks=88730rank=25600 of ranks=88730rank=25700 of ranks=88730rank=25800 of ranks=88730rank=25900 of ranks=88730rank=26000 of ranks=88730rank=26100 of ranks=88730rank=26200 of ranks=88730rank=26300 of ranks=88730rank=26400 of ranks=88730rank=26500 of ranks=88730rank=26600 of ranks=88730rank=26700 of ranks=88730rank=26800 of ranks=88730rank=26900 of ranks=88730rank=27000 of ranks=88730rank=27100 of ranks=88730rank=27200 of ranks=88730rank=27300 of ranks=88730rank=27400 of ranks=88730rank=27500 of ranks=88730rank=27600 of ranks=88730rank=27700 of ranks=88730rank=27800 of ranks=88730rank=27900 of ranks=88730rank=28000 of ranks=88730rank=28100 of ranks=88730rank=28200 of ranks=88730rank=28300 of ranks=88730rank=28400 of ranks=88730rank=28500 of ranks=88730rank=28600 of ranks=88730rank=28700 of ranks=88730rank=28800 of ranks=88730rank=28900 of ranks=88730rank=29000 of ranks=88730rank=29100 of ranks=88730rank=29200 of ranks=88730rank=29300 of ranks=88730rank=29400 of ranks=88730rank=29500 of ranks=88730rank=29600 of ranks=88730rank=29700 of ranks=88730rank=29800 of ranks=88730rank=29900 of ranks=88730rank=30000 of ranks=88730rank=30100 of ranks=88730rank=30200 of ranks=88730rank=30300 of ranks=88730rank=30400 of ranks=88730rank=30500 of ranks=88730rank=30600 of ranks=88730rank=30700 of ranks=88730rank=30800 of ranks=88730rank=30900 of ranks=88730rank=31000 of ranks=88730rank=31100 of ranks=88730rank=31200 of ranks=88730rank=31300 of ranks=88730rank=31400 of ranks=88730rank=31500 of ranks=88730rank=31600 of ranks=88730rank=31700 of ranks=88730rank=31800 of ranks=88730rank=31900 of ranks=88730rank=32000 of ranks=88730rank=32100 of ranks=88730rank=32200 of ranks=88730rank=32300 of ranks=88730rank=32400 of ranks=88730rank=32500 of ranks=88730rank=32600 of ranks=88730rank=32700 of ranks=88730rank=32800 of ranks=88730rank=32900 of ranks=88730rank=33000 of ranks=88730rank=33100 of ranks=88730rank=33200 of ranks=88730rank=33300 of ranks=88730rank=33400 of ranks=88730rank=33500 of ranks=88730rank=33600 of ranks=88730rank=33700 of ranks=88730rank=33800 of ranks=88730rank=33900 of ranks=88730rank=34000 of ranks=88730rank=34100 of ranks=88730rank=34200 of ranks=88730rank=34300 of ranks=88730rank=34400 of ranks=88730rank=34500 of ranks=88730rank=34600 of ranks=88730rank=34700 of ranks=88730rank=34800 of ranks=88730rank=34900 of ranks=88730rank=35000 of ranks=88730rank=35100 of ranks=88730rank=35200 of ranks=88730rank=35300 of ranks=88730rank=35400 of ranks=88730rank=35500 of ranks=88730rank=35600 of ranks=88730rank=35700 of ranks=88730rank=35800 of ranks=88730rank=35900 of ranks=88730rank=36000 of ranks=88730rank=36100 of ranks=88730rank=36200 of ranks=88730rank=36300 of ranks=88730rank=36400 of ranks=88730rank=36500 of ranks=88730rank=36600 of ranks=88730rank=36700 of ranks=88730rank=36800 of ranks=88730rank=36900 of ranks=88730rank=37000 of ranks=88730rank=37100 of ranks=88730rank=37200 of ranks=88730rank=37300 of ranks=88730rank=37400 of ranks=88730rank=37500 of ranks=88730rank=37600 of ranks=88730rank=37700 of ranks=88730rank=37800 of ranks=88730rank=37900 of ranks=88730rank=38000 of ranks=88730rank=38100 of ranks=88730rank=38200 of ranks=88730rank=38300 of ranks=88730rank=38400 of ranks=88730rank=38500 of ranks=88730rank=38600 of ranks=88730rank=38700 of ranks=88730rank=38800 of ranks=88730rank=38900 of ranks=88730rank=39000 of ranks=88730rank=39100 of ranks=88730rank=39200 of ranks=88730rank=39300 of ranks=88730rank=39400 of ranks=88730rank=39500 of ranks=88730rank=39600 of ranks=88730rank=39700 of ranks=88730rank=39800 of ranks=88730rank=39900 of ranks=88730rank=40000 of ranks=88730rank=40100 of ranks=88730rank=40200 of ranks=88730rank=40300 of ranks=88730rank=40400 of ranks=88730rank=40500 of ranks=88730rank=40600 of ranks=88730rank=40700 of ranks=88730rank=40800 of ranks=88730rank=40900 of ranks=88730rank=41000 of ranks=88730rank=41100 of ranks=88730rank=41200 of ranks=88730rank=41300 of ranks=88730rank=41400 of ranks=88730rank=41500 of ranks=88730rank=41600 of ranks=88730rank=41700 of ranks=88730rank=41800 of ranks=88730rank=41900 of ranks=88730rank=42000 of ranks=88730rank=42100 of ranks=88730rank=42200 of ranks=88730rank=42300 of ranks=88730rank=42400 of ranks=88730rank=42500 of ranks=88730rank=42600 of ranks=88730rank=42700 of ranks=88730rank=42800 of ranks=88730rank=42900 of ranks=88730rank=43000 of ranks=88730rank=43100 of ranks=88730rank=43200 of ranks=88730rank=43300 of ranks=88730rank=43400 of ranks=88730rank=43500 of ranks=88730rank=43600 of ranks=88730rank=43700 of ranks=88730rank=43800 of ranks=88730rank=43900 of ranks=88730rank=44000 of ranks=88730rank=44100 of ranks=88730rank=44200 of ranks=88730rank=44300 of ranks=88730rank=44400 of ranks=88730rank=44500 of ranks=88730rank=44600 of ranks=88730rank=44700 of ranks=88730rank=44800 of ranks=88730rank=44900 of ranks=88730rank=45000 of ranks=88730rank=45100 of ranks=88730rank=45200 of ranks=88730rank=45300 of ranks=88730rank=45400 of ranks=88730rank=45500 of ranks=88730rank=45600 of ranks=88730rank=45700 of ranks=88730rank=45800 of ranks=88730rank=45900 of ranks=88730rank=46000 of ranks=88730rank=46100 of ranks=88730rank=46200 of ranks=88730rank=46300 of ranks=88730rank=46400 of ranks=88730rank=46500 of ranks=88730rank=46600 of ranks=88730rank=46700 of ranks=88730rank=46800 of ranks=88730rank=46900 of ranks=88730rank=47000 of ranks=88730rank=47100 of ranks=88730rank=47200 of ranks=88730rank=47300 of ranks=88730rank=47400 of ranks=88730rank=47500 of ranks=88730rank=47600 of ranks=88730rank=47700 of ranks=88730rank=47800 of ranks=88730rank=47900 of ranks=88730rank=48000 of ranks=88730rank=48100 of ranks=88730rank=48200 of ranks=88730rank=48300 of ranks=88730rank=48400 of ranks=88730rank=48500 of ranks=88730rank=48600 of ranks=88730rank=48700 of ranks=88730rank=48800 of ranks=88730rank=48900 of ranks=88730rank=49000 of ranks=88730rank=49100 of ranks=88730rank=49200 of ranks=88730rank=49300 of ranks=88730rank=49400 of ranks=88730rank=49500 of ranks=88730rank=49600 of ranks=88730rank=49700 of ranks=88730rank=49800 of ranks=88730rank=49900 of ranks=88730rank=50000 of ranks=88730rank=50100 of ranks=88730rank=50200 of ranks=88730rank=50300 of ranks=88730rank=50400 of ranks=88730rank=50500 of ranks=88730rank=50600 of ranks=88730rank=50700 of ranks=88730rank=50800 of ranks=88730rank=50900 of ranks=88730rank=51000 of ranks=88730rank=51100 of ranks=88730rank=51200 of ranks=88730rank=51300 of ranks=88730rank=51400 of ranks=88730rank=51500 of ranks=88730rank=51600 of ranks=88730rank=51700 of ranks=88730rank=51800 of ranks=88730rank=51900 of ranks=88730rank=52000 of ranks=88730rank=52100 of ranks=88730rank=52200 of ranks=88730rank=52300 of ranks=88730rank=52400 of ranks=88730rank=52500 of ranks=88730rank=52600 of ranks=88730rank=52700 of ranks=88730rank=52800 of ranks=88730rank=52900 of ranks=88730rank=53000 of ranks=88730rank=53100 of ranks=88730rank=53200 of ranks=88730rank=53300 of ranks=88730rank=53400 of ranks=88730rank=53500 of ranks=88730rank=53600 of ranks=88730rank=53700 of ranks=88730rank=53800 of ranks=88730rank=53900 of ranks=88730rank=54000 of ranks=88730rank=54100 of ranks=88730rank=54200 of ranks=88730rank=54300 of ranks=88730rank=54400 of ranks=88730rank=54500 of ranks=88730rank=54600 of ranks=88730rank=54700 of ranks=88730rank=54800 of ranks=88730rank=54900 of ranks=88730rank=55000 of ranks=88730rank=55100 of ranks=88730rank=55200 of ranks=88730rank=55300 of ranks=88730rank=55400 of ranks=88730rank=55500 of ranks=88730rank=55600 of ranks=88730rank=55700 of ranks=88730rank=55800 of ranks=88730rank=55900 of ranks=88730rank=56000 of ranks=88730rank=56100 of ranks=88730rank=56200 of ranks=88730rank=56300 of ranks=88730rank=56400 of ranks=88730rank=56500 of ranks=88730rank=56600 of ranks=88730rank=56700 of ranks=88730rank=56800 of ranks=88730rank=56900 of ranks=88730rank=57000 of ranks=88730rank=57100 of ranks=88730rank=57200 of ranks=88730rank=57300 of ranks=88730rank=57400 of ranks=88730rank=57500 of ranks=88730rank=57600 of ranks=88730rank=57700 of ranks=88730rank=57800 of ranks=88730rank=57900 of ranks=88730rank=58000 of ranks=88730rank=58100 of ranks=88730rank=58200 of ranks=88730rank=58300 of ranks=88730rank=58400 of ranks=88730rank=58500 of ranks=88730rank=58600 of ranks=88730rank=58700 of ranks=88730rank=58800 of ranks=88730rank=58900 of ranks=88730rank=59000 of ranks=88730rank=59100 of ranks=88730rank=59200 of ranks=88730rank=59300 of ranks=88730rank=59400 of ranks=88730rank=59500 of ranks=88730rank=59600 of ranks=88730rank=59700 of ranks=88730rank=59800 of ranks=88730rank=59900 of ranks=88730rank=60000 of ranks=88730rank=60100 of ranks=88730rank=60200 of ranks=88730rank=60300 of ranks=88730rank=60400 of ranks=88730rank=60500 of ranks=88730rank=60600 of ranks=88730rank=60700 of ranks=88730rank=60800 of ranks=88730rank=60900 of ranks=88730rank=61000 of ranks=88730rank=61100 of ranks=88730rank=61200 of ranks=88730rank=61300 of ranks=88730rank=61400 of ranks=88730rank=61500 of ranks=88730rank=61600 of ranks=88730rank=61700 of ranks=88730rank=61800 of ranks=88730rank=61900 of ranks=88730rank=62000 of ranks=88730rank=62100 of ranks=88730rank=62200 of ranks=88730rank=62300 of ranks=88730rank=62400 of ranks=88730rank=62500 of ranks=88730rank=62600 of ranks=88730rank=62700 of ranks=88730rank=62800 of ranks=88730rank=62900 of ranks=88730rank=63000 of ranks=88730rank=63100 of ranks=88730rank=63200 of ranks=88730rank=63300 of ranks=88730rank=63400 of ranks=88730rank=63500 of ranks=88730rank=63600 of ranks=88730rank=63700 of ranks=88730rank=63800 of ranks=88730rank=63900 of ranks=88730rank=64000 of ranks=88730rank=64100 of ranks=88730rank=64200 of ranks=88730rank=64300 of ranks=88730rank=64400 of ranks=88730rank=64500 of ranks=88730rank=64600 of ranks=88730rank=64700 of ranks=88730rank=64800 of ranks=88730rank=64900 of ranks=88730rank=65000 of ranks=88730rank=65100 of ranks=88730rank=65200 of ranks=88730rank=65300 of ranks=88730rank=65400 of ranks=88730rank=65500 of ranks=88730rank=65600 of ranks=88730rank=65700 of ranks=88730rank=65800 of ranks=88730rank=65900 of ranks=88730rank=66000 of ranks=88730rank=66100 of ranks=88730rank=66200 of ranks=88730rank=66300 of ranks=88730rank=66400 of ranks=88730rank=66500 of ranks=88730rank=66600 of ranks=88730rank=66700 of ranks=88730rank=66800 of ranks=88730rank=66900 of ranks=88730rank=67000 of ranks=88730rank=67100 of ranks=88730rank=67200 of ranks=88730rank=67300 of ranks=88730rank=67400 of ranks=88730rank=67500 of ranks=88730rank=67600 of ranks=88730rank=67700 of ranks=88730rank=67800 of ranks=88730rank=67900 of ranks=88730rank=68000 of ranks=88730rank=68100 of ranks=88730rank=68200 of ranks=88730rank=68300 of ranks=88730rank=68400 of ranks=88730rank=68500 of ranks=88730rank=68600 of ranks=88730rank=68700 of ranks=88730rank=68800 of ranks=88730rank=68900 of ranks=88730rank=69000 of ranks=88730rank=69100 of ranks=88730rank=69200 of ranks=88730rank=69300 of ranks=88730rank=69400 of ranks=88730rank=69500 of ranks=88730rank=69600 of ranks=88730rank=69700 of ranks=88730rank=69800 of ranks=88730rank=69900 of ranks=88730rank=70000 of ranks=88730rank=70100 of ranks=88730rank=70200 of ranks=88730rank=70300 of ranks=88730rank=70400 of ranks=88730rank=70500 of ranks=88730rank=70600 of ranks=88730rank=70700 of ranks=88730rank=70800 of ranks=88730rank=70900 of ranks=88730rank=71000 of ranks=88730rank=71100 of ranks=88730rank=71200 of ranks=88730rank=71300 of ranks=88730rank=71400 of ranks=88730rank=71500 of ranks=88730rank=71600 of ranks=88730rank=71700 of ranks=88730rank=71800 of ranks=88730rank=71900 of ranks=88730rank=72000 of ranks=88730rank=72100 of ranks=88730rank=72200 of ranks=88730rank=72300 of ranks=88730rank=72400 of ranks=88730rank=72500 of ranks=88730rank=72600 of ranks=88730rank=72700 of ranks=88730rank=72800 of ranks=88730rank=72900 of ranks=88730rank=73000 of ranks=88730rank=73100 of ranks=88730rank=73200 of ranks=88730rank=73300 of ranks=88730rank=73400 of ranks=88730rank=73500 of ranks=88730rank=73600 of ranks=88730rank=73700 of ranks=88730rank=73800 of ranks=88730rank=73900 of ranks=88730rank=74000 of ranks=88730rank=74100 of ranks=88730rank=74200 of ranks=88730rank=74300 of ranks=88730rank=74400 of ranks=88730rank=74500 of ranks=88730rank=74600 of ranks=88730rank=74700 of ranks=88730rank=74800 of ranks=88730rank=74900 of ranks=88730rank=75000 of ranks=88730rank=75100 of ranks=88730rank=75200 of ranks=88730rank=75300 of ranks=88730rank=75400 of ranks=88730rank=75500 of ranks=88730rank=75600 of ranks=88730rank=75700 of ranks=88730rank=75800 of ranks=88730rank=75900 of ranks=88730rank=76000 of ranks=88730rank=76100 of ranks=88730rank=76200 of ranks=88730rank=76300 of ranks=88730rank=76400 of ranks=88730rank=76500 of ranks=88730rank=76600 of ranks=88730rank=76700 of ranks=88730rank=76800 of ranks=88730rank=76900 of ranks=88730rank=77000 of ranks=88730rank=77100 of ranks=88730rank=77200 of ranks=88730rank=77300 of ranks=88730rank=77400 of ranks=88730rank=77500 of ranks=88730rank=77600 of ranks=88730rank=77700 of ranks=88730rank=77800 of ranks=88730rank=77900 of ranks=88730rank=78000 of ranks=88730rank=78100 of ranks=88730rank=78200 of ranks=88730rank=78300 of ranks=88730rank=78400 of ranks=88730rank=78500 of ranks=88730rank=78600 of ranks=88730rank=78700 of ranks=88730rank=78800 of ranks=88730rank=78900 of ranks=88730rank=79000 of ranks=88730rank=79100 of ranks=88730rank=79200 of ranks=88730rank=79300 of ranks=88730rank=79400 of ranks=88730rank=79500 of ranks=88730rank=79600 of ranks=88730rank=79700 of ranks=88730rank=79800 of ranks=88730rank=79900 of ranks=88730rank=80000 of ranks=88730rank=80100 of ranks=88730rank=80200 of ranks=88730rank=80300 of ranks=88730rank=80400 of ranks=88730rank=80500 of ranks=88730rank=80600 of ranks=88730rank=80700 of ranks=88730rank=80800 of ranks=88730rank=80900 of ranks=88730rank=81000 of ranks=88730rank=81100 of ranks=88730rank=81200 of ranks=88730rank=81300 of ranks=88730rank=81400 of ranks=88730rank=81500 of ranks=88730rank=81600 of ranks=88730rank=81700 of ranks=88730rank=81800 of ranks=88730rank=81900 of ranks=88730rank=82000 of ranks=88730rank=82100 of ranks=88730rank=82200 of ranks=88730rank=82300 of ranks=88730rank=82400 of ranks=88730rank=82500 of ranks=88730rank=82600 of ranks=88730rank=82700 of ranks=88730rank=82800 of ranks=88730rank=82900 of ranks=88730rank=83000 of ranks=88730rank=83100 of ranks=88730rank=83200 of ranks=88730rank=83300 of ranks=88730rank=83400 of ranks=88730rank=83500 of ranks=88730rank=83600 of ranks=88730rank=83700 of ranks=88730rank=83800 of ranks=88730rank=83900 of ranks=88730rank=84000 of ranks=88730rank=84100 of ranks=88730rank=84200 of ranks=88730rank=84300 of ranks=88730rank=84400 of ranks=88730rank=84500 of ranks=88730rank=84600 of ranks=88730rank=84700 of ranks=88730rank=84800 of ranks=88730rank=84900 of ranks=88730rank=85000 of ranks=88730rank=85100 of ranks=88730rank=85200 of ranks=88730rank=85300 of ranks=88730rank=85400 of ranks=88730rank=85500 of ranks=88730rank=85600 of ranks=88730rank=85700 of ranks=88730rank=85800 of ranks=88730rank=85900 of ranks=88730rank=86000 of ranks=88730rank=86100 of ranks=88730rank=86200 of ranks=88730rank=86300 of ranks=88730rank=86400 of ranks=88730rank=86500 of ranks=88730rank=86600 of ranks=88730rank=86700 of ranks=88730rank=86800 of ranks=88730rank=86900 of ranks=88730rank=87000 of ranks=88730rank=87100 of ranks=88730rank=87200 of ranks=88730rank=87300 of ranks=88730rank=87400 of ranks=88730rank=87500 of ranks=88730rank=87600 of ranks=88730rank=87700 of ranks=88730rank=87800 of ranks=88730rank=87900 of ranks=88730rank=88000 of ranks=88730rank=88100 of ranks=88730rank=88200 of ranks=88730rank=88300 of ranks=88730rank=88400 of ranks=88730rank=88500 of ranks=88730rank=88600 of ranks=88730rank=88700 of ranks=88730

  Id  Name                  AP(%)     TP     FP     FN     GT   AvgIoU@conf(%)
  --  --------------------  --------- ------ ------ ------ ------ -----------------
   0 motorbike              98.0336    493   1145      5    498           77.0585
   1 car                    98.7864  50028  23110    288  50316           84.1365
   2 truck                  98.6819   1812   2200     13   1825           78.5244
   3 bus                    96.8156    360   1681      6    366           73.0953
   4 pedestrian             96.9481   4161   3740     98   4259           77.5513

for conf_thresh=0.25, precision=0.91, recall=0.97, F1 score=0.94
for conf_thresh=0.25, TP=55372, FP=5150, FN=1892, average IoU=83.34%
IoU threshold=50.00%, used area-under-curve for each unique recall
mean average precision (mAP@0.50)=97.85%
Total detection time: 117 seconds
Set -points flag:
 '-points 101' for MSCOCO
 '-points 11' for PascalVOC 2007 (uncomment 'difficult' in voc.data)
 '-points 0' (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset
Saving weights to /workspace/.cache/splits/combined_8000.weights
Saving weights to /workspace/.cache/splits/combined_last.weights
Saving weights to /workspace/.cache/splits/combined_final.weights

Last accuracy mAP@0.50=97.85%, best=97.90% at iteration #7090.

Training iteration has reached max batch limit of 8000.  If you want
to restart training with these weights, either increase the limit, or
use the "-clear" flag to reset the training images counter to zero.

